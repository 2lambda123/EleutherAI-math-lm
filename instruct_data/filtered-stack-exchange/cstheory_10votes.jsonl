{"input": "The complexity class PPAD (e.g. computing various Nash equilibria) can be defined as the set of total search problems polytime reducible to END OF THE LINE:\nEND OF THE LINE: Given circuits S and P with n input bits and n output bits such that P(0n) = 0n != S(0n), find an input x in {0,1}n such that P(S(x)) != x or S(P(x)) != x != 0n.\nCircuits or algorithms such as S and P implicitly define an exponentially large graph that is only revealed on a query-by-query basis (to keep the problem in PSPACE!), e.g. Papadimitrou's paper.\nHowever, I don't understand how one would design a circuit that enables arbitrary graphs (if there is a systematic structure to the graph, it appears much easier to find the circuit). For instance, how would one design a polynomially-sized circuit that represents an exponentially-long directed line, with an all-0 label for the source vertex and randomly assigned binary labels to all other vertices? This seems to be implicit in the PPAD-related papers.\nThe closest I've come from a search online is Galperin/Widgerson's paper, but the circuit described there takes two vertex labels and returns a Boolean answer to \"Are these vertices adjacent?\"\nSo, how would you design a polynomially-sized circuit of an exponentially-sized graph that takes an n-bit input and outputs the n-bit label of its predecessor or successor, respectively? Or even, does someone know of a resource that explains this well?", "output": "Your question seems to be asking: how does one represent arbitrary graphs (or even arbitrary path graphs) as a circuit of polynomial size? The answer is, you don't. The number of different path graphs with 2n vertices is (2n)!, far more than the number of different circuits with nc gates (exponential in nc log n). So almost all graphs with this many vertices cannot be represented by a succinct circuit.\nTherefore, as you hint, in some sense only graphs that have a high degree of structure can be represented in this way. That's what makes complexity classes like PPAD interesting: despite the structure that we know the input graphs to the EOL problem must have, we don't seem to know how to take advantage of the structure to solve the problem efficiently.\nIf I'm misunderstanding your question and you're really asking: how does one make a circuit that even meets the input requirements for EOL, for even a very highly structured graph: try the path graph that connects vertex x (considered as a number in binary) to x-1 and x+1, with ends at zero and at 2^n-1. Or if you want something less trivial that seems more difficult to solve EOL for: let E and D be the encryption and decryption functions for a fixed key in your favorite cryptosystem, let the neighbors of x in the graph be E(x) and D(x), and let the ends of the line be 0 and D(0).", "meta": {"post_id": 41, "input_score": 21, "output_score": 22, "post_title": "Succinct circuit representation of graphs"}}
{"input": "Possible Duplicate:\nWhat are the consequences of factoring being NP-complete? \n\nWhat notable reference works have covered this?", "output": "No, its not known to be NP-complete, and it would be very surprising if it were. This is because its decision version is known to be in $\\text{NP} \\cap \\text{co-NP}$. (Decision version: Does $n$ have a prime factor $\\lt k$?)\nIt is in NP, because a factor $p \\lt k$ such that $p \\mid n$ serves as a witness of a yes instance.\nIt is in co-NP because a prime factorization of $n$ with no factors $\\lt k$ serves as a witness of a no instance. Prime factorizations are unique, and can be verified in polynomial time because testing for primality is in P.", "meta": {"post_id": 159, "input_score": 14, "output_score": 36, "post_title": "Is integer factorization an NP-complete problem?"}}
{"input": "Are there any references covering this?", "output": "As well as implying NP=co-NP, it would also imply that BQP contained NP.\nIt would also seem to imply that hard instances of NP-complete problems were easy to generate.", "meta": {"post_id": 167, "input_score": 31, "output_score": 30, "post_title": "What would be the consequences of factoring being NP-complete?"}}
{"input": "Parity-L is the set of languages recognized by a non-deterministic Turing machine which can only distinguish between an even number or odd number of \"acceptance\" paths (rather than a zero or non-zero number of acceptance paths), and which is further restricted to work in logarithmic space. Solving a linear system of equations over \u21242 is a complete problem for Parity-L, and so Parity-L is contained in P.\nWhat other complexity class relations would be known, if Parity-L and P were equal?", "output": "parity-$L$ is in $NC^2$ and parity-$L=P$ would mean that $P$ can be simulated in parallel $\\log^2$ time or in $\\log^2$ space (since $NC^2$ is in $DSPACE(log^2 n)$)", "meta": {"post_id": 175, "input_score": 29, "output_score": 29, "post_title": "What are the consequences of Parity-L = P?"}}
{"input": "I'm trying to wrap my head around what the real differences between the Actor Model of concurrency and Communicating Sequential Processes (CSP) model of concurrency.  \nSo far the best that I have been able to come up with is that the Actor Model allows the number and layout of nodes to change while CSP has a fixed structure of nodes.", "output": "I believe one core difference is that in CSP, processes synchronize when messages are received (i.e. a message cannot be sent from one process unless another process is in a receiving mode), while the Actor model is inherently asynchronous (i.e. messages are immediately sent to other processes' address, irrespective of whether they're actively waiting on a message or not).\nThere should be another answer that is more well-developed, however.", "meta": {"post_id": 184, "input_score": 32, "output_score": 22, "post_title": "What's the difference between the Actor Model of Concurrency and Communicating Sequential Processes"}}
{"input": "A problem P is said to be in APX if there exists some constant c > 0 such that a polynomial-time approximation algorithm exists for P with approximation factor 1 + c.\nAPX contains PTAS (seen by simply picking any constant c > 0) and P.\nIs APX in NP? In particular, does the existence of a polynomial-time approximation algorithm for some approximation factor imply that the problem is in NP?", "output": "APX is defined as a subset of NPO, so yes, if an optimization problem is in APX then the corresponding decision problem is in NP.\nHowever, if what you're asking is whether an arbitrary problem must be in NP (or NPO) if there is a poly time O(1)-approximation, then the answer is no.  I don't know of any natural problems that serve as a counter-example, but one could define an artificial maximization problem where the objective is the sum of two terms, a large term that is easily optimized in P, and a much smaller term that adds a small amount if part of the solution encodes an answer to some hard problem (outside of NP).  Then you could find, say, a 2-approximation in poly time by concentrating on the easy term, but finding an optimal solution would require solving the hard problem.", "meta": {"post_id": 284, "input_score": 16, "output_score": 22, "post_title": "Is APX contained in NP?"}}
{"input": "Are there any benefits to calculating the time complexity of an algorithm using lambda calculus?  Or is there another system designed for this purpose?\nAny references would be appreciated.", "output": "A recent developpement on this topic: U. dal Lago and B. Accatoli proved that the length of the leftmost-outermost reduction (LOr) of a $\\lambda$-term is an invariant (time) cost model for $\\lambda$-calculus.\nThey show that Turing machines (with cost=time) and $\\lambda$-terms (with cost=length of the LOr) can simulate each other with a polynomial overhead in time. So for instance the definition of the class P does not depend on which of the two computation model you use to define it.\nhttp://arxiv.org/abs/1405.3311", "meta": {"post_id": 376, "input_score": 44, "output_score": 23, "post_title": "Using lambda calculus to derive time complexity?"}}
{"input": "Scott Aaronson proposed an interesting challange: can we use supercomputers today to help solve CS problems in the same way that physicists use large particle colliders?\n\nMore concretely, my proposal is to\n  devote some of the world\u2019s computing\n  power to an all-out attempt to answer\n  questions like the following: does\n  computing the permanent of a 4-by-4\n  matrix require more arithmetic\n  operations than computing its\n  determinant?\n\nHe concludes that this would require ~$10^{123}$ floating point operations, which is beyond our current means.  The slides are available and are also worth reading.  \nIs there any precedence for solving open TCS problems through brute force experimentation?", "output": "In \"Finding Efficient Circuits Using SAT-solvers\", Kojevnikov, Kulikov, and Yaroslavtsev have used SAT solvers to find better circuits for computing $MOD_k$ function. \nI have used computers to find proofs of time-space lower bounds, as described here. But that was only feasible because I was working with an extremely restrictive proof system.\nMaverick Woo and I have been working for some time to find the \"right\" domain for proving circuit upper/lower bounds using computers. We had hoped that we may resolve $CC^0$ vs $ACC^0$ (or a very weak version of it) using SAT solvers, but this is looking more and more unlikely. (I hope Maverick doesn't mind me saying this...)\nThe first generic problem with using brute-force search to prove nontrivial lower bounds is that it just takes too damn long, even on a very fast computer. The alternative is to try to use SAT solvers, QBF solvers, or other sophisticated optimization tools, but they do not seem to be enough to offset the enormity of the search space. Circuit synthesis problems are among the hardest practical instances one can come by.\nThe second generic problem is that the \"proof\" of the resulting lower bound (obtained by running brute-force search and finding nothing) would be insanely long and apparently yield no insight (other than the fact that the lower bound holds). So a big challenge to \"experimental complexity theory\" is to find interesting lower bound questions for which the eventual \"proof\" of the lower bound is short enough to be verifiable, and interesting enough to lead to further insights.", "meta": {"post_id": 524, "input_score": 25, "output_score": 24, "post_title": "Is \"Experimental Complexity Theory\" being used to solve open problems?"}}
{"input": "As far as I understand, the geometric complexity theory program attempts to separate $VP \\neq VNP$ by proving that the permament of a complex-valued matrix is much harder to compute than the determinant.\nThe question I had after skimming through the GCT Papers: Would this immediately imply $P \\neq NP$, or is it merely a major step towards this goal?", "output": "Assuming the generalized Riemann hypothesis (GRH), the following quite strong connections are known between $ VP= VNP $ and the collapse of the polynomial hierarchy ($ {\\rm PH}$):\n\n\nIf $ VP= VNP\\,$ (over any field) then the polynomial hierarchy collapses to the second level;\nIf $ VP=VNP\\,$ over a field of characteristic $ 0 $, then $ \\rm{NC}^3/{\\rm poly}={\\rm P}/{\\rm poly} = {\\rm PH}/{\\rm poly} $;\nIf $ VP=VNP\\,$ over a field of finite characteristic $ p $, then $ \\rm{NC}^2/{\\rm poly}={\\rm P}/{\\rm poly} = {\\rm PH}/{\\rm poly} $. \n\n\nThese are results from: Peter Burgisser, \"Cook\u2019s versus Valiant\u2019s hypothesis\",  Theor. Comp. Sci., 235:71\u201388,\n2000.\nSee also: Burgisser, \"Completeness and Reduction in Algebraic Complexity Theory\", 1998.", "meta": {"post_id": 529, "input_score": 38, "output_score": 25, "post_title": "Does $VP \\neq VNP$ imply $P \\neq NP$?"}}
{"input": "Let class A denote all the graphs of size $n$ which have a Hamiltonian cycle. It is easy to produce a random graph from this class--take $n$ isolated nodes, add a random Hamiltonian cycle and then add edges randomly.\nLet class B denote all the graphs of size $n$ which do not have a Hamiltonian cycle. How can we pick a random graph from this class? (or do something close to that)", "output": "This is impossible (unless NP=coNP) since in particular that implies a poly-time function whose range is the non-Hamiltonian graphs (the function goes from the random string to the output graph), which in turn will imply an NP-proof of non-Hamiltonianicity (to prove G doesn't have an Hamiltonian circuit, show x that maps to it.)", "meta": {"post_id": 562, "input_score": 28, "output_score": 34, "post_title": "How to produce a random graph that does not have a Hamiltonian cycle?"}}
{"input": "If $f$ is a convex function then Jensen's inequality states that $f(\\textbf{E}[x]) \\le \\textbf{E}[f(x)]$, and mutatis mutandis when $f$ is concave.  Clearly in the worst case you cannot upper bound $\\textbf{E}[f(x)]$ in terms of $f(\\textbf{E}[x])$ for a convex $f$, but is there a bound that goes in this direction if $f$ is convex but \"not too convex\"?  Is there some standard bound that  gives conditions on a convex function $f$ (and possibly the distribution as well, if necessary) that would allow you to conclude that $\\textbf{E}[f(x)] \\le \\varphi(f)f(\\textbf{E}[x])$, where $\\varphi(f)$ is some function of the curvature/degree of convexity of $f$?  Something akin to a Lipschitz condition, perhaps?", "output": "EDIT: original version missed an absolute value.  sorry!!\nHi Ian.  I will briefly outline two sample inequalities, one using a Lipschitz bound, the other using a bound on the second derivative, and then discuss some difficulties in this problem.  Although I'm being redundant, since an approach using one derivative explains what happens with more derivatives (via Taylor), it turns out that the second derivative version is quite nice.\nFirst, with a Lipschitz bound: simply re-work the standard Jensen inequality.  The same trick applies: compute the Taylor expansion at the expected value.\nSpecifically, Let $X$ have corresponding measure $\\mu$, and set $m := \\textrm E(x)$.\nIf $f$ has Lipschitz constant $L$, then by Taylor's theorem\n$$\nf(x) = f(m) + f'(z)(x-m) \\leq f(m) + L|x-m|,\n$$\nwhere $z \\in [m, x]$ (note that $x\\leq m$ and $x> m$ are possible). Using this and re-working the Jensen proof (I am paranoid and checked that the standard one is indeed on wikipedia),\n\\begin{align}\n\\operatorname{E}(f(X)) & = \n\\int f(x) \\, d\\mu(x) \n\\leq f(m) \\int d\\mu(x) + L\\int |x-m| \\, d\\mu(x) \\\\[6pt]\n& = f(\\operatorname{E}(X)) + L \\operatorname{E} (|X-\\operatorname{E}(X)|).\n\\end{align}\nNow, suppose $|f''(x)| \\leq \\lambda$.  In this case,\n\\begin{align}\nf(x) & = f(m) + f'(m)(x-m) + f''(z) \\frac{(x-m)^2} 2 \\\\[6pt]\n& \\leq f(m) + f'(m)(x-m) + \\lambda \\frac{(x-m)^2} 2,\n\\end{align}\nand so\n\\begin{align}\n\\operatorname{E}(f(X))\n& \\leq f(m) + f'(m)(\\operatorname{E}(X) - m) + \\frac {\\lambda \\operatorname{E}((X-m)^2)}{2} \\\\[6pt]\n& = f(\\operatorname{E}(X)) + \\frac {\\lambda \\operatorname{Var}(X)}2.\n\\end{align}\nI'd like to briefly mention a few things.  Sorry if they are obvious.\nOne is that, you can't merely say \"wlog $\\operatorname{E}(X) = 0$\" by shifting the distribution, because you are changing the relationship between $f$ and $\\mu$.\nNext is that the bound must depend on the distribution in some way.  To see this, imagine that $X \\sim \\textrm{Gaussian}(0, \\sigma^2)$ and $f(x) = x^2$.  Whatever the value of $\\sigma$, you still get $f(\\operatorname{E}(X)) = f(0) = 0$.  On the other hand, $\\operatorname{E}(f(X)) = \\operatorname{E}(X^2) = \\sigma^2$.  Thus, by changing $\\sigma$, you can make the gap between the two quantities arbitrary!  Intuitively, more mass is pushed away from the mean, and thus, for any strictly convex function, $\\operatorname{E} (f(X))$ will increase.\nLastly, I don't see how to get a multiplicative bound like you suggest.  Everything I have used in this post is standard: Taylor's theorem and derivative bounds are bread&butter in statistics bounds, and they automatically give additive, not multiplicative errors.\nI will think about it though, and post something.  Vague intuition is it will need very strenous conditions on both the function and the distribution, and that the additive bound is actually at the heart of it.", "meta": {"post_id": 682, "input_score": 22, "output_score": 21, "post_title": "Bounds on $E[f(x)]$ in terms of $f(E[x])$ other than Jensen's inequality?"}}
{"input": "I'm undergraduate computer science student and I'm currently planning for my graduation project. I need some ideas in quantum computing field. any help?", "output": "I posted some quantum complexity theory project ideas at http://scottaaronson.com/blog/?p=471\n(But beware, most of these are problems that have been open for years!  My suggestion for an undergraduate project would be to break off a chunk of one of the problems.)", "meta": {"post_id": 710, "input_score": 16, "output_score": 29, "post_title": "Quantum computing project ideas"}}
{"input": "This question is related to an answer I posted in response to another question.\nThe 3-partition problem is the following problem:\nInstance: Positive integers a1, \u2026, an, where n=3m and the sum of the n integers is equal to mB, such that each ai satisfies B/4 < ai < B/2.\nQuestion: Can the integers a1, \u2026, an be partitioned into m multisets so that the sum of each multiset is equal to B?\nIt is well-known that the 3-partition problem is NP-complete in the strong sense that it remains NP-complete even if the numbers in the input are given in unary.  See Garey and Johnson for a proof.\nQuestions: Does the 3-partition problem remain NP-complete if the numbers a1, \u2026, an are all distinct?  Does it remain NP-complete in the strong sense?\n(My feeling is that the answers to both questions are probably yes because I do not see any reason why the problem should become easier if all numbers are distinct.)\nIt does not seem that the proof in Garey and Johnson establishes the NP-completeness of this restricted version.\nIn the answer to the other question linked above, I gave a proof that the 6-partition problem (defined analogously) with distinct numbers is NP-complete in the strong sense.", "output": "It is proved in [1, Corollary 7], that 3-partition is strongly NP-hard when the integers $a_1, \\ldots, a_n$ are all distinct. The bounds $B/4 < a_i < B/2$ are not imposed in [1], but this should not make a difference.\n[1]: Heather Hulett, Todd G. Will, Gerhard J. Woeginger: Multigraph realizations of degree sequences: Maximization is easy, minimization is hard. Oper. Res. Lett. 36(5): 594-596 (2008). DOI", "meta": {"post_id": 716, "input_score": 25, "output_score": 21, "post_title": "Computational complexity of the 3-partition problem with distinct numbers"}}
{"input": "Leaf languages are a beautiful way to uniformly define many complexity classes. Most complexity classes are usually specified by a model of computation (e.g., deterministic/randomized TM), and a resource bound (log time, poly space, etc.). However in the leaf language formulation, there is only one model of computation, and the class is specified by giving its leaf language.\nThe details are too long to explain, so I'll direct interested readers to either of these two surveys: \n\nUniform characterizations of complexity classes by H Vollmer\nLeaf Language Classes by KW Wagner\n\nBoth surveys do a great job of explaining the formulation within the first few pages.\nIn Wagner's survey, he says \"it turns out that practically every complexity class considered so far can be described by leaf languages.\"\nMy question relates to this statement. I know there are some classes for which we do not know a leaf language characterization, so this means either the classes don't necessarily have such a characterization, or we haven't found it.  \nDo we expect every complexity class (say between P and PSPACE) to have a leaf language characterization? (Let's restrict ourselves to \"natural\" complexity classes.) Is there any result of this sort in the literature? \n(A related question that I'd be happy to know the answer to: Is there a (heuristic) method to come up with a leaf language for a given class?)\n\nEDIT: Suresh points out that there is a short definition of leaf languages in the Wikipedia article. I'm copying it below.\nSeveral complexity classes are typically defined in terms of a polynomial-time nondeterministic Turing machine, where each branch can either accept or reject, and the entire machine accepts or rejects as some function of the branches' conditions. For example, a non-deterministic Turing machine accepts if at least one branch accepts, and rejects only if all branches reject. A co-non-deterministic Turing machine, on the other hand, accepts only if all branches accept, and rejects if any branch rejects. Many classes can be defined in this fashion.", "output": "Have a look at\n\nBernd Borchert, Riccardo Silvestri: A Characterization of the Leaf Language Classes. Inf. Process. Lett. 63(3): 153-158 (1997) (doi link here)\n\nThe authors characterize the leaf language classes as those which are (a) \"countable\", (b) are \"downward\" closed wrt polytime many-one reducibility, and (c) \"join-closed\" (i.e., disjoint union) wrt polytime many-one reducibility. \nMore formally, all the languages $L$ in a leaf language class have a bijection with the natural numbers, and the property that for every $C,D \\in L$, if $E \\leq^P_m C \\sqcup D$ then $E \\in L$ as well (the $\\sqcup$ denotes disjoint union). Also, every \"non-leaf language class\" contains a language which fails to have one of these properties.\nFrom these three conditions we can get many examples of classes which aren't leaf language classes. For example, the \"countable\" condition rules out advice classes like $P/poly$, and the \"downward closed wrt polytime many-one reducibility\" rules out fixed resource-bound classes like $SPACE[n]$. (Recall that the usual proof that $SPACE[n] \\neq P$ uses the fact that $SPACE[n]$ is not closed under such reductions.)", "meta": {"post_id": 761, "input_score": 23, "output_score": 24, "post_title": "Do all complexity classes have a leaf language characterization?"}}
{"input": "Ladner's Theorem states that if P \u2260 NP, then there is an infinite hierarchy of complexity classes strictly containing P and strictly contained in NP.  The proof uses the completeness of SAT under many-one reductions in NP.  The hierarchy contains complexity classes constructed by a kind of diagonalization, each containing some language to which the languages in the lower classes are not many-one reducible.\nThis motivates my question:\n\nLet C be a complexity class, and let D be a complexity class that strictly contains C.  If D contains languages that are complete for some notion of reduction, does there exist an infinite hierarchy of complexity classes between C and D, with respect to the reduction?\n\nMore specifically, I would like to know if there are results known for D = P and C = LOGCFL or C = NC, for an appropriate notion of reduction.\n\nLadner's paper already includes Theorem 7 for space-bounded classes C, as Kaveh pointed out in an answer.  In its strongest form this says: if NL \u2260 NP then there is an infinite sequence of languages between NL and NP, of strictly increasing hardness.  This is slightly more general than the usual version (Theorem 1), which is conditional on P \u2260 NP.  However, Ladner's paper only considers D = NP.", "output": "The answer to your question is \"yes\" for a wide variety of classes and reductions, including logspace reductions and the classes you mentioned, as is proved in these papers:\n\nH. Vollmer.  The gap-language technique revisited.  Computer Science Logic, Lecture Notes in Computer Science Vol. 533, pages 389-399, 1990.\nK. Regan and H. Vollmer.  Gap-languages and log-time complexity classes.  Theoretical Computer Science, 188(1-2):101-116, 1997.\n\n(You can download gzipped postscript files of these papers here.)\nThe proofs follow the basic principle of Uwe Sch\u00f6ning's extension of Ladner's theorem:\n\nUwe Sch\u00f6ning.  A uniform approach to obtain diagonal sets in complexity classes.  Theoretical Computer Science 18(1):95-103, 1982.\n\nSch\u00f6ning's proof has always been my favorite proof of Ladner's theorem -- it's both simple and general.", "meta": {"post_id": 799, "input_score": 48, "output_score": 36, "post_title": "Generalized Ladner's Theorem"}}
{"input": "This question most likely has a simple answer; however, I do not see it.\nLet $g:\\mathbb{N} \\rightarrow \\mathbb{N}$ be an uncomputable function and $c$ a positive real number. Can there be a computable function $f : \\mathbb{N} \\rightarrow \\mathbb{N}$ such that, for all $n$ large enough: $g(n) \\leq f(n) \\leq c \\cdot g(n)$ (that is $f(n) = \\Theta(g(n)$)?", "output": "Sure: just take g(n) = n + halt(n) (where halt(n)=1 if TM number n halts, and 0 ow).", "meta": {"post_id": 914, "input_score": 6, "output_score": 24, "post_title": "Computable function $f = \\Theta(g)$ with $g$ uncomputable"}}
{"input": "In 1995, Russell Impagliazzo proposed five complexity worlds:\n1- Algorithmica: $P=NP$ with all the amazing consequences.\n2- Heuristica: $NP$-complete problems are hard in the worst-case ($P \\ne NP$) but are efficiently solvable in the average-case.\n3- Pessiland: There exist average-case $NP$-complete problems but one-way functions do not exist. This implies that we can not generate hard instances of $NP$-complete problem with known solution.  \n4- Minicrypt: One-way functions exist but public-key cryptographic systems are impossible\n5- Cryptomania: Public-key cryptographic systems exist and secure communication is possible.\n\nWhich world is favored by the recent advances in computational complexity? What is the best evidence for the choice?\n\nRussell Impagliazzo, A Personal View of Average-Case Complexity\n, 1995\nImpagliazzo's Five Worlds,\nThe Computational Complexity\n     blog", "output": "About a year ago I co organized a workshop on complexity and cryptography: status of Impagliazzo's worlds, and the slides and videos on web site may be of interest.\nThe short answer is that not much has changed in the sense that most researchers still believe we live in \"Cryptomania\" and we still have more or less the same evidence for this, and not much progress on collapsing any of the worlds for one another. \nPerhaps the most significant piece of new information is Shor's algorithm that shows that at least if you replace P with BQP, the most commonly used public key cryptosystems are insecure. But, because of Lattice based cryptosystems, the default assumption is that we live in cryptomania even in this case, though perhaps the consensus here is a bit weaker than the classical case. Even in the classical case, there seems to be much more evidence for the existence of one-way functions (\"Minicrypt\") than the existence of public key encryption (\"Cryptomania\"). Still, given the effort people have spent in trying to break various public key cryptosystem, there's significant evidence for the latter as well.", "meta": {"post_id": 1026, "input_score": 36, "output_score": 30, "post_title": "Status of Impagliazzo's Worlds?"}}
{"input": "The problem #SAT is the canonical #P-complete problem. It's a function problem rather than a decision problem. It asks, given a boolean formula $F$ in propositional logic, how many satisfying assignments $F$ has. Which are the best lower bounds on #SAT?", "output": "To my knowledge, no one has figured out how to exploit the \"counting solutions\" property of #SAT in any lower bound on deterministic algorithms, so unfortunately the best known lower bounds for #SAT are basically the same as that for SAT.\nHowever, there has been a little progress. Note that the decision version of #SAT is called \"Majority-SAT\": given a formula, do at least $1/2$ of the possible assignments satisfy it? \"Majority-SAT\" is $PP$-complete, and given an algorithm for Majority-SAT, one can solve #SAT with $O(n)$ calls to the algorithm.\nThe closest that people have gotten to new lower bounds for #SAT (that are not known to hold for SAT) is with lower bounds for \"Majority-of-Majority-SAT\": given a propositional formula over two sets of variables X and Y, for at least $1/2$ of the possible assignments to $X$, is it true that at least $1/2$ of the assignments to $Y$ make the formula satisfiable? This problem is in the \"second level\" of the counting hierarchy (the class $PP^{PP}$). Quantum time-space lower bounds (and more) are known for this class.\nThe survey at http://pages.cs.wisc.edu/~dieter/Papers/sat-lb-survey-fttcs.pdf gives an overview of results in this direction.\nUPDATE: As of 2019, the first paragraph in the above is obsolete. It is known that #SAT requires a time-space product that is basically $n^2$. See for example\n\"Quadratic Time-Space Lower Bounds for Computing Natural Functions with a Random Oracle\" https://drops.dagstuhl.de/opus/volltexte/2018/10149/", "meta": {"post_id": 1046, "input_score": 18, "output_score": 31, "post_title": "Lower bounds on #SAT?"}}
{"input": "What is the exact time complexity of the undirected st-connectivity log-space algorithm by Omer Reingold ?", "output": "It seems that the time complexity of Reingold's algorithm is not treated in either the Reingold's paper or in Arora-Barak textbook. It would also appear that the analysis is rather tedious, as the time complexity depends on the exact expander graph used in the construction and on some constants that are chosen to \"sufficiently large\".\nTo get some rough idea on the time complexity, observe that Reingold's algorithm, given graph $G$, transforms it (implicitly) into an expander graph $G'$ and traverses every walk of length $l = O(\\log n)$. The $O$-notation hides some quite large constants here. The graph $G'$ has constant degree of $d = 2^b$ for some sufficiently large $b$, meaning that there are $d^l = O(n^c)$ such walks for some rather large constant $c$. Skimming some lecture notes on the topic it would seem that $c \\ge 10^9b$.", "meta": {"post_id": 1063, "input_score": 11, "output_score": 23, "post_title": "Time complexity analysis for Reingold's UST-CONN algorithm"}}
{"input": "In his \"Computational Complexity\" book, Papadimitriou writes:\n\nRP is in some sense a new and unusual kind of complexity class. Not any polynomially bounded nondeterministic Turing machine can be the basis of defining a language in RP. For a machine N to define a language in RP, it must have the remarkable property that on all inputs it either rejects unanimously, or it accepts by majority. Most nondeterministic machines behave in other ways for at least some inputs ... There is no easy way to tell whether a machine always halts with a certified output. We informally call such classes semantic classes, as opposed to the syntactic classes such as P and NP, where we can tell immediately by a superficial check whether an appropriately standardized machine indeed defines a language in the class.\n\nSeveral pages later, he points that:\nlanguage L is in the class PP if there is a nondeterministic polynomially bounded Turing machine N such that, for all inputs x, $x \\in L$ iff more than half of the computations of N on input x end up accepting. We say that N decides L by majority. \nQuestion 1: Why Papadimitriou concludes that PP is a syntactic class, while its definition is only slightly different from that of RP?\nQuestion 2: Whether being \"semantic\" for a complexity class is equivalent to NOT having complete problems, or the lack of complete problems is thought of as a property that we GUESS semantic classes possess?\nEdit: See related topic Do all complexity classes have a leaf language characterization?", "output": "RP involves a promise, that either 0 paths accept or more than half accept, no matter what the input is. For PP, there is no such promise. If more than half the paths accept, then $x \\in L$, otherwise, $x \\notin L$. (PP can be defined so that the acceptance criteria are $\\geq 1/2$ and $< 1/2$ respectively.)\nOr in other words, if I give you a probabilistic TM claiming it is a PP machine deciding some language, you can be sure that it decides some language. Clearly, the language it decides is this one: Try input $x$. See if more than 1/2 of the paths accept (or more than 1/2 random strings cause it to accept). If so, $x \\in L$. If not, $x \\notin L$. So we've defined a language using this TM.\nOn the other hand, if I give you a probabilistic TM claiming it is a RP machine deciding some language, you can't even be sure that it decides any language. The problem is that when you observe only a few paths accepting, you don't know if $x$ is in $L$ or not. So if I give you a RP machine, you just have to take my word for it. Indeed, checking if this machine defines a language is uncomputable.\nAs for your second question, for syntactic classes usually there's an obvious complete problem, which is like \"Given machine M, decide if it accepts in time T on input x.\" If you're given a nondeterministic machine, this problem is NP-complete, if it's a PP-machine, then it's PP-complete, etc. The obvious complete problem for semantic classes is undecidable, as I mentioned. So we don't get a complete problem for free for semantic classes. But a semantic class can have a complete problem. For example if P = BPP (as is widely believed), then BPP has a syntactic characterization.\nEDIT: Since there's some discussion on how to define semantic and syntactic classes, I'd like to point out that Papadimitriou gives a definition in his book when talking about leaf languages. (See my question about leaf languages for some references.)\nHe says that syntactic classes are those for which there exists some language that defines the class using the leaf language technique. Semantic classes are those for which all such characterizations require promise problems. This is a rigorous definition, but only works for those languages that have leaf language characterizations.", "meta": {"post_id": 1233, "input_score": 41, "output_score": 34, "post_title": "Semantic vs. Syntactic Complexity Classes"}}
{"input": "I am seeking a definitive answer to whether or not generation of \"truly random\" numbers\nis Turing computable.  I don't know how to phrase this precisely.\nThis StackExchange question on \"efficient algorithms for random number generation\"\ncomes close to answering my question.\nCharles Stewart says in his answer, \"it [Martin-L\u00f6f randomness] cannot be generated by a machine.\" Ross Snider says, \"any deterministic process (such as Turing/Register Machines) can not produce 'philosophical' or 'true' random numbers.\" Is there a clear and accepted notion of what constitutes a truly random number generator?\nAnd if so, is it known that it cannot be computed by a Turing Machine?\nPerhaps pointing me to the relevant literature would suffice.  Thanks for any help you can provide!\nEdit. Thanks to Ian and Aaron for the knowledgeable answers!  I am relatively unschooled in this area, and I am grateful for the assistance. If I may extend the question a bit in this addendum: Is it the case that a TM with access to a pure source of randomness (an oracle?), can compute a function that a classical TM cannot?", "output": "I am joining the discussion fairly late, but I will try to address several questions that were asked earlier.\nFirst, as observed by Aaron Sterling, it is important to first decide what we mean by \"truly random\" numbers, and especially if we are looking at things from a computational complexity or computability perspective.\nLet me argue however that in complexity theory, people are mainly interested in pseudo-randomness, and pseudo-random generators, i.e. functions from strings to strings such that the distribution of the output sequences cannot be told apart from the uniform distribution by some efficient process (where several meanings of efficient can be considered, e.g. polytime computable, polynomial-size circuits etc). It is a beautiful and very active research area, but I think most people would agree that the objects it studies are not truly random, it is enough that they just look random (hence the term \"pseudo\"). \nIn computability theory, a concensus has emerged to what should be a good notion of \"true randomness\", and it is indeed the notion of Martin-L\u00f6f randomness which prevailed (other ones have been proposed and are interesting to study but do not bare all the nice properties Martin-L\u00f6f randomness has). To simplify matters, we will consider randomness for infinite binary sequences (other objects such as functions from strings to strings can easily be encoded by such sequence). \nAn infinite binary sequence $\\alpha$ is Martin-L\u00f6f random if no computable process  (even if we allow this process to be computable in triple exponential time or higher) can detect a randomness flaw. \n(1) What do we mean by \"randomness flaw\"? That part is easy: it is a set of measure 0, i.e. a property that almost all sequences do not have (here we talk about Lebesgue measure i.e. the measure where each bit has a $1/2$ probability to be $0$ independently of all the other bits). An example of such a flaw is \"having asymptotically 1/3 of zeroes and 2/3 of ones\", which violates the law of large numbers. Another example is \"for every n, the first 2n bits of $\\alpha$ are perfectly distributed (as many zeroes as ones)\". In this case the law of large numbers is satified, but not the central limit theorem. Etc etc.\n(2) How can a computable process test that a sequence does not belong to a particular set of measure 0? In other words, what sets of measure 0 can be computably described? This is precisely what Martin-L\u00f6f tests are about. A Martin-L\u00f6f test is a computable procedure which, given an input k, computably (i.e., via a Turing machine with input $k$) generates a sequence of strings $w_{k,0}$, $w_{k,1}$, ... such that the set $U_k$ of infinite sequences starting by one of those $w_{k,i}$ has measure at most $2^{-k}$ (if you like topology, notice that this is an open set in the product topology for the set of infinite binary sequences). Then the set $G=\\bigcap_k U_k$ has measure $0$ and is referred to as Martin-L\u00f6f nullset. We can now define Martin-L\u00f6f randomness by saying that an infinite binary sequence $\\alpha$ is Martin-L\u00f6f random if it does not belong to any Martin-L\u00f6f nullset.  \nThis definition might seem technical but it is widely accepted as being the right one for several reasons:\n\nit is effective enough, i.e. its definition involves computable processes\nit is strong enough: any \"almost sure\" property you may find in a probability theory textbook (law of large numbers, law of iterated logarithm, etc) can be tested by a Martin-L\u00f6f test (although this is sometimes hard to prove)\nit has been independently proposed by several people using different definitions (in particular the Levin-Chaitin definition using Kolmogorov complexity); and the fact that they all lead to the same concept is a hint that it should be the right notion (a little bit like the notion of computable function, which can be defined via Turing machines, recursive functions, lambda-calculus, etc.) \nthe mathematical theory behind it is very nice! see the three excellent books An Introduction to Kolmogorov Complexity and Its Applications (Li and Vitanyi), Algorithmic randomness and complexity (Downey and Hirschfeldt) Computability and Randomness (Nies).\n\nWhat does a Martin-L\u00f6f random sequence look like? Well, take a perfectly balanced coin and start flipping it. At each flip, write a 0 for heads and a 1 for tails. Continue until the end of time. That's what a Martin-L\u00f6f sequence looks like :-) \nNow back to the initial question: is there a computable way to generate a Martin-L\u00f6f random sequence? Intuitively the answer should be NO, because if we can use a computable process to generate a sequence $\\alpha$, then we can certainly use a computable process to describe the singleton {$\\alpha$}, so $\\alpha$ is not random. Formally this is done as follows. Suppose a sequence $\\alpha$ is computable. Consider the following Martin-L\u00f6f test: for all $k$, just output the prefix $a_k$ of $\\alpha$ of length $k$, and nothing else. This has measure at most (in fact, exactly) $2^{-k}$, and the intersection of the sets $U_k$ as in the definition is exactly {${\\alpha}$}. QED!!\nIn fact a Martin-L\u00f6f random sequence $\\alpha$ is incomputable in a much stronger sense: if some oracle computation with oracle $\\beta$ (which itself is an infinite binary sequence) can compute $\\alpha$, then for all $n$, $n-O(1)$ bits of $\\beta$ are needed to compute the first $n$ bits of $\\alpha$ (this is in fact a characterization of Martin-L\u00f6f randomness, which unfortunately is rarely stated as is in the literature). \n\nOk, now the \"edit\" part of Joseph's question: Is it the case that a TM with access to a pure source of randomness (an oracle?), can compute a function that a classical TM cannot?\nFrom a computability perspective, the answer is \"yes and no\". If you are given access to a random source as an oracle (where the output is presented as an infinite binary sequence), with probability 1 you will get a Martin-L\u00f6f random oracle, and as we saw earlier Martin-L\u00f6f random implies non-computable, so it suffices to output the oracle itself! Or if you want a function $f: \\mathbb{N} \\rightarrow \\mathbb{N}$, you can consider the function $f$ which for all $n$ tells you how many zeroes there are among the first $n$ bits of your oracle. If the oracle is Martin-L\u00f6f random, this function will be non-computable. \nBut of course you might argue that this is cheating: indeed, for a different oracle we might get a different function, so there is a non-reproducibility problem. Hence another way to understand your question is the following: is there a function $f$ which is non-computable, but which can be \"computed with positive probability\", in the sense that there is an Turing machine with access to a random oracle which, with positive probability (over the oracle), computes $f$. The answer is no, due to a theorem of Sacks whose proof is quite simple. Actually it has mainly been answered by Robin Kothari: if the probability for the TM to be correct is greater than 1/2, then one can look for all $n$ at all the possible oracle computations with input $n$ and find the output which gets the \"majority vote\", i.e. which is produced by a set of oracles of measure more than 1/2 (this can be done effectively). The argument even extend to smaller probabilities: suppose the TM outputs $f$ with probability $\\epsilon >0$. By Lebesgue's density theorem, there exists a finite string $\\sigma$ such that if we fix the first bits of the oracle to be exactly $\\sigma$, and then get the other bits at random, then we compute $f$ with probability at least 0.99. By taking such a $\\sigma$, we can apply the above argument again.", "meta": {"post_id": 1263, "input_score": 44, "output_score": 63, "post_title": "Truly random number generator: Turing computable?"}}
{"input": "Is BQP equal to BPP with access to an Abelian hidden subgroup oracle?", "output": "Like many complexity-class separations, our best guess is that the answer is that BPP^{HSP} != BQP, but we can only prove this rigorously relative to oracles.  This separation was observed by Scott Aaronson in this blog post\nwhere he observed that the welded-tree speedup of Childs, Cleve, Deotto, Farhi, Gutmann and Spielman was not contained in SZK.\nOn the other hand, BPP^{HSP} is contained in SZK, at least if the goal is to determine the size of the hidden subgroup.  This includes even the abelian HSP, although I'm not sure how exactly to find the generators of an arbitrary hidden subgroup in SZK.  The reason we can decide the size of the hidden subgroup is that if f:G->S has hidden subgroup H, and we choose g uniformly at random from G, then f(g) is uniformly random over a set of size |G|/|H|. In particular, f(g) has entropy log|G| - log|H|.  And entropy estimation is in SZK.", "meta": {"post_id": 1298, "input_score": 23, "output_score": 26, "post_title": "Is BQP equal to BPP with access to an Abelian hidden subgroup oracle?"}}
{"input": "Coppersmith\u2013Winograd algorithm is the asymptotically fastest known algorithm for multiplying two $n \\times n$ square matrices. The running time of their algorithm is $O(n^{2.376})$  which is the best known so far. What is the space complexity of this algorithm ? Is it in $\\Theta(n^2)$ ?", "output": "Yes, all algorithms which stem from Strassen's original algorithm (this includes most known $n^{3-\\varepsilon}$ algorithms for matrix multiplication, but not all -- see the comments) have space complexity $\\Theta(n^2)$. If you could find a $n^{3-\\varepsilon}$ time algorithm with $poly(\\log n)$ space complexity, this would be a great advance. One application would be a $2^{(1-\\varepsilon)n}$ time, $poly(n)$ space algorithm for the Subset-Sum problem. \nHowever there are some obstacles to such a result. For some computational models, there are fairly strong lower bounds for the time-space product of matrix multiplication. References like Yesha and Abrahamson will give you more information.", "meta": {"post_id": 1313, "input_score": 24, "output_score": 31, "post_title": "Space complexity of Coppersmith\u2013Winograd algorithm"}}
{"input": "I believe the answer to this question is well-known; but, unfortunately, I don't know.\nIn quantum computing, we know that mixed states are represented by density matrices. And the trace norm of the difference of two density matrices characterizes the distinguishability of the two corresponding mixed states. Here, the definition of trace norm is the sum of all eigenvalues of the density matrix, with an extra multiplicative factor 1/2 (in accordance with statistical difference of two distributions). It is well-known that, when the the difference of two density matrices is one, then the corresponding two mixed states are totally distinguishable, while when the difference is zero, the two mixed states are totally indistinguishable.\nMy question is, does the trace norm of the difference of two density matrices being one imply these two density matrices can be simultaneously diagonalizable? If this is the case, then taking the optimal measurement to distinguish these two mixed states will behave like to distinguish two distributions over the same domain with disjoint support.", "output": "Here is one way to prove the fact you are interested in.\nSuppose $\\rho_0$ and $\\rho_1$ are density matrices.  Like every other Hermitian matrix, it is possible to express the difference $\\rho_0-\\rho_1$ as\n$$\\rho_0-\\rho_1 = P_0-P_1$$ for $P_0$ and $P_1$ being positive semidefinite and having orthogonal images.  (Sometimes this is called a Jordan-Hahn decomposition; it is unique and easily obtained from a spectral decomposition of $\\rho_0-\\rho_1$.) Note that the fact that $P_0$ and $P_1$ have orthogonal images implies that they are simultaneously diagonalizable, which I interpret is the property you are interested in.\nThe trace norm of the difference $\\rho_0-\\rho_1$ (as you define it, with the multiplicative factor 1/2), is given by $$\\|\\rho_0-\\rho_1\\|_{\\text{tr}} = \\frac{1}{2}\\operatorname{Tr}(P_0) + \\frac{1}{2}\\operatorname{Tr}(P_1).$$  Under the assumption that this quantity is 1, we will conclude that $P_0=\\rho_0$ and $P_1=\\rho_1$, which proves what you want to prove.\nTo draw this conclusion, note first that $\\operatorname{Tr}(P_0)-\\operatorname{Tr}(P_1)=0$ and $\\operatorname{Tr}(P_0)+\\operatorname{Tr}(P_1)=2$, so $\\operatorname{Tr}(P_0)=\\operatorname{Tr}(P_1)=1$.  Next, take $\\Pi_0$ and $\\Pi_1$ to be the orthogonal projections onto the images of $P_0$ and $P_1$, respectively.  We have $$\\Pi_0 (\\rho_0 - \\rho_1) = \\Pi_0 (P_0 - P_1) = P_0$$ so $$\\operatorname{Tr}(\\Pi_0 \\rho_0) - \\operatorname{Tr}(\\Pi_0 \\rho_1) = 1.$$ Both $\\operatorname{Tr}(\\Pi_0 \\rho_0)$ and $\\operatorname{Tr}(\\Pi_0 \\rho_1)$ must be contained in the interval [0,1], from which we conclude that $\\operatorname{Tr}(\\Pi_0\\rho_0)=1$ and $\\operatorname{Tr}(\\Pi_0\\rho_1) = 0$.  From these equations it is not difficult to conclude $\\Pi_0\\rho_0=\\rho_0$ and $\\Pi_0\\rho_1=0$, and therefore $P_0=\\rho_0$ by the equation above.  A similar argument shows $P_1=\\rho_1$.", "meta": {"post_id": 1348, "input_score": 12, "output_score": 23, "post_title": "Does the trace norm of the difference of two density matrices being one imply these two density matrices can be simultaneously diagonalizable?"}}
{"input": "In a couple recent questions (q1 q2), there has been discussion of \"Theory A\" vs \"Theory B\", seemingly to capture the divide between the study of logic and programming languages and the study of algorithms and complexity.\nThis terminology was new to me, and a quick web search didn't come up with any obvious references explaining it.\nDoes anyone know of a reference or references that explain the origin of this terminology, and what, if any, substantive benefit is intended to be derived from making this distinction?", "output": "It comes from the handbook on theoretical computer science, which had two volumes: A was for algorithms and complexity, and B was for logic and semantics. \nJukka, did ICALP predate this ? Or was it in response to this ? \nAs for benefits, I think there's always some utility in taxonomizing areas based on topics of interest, and forms of study. However, as with all taxonomizations, the problem comes when you forget to \"go back up the tree and down the other side\" :). \nEDIT: as ICALP explicitly states, this division comes from the Elsevier journal Theoretical Computer Science, which itself predates the handbook, so I think that's a more accurate source. \nEDIT ++: From the history of the EATCS comes this snippet about TCS, the journal:\n\nSince that time M. Nivat, who is still\n  Editor-in-Chief has reported regularly\n  to council and general assembly and\n  occasionally in the Bulletin - e.g.\n  when the split into sections A\n  (automata, algebra und algorithms) and\n  B (logic, semantics and related\n  topics) was decided upon (Bulletin no.\n  45, p.2,3, October 1991);\n\nwhich yields 1991 as when this first started happening at the journal. However, the Handbook was first published in September 1990 !", "meta": {"post_id": 1521, "input_score": 37, "output_score": 39, "post_title": "Origins and applications of Theory A vs Theory B?"}}
{"input": "In the survey \"Small Depth Quantum Circuits\" by D. Bera, F. Green and S. Homer (p. 36 of ACM SIGACT News, June 2007 vol. 38, no. 2), I read the following sentence:\n\nThe classical version of $QAC^0$ (in which $AND$ and $OR$ gates have at most constant fanout) is provably weaker than $AC^0$.\n\nA reference for this claim is missing. I will call this class $AC^0_{bf}$, where $bf$ stands for \"bounded fanout\". (The Complexity Zoo is down and I can't verify if such class has already a name in the literature).\nIf we assume unbounded fanout for the input bits, then these circuit seem to be equivalent to constant depth formulae up to a polynomial increase in the size, so the above claim doesn't make sense. \nInstead, if we assume bounded fanout for the input bits too, then I cannot think of any language that separates this class from $AC^0$. A possible candidate could be the language $X := \\{x | \\mbox{weight}(x) = 1 \\}$, i.e., the language of the strings with only one 1. It is easy to show $X \\in AC^{0}$, but I didn't manage to prove that $X \\notin AC^{0}_{bf}$. \nThe questions are:\n\nIs $AC^0_{bf}$ actually weaker than $AC^0$? If it is, any idea or any reference on how to prove it? And what is a language that separates those two classes? What about $X$?", "output": "A bound on fan-out of input bits and gates will make the size of the circuit linear. Let $k$ be a bound on the fan-out of the gates and inputs. It is a DAG with max out degree bounded by $k$ and max path of length $d$. The number of available wires in each level can increase $k$ times, and the number of available wires at top is $kn$, so the total number of wires in the circuit is at most $kn \\sum_{i=0}^d k^i \\leq k^{d+1} n$ which is $O(n)$.\nAny $\\mathsf{AC^0}$ function which requires super-linear size will separate the class of functions with bounded fan-out (applied also to input bits) from $\\mathsf{AC^0}$. Here are some examples:\n\n[CR96]: An $\\mathsf{AC^0}$ function that need super-linear size is the $\\frac{1}{4}$-approximate selector. A $\\frac{1}{4}$-approximate selector is any function whose value is:\n\n$0$ whenever the number of $1$s is at most $\\frac{n}{4}$, \n$1$ whenever the number of $0$s is at most $\\frac{n}{4}$, \ncan be either $0$ or $1$ otherwise.\n\n[Ros08] shows that the $k$-clique has $\\mathsf{AC^0}$ functions complexity $n^{\\Theta(k)}$ ($n^2$ input bits are possible edges of a graph with $n$ vertices). This gives a super line size lowerbound for $k\\gt 2$.\nIt is probably possible to generalize the example in 2 can to existence of any nontrivial (requiring more than one bit) fixed induced substructure in a given unordered structure, e.g.: \n\nexistence of a path of length 2 in a given graph,\n$\\#_1(x)=2$,\n\nsince they require super constant number of gates depending on a bit which is not possible in $\\mathsf{AC^0_{bf}}$.\nThe easiest example is a duplicator gate, i.e. a gate that creates $\\omega(1)$ copies of its input bit. This is not possible in $\\mathsf{AC^0_{bf}}$ since only $O(1)$ of gates can depend on each input bit.\n\nAlso any $\\mathsf{AC^0_{bf}}$ circuit of size $S$ can be turned into a formula of size at most $k^dS$ and therefore has a $\\mathsf{AC^0_{bf}}$ formula of size $k^{2d+1}n$ so any function of superlinear $\\mathsf{AC^0}$ formula complexity will not be in $\\mathsf{AC^0_{bf}}$.\n\nReferences: \n[CR96] S. Chaudhuri and J. Radhakrishnan, \"Deterministic Restrictions in Circuit Complexity\", 1996\n[Ros08] Benjamin Rossman, \"On the Constant-Depth Complexity of k-Clique\", 2008\n[Juk] Stasys Jukna, \"Boolean Function Complexity: Advances and Frontiers\", draft", "meta": {"post_id": 1824, "input_score": 26, "output_score": 23, "post_title": "Is $AC^0$ with bounded fanout weaker than $AC^0$?"}}
{"input": "Updated below\nWe all know the critical importance of peer-review.  It is the main form of quality control and feedback on research.  However, to an early-stage researcher (like me), it can sometimes be a confusing system/process.\nAccordingly, there are several treatises on the scientific refereeing process that give guidance.  Two (very different) examples from computer science -- this 1994 article by Parberry and a more recent one by Cormode -- offer great advice (though the latter might be a shade mischievous).\nHere, I'd like to solicit broader advice from the more experienced members of this community about the review process, with particular regard to the peculiarities of theoretical computer science.\n\nWhat are the main criteria for determining the significance of a paper's results?  How do I judge whether a paper should be accepted to the conference/journal? Is it important to verify correctness?\nWhat are the main elements of a referee report, and which parts are most important? Is it always necessary to give a recommendation of (non)acceptance? What goes in the report and what goes solely to the editor?\nHow does assessment for conferences differ from that in journals?  How do reports for conferences differ from those in journals? (How on earth do I rate my \"confidence\" in my recommendation?) Should the journal version be significantly different from the conference paper?\nWhat if I don't understand the paper? ...the proof?  (Is it my fault or theirs?)\nWhat about typographical/grammatical mistakes? What if there are a lot of them?\nHow much time should I spend on a report?\nHow many reports a year am I expected to write? When is it acceptable to refuse a request to referee?\n\nOf course, any other relevant questions and answers on this topic are encouraged, since this is CW.\nThis question is inspired by (stolen from) a similar post at MathOverflow.\nUpdate 15/02/2011:\nI am still very interested in getting more input on this question especially with regard to reviewing conference papers and program committee membership. (These two roles are themselves different beasts, and both very unlike being a referee for a journal article, IMO.)  Granted, program committee membership is rarer than refereeing or reviewing (and it hasn't been my privilege yet), but is a responsibility that every researcher in theoretical computer science must take on eventually.\n\nTime.  How much time am I expected to spend as a committee member or conference reviewer?  Given the probability that I could get ten or perhaps many more to handle in the space of a few weeks, how do I avoid running out of time?  What are the most important things to spend time on?\nConfidence.  What if the paper is too far from my area of expertise?  What factors should go into nominating/asking someone else to review a submission?  If it is not too far from my area of expertise and I elect to review it, when is it permissible to give a confidence rating of 1?\nCriteria.  There are critical differences between journals and conferences.  Some very important papers are not published in journals.  Some very important papers did not previously appear in conferences.  What are the most significant distinctions in criteria on which to assess papers in these settings?\nRecommendations.  Inherently, there are fewer recommendations that can be offered to the authors of a conference paper, primarily due to space and time constraints.  Also, there is usually only one round of review.  Another consideration is that my report becomes public to the entire strong committee.  What is the scope of suggestions/directives that I can offer?\n\nAs before, if you think I've missed out on asking any particular questions, do let me know, or edit directly.  This is CW, after all.\nThese new thoughts are partly motivated by reading a paper that Suresh mentioned on his blog.", "output": "To the best of your knowledge, does the paper make a significant, well-presented, and correct contribution to the state of the art?  If the paper fails any of the three criteria, it's fair to reject it for that reason alone, regardless of the other two.\nHere's what I think a report should contain.  Everything should be visible to the author, except possibly for serious accusations of misconduct.\na. A quick summary of the paper, to help the editor judge the quality of the results, and to help convince both the author and the editor that you actually read and understood the paper.  Place the result in its larger context.  Include a history of prior versions, even if the authors include it in the submission.  Be respectful, but brutally honest.\nb. A discussion of the strengths and weaknesses of the paper, in terms of correctness, novelty, clarity, importance, generality, potential impact, elegance, technical depth, robustness, etc.  If you suspect unethical behavior (plagiarism, parallel submission, cooked data), describe your suspicions.  Be respectful, but brutally honest.\nc. A recommendation to the editor for further action \u2014 accept, accept with minor revision, ask for a second round of reviewing, or reject outright.  Keep in mind that you are making a recommendation, not a decision; if you can't make up your mind, just say so.  Be respectful, but brutally honest.\nd. More detailed feedback to the author \u2014 more detailed justification for your recommendation, requests for clarification in the final version, missing references, bugs in the proofs, simplifications, generalizations, typos, etc.  Be respectful, but brutally honest.\nConference reports should be shorter; program committees have hundreds of papers to consider at once.  Whether there should be a difference between conference and journal papers is up to the journal (and indirectly, up to the community).  Most theoretical computer science journals do not insist on a significant difference; it is quite common for the conference and journal versions of a theory paper to be essentially identical.  When in doubt, ask the editor!\nIf you still don't understand the paper after making a good-faith effort, it's the author's fault, or possibly the editor's, but certainly not yours.  The author's primary responsibility is to effectively communicate their result to their audience, and a good editor will send you a paper to referee only if they think you're a good representative of the paper's intended audience.  But you do have to make a good-faith effort; do not expect to immediately understand everything (anything?) immediately on your first reading.\nIf there are a lot of errors, don't even read the paper; just recommend rejection on the grounds that the paper is not professionally written.  Otherwise, if you really want to be thorough, include a representative list of grammar, spelling, and punctuation mistakes, but don't knock yourself out finding every last bug.  Be respectful, but brutally honest.\nExpect to spend about an hour per page, mostly on internalizing the paper's results and techniques.  Be pleasantly surprised when it doesn't actually take that long.  (If it takes significantly less time than that, either the paper is either exceedingly elegant and well-written, you know the area extremely well, or the paper is technically shallow.  Don't confuse these three possibilities.) \nYou should write at least as many referee reports as other people write for you.  If this takes more time than writing your own papers, you're not spending enough time on your own papers.", "meta": {"post_id": 1893, "input_score": 67, "output_score": 61, "post_title": "How do I referee a paper?"}}
{"input": "I'm interested in an explicit Boolean function $f \\colon \\\\{0,1\\\\}^n \\rightarrow \\\\{0,1\\\\}$ with the following property: if $f$ is constant on some affine subspace of $\\\\{0,1\\\\}^n$, then the dimension of this subspace is $o(n)$. \nIt is not difficult to show that a symmetric function does not satisfy this property\nby considering a subspace $A=\\\\{x \\in \\\\{0,1\\\\}^n \\mid x_1 \\oplus x_2=1, x_3 \\oplus x_4=1, \\dots, x_{n-1} \\oplus x_n=1\\\\}$. Any $x \\in A$ has exactly $n/2$ $1$'s and hence $f$ is constant the subspace $A$ of dimension $n/2$.\nCross-post: https://mathoverflow.net/questions/41129/a-boolean-function-that-is-not-constant-on-affine-subspaces-of-large-enough-dimen", "output": "The objects you are searching for are called seedless affine dispersers with one output bit.  More generally, a seedless disperser with one output bit for a family $\\mathcal{F}$ of subsets of $\\{0,1\\}^n$ is a function $f : \\{0,1\\}^n \\to \\{0,1\\}$ such that on any subset $S \\in \\mathcal{F}$, the function $f$ is not constant.  Here, you are interested in $\\mathcal{F}$ being the family of affine subspaces\nBen-Sasson and Kopparty in \"Affine Dispersers from Subspace Polynomials\" explicitly construct seedless affine dispersers for subspaces of dimension at least $6n^{4/5}$.  The full details of the disperser are a bit too complicated to describe here.  \nA simpler case also discussed in the paper is when we want an affine disperser for subspaces of dimension $2n/5+10$.  Then, their construction views ${\\mathbb{F}}_2^n$ as ${\\mathbb{F}}_{2^n}$ and specifies the disperser to be $f(x) = Tr(x^7)$, where $Tr: {\\mathbb{F}}_{2^n} \\to {\\mathbb{F}}_2$ denotes the trace map: $Tr(x) = \\sum_{i=0}^{n-1} x^{2^i}$.  A key property of the trace map is that $Tr(x+y) = Tr(x) + Tr(y)$.", "meta": {"post_id": 1948, "input_score": 18, "output_score": 25, "post_title": "A Boolean function that is not constant on affine subspaces of large enough dimension"}}
{"input": "Which would be the consequences of #P = FP?\nI'm interested in both practical and theoretical consequences.\nFrom a practical point of view, I'm particularly interested in consequences on Artificial Intelligence.\nPointers to papers or books are more than welcome.\nPlease do not say that #P = FP implies P = NP, I already know that. Also, please do not say \"there will be no practical consequences if the algorithm runs in time $\\Omega(n^{\\alpha})$, where $\\alpha$ is the number of electrons in the Universe\": permit me to assume that, if a deterministic polynomial time algorithm for a #P-complete problem exists, its running time will be \"clement\" ($O(n^2)$, for example).", "output": "Here are a few theoretical consequences of the equality FP=#P, although they have nothing to do with artificial intelligence.  The assumption FP=#P is equivalent to P=PP, so let me use the latter notation.\nIf P=PP, then we have P=BQP: quantum polynomial-time computation can be simulated by classical, deterministic polynomial-time computation.  This is a direct consequence of BQP\u2286PP [ADH97, FR98] (and of an earlier result BQP\u2286PPP [BV97]).  On top of my knowledge, P=BQP is not known to follow from the assumption P=NP.  This situation is different from the case of randomized computation (BPP): since BPP\u2286NPNP [Lau83], the equality P=BPP follows from P=NP.\nAnother consequence of P=PP is that the Blum-Shub-Smale model of computation over the reals with rational constants is equvalent to Turing machines in a certain sense.  More precisely, P=PP implies P=BP(P\u211d0); that is, if a language L\u2286{0,1}* is decidable by a constant-free program over the reals in polynomial time, then L is decidable by a polynomial-time Turing machine.  (Here \u201cBP\u201d stands for \u201cBoolean part\u201d and has nothing to do with BPP.)  This follows from BP(P\u211d0)\u2286CH [ABKM09].  See the paper for definitions.  An important problem in BP(P\u211d0) is the square-root sum problem and friends (e.g. \u201cGiven an integer k and a finite set of integer-coordinate points on the plane, is there a spanning tree of total length at most k?\u201d) [Tiw92].\nSimilarly to the second argument, the problem of computing a specific bit in xy when positive integers x and y are given in binary will be in P if P=PP.\nReferences\n[ABKM09] Eric Allender, Peter B\u00fcrgisser, Johan Kjeldgaard-Pedersen and Peter Bro Miltersen.  On the complexity of numerical analysis.  SIAM Journal on Computing, 38(5):1987\u20132006, Jan. 2009.  http://dx.doi.org/10.1137/070697926\n[ADH97] Leonard M. Adleman, Jonathan DeMarrais and Ming-Deh A. Huang.  Quantum computability.  SIAM Journal on Computing, 26(5):1524\u20131540, Oct. 1997.  http://dx.doi.org/10.1137/S0097539795293639\n[BV97] Ethan Bernstein and Umesh Vazirani.  Quantum complexity theory.  SIAM Journal on Computing, 26(5):1411\u20131473, Oct. 1997.  http://dx.doi.org/10.1137/S0097539796300921\n[FR98] Lance Fortnow and John Rogers.  Complexity limitations on quantum computation.  Journal of Computer and System Sciences, 59(2):240\u2013252, Oct. 1999.  http://dx.doi.org/10.1006/jcss.1999.1651\n[Lau83] Clemens Lautemann.  BPP and the polynomial time hierarchy.  Information Processing Letters, 17(4):215\u2013217, Nov. 1983.  http://dx.doi.org/10.1016/0020-0190(83)90044-3\n[Tiw92] Prasoon Tiwari.  A problem that is easier to solve on the unit-cost algebraic RAM.  Journal of Complexity, 8(4):393\u2013397, Dec. 1992.  http://dx.doi.org/10.1016/0885-064X(92)90003-T", "meta": {"post_id": 2021, "input_score": 26, "output_score": 25, "post_title": "Consequences of #P = FP"}}
{"input": "In a lot of domains, there are canonical techniques which everybody working in the field should master. For example, for logspace reductions, the \"bit trick\" for composition consisting of not constructing the full output of the composed function, but always asking to recompute the result for every bit of output, permitting to keep logspace constraints.\nMy question is about non-relativizing techniques. Do theoricians have outlined some fundamental non-relativizing operations, or is there a different trick for each known non-relativizing proof ?", "output": "There's really only one \"flagship\" non-relativizing technique: namely, arithmetization (the technique used in the proofs of IP=PSPACE, MIP=NEXP, PP\u2284SIZE(nk), MAEXP\u2284P/poly, and several other results).\nHowever, the proof that all NP languages have computational zero-knowledge proofs (assuming one-way functions exist), due to Goldreich, Micali, and Wigderson, used a different non-relativizing technique (namely, the symmetries of the 3-COLORING problem).\nArora, Impagliazzo, and Vazirani argued that even \"local checkability,\" the property of NP-complete problems used in the proof of the original Cook-Levin Theorem (as well as the PCP Theorem), should count as a non-relativizing technique (though Lance Fortnow wrote a paper arguing the opposite).  The sticking point is whether it makes sense to relativize the complexity class of \"locally checkable problems.\"\nThe pebbling arguments used in results from the 1970s such as TIME(n)\u2260NTIME(n) have been put forward as another example of a non-relativizing technique.\nFor more, you might want to check out my algebrization paper with Wigderson, and especially the references therein.  We had to pretty much catalogue the existing non-relativizing techniques in order to figure out which ones were and weren't encompassed by the algebrization barrier.\nAddendum: I just realized that I forgot to mention measurement-based quantum computing (MBQC), which was recently used to great effect by Broadbent, Fitzsimons, and Kashefi to obtain quantum complexity theorems (such as QMIP = MIP*, and BQP = MIP with entangled BQP provers and BPP verifier) that most likely fail to relativize.", "meta": {"post_id": 2045, "input_score": 30, "output_score": 41, "post_title": "Are there canonical non-relativizing techniques?"}}
{"input": "One of the holy grails of algorithm design is finding a strongly polynomial algorithm for linear programming, i.e., an algorithm whose runtime is bounded by a polynomial in the number of variables and constraints and is independent of the size of the representation of the parameters (assuming unit cost arithmetic).  Would resolving this question have implications outside of better algorithms for linear programming?  For instance, would the existence/non-existence of such an algorithm have any consequences for geometry or complexity theory?\nEdit: Maybe I should clarify what I mean by consequences.  I'm looking for mathematical consequences or conditional results, implications that are known to be true now.  For instance: \"a polynomial algorithm for LP in the BSS model would separate/collapse algebraic complexity classes FOO and BAR\", or \"if there is no strongly polynomial algorithm then it resolves such-and-such conjecture about polytopes\", or \"a strongly polynomial algorithm for problem X which can be formulated as an LP would have interesting consequence blah\".  The Hirsch conjecture would be a good example, except that it only applies if simplex is polynomial.", "output": "This would show that parity and mean-payoff games are in P. See Sven Schewe. From Parity and Payoff Games to Linear Programming. MFCS 2009.", "meta": {"post_id": 2149, "input_score": 31, "output_score": 29, "post_title": "Consequences of existence of a strongly polynomial algorithm for linear programming?"}}
{"input": "This question is inspired by the Georgia Tech Algorithms and Randomness Center's t-shirt, which asks \"Randomize or not?!\"\nThere are many examples where randomizing helps, especially when operating in adversarial environments.  There are also some settings where randomizing doesn't help or hurt.  My question is:\n\nWhat are some settings when randomizing (in some seemingly reasonable way) actually hurts?\n\nFeel free to define \"settings\" and \"hurts\" broadly, whether in terms of problem complexity, provable guarantees, approximation ratios, or running time (I expect running time is where the more obvious answers will lie).  The more interesting the example, the better!", "output": "Here is a simple example from game theory. In games in which both pure and mixed Nash equilibria exist, the mixed ones are often much less natural, and much \"worse\".\nFor example, consider a simple balls and bins game: there are n bins, and n balls (players). Each player gets to pick a bin, and incurs a cost equal to the number of people in his bin. The pure Nash equilibrium has everyone each picking a unique bin, and nobody incurs cost more than 1. However, there is a mixed Nash equilibrium in which everyone randomly chooses a bin, and then with high probability, there will be one bin with ~ $\\log(n)/\\log\\log(n)$ people. Since OPT is 1, that means that (if what we care about is max player cost), if randomization is not allowed, then the price of anarchy is 1. But if randomization is allowed, it grows unboundedly with the number of players in the game.\nThe takeaway message: randomization can harm coordination.", "meta": {"post_id": 2229, "input_score": 17, "output_score": 25, "post_title": "Randomize or Not?"}}
{"input": "The Chomsky(\u2013Sch\u00fctzenberger) hierarchy is used in textbooks of theoretical computer science, but it obviously only covers a very small fraction of formal languages (REG, CFL, CSL, RE) compared to the full Complexity Zoo Diagram. Does the hierarchy play any role in current research anymore? I found only little references to Chomsky here at cstheory.stackexchange, and in Complexity Zoo the names Chomsky and Sch\u00fctzenberger are not mentioned at all.\nIs current research more focused on other means of description but formal grammars? I was looking for practical methods to describe formal languages with different expressiveness, and stumbled upon growing context sensitive language (GCSL) and visibly pushdown languages (VPL), which both lie between the classic Chomsky languages. Shouldn't the Chomsky hierarchy be updated to include them? Or is there no use of selecting a specific hierarchy from the full set of complexity classes? I tried to select only those languages that can be fit in gaps of the Chomsky hierarchy, as far as I understand:\nREG (=Chomsky 3) \u228a VPL \u228a DCFL \u228a CFL (=Chomsky 2) \u228a GCSL \u228a CSL (=Chomsky 1) \u228a R \u228a RE\nI still don't get where \"mildly context-sensitive languages\" and \"indexed languages\" fit in (somewhere between CFL and CSL) although there seems to be of practical relevance for natural language processing (but maybe anything of practical relevance is less interesting in theoretical research ;-). In addition you could mention GCSL \u228a P \u2282 NP \u2282 PSPACE and CSL \u228a PSPACE \u228a R to show the relation to the famous classes P and NP.\nI found on GCSL and VPL:\n\nRobert McNaughton: An Insertion into the Chomsky Hierarchy?. In: Jewels are Forever, Contributions on Theoretical Computer Science in Honor of Arto Salomaa. S. 204-212, 1999\nhttp://en.wikipedia.org/wiki/Nested_word#References (VPL)\n\nI'd also be happy if you know any more recent textbook on formal grammars that also deal with VPL, DCLF, GCSL and indexed grammars, preferable with pointers to practical applications.", "output": "From what I have seen in the Natural Language Processing community, formal grammars \u00e0 la Chomsky are not used so much any more. They (too) think that the Chomsky Hierarchy is outdated to model language.\nWhat took its place is stuff like Re-writting rule (the Lars algorithm), dependency models (Dan Klein), Tree Substitution Grammar (the DOP model), Binary Feature Grammars (Alex Clark).", "meta": {"post_id": 2252, "input_score": 50, "output_score": 22, "post_title": "Is the Chomsky-hierarchy outdated?"}}
{"input": "I was just wondering if this was possible?\nSurely there maybe some naive methods of doing so, but I was just wondering if someone can suggest efficient ways to do so.", "output": "You can just ignore that you have a max heap and build your min heap from it. O(n) time\ncomplexity. No need for additional array.", "meta": {"post_id": 2277, "input_score": 5, "output_score": 23, "post_title": "Is it possible to convert a Max heap to a Min heap in place?"}}
{"input": "I recently taught expanders, and introduced the notion of Ramanujan graphs.\nMichael Forbes asked why they are called this way, and I had to admit I don't know. \nAnyone?", "output": "To add some content to the answers here, I'll explain briefly what Ramanujan's conjecture is.\nFirst of all, Ramanujan's conjecture is actually a theorem, proved by Eichler and Igusa.  Here is one way to state it.  Let $r_m(n)$ denote the number of integral solutions to the quadratic equation $x_1^2 + m^2 x_2^2 + m^2 x_3^2 + m^2 x_4^2 = n$.  If $m=1$, that $r_m(n) > 0$ was of course proved by Legendre, but Jacobi gave the exact count: $r_1(n) = 8 \\sum_{d \\mid n, 4 \\not \\mid d} d$.  Nothing similarly exact is known for larger $m$ but Ramanujan conjectured the bound: $r_m(n) = c_m \\sum_{d \\mid n} d + O(n^{1/2 + \\epsilon})$ for every $\\epsilon > 0$, where $c_m$ is a constant dependent only on $m$.  \nLubtozky, Phillips and Sarnak constructed their expanders based on this result.  I'm not familiar with the details of their analysis but the basic idea, I believe, is to construct a Cayley graph of $PSL(2,Z_q)$ for a prime $q$ that $1 \\bmod 4$, using generators determined by every sum-of-four-squares decomposition of $p$, where $p$ is a quadratic residue modulo $q$.  Then, they relate the eigenvalues of this Cayley graph to $r_{2q}(p^k)$ for integer powers $k$.  \nA reference, other than the Lubotzky-Phillips-Sarnak paper itself, is Noga Alon's brief description in Tools from Higher Algebra.", "meta": {"post_id": 2315, "input_score": 27, "output_score": 36, "post_title": "Why are Ramanujan graphs named after Ramanujan?"}}
{"input": "What should you do when you see a question raised in public, say here on stack-exchange, that you know the answer to, because you are looking into as part of current research project?\nFor example, I see a TCS.SX question that I know the answer to, because I worked on the problem recently.  I haven't finished writing up the results yet and am trying to get a few more results to make an acceptable paper.  \nShould I contact the asker personally?  Claim credit publicly by publishing answer on the site?  What should I do?", "output": "I'll share my side of the story that is mentioned in Shiva's answer.\nShiva had several questions related to my own research (space-bounded algorithms for reachability problems). We were currently putting the final touches on a full draft of the proof, and were not ready to announce the result.  However, it was clear that Shiva was very interested in this area, so I emailed him saying we had a result in the works and gave him just the theorem statement.  A week later, we had our draft complete and I sent him a copy.  A few weeks later we shared our updated draft on the ECCC.\nThis worked well for several reasons.\n\nShiva and I have never met in person, but now we know each other as colleagues interested in similar problems.\nShiva also sent me a copy of his most recent work, which is also related and interesting.\nThe questions gave me an extra boost of motivation to complete a full draft quickly.\n\nI recommend this course of action in the future: partial disclosure via private communication, full disclosure, and public announcement.", "meta": {"post_id": 2328, "input_score": 37, "output_score": 29, "post_title": "When should you say what you know?"}}
{"input": "Matrix multiplication using regular (row - column inner product) technique takes $O(n^{3})$ multiplucations and $O(n^{3})$ additions. However assuming equal sized entries (number of bits in each entry of both matrices being multiplied) of size $m$ bits, the addition operation actually happens on $O(n^{3}nm) = O(n^{4}m)$ bits.\nSo it seems that the true complexity of matrix multiplication if measured via bit complexity should be $O(n^{4})$. \n$(1)$Is this correct?\nSupposing if one creates an algorithm which reduces the bit complexity to $O(n^{3+\\epsilon})$ rather than total multiplications and additions, this might be a sounder approach than say reducing the total multiplications and additions to $O(n^{2+\\epsilon})$ as attempted by researchers such as Coppersmith and Cohn.\n$(2)$ Is this a valid argument?", "output": "No, the bit complexity of matrix multiplication on $M$-bit entries is $n^{\\omega} (\\log n)^{O(1)} \\cdot M (\\log M)^{O(1)}$, where $\\omega < 2.4$ is the best known matrix multiplication exponent. Multiplication and addition of $M$-bit numbers can be done in $M (\\log M)^2$ time. Multiplying two $M$-bit numbers yields a number which has no more than $2M$ bits. Adding $n$ numbers of $M$ bits each, yields a number which has no more than $M+\\log n+O(1)$ bits. (Think about it: the sum is at most $n 2^M$, so the bit representation takes no more than $\\log (n 2^M)+O(1)$ bits.)\nReferences to fast integer multiplication algorithms can be found with a web search or wikipedia.", "meta": {"post_id": 2349, "input_score": 9, "output_score": 31, "post_title": "True Bit Complexity of matrix multiplication is $O(n^{4})$"}}
{"input": "I've been thinking of a variant of hex, where instead of the two players making moves alternately, each turn a player picked at random makes a move. How hard is it to determine the chances for each player winning? This problem is obviously in PSPACE, but can't it to be NP-hard, much less PSPACE-complete. The difficulties come from how the randomness makes it impossible for a player to be forced into making a choice among options; if that player is lucky he gets enough moves two take both options, and if the player is unlucky the opponent gets enough moves to block both options. On the other hand, I can't think of any polynomial-time algorithms for this.", "output": "You might want to look at the paper \"Random-Turn Hex and Other Selection Games,\" by Yuval Peres, Oded Schramm, Scott Sheffield, and David Wilson. From the introduction: \n\n\"Random-Turn Hex is the same as\n  ordinary Hex, except that instead of\n  alternating turns, players toss a coin\n  before each turn to decide who gets to\n  place the next stone. Although\n  ordinary Hex is famously difficult to\n  analyze, the optimal strategy for\n  Random-Turn Hex turns out to be very\n  simple.\"\n\nSo indeed, your intuition was right: this will be in BPP (or maybe P).", "meta": {"post_id": 2353, "input_score": 17, "output_score": 23, "post_title": "Complexity of hex with random turn order."}}
{"input": "First of all, I apologize in advance for any stupidity. I am by no means an expert on complexity theory (far from it! I am an undergraduate taking my first class in complexity theory) Here's my question. Now Savitch's Theorem states that \n$$\\text{NSPACE}\\left(f\\left(n\\right)\\right) \\subseteq \\text{DSPACE}\\left(\\left(f\\left(n\\right)\\right)^2\\right)$$\nNow I'm curious if if this lower bound was tight, i.e that is something along the lines of \n$\\text{NSPACE}\\left(f\\left(n\\right)\\right) \\subseteq \\text{DSPACE}\\left(\\left(f\\left(n\\right)\\right)^{1.9}\\right)$ is not achievable. \nIt seems like something there should be a straightforward combinatorial argument to be made here - each node in the configuration graph for a Deterministic Turing machine has only one outgoing edge, while each node in the configuration graph of a Non-Deterministic Turing machine can have more than one outgoing edge. What Savitch's algorithm is doing is converting configuration graphs with any number outgoing edge to configuration graphs with $<2$ outgoing edges.\nSince the configuration graph defines a unique TM (not sure about this), the combinatorial size of the latter is almost certainly larger than the former. This \"difference\" is perhaps a factor of $n^2$, perhaps less - I don't know. Of course, there are lots of little technical issues to be worked out, like how you need to make sure there are no loops and so forth, but my question is if this is a reasonable way to begun proving a thing like this.", "output": "This is a well known open question. You will see in complexity theory many open questions for which you'd wonder how come no one managed to solve them. Part of the reason is that we need new people like you to help us solve them :)\nFor the latest result in this area, showing that Savitch's algorithm is optimal in some restricted model, see Aaron Potechin's FOCS paper.\nSpecifically, he starts from the nice observation that because the configuration graph of a deterministic TM has only one outgoing edge (after fixing the input), one can think of it as an undirected graph, and so the question becomes something like the following: given a directed graph $G$ of $n$ vertices with two special vertices $s,t$, if we map it to an $N$ vertex undirected graph $G'$ (also with special vertices $s',t'$) such that the existence of each edge in $G'$ depends on one edge in $G$ and there is a path from $s$ to $t$ in $G$ iff there's a path between $s'$ and $t'$ in $G'$, how much bigger $N$ has to be from $n$.\nTo show that Savitch's algorithm is optimal, one needs to show that $N$ has to be at least $2^{\\Omega(\\log^2 n)}  = n^{\\Omega(\\log n)}$. To show $L\\neq NL$, it suffices to show the weaker bound that $N > n^c$ for every constant $c$.  I'm pretty sure that even $N > n^{10}$ is not known, though perhaps something like $N \\geq n^2$ is known for some not so interesting reasons.", "meta": {"post_id": 2426, "input_score": 29, "output_score": 31, "post_title": "Tight Lower bounds on Savitch's theorem"}}
{"input": "1) What, if any, is the relationship between static typing and formal grammars?\n2) In particular, would it be possible for a linear bounded automaton to check whether, say, a C++ or SML program was well typed? A nested stack automaton?\n3) Is there a natural way to express static typing rules in formal grammar terms?", "output": "It is not possible for linear bounded automata to check whether C++ programs, and unlikely to be possible for and LBA to check whether SML programs are well-typed. C++ has a Turing-complete type system, since you can code arbitrary programs as template metaprograms. \nSML is more interesting. It does have decidable type checking, but the problem is EXPTIME-complete. Hence it is unlikely an LBA can check it, unless there is a very surprising collapse in the complexity hierarchy. The reason for this is that SML requires type inference, and there are families of programs the size of whose type grows much faster than the size of the program. As an example, consider the following program:\nfun delta x = (x, x)        (* this has type 'a -> ('a * 'a), so its return value\n                               has a type double the size of its argument *)\n\nfun f1 x = delta (delta x)  (* Now we use functions to iterate this process *)\nfun f2 x = f1 (f1 x)        \nfun f3 x = f2 (f2 x)        (* This function has a HUGE type *)\n\nFor simpler type systems, such as C or Pascal's, I believe it is possible for an LBA to check it. \nIn the early days of programming languages research, people sometimes used van Wingaarden grammars (aka two-level grammars) to specify type systems for programming languages. I believe Algol 68 was specified in this way. However, I am told this technique was abandoned for essentially pragmatic reasons: it turned out to be quite difficult for people to write grammars that specified what they thought they were specifying! (Typically, the grammars people wrote generated larger languages than they intended.) \nThese days people use schematic inference rules to specify type systems, which is essentially a way of specifying predicates as the least fixed point of a collections of Horn clauses. Satisfiability for first-order Horn theories is undecidable in general, so if you want to capture everything type theorists do, then whatever grammatical formalism you choose will be stronger than is really convenient.\nI know there has been some work on using attribute grammars to implement type systems. They claim there are some software engineering benefits for this choice: namely, attribute grammars control information flow very strictly, and I am told this makes program understanding  easier.", "meta": {"post_id": 2428, "input_score": 26, "output_score": 21, "post_title": "Context Sensitive Grammars and Types"}}
{"input": "Hey Guys, I understand that the padding trick allows us to translate complexity classes upwards - for example $P=NP \\rightarrow EXP=NEXP$. Padding works by \"inflating\" the input, running the conversion (say from say $NP$ to $P$), which yields a \"magic\" algorithm which you can run on the padded input. While this makes technical sense, I can't get a good intuition of how this works. What exactly is going on here? Is there a simple analogy for what padding is? \nCan provide a common sense reason why this is the case?", "output": "I think the best way to get intuition for this issue is to think of what the complete problems for exponential time classes are.  For example, the complete problems for NE are the standard NP-complete problems on succinctly describable inputs, e.g., given a circuit that describes the adjacency matrix of a graph, is the graph 3-colorable?  Then the problem of\nwhether E=NE becomes equivalent to whether NP problems are solvable in polynomial time on the\nsuccinctly describable inputs, e.g., those with small effective Kolmogorov complexity.   This is obviously no stronger than whether they are solvable on all inputs.  The larger the time bound, the smaller the Kolmogorov complexity of the relevant inputs, so collapses for larger time bounds are in effect algorithms that work on smaller subsets of inputs.\nRussell Impagliazzo", "meta": {"post_id": 2434, "input_score": 25, "output_score": 30, "post_title": "Why do equalities between complexity classes translate upwards and not downwards?"}}
{"input": "We know that if you have a PSPACE machine, it's powerful enough to give an interactive proof of any level the polynomial hierarchy. (And if I remember right, all you need is #P.) But suppose you want to give an interactive proof of membership in a $\\Sigma_2$ language. Is it enough to be able to solve problems in $\\Sigma_2$? Is solving problems in $\\Sigma_5$ adequate? More generally, if you can solve $\\Sigma_k$ or $\\Pi_k$ problems, for what $\\Sigma_\\ell$ is this sufficient to generate interactive proofs of all languates in $\\Sigma_\\ell$?\nThis question was inspired by this cstheory stackexchange question.", "output": "This is a known (wonderful) open problem that I've worked on from time to time without success.\nAvi Wigderson and I mentioned the problem in our algebrization paper, where we raised the question of whether or not containments such as coNP \u2286 IPNP can be proved via algebrizing techniques. (Here IPNP denotes IP with a BPP verifier and a BPPNP prover.)  If (as I conjecture) the answer is no, then that would provide a formal reason why any interactive protocol like the one Peter asks for would require non-relativizing techniques that go \"fundamentally beyond\" the ones used for IP=PSPACE.\nAn analogous question is whether or not BQP = IPBQP, where IPBQP means IP with a BPP verifier and a BQP (quantum polynomial-time) prover.  That question is also open---although a recent breakthrough by Broadbent, Fitzsimons, and Kashefi showed that a closely-related statement is true.", "meta": {"post_id": 2461, "input_score": 38, "output_score": 25, "post_title": "Interactive proofs for levels of the polynomial hierarchy"}}
{"input": "Does anyone know about an NP-completeness result for the DOMINATING SET problem in graphs, restricted to the class of planar bipartite graphs of maximum degree 3?\nI know it is NP-complete for the class of planar graphs of maximum degree 3 (see the Garey and Johnson book), as well as for bipartite graphs of maximum degree 3 (see M. Chleb\u00edk and J. Chleb\u00edkov\u00e1, \"Approximation hardness of dominating set problems in bounded degree graphs\"), but could not find the combination of the two in the literature.", "output": "What if you simply do the following: Given a graph $G = (V,E)$, construct another graph $G' = (V \\cup U, E')$ by subdividing each edge of $G$ in 4 parts; here $U$ is the set of new nodes that we introduced, and $|U| = 3|E|$.\nThe graph $G'$ is bipartite. Moreover, if $G$ is planar and has max. degree 3, then $G'$ is also planar and has max. degree 3.\nLet $D'$ be a (minimum) dominating set for $G'$. Consider an edge $(x,y) \\in E$ that was subdivided to form a path $(x,a,b,c,y)$ in $G'$. Now clearly at least one of $a,b,c$ is in $D'$. Moreover, if we have more than one of $a,b,c$ in $D'$, we can modify $D'$ so that it remains a valid dominating set and its size does not increase. For example, if we have $a \\in D'$ and $c \\in D'$, we can equally well remove $c$ from $D'$ and add $y$ to $D'$. Hence w.l.o.g. we have $|D' \\cap U| = |E|$.\nThen consider $D = D' \\cap V$. Assume that $x \\in V$ and $x \\notin D'$. Then we must have a node $a \\in D'$ such that $(x,a) \\in E'$. Hence there is an edge $(x,y) \\in E$ such that we have a path $(x,a,b,c,y)$ in $G'$. Since $a,b,c \\in U$ and $a \\in D'$, we have $b, c \\notin D'$, and to dominate $c$ we must have $y \\in D'$. Hence in $G$ node $y$ is a neighbour of $x$ with $y \\in D$. That is, $D$ is a dominating set for $G$.\nConversely, consider a (minimum) dominating set $D$ for $G$. Construct a dominating set $D'$ for $G'$ so that $|D'| = |D| + |E|$ as follows: For an edge $(x,y) \\in E$ that was subdivided to form a path $(x,a,b,c,y)$ in $G'$, we add $a$ to $D'$ if $x \\notin D$ and $y \\in D$; we add $c$ to $D'$ if $x \\in D$ and $y \\notin D$; and otherwise we add $b$ to $D'$. Now it can be checked that $D'$ is a dominating set for $G'$: By construction, all nodes in $U$ are dominated. Now let $x \\in V \\setminus D'$. Then there is a $y \\in V$ such that $(x,y) \\in E$, and hence along the path $(x,a,b,c,y)$ we have $a \\in D'$, which dominates $x$.\nIn summary, if $G$ has a dominating set of size $k$, then $G'$ has a dominating set of size at most $k + |E|$, and if $G'$ has a dominating set of size $k + |E|$, then $G$ has a dominating set of size at most $k$.\nEdit: Added an illustration. Top: the original graph $G$; middle: graph $G'$ with a \"normalised\" dominating set; bottom: graph $G'$ with an arbitrary dominating set.", "meta": {"post_id": 2505, "input_score": 19, "output_score": 25, "post_title": "Is the dominating set problem restricted to planar bipartite graphs of maximum degree 3 NP-complete?"}}
{"input": "This question is about Page 125 of the book \"Cellular automata in hyperbolic spaces: Volume 2\" By Maurice Margenstern, Publisher Archives contemporaines, 2008.\nhttp://books.google.com/books?id=eEgvfic3A4kC&pg=PA125\nIn the author's opinion, the question P=NP is ill-posed because in the hyperbolic setting P=NP or in the notation used later in the book Ph=NPh.\nI don't know enough about complexity to know what to make of this, but it sounds interesting.\nSo the question is basically, what do you make of it?\nDo his claims make sense ?", "output": "P=NP is a well-defined mathematical question which does not depend on space-time geometry. The question \"which problems can be solved by computations that are tractable in this universe?\" may depend on physics, and the answer does indeed appear to change in hyperbolic space or with quantum mechanics (e.g. quantum computing). However, this doesn't affect the P=NP question.\nIn fact, one of the first reactions of a theoretical computer scientist would have to your reference is: \"What complexity class can be computed by a cellular automaton in hyperbolic space?\" If you redefine complexity classes when you change to hyperbolic space, it becomes much harder to talk about this question.\nAnd if you look later in the book, the author defines P$_h$ as problems solvable in polynomial time on a hyperbolic cellular automaton, and proves P$_h$=PSPACE (and NP$_h$=P$_h$=PSPACE), so even the author isn't really taking complexity classes to change in hyperbolic space.", "meta": {"post_id": 2585, "input_score": 17, "output_score": 39, "post_title": "Meaning of P=NP? depends on space-time geometry ?"}}
{"input": "What is the relationship between DNA-algorithms and the complexity classes defined using Turing machines? What do the complexity measures like time and space correspond to in DNA-algorithms? Can they be used to solve instances of NP-complete problems like TSP that von Neumann machines can not solve feasibly in practice?", "output": "Soundbite answer: DNA computing does not provide a magic wand to solve NP-complete problems, even though some respected researchers in the 1990s thought for a time it might.\nThe inaugural DNA computing experiment was performed in a laboratory headed by the renowned number theorist Len Adleman.  Adleman solved a small Traveling Salesman Problem -- a well-known NP-complete problem, and he and others thought for a while the method might scale up.  Adleman describes his approach in this short video, which I find fascinating.  The problem they encountered was that to solve a TSP problem of modest size, they would need more DNA than the size of the Earth.  They had figured out a way to save time by increasing the amount of work done in parallel, but this did not mean the TSP problem required less than exponential resources to solve. They had only shifted the exponential cost from amount-of-time to amount-of-physical material.\n(There's an added question: if you require an exponential amount of machinery to solve a problem, do you automatically require an exponential amount of time, or at least preprocessing, to build the machinery in the first place?  I'll leave that issue to one side, though.)\nThis general problem -- reducing the time a computation requires at the expense of some other resource -- has shown up many times in biologically-inspired models of computing.  The Wikipedia page on membrane computing (an abstraction of a biological cell) says that a certain type of membrane system is able to solve NP-complete problems in polynomial time.  This works because that system allows for the creation of exponentially-many subobjects inside an overall membrane, in polynomial time.  Well... how does an exponential amount of raw material arrive from the outside world an enter through a membrane with constant surface area?  Answer: it's not considered.  They're not paying for a resource that the computation would otherwise require.\nFinally, to respond to Anthony Labarre, who linked to a paper showing AHNEPs can solve NP-complete problems in polynomial time.  There's even a paper out showing AHNEPs can solve 3SAT in linear time.  AHNEP = Accepting Hybrid Network of Evolutionary Processors.  An evolutionary processor is a model inspired by DNA, whose core has a string that at each step can be changed by substitution, deletion, or (importantly) insertion.  Further, an arbitrarily large number of strings is available at every node, and at each communication step, all nodes send all their correct strings to all attached nodes.  So without time cost, it's possible to transfer exponential amounts of information, and because of the insertion rule, individual strings can become ever larger over the course of the computation, so it's a double whammy.\nIf you are interested in recent work in biocomputation, by researchers who focus on computations that are real-world practical, I can offer this book review I recently wrote for SIGACT News, which touches briefly on multiple areas.", "meta": {"post_id": 2703, "input_score": 21, "output_score": 32, "post_title": "DNA-algorithms and NP-completeness"}}
{"input": "This is a naive question, out of my expertise; apologies in advance.\nGoldbach's Conjecture and many other unsolved questions in mathematics can be written\nas short formulas in predicate calculus.\nFor example, Cook's paper \"Can Computers Routinely Discover Mathematical Proofs?\" formulates\nthat conjecture as\n$$\\forall n [( n > 2 \\wedge 2 | n) \\supset \\exists r \\exists s (P(r) \\wedge P(s) \\wedge n = r + s) ]$$\nIf we restrict attention to polynomially-long proofs, then theorems with such proofs are in NP.\nSo if P=NP, we could determine whether e.g. Goldbach's Conjecture is true in polynomial time.\nMy question is: Would we also be able to exhibit a proof in polynomial time?\nEdit. As per the comments of Peter Shor and Kaveh, \nI should have qualified my claim that we could\ndetermine if Goldbach's conjecture is true if it indeed is one of the theorems with a short proof.  Which of course we do not know!", "output": "Dana has answered the question. But here are some comments on the practical side.\nNote that it is undecidable to check if a given sentence is provable in ZFC. $P=NP$ has no consequence on this. $P=NP$ (in fact $P=coNP$) means it is easy to find proofs for propositional tautologies, not first-order sentences like GC.\nIt is $NP$ to check if there is a proof of a given sentence of given length $l$ (in unary) in a fixed theory (e.g. ZFC). So if $P=NP$, then there is a polytime algorithm to check this. Taking $l$ to be some fixed polynomial in the length of the sentence will result in a polytime algorithm.\nPractically (this is mentioned by Godel in his famous letter to von Neumann): if $P=NP$, then there is a polynomial time algorithm that given a first-order sentence and $l$ (in unary), the algorithm can find if the sentence has a size $l$ proof in ZFC. Godel's idea was that in this case, if the equivalence $P=NP$ is really feasible (i.e. the algorithm is not just $P$ but is in say $DTime(n^2)$), then one can take this algorithm and run it to check for proofs of feasible but very large length which is going to be larger than any proof any human can ever come up with, and if the algorithm does not find an answer, then the sentence is practically impossible to prove. The trick Dana has mentioned will also work here to find the proof.\nFor practical means:\n\n$P=NP$ is not enough, we need the algorithm to be feasible in practice, an algorithm in $DTime(10000n^{10000})$ would not help.\nit will find a proof only if there is one (i.e. the sentence is not an undecidable sentence in ZFC), moreover the proof should be feasibly short.\nit can be the case that $P\\neq NP$, but we can still find these feasible proofs algorithmically, for example if $NP=DTime(n^{\\log^* n})$.", "meta": {"post_id": 2800, "input_score": 36, "output_score": 25, "post_title": "If P=NP, could we obtain proofs of Goldbach's Conjecture etc.?"}}
{"input": "In The computational complexity of linear optics (ECCC TR10-170), Scott Aaronson and Alex Arkhipov argue that if quantum computers can be efficiently simulated by classical computers then the polynomial hierarchy collapses to the third level.  The motivating problem is sampling from a distribution defined by a linear-optical network; this distribution can be expressed as the permanent of a particular matrix.  In the classical case all entries of the matrix are non-negative, and so a probabilistic polynomial-time algorithm exists, as shown by Mark Jerrum, Alistair Sinclair, and Eric Vigoda (JACM 2004, doi: 10.1145/1008731.1008738).  In the quantum case the entries are complex numbers.  Note that in the general case (when the entries are not required to be non-negative) the permanent cannot be approximated even within a constant factor, by Valiant's classic 1979 result.\nThe paper defines a distribution $D_A$ defined by a matrix $A$, and a sampling problem\n\nBosonSampling\nInput: matrix $A$\nSample: from distribution $D_A$\n\nUsing a hardness result seems to be weak evidence for a separation between the classical and quantum worlds, since it is possible that the class of matrices in the specific quantum setup will all be of special form.  They might have complex entries, but may still possess a lot of structure.  There could therefore exist an efficient sampling procedure for such matrices, even though the general problem is #P-hard.\n\nHow does the use of BosonSampling in the paper avoid easy classes?\n\nThe paper uses a lot of background I don't have in quantum complexity.  Given all the quantum people on this site, I'd really appreciate a pointer in the right direction.  How would the arguments hold up if one were to discover that the class of complex-valued matrices seen in a specific experimental setup actually corresponded to a class of distributions that was easy to sample from?  Or is there something inherent in the quantum system that guarantees this cannot happen?", "output": "Thanks for your question!  There are two answers, depending on whether you're interested in the hardness results for exact or approximate BosonSampling.\nIn the exact case, we prove that given any n-by-n complex matrix A, you can construct an optical experiment that produces a particular output with probability proportional to |Per(A)|2.  This, in turn, implies that no classical polynomial-time algorithm can sample from exactly the same distribution as the optical experiment (given a description of the experiment as input), unless P#P = BPPNP.  In fact we can strengthen that, to give a single distribution Dn (depending only on the input length n) that can be sampled using an optical experiment of poly(n) size, but that can't be sampled classically in poly(n) time unless P#P = BPPNP.\nIn the approximate case, the situation is more complicated.  Our main result says that, if there's a classical polynomial-time algorithm that simulates the optical experiment even approximately (in the sense of sampling from a probability distribution over outputs that's 1/poly(n)-close in variation distance), then in BPPNP, you can approximate |Per(A)|2, with high probability over an n-by-n matrix A of i.i.d. Gaussians with mean 0 and variance 1.\nWe conjecture that the above problem is #P-hard (at the very least, not in BPPNP), and pages 57-82 of our paper are all about the evidence for that conjecture.\nOf course, maybe our conjecture is false, and one can actually give a poly-time algorithm to approximate the permanents of i.i.d. Gaussian matrices.  That would be a phenomenal result!  However, the whole point of 85% of the work we did was to base everything on a hardness conjecture that was as clean, simple, and \"quantum-free\" as possible.  In other words, instead of the assumption\n\"approximating the permanents of some weird, special matrices that happen to arise in our experiment is #P-hard,\"\nwe show that it suffices to make the assumption\n\"approximating the permanents of i.i.d. Gaussian matrices is #P-hard.\"", "meta": {"post_id": 2892, "input_score": 25, "output_score": 25, "post_title": "How does the BosonSampling paper avoid easy classes of complex matrices?"}}
{"input": "Does it make sense to consider a category of all NP-complete problems, with morphisms as poly-time reductions between different instances? Has anyone ever published a paper about this, and if so, where can I find it?", "output": "The area you want to look at is called \"implicit complexity theory\". A random and incomplete fistful of names to Google for are Martin Hofmann, Patrick Baillot, Ugo Dal Lago, Simona Ronchi Della Rocca, and Kazushige Terui. \nThe basic technique is to relate complexity classes to subsystems of linear logic (the so-called \"light linear logics\"), with the idea that the cut-elimination for the logical system should be complete for the given complexity class (such as LOGSPACE, PTIME, etc). Then via Curry-Howard you get out a programming language in which precisely the programs in the given class are expressible. As you might expect from the mention of linear logic, these all these systems then give rise to monoidal closed categories of various flavors, which leaves you with a purely algebraic and machine-independent characterization of various complexity classes. \nOne of the things that make this area interesting is that neither traditional complexity nor logical/PL methods are entirely appropriate. \nSince the categories involved typically have closed structure, the combinatoric methods favored by complexity theorists often break down (since higher-order programs tend to resist combinatorial characterizations). A typical example of this is the failure of syntactic methods to handle contextual equivalence. Similarly, the methods of semantics also have trouble, since they are often too extensional (since traditionally semanticists have wanted to hide the internal structure of functions). The simplest example I know here is the closure of LOGSPACE under composition: this is AFAIK only possible due to dovetailing and selective recomputation, and you can't treat the problems as pure black boxes.\nYou will likely also want to have some familiarity with game semantics and Girard's Geometry of Interaction (and their precursor, Kahn-Plotkin-Berry's concrete data structures) if you get seriously into this area -- the ideas of token-passing representations of higher-order computations used in this work supply a lot of the intuitions for ICC.\nSince I've pointed out the central role of monoidal categories in this work, you might reasonably wonder about the connections to Mulmuley's GCT. Unfortunately, I can't help you here, since I simply don't know enough. Paul-Andr\u00e9 Melli\u00e8s might be a good person to ask, though.", "meta": {"post_id": 3074, "input_score": 28, "output_score": 21, "post_title": "A category of NP-complete problems?"}}
{"input": "The Clifford group of quantum operators is generated by the quantum operations:\n\nControlled-Z,\nHadamard, and\nPhase ($= |0\\rangle\\langle0| + i |1\\rangle\\langle1|$).\n\nA circuit composed only of these gates can be simulated efficiently on a classical computer. However, if I understand correctly, not all classical algorithms can be implemented efficiently using Clifford group operations, at least as far as we know.\nIs there a construction to implement, even inefficiently or approximately, a classical algorithm using Clifford group operations?\nFor instance, how do you implement a Toffoli gate using Clifford group gates, if it's possible?", "output": "As pointed out in a comment above, if it were possible to coherently implement a Toffoli gate using Clifford group gates, then the Clifford group would be universal for quantum computation. It was noted in Section 5 of this paper that something even stronger is true: informally speaking, if there exists a class of quantum circuits which can be simulated efficiently classically, and which is universal for classical computation, then BQP=BPP. Thus we would expect simulable classes of quantum circuits not to be universal for classical computation.\nClifford group circuits themselves are particularly weak, and correspond to the complexity class Parity-L, as was shown here.", "meta": {"post_id": 3287, "input_score": 13, "output_score": 24, "post_title": "Clifford group quantum operations and classical computation"}}
{"input": "The central problem of complexity theory is arguably $P$ vs $NP$.\nHowever, since Nature is quantum, it would seem more natural to consider the classes $BQP$ (ie decision problems solvable by a quantum computer in polynomial time, with an error probability of at most 1/3 for all instances) ans $QMA$ (the quantum equivalent of $NP$) instead.\nMy questions:\n1) Would a solution to the $P$ vs $NP$ problem give a solution to $BQP$ vs $QMA$?\n2) Do the three barriers of relativization, natural proofs and algebrization also apply to the $BQP$ vs $QMA$ problem?", "output": "1) No implication is known in either direction.  We know that P=NP implies P=PH.  But we don't know if BQP and QMA are in PH, so maybe P could equal NP yet BQP and QMA still wouldn't collapse.  (On the other hand, note that QMA\u2286PP\u2286P#P, so certainly P=P#P would imply BQP=QMA.)  To show that BQP=QMA implies P=NP seems even more hopeless in the present state of knowledge.\n2) Absolutely, all three barriers apply with full force to BQP vs. QMA (and even to the \"easier\" problem of proving P\u2260PSPACE).  First, relative to a PSPACE oracle (or even the low-degree extension of a PSPACE oracle), we have\nP = NP = BQP = QMA = PSPACE,\nso certainly nonrelativizing and non-algebrizing techniques will be needed to separate any of these classes.  Second, to get a natural proofs barrier for putting stuff outside BQP, all you need is a pseudorandom function family that's computable in BQP, which is a formally weaker requirement than a pseudorandom function family computable in P.\nAddendum: Let me say something about a \"metaquestion\" which you didn't ask but hinted at, of why people still focus on P vs. NP even though we believe Nature is quantum.  Personally, I've always seen P vs. NP as nothing more than the \"flagship\" for a whole bunch of barrier questions in complexity theory (P vs. PSPACE, P vs. BQP, NP vs. coNP, NP vs. BQP, the existence of one-way functions, etc), none of which we know how to answer, and all of which are related in the sense that any breakthrough with one would very likely lead to breakthroughs with the others (even where we don't have formal implications between the questions, which in many cases we do).  P vs. NP isn't inherently more fundamental than any of the others -- but if we have to pick one question to serve as the poster child for complexity, then it's a fine choice.", "meta": {"post_id": 3304, "input_score": 35, "output_score": 34, "post_title": "$BQP$ vs $QMA$?"}}
{"input": "Let $f$ be a Boolean function and let's think about f as a function from $\\{-1,1\\}^n$ to $\\{ -1,1 \\}$. In this language the Fourier expansion of f is simply the expansion of f in terms of square free monomials. (These $2^n$ monomials form a basis to the space of real functions on $\\{-1,1\\}^n$. The sum of the squares of the coefficients is simply $1$ so $f$ leads to a probability distribution on square free monomials. Let's call this distribution the F-distribution.\nIf f can be described by a bounded depth circuit of polynomial size then we know by a theorem of Linial, Mansour and Nisan that the F distribution is concentrated on monomials of $\\text{polylog } n$ size up to almost-exponentially-small weight. This is derived from Hastad switching lemma. (A direct proof would be most desirable.)\nWhat happens when we add mod 2 gates? One example to consider is the function $IP_{2n}$ on $2n$ variables which is described as the mod 2 inner product of the first n variables and the last n variables. Here the F-distribution is uniform.\n\nQuestion: Is the F-distribution of a Boolean function described by\n  bounded depth polynomial size AND, OR,\n  MOD$_2$ circuit concentrated (up to\n  superpolynomially small error) on $o(n)$\n  \"levels\"?\n\nRemarks: \n\nOne possible path to a counterexample would be to \"glue somehow\" various IP$_2k$ on disjoint sets of variables but I don't see how to do it. Perhaps one should weaken the question and allow assigning some weights to the variables, but I don't see a clear way for doing it either. (So referring to these two matters is also part of what I am asking about.)\nI would speculate that a positive answer to the question, (or to a successful variation) will apply also when you allow mod$_k$ gates. (So asking the question was motivated by Ryan Williams' recent impressive ACC result.)   \nFor MAJORITY the F-distribution is large (1/poly) for every \"level\".\n\n\nAs shown by Luca, the answer to the question I asked is \"no\". The question that is left is to propose ways to find properties of the F distributions of Boolean functions that can be described by AND OR and mod 2 gates not shared by MAJORITY. \n\nAn attempt to save the question by talking about MONOTONE functions:\n\nQuestion: Is the F-distribution of a MONOTONE Boolean function described by\n  bounded depth polynomial size AND, OR,\n  MOD$_2$ circuit concentrated (up to\n  superpolynomially small error) on $o(n)$\n  \"levels\"?\n\nWe may speculate that we can even replace $o(n)$ by $\\text{polylog} (n)$ so a counterexample for this strong version can be interesting.", "output": "Gil, would something like this be a counterexample?\nLet $m$ be such that $n=m+\\log m$, and think of an $n$-bit input as being a pair $(x,i)$ where $x$ is an m-bit string $(x_1,\\ldots ,x_m)$ and $i$ is an integer in the range $1,\\ldots,m$ written in binary.\nThen we define $f(x,i):= x_1 \\oplus \\cdots \\oplus x_i$\r\nNow for each $i=1,\\ldots,m$ the function f() has $1/m$ correlation with the Fourier character $x_1 \\oplus \\cdots \\oplus x_i$, and so the \"level i\" has at least a $1/m^2$ fraction of the mass. (In fact more, but this should suffice)\nf() can be realized in depth-3: put all the XORs in a layer, and then do the \"selection\" in two layers of ANDs, ORs and NOTs (not counting the NOTs as adding to the depth, as usual).", "meta": {"post_id": 3332, "input_score": 30, "output_score": 32, "post_title": "Fourier coefficients Boolean Functions described by Bounded Depth Circuits with AND OR and XOR gates"}}
{"input": "I was searching about Matrix multiplication, So I first visit wiki matrix multiplication algorithms, In references I found a paper which claim that uses $O(n^2 log(n))$ algorithm , I'd going to read article but it's complicated and will takes too many time to read it, but if there is anyone who reads this article or knows about this algorithm, Is this true? and are you knowing about the base Idea of this to describe it a little.\nThanks in advance, I know it's a bit general question but, if I found it's good approach I'll going to learn details.", "output": "I came across this paper about a year ago, but have not gotten around to reading it closely. I can tell you that the approach is not believed to be correct. On page 36 of the same paper, there is an attached comment by Don Knuth, who points out what looks to be a serious shortcoming of the approach. \nTo understand this paper, you will need to learn about group algebra and representation theory. It will be tough if you haven't seen that kind of material before.", "meta": {"post_id": 3360, "input_score": 13, "output_score": 35, "post_title": "Matrix multiplication in $O(n^2 \\log n)$"}}
{"input": "Consider a nondeterministic finite automata $A = (Q, \\Sigma, \\delta, q_0, F)$, and a function $f(n)$. Additionally we define $\\Sigma^{\\leq k} = \\bigcup_{i \\leq k} \\Sigma^i$.\nNow lets analyze the following statement:\n\nIf $\\Sigma^{\\leq f(|Q|)} \\subseteq L(A)$, then $L(A) = \\Sigma^*$.\n\nIt is easy to show, that for $f(n) = 2^n+1$ it is true, hence if the automata produces every word with length upto $2^{|Q|}+1$, then it produces $\\Sigma^*$.\nBut does it still hold if $f$ is a polynom?\nIf not, what could a construction of a NFA $A$ for a given polynom $p$ look like, s.t. $\\Sigma^{\\leq p(|Q|)} \\subseteq L(A) \\subsetneq \\Sigma^*$?", "output": "EDIT AT 10/12/06:\nok, this is pretty much the best construction I can get, see if any one come up with better ideas.\n\nTheorem. For each $n$ There is an $(5n+12)$-state NFA $M$ over alphabets $\\Sigma$ with $|\\Sigma|=5$ such that the shortest string not in $L(M)$ is of length $(2^n-1)(n+1)+1$.\n\nThis will give us $f(n) = \\Omega(2^{n/5})$.\nThe construction is pretty much the same with the one in Shallit's, except we construct an NFA directly instead of representing the language by a regular expression first. Let \n$\\Sigma = \\{{0 \\brack 0},{0 \\brack 1},{1 \\brack 0},{1 \\brack 1},\\sharp\\}$.\nFor each $n$, we are going to construct an NFA recognizing language $\\Sigma^*-\\{s_n\\}$, where $s_n$ is the following sequence (take $n=3$ for example):\n$s_3 = \\sharp{0 \\brack 0}{0 \\brack 0}{0 \\brack 1}\\sharp{0 \\brack 0}{0 \\brack 1}{1 \\brack 0}\\sharp \\ldots \\sharp{1 \\brack 1}{1 \\brack 1}{0 \\brack 1}\\sharp$.\nThe idea is that we can construct an NFA consists of five parts; \n\na starter, which ensures the string starts with $\\sharp{0 \\brack 0}{0 \\brack 0}{0 \\brack 1}\\sharp$; \na terminator, which ensures the string ends with $\\sharp{1 \\brack 1}{1 \\brack 1}{0 \\brack 1}\\sharp$;\na counter, which keeps the number of symbols between two $\\sharp$'s as $n$;\nan add-one checker, which guarantees that only symbols with the form $\\sharp{x \\atop x+1}\\sharp$ appears; finally,\na consistent checker, which guarantees that only symbols with the form $\\sharp{x \\atop y}\\sharp{y \\atop z}\\sharp$ can appear concurrently.\n\nNote that we do want to accept $\\Sigma^*-\\{s_n\\}$ instead of $\\{s_n\\}$, so once we find out that the input sequence is disobeying one of the above behaviors, we accept the sequence immediately. Otherwise after $|s_n|$ steps, the NFA will be in the only possible rejecting state. And if the sequence is longer than $|s_n|$, the NFA also accepts. So any NFA satisfies the above five conditions will only reject $s_n$.\nIt may be easy to check the following figure directly instead of a rigorous proof:\n\nWe start at the upper-left state. The first part is the starter, and the counter, then the consistent checker, the terminator, finally the add-one checker. All the arc with no terminal nodes point to the bottom-right state, which is an all time acceptor. Some of the edges are not labeled due to lack of spaces, but they can be recovered easily. A dash line represents a sequence of $n-1$ states with $n-2$ edges.\nWe can (painfully) verify that the NFA rejects $s_n$ only, since it follows all the five rules above. So a $(5n+12)$-state NFA with $|\\Sigma|=5$ has been constructed, which satisfies the requirement of the theorem.\nIf there's any unclearliness/problem with the construction, please leave a comment and I'll try to explain/fix it.\n\nThis question has been studied by Jeffrey O. Shallit et al., and indeed the optimal value of $f(n)$ is still open for $|\\Sigma|>1$. (As for unary language, see the comments in Tsuyoshi's answer) \nIn page 46-51 of his talk on universality, he provided a construction such that:\n\nTheorem. For $n\\geq N$ for some $N$ large enough, there is an $n$-state NFA $M$ over binary alphabets such that the shortest string not in $L(M)$ is of length $\\Omega(2^{cn})$ for $c=1/75$.\n\nThus the optimal value for $f(n)$ is somewhere between $2^{n/75}$ and $2^n$. I'm not sure if the result by Shallit has been improved in recent years.", "meta": {"post_id": 3496, "input_score": 29, "output_score": 21, "post_title": "Conditions for NFA universality"}}
{"input": "(crossposted from MathOverflow)\nHi,\nI was reading this thread: https://mathoverflow.net/questions/16393/finding-a-cycle-of-fixed-length\nI want to find a 5-cycle in a graph.  Actually, what I really want is a shortest odd cycle of length at least 5, but maybe that is a little beside the point.  For my purposes, I treat $m$ and $n$ the same in the complexity analysis.  \nCan we do better than colour coding for finding a 5-cycle in this case?  Let me give a specific formulation of my question:\n\nWhat is the minimum $\\alpha$ such that there is an $O(m^\\alpha)$-time algorithm for detecting a cycle of length 5?  What is the algorithm?  And what is this $\\alpha$ if you forbid impractical methods like Coppersmith-Winograd fast matrix multiplication?", "output": "To add to Mihai's answer:\nIndeed, 5-cycle (and in general $k$-cycle) in sparse graphs can be solved much faster than $O(mn)$ time using the high degree / low degree trick. You need only look at another paper of Alon, Yuster and Zwick:\nhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.101.4120\nFor example, a 5-cycle can be found in $O(m^{1.67})$ time, without any dependence on matrix multiplication. See Theorem 3.4 of the above linked paper. \nAlso, while it is not too hard to reduce 5-cycle detection to Boolean matrix multiplication (with constant factor overhead), a reduction in the opposite direction does not appear in the color-coding paper. A tight reduction (which preserves the runtime complexity) from Boolean matrix multiplication to 5-cycle detection is not known.", "meta": {"post_id": 3786, "input_score": 21, "output_score": 21, "post_title": "Finding a 5-cycle in a sparse graph efficiently."}}
{"input": "What are the most significant research papers on the foundations of generics in C# and .NET?", "output": "Most of the important work on generics for C# was done by Andrew Kennedy at Microsoft Research Cambridge. He has a web page devoted to the topic. A fairly recent paper discussion the foundations is this one (which definitely looks like theory to me).\nMore recent, but interesting, work went into the design of C$\\omega$. Also looking at the rather large amount of literature on Java generics, such as Featherweight Java, will also help. If you really want to start looking at the foundations, consider Cardelli's work on Types and Semantics, and perhaps consider looking at System F (and the original papers of Reynolds and Girard).", "meta": {"post_id": 3863, "input_score": 12, "output_score": 22, "post_title": "C# Generics Research Papers"}}
{"input": "Peter Shor showed that two of the most important NP-intermediate problems, factoring and the discrete log problem, are in BQP. In contrast, the best known quantum algorithm for SAT (Grover's search) only yields a quadratic improvement over the classical algorithm, hinting that NP-complete problems are still intractable on quantum computers. As Arora and Barak point out, there's also a problem in BQP that is not known to be in NP, leading to the conjecture that the two classes are incomparable.\nIs there any knowledge/conjecture as to why these NP-intermediate problems are in BQP, but why SAT (as far as we know) isn't? Do other NP-intermediate problems follow this trend? In particular, is graph isomorphism in BQP? (this one doesn't google well).", "output": "The folklore answer is that factoring is \"structured\" in a way that general NP-complete problems aren't, and this is why we have only been able to find quantum advantage for intermediate problems.\nArguably a simpler version of your question is to look not at computational complexity, but at the query complexity of boolean functions.  Here we can say some things provably, such as the fact that superpolynomial speedups are possible only for partial functions (proved in http://arxiv.org/abs/quant-ph/9802049) and not for functions that are symmetric in their inputs and outputs (proved in http://arxiv.org/abs/0911.0996).\nThese results do not directly shed light on the BQP vs NP question, but are I think meaningful steps towards determining where there is quantum advantage.", "meta": {"post_id": 3888, "input_score": 31, "output_score": 21, "post_title": "NP-intermediate problems with efficient quantum solutions"}}
{"input": "I was wondering if the JSON spec defined a regular language.  It seems simple enough, but I'm not sure how to prove it myself.\nThe reason I ask, is because I was wondering if one could use regular expressions to effectively pars JSON.\nCould someone with enough rep please create the tags json and regular-language for me?", "output": "Since $a^n b^n$ is not a regular language, neither is JSON, since $[^n 5 ]^n$ is valid input for any $n$.  Likewise, your regular expression parser would have to properly reject any input $[^m 4 ]^n$ where $m \\ne n$ which you cannot do with regular expressions.\nHence, JSON is not regular.", "meta": {"post_id": 3987, "input_score": 21, "output_score": 30, "post_title": "Is JSON a Regular Language?"}}
{"input": "Consider the set of planar graphs where all the internal faces are triangles. If there is an interior point of odd degree the graph cannot be three colored. If every interior point has even degree can it always be three colored? Ideally I'd like a small counterexample.", "output": "This result extends to high dimensions. A triangulation of a d-dimensional sphere so that every vertex has an even degree is (d+1) colorable. See, for example this paper: Jacob E. Goodman and Hironori Onishi, \nEven triangulations of $S^3$ and\nthe coloring of graphs, Trans. Am. Math. Soc. 246 (1978), 501\u2013510.", "meta": {"post_id": 4027, "input_score": 21, "output_score": 24, "post_title": "Coloring Planar Graphs"}}
{"input": "In trying to devise my own sorting algorithm, I'm looking for the optimal benchmark to which I can compare it.  For an unsorted ordering of elements A and a sorted ordering B, what is an efficient way to calculate the optimal number of transpositions to get from A to B ?\nA transposition is defined as switching the position of 2 elements in the list, so for instance\n1 2 4 3\n\nhas one transposition (transposition 4 and 3) to make it\n1 2 3 4\n\nSomething like\n1 7 2 5 9 6\n\nrequires 4 transpositions (7, 2), (7, 6), (6,5), (9, 7)\nUpdate (9/7/11): question changed to use \"transposition\" instead of \"swaps\" to refer to non-adjacent exchanges.", "output": "If you're only dealing with permutations of $n$ elements, then you will need exactly $n-c(\\pi)$ swaps, where $c(\\pi)$ is the number of cycles in the disjoint cycle decomposition of $\\pi$. Since this distance is bi-invariant, transforming $\\pi$ into $\\sigma$ (or $A$ into $B$, or conversely) requires $n-c(\\sigma^{-1}\\circ\\pi)$ such moves.", "meta": {"post_id": 4096, "input_score": 16, "output_score": 23, "post_title": "Minimum number of transpositions to sort a list"}}
{"input": "It's well-known that there are tons of amateurs--myself included--who are interested in the P vs. NP problem.  There are also many amatuers--myself still included--who have made attempts to resolve the problem.\nOne problem that I think the TCS community suffers from is a relatively high interested-amateur-to-expert ratio; this leads to experts being inundated with proofs that P != NP, and I've read that they are frustrated and overwhelmed, quite understandably, by this situation.  Oded Goldreich has written on this issue, and indicated his own refusal to check proofs.\nAt the same time, speaking from the point of view of an amateur, I can assert that there are few things more frustrating for non-expert-level TCS enthusiasts of any level of ability than generating a proof that just seems right, but lacking both the ability to find the error in the proof yourself and the ability to talk to anyone who can spot errors in your proof.  Recently, R. J. Lipton wrote on the problem of amateurs who try to get taken seriously.\nI have a proposal for resolving this problem, and my question is whether or not others think it reasonable, or if there are problems with it.\nI think experts should charge a significant but reasonable sum of money (say, 200 - 300 USD) in exchange for agreeing to read proofs in detail and find specific errors in them.  This would accomplish three things:\n\nAmateurs would have a clear way to get their proofs evaluated and taken seriously.\nExperts would be compensated for their time and energy expended.\nThere would be a significantly high cost imposed on proof-checking that the number of proofs that amateurs submit would go down dramatically.\n\nAgain, my question is whether or not this is a reasonable proposal.  Obviously, I have no ability to cause experts to adopt what I suggest; however, I'm hoping that experts will read what I've written and decide that it's reasonable.", "output": "I have some \"real-world experience\" in this nascent industry (and no, I'm not talking about my $200,000 offer to Deolalikar :-) )\nIn January, a software developer emailed me that he had an attempted proof of P\u2260NP, and that while he was almost sure there was an error, he couldn't find it.  He asked if I knew any grad students who'd be willing to find the error for him in exchange for a few hundred dollars.\nTo give you some context: I get a proof of either P\u2260NP or P=NP in my inbox roughly once per month.  Many of these emails go to a long list of complexity theorists (Cook, Karp, Fortnow, Sipser...); they often include religious or metaphysical ruminations as well as dark hints about academic conspiracies.  (In one case, there were graphic death threats against me, which led to my contacting the police.)  Virtually none of them acknowledge any possibility that the proof might be wrong, or that the author might have misunderstood the question.  And when, back in grad school, I tried to correspond with the authors, I found all of them to be fervent believers in Churchill's maxim \"never, never, never, never give up.\"\nSo the software developer's request really impressed me!  This was the first time I'd ever seen a P\u2260NP proof accompanied by this level of self-awareness---both about the imposition being made on people's time and (more importantly) about the likelihood of error.  As it happened, my PhD student Michael Forbes sent the author a beautiful, detailed report explaining the problems with his approach; the author thanked Michael and (I think! :-) ) paid up as promised.\nSo yes: for amateurs who want someone to examine their P vs. NP proofs (or similar work), I think paying a grad student a few hundred bucks is a great way to go.  (Note that grad students are a much better choice than professors: not only do they have more energy and enthusiasm for such things, they also need the money more.)  I wish more amateurs availed themselves of this option.", "meta": {"post_id": 4489, "input_score": 20, "output_score": 42, "post_title": "Should experts in TCS charge money to read proofs that P != NP?"}}
{"input": "I have a question about page 9 in Proofs and Types.\nThe given $\\rightarrow$Introduction rule says that $A \\rightarrow B$ can be deduced from $B$ if the deduction of $B$ contains an arbitrary number of $A$s (0 or more).  How can this be true if there are zero $A$s in the deduction of $B$?", "output": "Dave Clarke's answer basically says it all: this is the standard convention in classical and constructive mathematics.  Nonetheless, your objection is the source of a century-old subdiscipline of philosophical logic called \"relevance logic\", which can be seen as rejecting the axiom p \u2192 (q \u2192 p) -- or in terms of natural deduction, rejecting precisely this ability to use a hypothesis zero times, or equivalently in terms of sequent calculus, rejecting the structural rule of weakening. Reconsidering other structural rules/axioms leads more generally to substructural logics, which have found applications in linguistics and theoretical computer science.  (One important example, linear logic, is mentioned in the appendix to Proofs and Types.)", "meta": {"post_id": 4683, "input_score": 7, "output_score": 21, "post_title": "Discharged hypotheses in ->Introduction"}}
{"input": "I would like to understand how the Arora-Kale SDP solver approximates the Goemans-Williamson relaxation in nearly linear time, how the Plotkin-Shmoys-Tardos solver approximates fractional \"packing\" and \"covering\" problems in nearly linear time, and how the algorithms are instantiations of the \"learning from experts\" abstract framework.\nKale's thesis has an excellent presentation, but I find it very difficult to directly jump into the abstract framework, and I would prefer to start from an example of a simple problem for which it's absolutely obvious what to do, and then move to more general problems, progressively adding \"features\" to the algorithm and to its analysis.\nFor example:\n\nHow does Plotkin-Shmoys solve the linear programming relaxation of unweighted vertex cover? Weighted vertex cover? Set cover? Bipartite matching?\nWhat is the simplest example in which the Arora-Kale algorithm is doing something interesting? How does it compute the largest eigenvalue of the Laplacian of a graph?\n\n(Computing the largest eigenvalue of the Laplacian is equivalent to the problem of solving a weaker version of the Goemans-Williamson SDP relaxation of Max Cut, in which, instead of requiring each vector to be of length one, you want the sum of the squares of the norms to be |V|.)", "output": "Luca, since a year has passed, you probably have researched your own\nanswer.  I'm answering some of your questions here just for the\nrecord.  I review some Lagrangian-relaxation algorithms for the\nproblems you mention, and sketch the connection to learning (in\nparticular, following expert advice).  I don't comment here on SDP\nalgorithms.\nNote that the particular algorithms that you mention do not run in\nnearly linear time.  (There is a nearly linear-time algorithm for\nexplicitly given packing or covering problems.  See\nBeating Simplex for Fractional Packing and Covering Linear Programs.)\nThe algorithms you have in mind typically have variants that run in a\nnearly linear number of iterations, but each iteration typically\nrequires at least linear time as well.  I discuss some of these\nalgorithms below.\nSome useful functions\nBefore we start, here are some functions that we will use in the proof sketches.\n(If you are interested in the algorithms, but not the proof details, you can skip ahead.)\nFor any vector $y$, define $\\mbox{Lmax}(y)$ to be $\\ln \\sum_i \\exp(y_i)$.\nThis function is an upper bound on $\\max_i y_i$:\n$$\\max_i y_i ~\\le~ \\mbox{Lmax}(y) ~\\le~ \\max_i y_i + \\ln m.$$\nAnalogously, define $\\mbox{Lmin}(y)$ to be $-\\mbox{Lmax}(-y)$,\na lower bound on $\\min_i y_i$.\nFor convenience in what follows, \nwe use $g(y)$ to denote the gradient $\\nabla \\mbox{Lmin}(y)$ of Lmin.\nWe use $G(y)$ to denote the gradient $\\nabla \\mbox{Lmax}(y)$ of Lmax.\nExplicitly, $g_i(y)$ is $\\exp(-y_i)/\\sum_{i'} \\exp(-y_{i'})$\nwhile $G_i(y)$ is $\\exp(y_i)/\\sum_{i'} \\exp(y_{i'})$.\nLmin and Lmax are smooth in the following sense: \nfor any vectors $d\\in[0,\\varepsilon]^n$ and $y\\in R^n$,\n$$\\mbox{Lmin}(y+d) ~\\ge~ \\mbox{Lmin}(y) \n~+~ (1-O(\\varepsilon))\\, d \\cdot g(y)$$\nand\n$$\\mbox{Lmax}(y+d) ~\\le~ \\mbox{Lmax}(y) \n~+~ (1+O(\\varepsilon))\\, d \\cdot G(y).$$\nNote that both of the gradients have 1-norm equal to 1:\n$|G(y)| = |g(y)| = 1$.  (Throughout we use $|z|$ to denote the 1-norm.)\nNote also that, for a matrix $A$, \nthe gradient of the function $x\\mapsto \\mbox{Lmin}(Ax)$ with respect to $x$\nis (by the chain rule) $(g(Ax))^T A$.\nMore explicitly, the partial derivative of the function with respect to $x_j$\nis $\\sum_i A_{ij} \\exp(-A_i x) / \\sum_i \\exp(-A_i x)$.\nLikewise,  the partial derivative of Lmax$(Ax)$ \nwith respect to $x_j$ is $\\sum_i A_{ij} \\exp(A_i x)/\\sum_i \\exp(A_i x)$. \nFractional Set Cover\nFix a Set-Cover instance.\nLet $A$ denote the element/set incidence matrix.\nThus, $A_{es} = 1$ if $e\\in s$, else 0,\nand $A_e x$ is the extent that  fractional cover $x$ covers element $e$.\nThe LP is $\\min\\{ |x| : A x \\ge 1; x \\ge 0\\}$.\nGiven $\\varepsilon\\in (0,1)$, the algorithm is\n\n\nInitialize all $x_s = 0$.  Let $N=\\log(n)/\\varepsilon$.  \nRepeat until $\\min_e A_e x \\ge N$:   \n2.1. Choose $s$ maximizing the partial derivative of Lmin$(Ax)$ w.r.t. $x_s$.\n      (Explicitly, choose $s$ maximizing $\\sum_{e\\in s} \\exp(-\\sum_{s'\\ni e} x_{s'})$.)   \n2.2. Increase $x_s$ by $\\varepsilon$.    \nReturn $x/\\min_{e} A_e x$.\n\n\nThe algorithm returns a $(1+O(\\varepsilon))$ approximate solution\nin $O(|x^*|\\log(n)/\\varepsilon^2)$ iterations, where $n$ is the number of elements\nand $x^*$ is the optimal fractional set cover (trivially $|x^*|\\le n$).\n(A similar algorithm appears in the paper Chandra mentioned.\nVertex Cover is of course a special case.)\n(Remark: Note that the iteration bound does not depend on the number\nof sets, just the number of elements.  Thus, the algorithm can be used\nwith an implicitly defined set system, as long as, given weights on the\nelements, one can efficiently find a set of maximum (or near-maximum) total weight.\nThis kind of oracle is the same as the separation oracle required to apply\nthe ellipsoid algorithm to the dual problem. For packing problems such\nas set packing, you need an oracle that, given weights on the elements,\nreturns a set minimizing the total weight.  For problems such as\nmulti-commodity flow, you might, for example, need to find a path\nminimizing the sum of some given edge weights.)\nHere's a sketch of the proof of the performance guarantee.\nIn each iteration, the partial derivative w.r.t. the chosen $s$\nis at least $1/|x^*|$, where $x^*$ is the optimal fractional set cover.\n(To see why, recall that the gradient of Lmin$(Ax)$ with respect to $x$ is $(g(Ax))^T A$.\nIf we were to choose a set $s'$ at random from the distribution $x^*/|x^*|$,\nthe expected value of the partial derivative with respect to $x_{s'}$\nwould thus be $(g(Ax))^T \\,A x^*/|x^*|$.\nSince $Ax^* \\ge 1$, this is at least $|g(Ax)|/|x^*|$.\nSince $|g(Ax)|=1$, this is at least $1/|x^*|$.\nThus, there must exist some $s$ giving partial derivative at least $1/|x^*|$.\nSince the algorithm chooses $x_s$ in each iteration to maximize\nthe partial derivative, it achieves a partial derivative of at least $1/|x^*|$.)\nThen, the step size $\\varepsilon$ is chosen just small enough so that \nno coordinate of $A x$ increases by more than $\\varepsilon$.\nThus, because of the smoothness of Lmin,  increasing $x_s$\nto $x_s+\\varepsilon$ increases $\\mbox{Lmin}(Ax)$ by at least\n$(1-O(\\varepsilon))\\varepsilon/|x^*|$.\nIn this way, the algorithm maintains the invariant\n$$\\mbox{Lmin}(Ax) \\ge (1-O(\\varepsilon)) |x|/|x^*| - \\ln n.$$\n(Note that Lmin$(\\overline 0)$ equals $\\ln n$.)\nAt termination, in the invariant, the $\\ln n$ term is $O(\\varepsilon)$ times the left-hand side,\nso by calculation one gets $\\min_e A_e x \\ge  (1-O(\\varepsilon)) |x|/|x^*|$.\nAfter the normalization in the last line of the algorithm,\nthis implies $|x| \\le (1+O(\\varepsilon))|x^*|$.\nFWIW, the inequalities involved in proving the invariant are essentially\nthe same as those involved in proving the Chernoff bound.\n(In fact, this algorithm can be derived by applying the\nmethod of conditional probabilities to a randomized-rounding\nscheme that repeatedly samples sets from the distribution $x^*/|x^*|$\n(with replacement), increasing $x_s$ for each sampled set $s$.\nThis derandomization of that gives the algorithm:\nthe underlying invariant is just that the pessimistic estimator stays below 1.\nThe exponential penalties in the pessimistic estimator come from the\nusing the Chernoff bound in the analysis of the rounding scheme.\nThis basic idea is explained further in the paper Chandra mentioned.)\nFractional Weighted Set Cover (and general fractional Covering)\nTo handle problems such as Weighted Set Cover efficiently,\nwe modify the algorithm to use non-uniform increments\n(an idea due to Garg and Konemann).   \nThe LP is $\\min\\{ c\\cdot x : (\\forall e) \\sum_{s\\ni e} x_s \\ge 1\\}$, \nwhere $e$ ranges over the elements, $s$ ranges over the sets,\nand all variables are non-negative.\nTo present the algorithm, first rewrite the problem as a general covering problem.\nLet $A_{es} = 1/c_s$ for $e\\in s$ and $A_{es} = 0$ otherwise.\nThen (with a change of variables, scaling each $x_s$ by $c_s$),\nthe LP is $\\min\\{ |x| : A x \\ge 1; x \\ge 0\\}$,\nwhich we can view as a general covering LP.\nHere is the algorithm:\n\n\nInitialize all $x_s = 0$.  Let $N=\\log(n)/\\varepsilon$.\nRepeat until all covering constraints have been deleted:\n2.1. Choose $s$ maximizing the partial derivative of Lmin$(Ax)$ w.r.t. $x_s$.\n     (Explicitly, choose $s$ maximizing $\\sum_{e\\in s} \\exp({-\\sum_{s'\\ni e} x_{s'}})/c_s$.)\n2.2. Increase $x_s$ by $\\delta$, where $\\delta$ is chosen maximally such that, for every remaining covering constraint $e$, the increase in $A_e \\cdot x$ is at most $\\varepsilon$.\n2.3 Delete all covering constraints $e$ such that $A_e\\cdot x \\ge N$.\nReturn $x/\\min_e A_e\\cdot x$.\n\n\nThe algorithm returns a $(1+O(\\varepsilon))$-approximate solution\nin $O(n\\log(n)/\\varepsilon^2)$ iterations, where $n$ is the number of covering constraints.\n(Each iteration increases some remaining $A_e x$ by $\\varepsilon$; this can happen\nonly $N/\\varepsilon$ times to a constraint before it is deleted.)\nThe proof of correctness is via essentially the same invariant as for Set Cover.\nWeighted Vertex Cover is a special case. \nMaximum Fractional Bipartite Matching\nGiven a graph $G=(U,W,E)$,\nthe natural LP for the problem is $\\max\\{|x| : \\forall v.\\, \\sum_{e\\ni v} x_e \\le 1\\}$.\nIn matrix representation, this is a packing LP $\\max\\{|x| : Ax \\le 1; x \\ge 0\\}$\nwith 0-1 coefficients ($A_{ve} = 1$ if $v\\in e$).\nSuch problems do not require non-uniform increments, so a simple algorithm analogous to the unweighted Set Cover algorithm (but for packing) will do:\n\n\nInitialize all $x_e = 0$.  Let $N=\\log(n)/\\varepsilon$.\nWhile $A x < N$:\n2.1. Choose $e$ minimizing the partial derivative of Lmax$(Ax)$ w.r.t. $x_e$.\n      (Explicitly, choose $e$ to minimize $\\sum_{v\\in e} \\exp(\\sum_{e'\\ni v} x_{e'})$.)\n2.2. Increase $x_e$ by $\\varepsilon$.  \nReturn $x/\\max_{v} A_v x$.\n\n\nThe algorithm returns a $(1-O(\\varepsilon))$-approximate solution in $O(n\\log(n)/\\varepsilon^2)$ iterations.\n(This is because each iteration increases $|x|$ by $\\varepsilon$,\nand finally, before normalization, $|x| = O(N n)$.)\nJust for fun, here is a curious alternative algorithm for Perfect Bipartite Matching.\nRecall that $G=(U,W,E)$.  Let $n=|U|=|W|$.\n\n\nInitialize all $x_e = 0$.  Let $N=4\\ln(n)/\\varepsilon$.  \nRepeat $n\\,N$ times:\n2.1. Choose $u$ uniformly at random from $U$.\n 2.2. Choose $w$ such that $(u,w)\\in E$ minimizing $\\sum_{e\\ni w} x_e$.\n 2.3. Increase $x_{uw}$ by $\\varepsilon$.   \nReturn $x/N$.\n\n\nIf $G$ has a perfect matching, the algorithm returns\nan $x$ such that $|x|=n$, and, with high probability,\nfor all vertices $u\\in U$, $1-O(\\varepsilon) \\le \\sum_{e\\ni u} x_e \\le 1+O(\\varepsilon)$,\nand for all vertices $w\\in W$, $\\sum_{e\\ni w} x_e \\le 1+O(\\varepsilon)$.\nIf you are interested in the details of the proof, please ask...\nMixed Packing and Covering\nYou may have asked about bipartite matching hoping for an example\nof a mixed packing and covering problem, that is, one of the form\n$$\\exists x?~ Px \\le p; Cx \\ge c; x \\ge 0.$$\nHere's one algorithm for such problems.\nFirst, normalize so that $p=\\overline 1$ and $c=\\overline 1$.\nLet $m$ be the number of constraints (rows in $P$ plus rows in $C$).\n\n\nInitialize all $x_j = 0$.  Let $N=2\\ln(m)/\\varepsilon$.\nWhile $P x < N$:\n2.1. Choose $j$ so that the partial derivative of Lmax$(Px)$ with respect to $x_j$ is at most the partial derivative of Lmin$(Cx)$ with respect to $x_j$.  (Explicitly, choose $j$ such that $$\\frac{\\sum_i P_{ij} \\exp(P_i x)}{\\sum_{i}\\exp(P_i x)} \\le \\frac{\\sum_i C_{ij} \\exp(-C_i x)}{\\sum_{i}\\exp(-C_i x)}.)$$\n2.2. Increase $x_j$ by $\\delta$, where $\\delta$ is chosen maximally such that no constraint $P_i x$ or remaining constraint $C_i x$ increases by more than $\\varepsilon$. \n2.3. Delete all covering constraints $i$ such that $C_i x \\ge N$.\nReturn $x/\\max_i P_i x$.\n\n\nAssuming the given problem is feasible, the algorithm\nreturns an $x$ such that $Px\\le 1$ \nand $Cx\\ge 1-O(\\varepsilon)$.\nThe number of iterations is $O(m\\ln(m)/\\varepsilon^2)$,\nbecause each iteration increases some constraint by $\\varepsilon$,\nand this can happen for each constraint at most $N$ times.\nThe proof of correctness is via the invariant\n$$\\mbox{Lmax}(Px) \\le 2\\ln(m) + (1+O(\\varepsilon)) \\mbox{Lmin}(Cx).$$\nThe invariant implies\n$$\\max Px \\le 2\\ln(m) + (1+O(\\varepsilon)) \\min Cx.$$\nAt termination the left-hand side is $\\Omega(\\log(m)/\\varepsilon)$,\nproving the performance guarantee.\nIn Step 2.1, the desired $j$ must exist as long as the original problem is feasible.\n(This is because, for any feasible $x^*$, and any $x$,\nif we were to choose a random $j'$ from the distribution $x^*/|x^*|$,\nthe expected value of the partial derivative of Lmax$(Px)$ with respect to $x_{j'}$\nwould be at most $1/|x^*|$ (see the previous proof sketch for Set Cover).\nLikewise, the expected value of the partial derivative of Lmin$(Cx)$ with respect to $x_{j'}$\nwould be at least $1/|x^*|$.\nThus, there is an $j$ such that the partial derivative of Lmax$(Px)$ with respect to $x_{j'}$\nis at most the partial derivative of Lmin$(Cx)$.)\nThen the invariant is maintained in each iteration because,\nby the choice of $x_j$ and $\\delta$, \nand the smoothness of Lmin and Lmax,\nincreasing $x_j$ to $x_j+\\delta$\nincreases Lmax$(Px)$ \nby at most $1+O(\\varepsilon)$\ntimes the increase in Lmin$(Cx)$.\nLearning (following experts / boosting)\nOne reference for understanding this connection is\nAdaptive game playing using multiplicative weights, by Freund and Schapire.\nHere is a quick summary to give the technical idea.\nConsider the following repeated game.  In each round $t$:  \n\nYou choose a probability distribution $p^t$ on $[n]$ (the $n$ so-called experts).  \nKnowing $p^t$, the adversary then chooses a payoff vector $a^t\\in [0,1]^{n}$.  \nYou receive payoff $p^t\\cdot a^t$ for the round.  \n\nThe game stops after some number of rounds.\nYour goal is to minimize your regret\nin comparison to any single expert (i.e., pure strategy) $i$.\nThat is, your goal is to minimize $(\\max_i \\sum_t a^t_i) - \\sum_t p^t\\cdot a^t$.\nFix any $\\varepsilon>0$.\nLet vector $y^t$ denote $\\varepsilon \\sum_{s \\le t} a^s$, that is,\n$\\varepsilon$ times the vector sum of the payoff vectors up to time $t$.\nRecall that $G(y)$ is the gradient of Lmax$(y)$.\nHere's the basic strategy we will analyze:\nOn round $t$, choose $p^t$ to be $G(y^{t-1})$.\nBy inspection, this gives you payoff $a^t \\cdot G(y^{t-1})$ in round $t$.\nBecause of the smoothness property of $F$,\n$$\\mbox{Lmax}(y^t) \\le \\mbox{Lmax}(y^{t-1}) + (1+O(\\varepsilon))  \\varepsilon a^t \\cdot G(y^{t-1}).$$\nThat is, in each round, $\\mbox{Lmax}(y^t)$ can't increase by more than $\\varepsilon(1+O(\\varepsilon))$ times your payoff.\nSince $\\mbox{Lmax}(\\overline 0) = \\ln n$, \nthis maintains the invariant that $\\mbox{Lmax}(y^t)$\nis at most your total payoff times $\\varepsilon(1+O(\\varepsilon)$,\nplus $\\ln(n)$.\nOn the other hand, your regret in comparison to the best expert $i$\nis $\\max_i \\sum_t a^t_i$, i.e., $\\varepsilon^{-1} \\max_i y^t_i$,\nwhich is in turn at most $\\varepsilon^{-1} \\mbox{Lmax}(y^t)$.\nThus, your regret is at most $\\varepsilon^{-1} \\ln(n)$, plus $O(\\varepsilon)$ times your total payoff.\nRemark: I think, as Freund and Schapire point out, a \"boosting\" algorithm (in learning theory) is also implicit in this analysis.  See their paper for more details.\nMinimizing total payoff\nYou can derive a similar strategy for the setting where the goal is to minimize,\nrather than maximize, the total payoff.\nYour regret, which you still want to minimize, is $\\sum_t p^t\\cdot a^t - \\min_i a^t_i$.\nIn that case, the corresponding strategy is to choose $p^t$ to be the gradient of $\\mbox{Lmin}(y^t)$.\nWith this strategy your regret is again at most\n$\\varepsilon^{-1} \\ln n$ plus $O(\\varepsilon)$ times your total payoff.\nConnection to Lagrangian-relaxation algorithms\nTo see the connection to Lagrangian-relaxation algorithms, fix a Set-Cover instance.\nConsider the latter type of game (with the goal of minimizing payoff),\nwhere the experts correspond to the elements $e$ of your set system.\nIn each round, choose the probability distribution $p^t$ \nto be the gradient of Lmin$(y^t)$ as above, \nand have the adversary choose the payoff vector $a^t$ as a function of $p^t$ as follows:\nchoose the set $s^t$ maximizing $\\sum_{e\\in s} p^t_e$,\nthen let $a^t_e = 1$ if $e\\in s^t$, and $a^t_e = 0$ otherwise.\nGiven the correct stopping condition (discussed below),\nthis process gives you exactly the Set-Cover algorithm discussed at the start.\nThe performance guarantee of the algorithm follows from the regret bound as follows.\nLet $X_s$ be the number of times the adversary chose set $s$ during the play.\nLet $x^*$ be the optimal fractional set cover.\nLet $T=|X_s|$ be the number of rounds played.\nThe regret bound implies\n$$\\textstyle \\sum_t a^t\\cdot p^t \\le  \\varepsilon^{-1}\\ln(m) + \\min_e \\sum_t a_e^t.$$\nUsing the definition of $a^t$, the $t$th payoff\n(the $t$th term in the sum on the left)\nequals $\\sum_{e\\in s^t} p^t_e$.\nThe adversary chose $s^t$ to minimize this payoff.\nIf the adversary had instead chosen $s^t$ randomly \nfrom the distribution $x^*/|x^*|$, the expectation of\nthe payoff would have been\n$$ \\sum_s \\frac{x^*_s}{|x^*|} \\sum_{e\\in s} p^t_e\n~=~\n\\frac{1}{|x^*|} \\sum_e p^t_e \\sum_{s\\ni e} x^*_s \n~\\ge~\n\\frac{1}{|x^*|} \\sum_e p^t_e\n ~=~\n\\frac{1}{|x^*|}.$$\n(Above we use that $\\sum_{s\\ni e} x^*_s \\ge 1$ for all $e$, and $|p^t| = 1$.)\nSince each payoff is at least $1/|x^*|$, the regret bound implies\n$$ \\frac{T}{|x^*|} \\le  \\varepsilon^{-1}\\ln(m) + \\min_e \\sum_t a_e^t.$$\nBy the definition of $X$,\nwe have $|X| = T$ (each round chooses one set),\nand $\\sum_t a_e^t = \\sum_e [e\\in s^t] = \\sum_{s\\ni e} X_s$,\ngiving\n$$\\frac{|X|}{|x^*|} \\le  \\varepsilon^{-1}\\ln(m) +\\min_e \\sum_{s\\ni e} X_s.$$ \nWe make the process stop when $\\min_e \\sum_{s\\ni e} X_s = \\Omega(\\varepsilon^{-2}\\ln m)$, \nso then (rearranging terms)\n$$\\frac{|X|}{\\min_e \\sum_{s\\ni e} X_s}~ \\le~ (1+O(\\varepsilon)|x^*|.$$\nThat is, normalizing $X$ gives a fractional set cover\nof size at most $(1+O(\\varepsilon))$ times optimum.\nRemark: In a sense, this learning theory interpretation\ngeneralizes the algorithmic interpretation.  However, some\nof the algorithmic techniques necessary for efficiency \n(such as non-uniform increments and dropping satisfied\ncovering constraints) don't seem to carry over into the \nlearning theory setting naturally.  Likewise, algorithms for\nmixed packing and covering LPs (e.g. these)\ndon't seem to have natural analogues in the learning-theory setting.", "meta": {"post_id": 4697, "input_score": 36, "output_score": 26, "post_title": "Toy Examples for Plotkin-Shmoys-Tardos and Arora-Kale solvers"}}
{"input": "2 questions for the computational geometers or algebraists:\nI am just beginning to dive into computational geometry and I am loving it =)\nI am attempting to read the famous article by Guibas and Stolfi called \"Primitives for the manipulation of general subdivisions and the computation of Voronoi Diagrams\" in order to implement a Delaunay triangulation algorithm. I am tempted to skip all the theoretical stuff and just read the description of their quad-edge data structure to save time. However, I think it may be worth it to understand all the math in the article if the structure is widely used, or just because it may be beautiful.\nThe math is a little to dense for me. I'm not completely ignorant on topology, but the description of their edge algebra requires knowledge of abstract algebra that I don't have.\nMy two questions are: What other applications of the quad-edge structure are there besides computing Delaunay/Voronoi? It seems like an extremely powerful tool.\nThe second question; What is an abstract algebra? It would be great if you could give me a reference to an introduction to abstract algebra, just enough so I can understand the section on their edge algebra. \nThank you!", "output": "I think Guibas and Stolfi's \u201cedge algebra\u201d formalism is a bit unnecessary.\nAll that's really necessary is to remember the distinction between primal and dual graphs.  Each face $f$ of the primal graph has a corresponding dual vertex $f^*$;  each edge $e$ of the primal graph has a corresponding dual edge $e^*$; and each vertex $v$ of the primal graph has a corresponding dual face $v^*$.  Primal edges connect primal vertices and separate primal faces; dual edges connect dual vertices and separate dual faces.  The dual of the dual of anything is the original thing.  See Figure 4 in Guibas and Stolfi's paper:\n\nGuibas and Stolfi propose thinking about each edge (either primal or dual) as a collection of four directed, oriented edges; for simplicity, I'll call these darts.  Each dart $\\vec{e}$ points from one endpoint $\\text{tail}(\\vec{e})$ to the other endpoint $\\text{head}(\\vec{e})$, and locally separates two faces $\\text{left}(\\vec{e})$ and $\\text{right}(\\vec{e})$.  The choice of which endpoint to call $\\text{tail}(\\vec{e})$ is the dart's direction, and the choice of which face to call $\\text{left}(\\vec{e})$ is its orientation.  (Guibas and Stolfi use \u201cOrg\u201d and \u201cDest\u201d instead of \u201ctail\u201d and \u201chead\u201d, but I prefer the shorter labels, because Unnecessary Abbreviations Are Evil.)\nFor any dart $\\vec{e}$, Guibas and Stolfi associate three related darts:\n\n$\\text{tailNext}(\\vec{e})$: The dart leaving $\\text{tail}(\\vec{e})$ next in counterclockwise order after $\\vec{e}$.\n$\\text{flip}(\\vec{e})$: The \u201csame\u201d dart as $\\vec{e}$, but with $\\text{left}(\\vec{e})$ and $\\text{right}(\\vec{e})$ swapped.\n$\\text{rotate}(\\vec{e})$: The dual dart obtained by giving $\\vec{e}$ a quarter turn counterclockwise around its midpoint. \n\n\nThese three functions satisfy all sorts of wonderful identities, like the following:\n\n$\\text{right}(\\text{tailNext}(\\vec{e})) = \\text{left}(\\vec{e})$\n$\\text{right}(\\text{flip}(\\vec{e})) = \\text{left}(\\vec{e})$\n$\\text{right}(\\text{rotate}(\\vec{e})) = \\text{head}(\\vec{e})^*$\n$\\text{flip}(\\text{flip}(\\vec{e})) = \\vec{e}$\n$\\text{rotate}(\\text{rotate}(\\text{rotate}(\\text{rotate}(\\vec{e})))) = \\vec{e}$\n$\\text{tailNext}(\\text{rotate}(\\text{tailNext}(\\text{rotate}(\\vec{e})))) = \\vec{e}$\n\nFor a complete list, see page 83 of the paper (but beware that the authors use postfix notation $e~Flip$, presumably because it's closer to the declarative code e.Flip).  Guibas and Stolfi call any triple of functions satisfying all these identities an edge algebra.\nMoreover, given these three functions, one can define several other useful functions like\n\n$\\text{reverse}(\\vec{e}) = \\text{rotate}(\\text{flip}(\\text{rotate}(\\vec{e})))$ \u2014 swap head and tail vertices\n$\\text{leftNext}(\\vec{e}) = \\text{rotate}(\\text{tailNext}(\\text{rotate}(\\text{rotate}(\\text{rotate}(\\vec{e})))))$ \u2014 the next dart after $\\vec{e}$ in counterclockwise order around the face $\\text{left}(\\vec{e})$\n\nFinally, knowing these functions tell you absolutely everything about the topology of the subdivision, and any polygonal subdivision of any surface (orientable or not) can be encoded using these three functions.\nThe quad-edge data structure is a particularly convenient representation of a surface graph that provides access to all these functions, along with several other constant-time operations like inserting, deleting, contracting, expanding, and flipping edges; splitting or merging vertices or faces; and adding or deleting handles or cross-caps.\nHave fun!", "meta": {"post_id": 4746, "input_score": 18, "output_score": 31, "post_title": "The quad-edge data structure (Delaunay/Voronoi)"}}
{"input": "This question is inspired by a similar question about applied mathematics on mathoverflow, and that nagging thought that important questions of TCS such as P vs. NP might be independent of ZFC (or other systems). As a little background, reverse mathematics is the project of finding the axioms necessary to prove certain important theorems. In other words, we start at a set of theorems we expect to be true and try to derive the minimal set of 'natural' axioms that make them so. \nI was wondering if the reverse mathematics approach has been applied to any important theorems of TCS. In particular to complexity theory. With deadlock on many open questions in TCS it seems natural to ask \"what axioms have we not tried using?\". Alternatively, have any important questions in TCS been shown to be independent of certain simple subsystems of second-order arithmetic?", "output": "Yes, the topic has been studied in proof complexity. It is called Bounded Reverse Mathematics. You can find a table containing some reverse mathematics results on page 8 of Cook and Nguyen's book, \"Logical Foundations of Proof Complexity\",  2010. Some of Steve Cook's previous students have worked on similar topics, e.g. Nguyen's thesis, \"Bounded Reverse Mathematics\", University of Toronto, 2008.\nAlexander Razborov (also other proof complexity theorists) has some results on the weak theories needed to formalize the circuit complexity techniques and prove circuit complexity lowerbounds. He obtains some unprovability results for weak theories, but the theories are considered too weak.\nAll of these results are provable in $RCA_0$ (Simpson's base theory for Reverse Mathematics), so AFAIK we don't have independence results from strong theories (and in fact such independence results would have strong consequences as Neel has mentioned, see Ben-David's work (and related results) on independence of $\\mathbf{P} vs. \\mathbf{NP}$ from $PA_1$ where $PA_1$ is an extension of $PA$).", "meta": {"post_id": 4816, "input_score": 38, "output_score": 24, "post_title": "Axioms necessary for theoretical computer science"}}
{"input": "Is a deterministic polynomial-time algorithm known for the following problem: \nInput: a natural number $n$ (in binary encoding)\nOutput: a prime number $p > n$. \n(According to a list of open problems by Leonard Adleman, the problem was open in 1995.)", "output": "The current best unconditional result was given by Odlyzko,  which finds a prime $p >N$ in $O(N^{1/2 + o(1)})$ time. The strong conjecture in Polymath4 project seeks to resolve if this can be done in polynomial time, under reasonable number-theoretic assumptions like the GRH. \nhttp://michaelnielsen.org/polymath1/index.php?title=Finding_primes\nCurrently the project seeks to answer the following question:\n\nGiven a number $N$ and an interval between $N$ and $2N$, check in time $O(N^{1/2 - c})$ for some $c>0$ if the interval contains a prime.\n\nSo far, they have a strategy which determines the parity of the number of primes in the interval.\nhttp://polymathprojects.org/2010/06/29/draft-version-of-polymath4-paper/", "meta": {"post_id": 4882, "input_score": 28, "output_score": 23, "post_title": "Finding a prime greater than a given bound"}}
{"input": "Suppose, transformation T is defined as given in the diagrams below. \nEvery vertex (v) is replaced by deg(v)-gon. And then graph is reconnected as shown.\n\nThose on the left are Gs and on the right are T(G)s.\nIt is easy to see that every vertex in  T(G) has degree 3. \nThis paper claims that graph isomorphism of such graphs can be tested in polynomial time. Also, G can be converted to T(G) in polynomial time. \nStatement I: G1 and G2 are isomorphic iff T(G1) and T(G2) are isomorphic.\nEDIT:\nSpecifications for G1,G2:\n\nG1 = (V1,E1) and G2=(V2,E2) \n|E1| = |E2| and |V1| = |V2|\nSort[{deg(v)|v in V1}] = Sort[{deg(u)| u in V2}]\n\nIf Statement I is True then do we have solution for GI problem? \nNote: I am n00b in this field. I invent funny techniques daily.", "output": "Along with the already-given answers stating the existence of two graphs G1\u2260G2 for which T(G1)=T(G2), there is also a different problem: there exist pairs G1=G2 for which T(G1)\u2260T(G2). This is because the transformation depends not just on the isomorphism class of G, but also on the cyclic ordering of the edges around each vertex of G.\nEdited to add an example based on Mark Reitblatt's comment:", "meta": {"post_id": 5003, "input_score": 5, "output_score": 23, "post_title": "Is this graph transformation unique up to isomorphism? [Answer:NO]"}}
{"input": "My question today is (as usual) a bit silly; but I would request you to kindly consider it.\nI wanted to know about the genesis and/or motivation behind the treewidth concept. I sure understand that it is used in FPT algorithms, but I do not think that that was the reason why this notion was defined.\nI have written up the scribe notes on this topic in the class of Prof Robin Thomas. I think I understand some of the applications of this concept (as in it transfers separation properties of the tree to the graph decomposed), but for some reason I am not really convinced that the reason this concept was developed was to measure closeness of a graph to a tree.\nI will try to make myself more clear (I am not sure if I can, please let me know if the question is not clear). I would like to know if similar notions existed elsewhere in some other branch of mathematics from where this notion was supposedly \"borrowed\". My guess will be topology -- but owing to my lack of background, I cannot say anything.\nThe primary reason as to why I am curious about this would be -- the first time I read its definition, I was not sure why and how would anyone conceive of it and to what end. If the question is not still clear I would finally try stating it this way - Let us pretend the notion of treewidth did not exist. What natural questions (or extensions of some mathematical theorems/concepts) to discrete settings will lead one to conceive of a definition (let me use the word involved) as treewidth's.", "output": "If you really want to know what led Neil Robertson and me to tree-width, it wasn't algorithms at all. We were trying to solve Wagner's conjecture that in any infinite set of graphs, one of them is a minor of another, and we were right at the beginning. We knew it was true if we restricted to graphs with no k-vertex path; let me explain why. We knew all such graphs had a simple structure (more exactly, every graph with no k-vertex path has this structure, and every graph with this structure has no 2^k-vertex path); and we knew that in every infinite set of graphs all with this structure, one of them was a minor of another. So Wagner's conjecture was true for graphs with a bound on their maximum path length.\nWe also knew it was true for graphs with no k-star as a minor, again because we had a structure theorem for such graphs. We tried to look for more general minors that had corresponding structure theorems that we could use to prove Wagner's conjecture, and that led us to path-width; exclude ANY tree as a minor and you get bounded path-width, and if you have bounded path-width then there are trees you can't have as a minor. (That was a hard theorem for us; we had a tremendously hard proof in the first Graph Minors paper, don't read it, it can be made much easier.) But we could prove Wagner's conjecture for graphs with bounded path-width, and that meant it was true for graphs not containing any fixed tree as a minor; a big generalization of the path and star cases I mentioned earlier. \nAnyway, with that done we tried to get further. We couldn't do general graphs, so we thought about planar graphs. We found a structure theorem for the planar graphs that did not contain any fixed planar graph as a minor (this was easy);\nit was bounded tree-width. We proved that for any fixed planar graph, all the planar graphs that did not contain it as a minor had bounded tree-width. As you can imagine, that was really exciting; by coincidence, the structure theorem for excluding planar graphs (inside bigger planar graphs) was a natural twist on the structure theorem for excluding trees (inside general graphs). We felt we were doing something right. And that let us prove Wagner's conjecture for all planar graphs, because we had this structure theorem. \nSince tree-width worked for excluding planar graphs inside bigger planar graphs, it was a natural question whether it worked for excluding planar graphs inside non-planar graphs -- was it true that for every fixed planar graph, all graphs not containing it as a minor had bounded tree-width? This we couldn't prove for a long time, but that's how we got to thinking about tree-width of general graphs. And once we had the concept of tree-width, it was pretty clear that it was good for algorithms. (And yes, we had no idea that Halin had thought about tree-width already.)", "meta": {"post_id": 5018, "input_score": 68, "output_score": 68, "post_title": "The origin of the notion of treewidth"}}
{"input": "I think that a size hierarchy theorem for circuit complexity can be a major breakthrough in the area.\nIs it an interesting approach to class separation?\nThe motivation for the question is that we have to say\n\nthere is some function that cannot be computed by size $f(n)$ circuits and can be computed by a size $g(n)$ circuit where $f(n)<o(g(n))$. (and possibly something regarding the depth)\n\nso, if $f(m)g(n) \\leq n^{O(1)}$, the property seem to be unnatural (it violates the largeness condition). Clearly we can't use diagonalization, because we aren't in a uniform setting. \nIs there a result in this direction?", "output": "In fact it is possible to show that, for every $f$ sufficiently small (less than $2^n/n$), there are functions computable by circuits of size $f(n)$ but not by circuits of size $f(n)-O(1)$, or even $f(n)-1$, depending on the type of gates that you allow.\nHere is a simple argument that shows that there are functions computable in size $f(n)$ but not size$ f(n)-O(n)$.\nWe know that:\n\nthere is a function $g$ that requires circuit complexity at least $2^n/O(n)$, and, in particular, circuit complexity more than $f(n)$.\nthe function $z$ such that $z(x)=0$ for every input $x$ is computable by a constant-size circuit.\nif two functions $g_1$ and $g_2$ differ only in one input, then their circuit complexity differs by at most $O(n)$\n\nSuppose that $g$ is nonzero on $N$ inputs. Call such inputs $x_1,\\ldots,x_N$. We can consider, for each $i$, the function $g_i(x)$ which is the indicator function of the set $\\{ x_1,\\ldots,x_i \\}$; thus $g_0=0$ and $g_N=g$.\nClearly there is some $i$ such that $g_{i+1}$ has circuit complexity more than $f(n)$ and $g_i$ has circuit complexity less than $f(n)$. But then $g_{i}$ has circuit complexity less than $f(n)$ but more than $f(n) - O(n)$.", "meta": {"post_id": 5110, "input_score": 18, "output_score": 33, "post_title": "Hierarchy theorem for circuit size"}}
{"input": "I understand that Turing completeness requires unbounded memory and unbounded time.\nHowever there is a finite amount of atoms in this universe, thus making memory bounded. For example even though $\\pi$ is irrational there is no way to store more than a certain number of digits even if all the atoms in the universe were used for this purpose.\nWhat then are the limits of computability of an implemented Turing machine (which could use all the resources of the universe but no more) based on the limits of the universe? What is the maximum number of digits of $\\pi$? Are there any papers on this subject that might be interesting to read?", "output": "Seth Lloyd has a paper on the subject. You need energy to compute, but if you put too much energy into a small region, it forms a black hole. This slows down time (making the time it takes for the computation to complete relatively longer), and any computation done in the interior of a black hole is wasted, as the results cannot be extracted from the black hole and used. Seth calculates the limits on the amount of computation possible, and shows that for some measures of computation, the most computationally intensive environment possible in the universe would be that surrounding a black hole.", "meta": {"post_id": 5157, "input_score": 19, "output_score": 36, "post_title": "What are the limits of computation in this universe?"}}
{"input": "Is there a way to prove the following theorem in Coq?\nTheorem bool_pirrel : forall (b : bool) (p1 p2 : b = true), p1 = p2.\nEDIT: An attempt to give a brief explanation for \"what proof irrelevance is\" (correct me someone if I am wrong or inaccurate)\nThe basic idea is that in the proposition world (or the Prop sort in Coq), what you (and you should) really care about is the provability of a proposition, not the proofs of it, there may be many (or none). In case you have multiple proofs, from the provability point of view, they are equal in the sense that they prove the same proposition. So their distinction is just irrelevant. This differs from the computational point of view where you really care about the distinction of two terms, e.g., basically, you don't want the two inhabitants of the bool type (or Set in Coq's words), namely true and false to be equal. But if you put them in Prop, they are treated equal.", "output": "Proof irrelevance in general is not implied by the theory behind Coq. Even proof irrelevance for equality is not implied; it is equivalent to Streicher's axiom K. Both can be added as axioms.\nThere are developments where it's useful to reason about proof objects, and proof irrelevance makes this nigh-impossible. Arguably these developments should have all the objects whose structure matters recast in Set, but with the basic Coq theory the possibility is there.\nThere is an important subcase of proof irrelevance that always holds. Streicher's axiom K always holds on decidable domains, i.e. equality proofs on decidable sets are unique. The general proof is in the Eqdep_dec module in the Coq standard library. Here's your theorem as a corollary (my proof here is not necessarily the most elegant):\nRequire Bool.\nRequire Eqdep_dec.\nTheorem bool_pirrel : forall (b : bool) (p1 p2 : b = true), p1 = p2.\nProof.\n  intros; apply Eqdep_dec.eq_proofs_unicity; intros.\n  destruct (Bool.bool_dec x y); tauto.\nQed.\n\nFor this special case, here's a direct proof (inspired by the general proof in Eqdep_dec.v). First, define we define a canonical proof of true=b (as usual in Coq, it's easier to have the constant first). Then we show that any proof of true=b has to be refl_equal true.\nLet nu b (p:true = b) : true = b :=\n  match Bool.bool_dec true b with\n    | left eqxy => eqxy\n    | right neqxy => False_ind _ (neqxy p)\n  end.\nLemma bool_pcanonical : forall (b : bool) (p : true = b), p = nu b p.\nProof.\n  intros. case p. destruct b.\n  unfold nu; simpl. reflexivity.\n  discriminate p.\nQed.\n\nIf you add classical logic to Coq, you get proof irrelevance. Intuitively speaking, classical logic gives you a decision oracle for propositions, and that's good enough for axiom K. There is a proof in the Coq standard library module Classical_Prop.", "meta": {"post_id": 5158, "input_score": 23, "output_score": 31, "post_title": "Prove proof irrelevance in Coq?"}}
{"input": "This is a follow up question to \nWhat is the difference between proofs and programs (or between propositions and types)?\nWhat program would correspond to a non-constructive (classical) proof of the form $\\forall k \\ T(e,k) \\lor \\lnot \\forall k \\ T(e,k)$? (Assume that $T$ is some interesting decidable relation e.g. $e$-th TM does not halt in $k$ steps.)\n(ps: I am posting this question partly because I am interested in learning more about what Neel means by \"the Godel-Gentzen translation is a continuation-passing transformation\" in his comment.)", "output": "This an interesting question. Obviously one can't expect to have a program that decides for each $e$ whether $\\forall k T(e, k)$ holds or not, as this would decide the Halting Problem. As mentioned already, there are several ways of interpreting proofs computationally: extensions of Curry-Howard, realizability, dialectica, and so on. But they would all computationally interpret the theorem you mentioned more or less in the following way.\nFor simplicity consider the equivalent classical theorem\n(1) $\\exists i \\forall j (\\neg T(e, j) \\to \\neg T(e, i))$\nThis is (constructively) equivalent to the one mentioned because given $i$ we can decide whether $\\forall k T(e, k)$ holds or not by simply checking the value of $\\neg T(e, i)$. If $\\neg T(e, i)$ holds then $\\exists i \\neg T(e, i)$ and hence $\\neg \\forall i T(e, i)$. If on the other hand $\\neg T(e, i)$ does not hold then by (1) we have $\\forall j (\\neg T(e, j) \\to \\bot)$ which implies $\\forall j T(e, j)$. \nNow, again we can't compute $i$ in (1) for each given $e$ because we would again solve the Halting Problem. What all interpretations mentioned above would do is to look at the equivalent theorem\n(2) $\\forall f \\exists i' (\\neg T(e, f(i')) \\to \\neg T(e, i'))$\nThe function $f$ is called the Herbrand function. It tries to compute a counter example $j$ for each given potential witness $i$. It is clear that (1) and (2) are equivalent. From left to right this is constructive, simply take $i' = i$ in (2), where $i$ is the assumed witness of (1). From right to left one has to reason classically. Assume (1) was not true. Then, \n(3) $\\forall i \\exists j \\neg (\\neg T(e, j) \\to \\neg T(e, i))$ \nLet $f'$ be a function witnessing this, i.e. \n(4) $\\forall i \\neg (\\neg T(e, f'(i)) \\to \\neg T(e, i))$ \nNow, take $f = f'$ in (2) and we have $(\\neg T(e, f'(i')) \\to \\neg T(e, i'))$, for some $i'$. But taking $i = i'$ in (4) we obtain the negation of that, contradiction. Hence (2) implies (1).\nSo, we have that (1) and (2) are classically equivalent. But the interesting thing is that (2) has now a very simple constructive witness. Simply take $i' = f(0)$ if $T(e, f(0))$ does not hold, because then the conclusion of (2) is true; or else take $i' = 0$ if $T(e, f(0))$ holds, because then $\\neg T(e, f(0))$ does not hold and the premise of (2) is false, making it again true.\nHence, the way to computationally interpret a classical theorem like (1) is to look at a (classically) equivalent formulation which can be proven constructively, in our case (2). \nThe different interpretations mentioned above only diverge on the way the function $f$ pops up. In the case of realizability and the dialectica interpretation this is explicitly given by the interpretation, when combined with some form of negative translation (like Goedel-Gentzen's). In the case of Curry-Howard extensions with call-cc and continuation operators the function $f$ arises from the fact that the program is allowed to \"know\" how a certain value (in our case $i$) will be used, so $f$ is the continuation of the program around the point where $i$ is computed.\nAnother important point is that you want the passage from (1) to (2) to be \"modular\", i.e. if (1) is used to prove (1'), then its interpretation (2) should be used used in similar way to prove the interpretation of (1'), say (2'). All the interpretations mentioned above do that, including the Goedel-Gentzen negative translation.", "meta": {"post_id": 5245, "input_score": 30, "output_score": 25, "post_title": "Curry-Howard and programs from non-constructive proofs"}}
{"input": "If a problem is NP-hard (using polynomial time reductions), does that imply that it is P-hard (using log space or NC reductions)?  It seems intuitive that if it is as hard as any problem in NP that it should be as hard as any problem in P, but I don't see how to chain the reductions and get a log space (or NC) reduction.", "output": "No such implication is known.  In particular it may be that $L \\ne P = NP$ in which case all problems (including trivial ones) are NP-hard under poly-time reductions (as the reduction can just solve the problem), but trivial ones (in particular ones that lie in L) are surely not P-hard under logspace reductions (as otherwise L=P).  \nThe same goes for NC instead of L.", "meta": {"post_id": 5395, "input_score": 22, "output_score": 32, "post_title": "Does NP-hardness imply P-hardness?"}}
{"input": "I'm a beginner working on methods proving program equivalence. I've read a few papers about defining logical relations or simulations to prove two programs are equivalent. But I am quite confused about these two techniques.\nI only know logical relations are inductively defined while simulations are based on coinduction. Why are they defined in such ways? What are their pros and cons respectively? Which one should I choose in different situations?", "output": "I have an answer to this question which is possibly novel.  In fact, I am still thinking through it for the last 6 months or so, and it hasn't been written about in papers yet.\nThe general thesis is that relational reasoning principles like \"logical relations\", \"simulations\", and even \"invariants\" are manifestations of data abstraction or information hiding.  Wherever there is information hiding, these principles crop up.\nThe first people to discover it were automata theorists.  Automata have hidden state.  So you need relational reasoning to talk about their equivalence.  Automata theorists struggled with homomorphisms for a while, gave up, and came up with a notion called \"relational covering\", which is a form of simulation relations.\nMilner picked up the idea in a little-known but very fundamental paper called \"An algebraic notion of simulation between programs\" in 1971.  Hoare knew it and used it in coming up with \"Proof of correctness of data representations\" in 1972 (but used abstraction functions instead of relations because he thought they were \"simpler\").  He later retracted the simplicity claim and went back to using relations in \"Data refinement refined\".  Reynolds used relational reasoning in \"Craft of Programming\", Chapter 5 (1981).  He thought relations were more natural and general than abstraction functions.  If you go back and read this chapter, you will find relational parametricity ideas lurking around, waiting to be discovered.  Sure enough, two years later, Reynolds published \"Types, abstraction and parametric polymorphism\" (1983).\nIt looks like all these ideas have nothing to do with types, but they really do.  Stateful languages and models have built-in data abstraction.  You don't need to define an \"abstract data type\" to get information hiding.  You just declare a local variable and hide it.  We can teach it to first year students in Java classes in the first few weeks.  No sweat.\nFunctional languages and models, on the other hand, have to get their information hiding via types.  Functional models don't have built-in data abstraction.  We have to add it on explicitly, using $\\forall$ or $\\exists$.  So, if you translate a stateful language into a functional language, you will notice all the local state getting translated into type variables.  For an explicit description of how this works, see my paper \"Objects and classes in Algol-like languages\", but the ideas really come from Reynolds 1981 (\"The Essence of Algol\"). We are just understanding those classic ideas better now.\nTake two machines $M$ and $M'$ that you want to prove equivalent.  Milner 1971 says, define a relation between the states of $M$ and $M'$ and show that the two machines preserve the relation.  Reynolds parametricity says, think of the states of the machines as belonging to types $X$ and $X'$.  Define a relation $R$ between them.  If the machines are of type $F(X)$ and $F(X')$, parameterized by the types of their states, then check that the two machines are related by the relation $F(R)$.  \nSo, simulations and relational parametricity are essentially the same idea.  It is not merely a superficial resemblance.  The former is made for stateful languages where there is built-in data abstraction.  The latter is made for stateless languages where data abstraction is obtained via type variables.  \nWhat about logical relations then?  On the surface, logical relations appear to be a more general idea.  Whereas parametricity talks about how to relate type variables within the same model, logical relations appear to relate types across different models.  (Dave Clarke wrote a brilliant exposition of this earlier.)  But my feeling is (and it still needs to be demonstrated) that this is an instance of some form of higher-type parametricity which hasn't yet been formulated.  Stay tuned for more progress on that front.\n\n[Note added] The connection between logical relations and simulations is discussed in our recent paper Logical relations and parametricty: A Reynolds programme for Category Theory and Programming Languages.", "meta": {"post_id": 5427, "input_score": 32, "output_score": 24, "post_title": "What are the differences between logical relations and simulations?"}}
{"input": "I wonder if there is any justification to believe that $NL=L$ or to believe that $NL\\neq L$?\nIt is known that $NL \\subset L^2$.\nThe literature on derandomization of $RL$ is pretty convincing that $RL=L$. \nDoes anyone know about some articles or ideas convincing that $NL\\neq L$?", "output": "First, let me cite skepticism that $L \\neq NL$. As it has been shown that undirected graph connectivity is in $L$ (Reingold), and that $NL=coNL$ (Immerman-Szelepcs\u00e9nyi), I think that confidence in $L \\neq NL$ has only decreased. Some prominent researchers have never had a strong belief. For example, Juris Hartmanis (founder of the CS department at Cornell and Turing award winner) has said:\n\nWe believe that NLOGSPACE differs from LOGSPACE, but not with the same depth of conviction as for the other complexity classes. (Source)\n\nI know he said similar things in the literature as far back as the 70's.\nThere is some evidence against $L=NL$, although it is circumstantial. There has been work on proving space lower bounds for $s$-$t$ connectivity (the canonical $NL$-complete problem) in restricted computational models. These models are strong enough to run the algorithm of Savitch's theorem (which gives an $O(\\log^2 n)$ space algorithm) but are provably not strong enough to do asymptotically better. See the paper \"Tight Lower Bounds for st-Connectivity on the NNJAG Model\". These NNJAG lower bounds show that, if it's possible to beat Savitch's theorem and even get $NL \\subseteq SPACE[o(\\log^2 n)]$, one will certainly have to come up with an algorithm that's very different from Savitch. \nStill, I don't know of any unlikely, unexpected formal consequences that come from $L=NL$ (except for the obvious ones). Again, this is primarily because we already know things like $NL=coNL$.", "meta": {"post_id": 5431, "input_score": 23, "output_score": 31, "post_title": "Is there any justification to believe that $NL\\neq L$?"}}
{"input": "Banach's fixed point theorem says that if we have a nonempty complete metric space $A$, then any uniformly contractive function $f : A \\to A$ it has a unique fixed point $\\mu(f)$. However, the proof of this theorem requires the axiom of choice -- we need to choose an arbitrary element $a \\in A$ to start iterating $f$ from, to get the Cauchy sequence $a, f(a), f^2(a), f^3(a), \\ldots$.   \n\nHow are fixed point theorems stated in constructive analysis? \nAlso, are there any concise references to constructive metric spaces?\n\nThe reason I ask is that I want to construct a model of System F in which the types additionally carry metric structure (among other things). It's rather useful that in constructive set theory, we can cook up a family of sets $U$, such that $U$ is closed under products, exponentials, and $U$-indexed families, which makes it easy to give a model of System F. \nIt would be very nice if I could cook up a similar family of constructive ultrametric spaces. But since adding choice to constructive set theory makes it classical, obviously I need to be more careful about fixed point theorems, and probably other stuff too.", "output": "The axiom of choice is used when there is a collection of \"things\" and you choose one element for each \"thing\". If there is just one thing in the collection, that's not the axiom of choice. In our case we only have one metric space and we are \"choosing\" a point in it. So that's not the axiom of choice but elimination of existential quantifiers, i.e., we have a hypothesis $\\exists x \\in A . \\phi(x)$ and we say \"let $x \\in A$ be such that $\\phi(x)$\". Unfortunately, people often say \"choose $x \\in A$ such that $\\phi(x)$\", which then looks like application of the axiom of choice.\nFor reference, here is a constructive proof of Banach's fixed point theorem.\nTheorem: A contraction on an inhabited complete metric space has a unique fixed point.\nProof. Suppose $(M,d)$ is an inhabited complete metric space and $f : M \\to M$ is a contraction. Because $f$ is a contraction there exists $\\alpha$ such that $0 < \\alpha < 1$ and $d(f(x), f(y)) \\leq \\alpha \\cdot d(x,y)$ for all $x, y \\in M$.\nSuppose $u$ and $v$ are fixed point of $f$. Then we have $$d(u,v) = d(f(u), f(v)) \\leq \\alpha d(u,v)$$ from which it follows that $0 \\leq d(u,v) \\leq (\\alpha - 1) d(u,v) \\leq 0$, hence $d(u,v) = 0$ and $u = v$. This proves that $f$ has at most one fixed point.\nIt remains to prove the existence of a fixed point. Because $M$ is inhabited there exists $x_0 \\in M$. Define the sequence $(x_i)$ recursively by $$x_{i+1} = f(x_i).$$ We can prove by induction that $d(x_i, x_{i+1}) \\leq \\alpha^i \\cdot d(x_0, x_1)$. From this it follows that $(x_i)$ is a Cauchy sequence. Because $M$ is complete, the sequence has a limit $y = \\lim_i x_i$. Since $f$ is a contraction, it is uniformly continuous and so it commutes with limits of sequences: $$f(y) = f(\\lim_i x_i) = \\lim_i f(x_i) = \\lim_i x_{i+1} = \\lim_i x_i = y.$$\nThus $y$ is a fixed point of $f$. QED\nRemarks:\n\nI was careful not to say \"choose $\\alpha$\" and \"choose $x_0$\". It is common to say such things, and they just add to the confusion that prevents ordinary mathematicians from being able to tell what is and isn't the axiom of choice.\nIn the uniqeness part of the proof people often assume unnecessarily that there are two different fixed points and derive a contradiction. This way they have only managed to prove that if $u$ and $v$ are fixed points of $f$ then $\\lnot\\lnot (u = v)$. So now they need excluded middle to get to $u = v$. Even for classical mathematics this is suboptimal and just shows that the author of the proof does not exercise good logical hygiene.\nIn the existence part of the proof, the sequence $(x_i)$ depends on the existential witness $x_0$ we get from eliminating the assumption $\\exists x \\in M . \\top$. There is nothing wrong with that. We do that sort of thing all the time. We did not choose anything. Think of it this way: someone else gave us a witness $x_0$ for inhabitedness of $M$, and we are free to do something with it.\nClassically, \"$M$ is inhabited\" ($\\exists x \\in M . \\top$) and \"$M$ is non-empty\" ($\\lnot\\forall x \\in M . \\bot$) are equivalent. Constructively, the former makes more sense and is useful.\nBecause we showed uniqueness of fixed points we actually get a fixed-point operator $\\mathrm{fix}_M$ from contractions on $M$ to points of $M$, rather than just a $\\forall\\exists$ statement.\nFinally, the following fixed-point theorems have constructive versions:\n\nKnaster-Tarski fixed-point theorem for monotone maps on complete lattices\nBanach's fixed-point theorem for contractions on a complete metric space\nKnaster-Tarski fixed-point theorem for monotone maps on dcpos (proved by Pataraia)\nVarious fixed-point theorems in domain theory usually have constructive proofs\nRecursion theorem is a form of fixed-point theorem and it has a constructive proof\nI proved that Knaster-Tarski fixed-point theorem for monotone maps on chain-complete posets does not have a constructive proof. Similarly, the Bourbaki-Witt fixed-point theorem for progressive maps on chain-complete posets fails constructively. The counter-example for the later one comes from the effective topos: in the effective topos ordinals (suitably defined) form a set and the successor maps is progressive and has no fixed points. By the way, the successor map on the ordinals is not monotone in the effective topos.\n\n\nNow that's rather more information than you asked for.", "meta": {"post_id": 5922, "input_score": 15, "output_score": 22, "post_title": "Fixed point theorems for constructive metric spaces?"}}
{"input": "The Not All Equal $k$-SAT problem (NAE $k$-SAT), given a set $C$ of clauses over a set $X$ of boolean variables such that each clause contains at most $k$ literals, asks whether there exists a truth assignment of the variables such that each clause contains at least one true and at least one false literal.\nThe PLANAR NAE $k$-SAT problem is the restriction of NAE $k$-SAT to those instances where the incidence bipartite graph of $C$ and $X$ (i.e. the graph of parts $C$ and $X$ with an edge between $x\\in X$ and $c\\in C$ if and only if $x$ or $\\overline{x}$ belongs to $c$), is planar.\nIt is known that NAE 3-SAT is NP-complete (Garey and Johnson, Computers and Intractability; A Guide to the Theory of NP-Completeness), but PLANAR NAE 3-SAT is in P (see Planar NAE3SAT is in P, B. Moret, ACM SIGACT News, Volume 19 Issue 2, Summer 1988 - unfortunately I do not have access to this paper).\nIs PLANAR NAE $k$-SAT in P for some $k\\geq 4$? Is there a value of $k$ for which it has been shown to be NP-complete?", "output": "PLANAR NAE $k$-SAT is in P for all values of $k$ . \nReason is that we can reduce PLANAR NAE $k$-SAT to PLANAR NAE $3$-SAT. Let $\\phi$ be an instance of PLANAR NAE $k$-SAT, and suppose $\\phi$ contains a clause $C$ with literals $\\ell_1, \\ell_2, \\dots, \\ell_k$. Introduce a new variable $v_C$, and replace $C$ with two NAE clauses $C_1$ and $C_2$. $C_1$ contains $3$ literals $\\ell_1$, $\\ell_2$, and $v_C$, while $C_2$ contains $k-1$ literals $\\bar{v}_C, \\ell_3, \\ell_4, \\dots, \\ell_k$. It's easy to see that $C$ is satisfiable iff $C_1 \\wedge C_2$ is and that the transformation preserves planarity. Now, we can repeatedly apply this procedure on the clauses to eventually obtain an instance $\\phi'$ of NAE $3$-SAT as desired.", "meta": {"post_id": 5994, "input_score": 24, "output_score": 23, "post_title": "For which k is PLANAR NAE k-SAT in P?"}}
{"input": "I'm having a little trouble fully understanding the final steps of Shor's factoring algorithm.\nGiven an $N$ we want to factor, we choose a random $x$ which has order $r$.\nThe first step involves setting up the registers and applying the Hadamard operator. The second step a linear operator is applied. The third step the second register is measured (I believe this step can be performed later instead). The fourth step the discrete Fourier transform is applied to the first register. Then we measure the first register.\nHere's where I'm a little hazy:\nWe get a measurement in the form $\\mid j , x^k \\textrm{mod} N \\rangle $.\nFrom this we can find the convergents of the fraction $ \\frac{j}{2^q} $ , the convergents are possible values of the order $ r $. Here do we just try all the convergents $ < N $ and if we don't find $ r $ as one of the convergents do we just start again?\nAlso how does the probability for possible values $ j $ differ? They way I see it they should all have the same probability but Shor's paper says this isn't the case?\nJust a little confused as some papers seem to say different things.\nThanks.", "output": "From this we can find the convergents\n  of the fraction $j/2^q$ , the convergents\n  are possible values of the order $r.$\n  Here do we just try all the\n  convergents $<N$ and if we don't find $r$\n  as one of the convergents do we just\n  start again?\n\nYou could; the algorithm works fairly fast if you do. If you want to reduce the expected number of quantum steps, you could also do some other tests; for example you should check whether $r$ is a small multiple of one of the convergents. But if you don't find $r$ after these extended tests, you need to start again.\n\nAlso how does the probability for\n  possible values $j$ differ? They way I\n  see it they should all have the same\n  probability but Shor's paper says this\n  isn't the case?\n\nI don't know whether I can help you more with this, because you haven't given me enough information for me to tell why you're confused. The probability for each value of $k$ in the fraction $k/r$ is (very nearly) the same. However, depending on exactly where $k/r$ falls between the adjacent values of $j/2^q$ and $(j+1)/2^q$, the probabilities of the specific values of $j$ differ.", "meta": {"post_id": 6085, "input_score": 28, "output_score": 47, "post_title": "Shor's factoring algorithm help"}}
{"input": "Types and Programming Languages focuses quite a bit on subtyping, but as far as I can tell, subtyping doesn't seem especially fundamental. Does subtyping give you anything more than dependent types do? Working with dependent types is bound to be more work, so I can understand why subtypes might be useful in practice. However, I am more interested in type theory as a foundation for mathematics than as a basis for programming languages, should I pay much attention to subtyping?", "output": "However, I am more interested in type theory as a foundation for mathematics than as a basis for programming languages, should I pay much attention to subtyping? \n\nOne extra thing subtyping gives you is that subsumption implies that lots of coherence properties hold. A dependent type theory also needs a notion of proof irrelevance to model everything you can do with subtypes. For example, in dependent type theory you can approximate forming a subset with a dependent record: \n$$\r\n\\{x \\in S \\;|; P(x)\\} \\mbox{ vs. } \\Sigma x:S.\\;P(x)\r\n$$\nHowever, note that the cardinality of the subset will be smaller than $S$, whereas the dependent record can have a bigger cardinality (since there can be many possible proofs of $P(x)$ for each $x:$). \nTo faithfully represent subtyping (which says that if $X <: Y$, and $x:X$ then $x:Y$), you need $P(x)$ to be proof-irrelevant -- that is, for there to be at most one inhabitant of the type $P(x)$. \nOnce you have that, you can systematically elaborate subtyping into dependent type theory. See William Lovas's thesis for an example of adding subtyping to a dependent type theory (in this case, Twelf).", "meta": {"post_id": 6519, "input_score": 25, "output_score": 24, "post_title": "Do dependent types give you everything subtyping does?"}}
{"input": "Greg Egan in his fiction \"Dark Integers\" (story about two universes with two different mathematics communicating by means of proving theorems around of inconsistence in arithmetic) claims that it is possible to build general purpose computer solely on existing internet routers using only its basic functionality of packet switching (and checksum correction, to be precise).\nIs this possible, in principle?\nUpdate.\nTo make the question more precise:\nWhat is an absolutely minimal set(s) of properties the router network must have that it will be possible to build general purpose computer on top of it?", "output": "This can be helpful:\nParasitic computing is an example of a potential technology that could be viewed simultaneously as a threat or healthy addition to the online universe. On the Internet, reliable communication is guaranteed by a standard set of protocols, used by all computers. These protocols can be exploited to compute with the communication infrastructure, transforming the Internet into a distributed computer in which servers unwittingly perform computation on behalf of a remote node. In this model, one machine forces target computers to solve a piece of a complex computational problem merely by engaging them in standard communication.\nIn the parasitic computing site you can detailed information on how you can solve a 3-SAT problem using the checksum of TCP packets.\nOther useful links:\n\nSeminar report on parasitic computing by K.K.Maharana\nNature's article on parasitic computing (Aug 2001)", "meta": {"post_id": 6713, "input_score": 14, "output_score": 21, "post_title": "Dark Integers: General Purpose Computations on Internet Routers"}}
{"input": "I already read examples of formulas in CTL but not in LTL and vice-versa, but I'm having trouble gaining a mental grasp on LTL formulas and really what, at the heart, is the difference.", "output": "To really understand the difference between LTL and CTL you have to study the semantics of both languages. LTL formulae denote properties that will be interpreted on each execution of a program. For each possible execution (a run), which can be see as a sequence of events or states on a line \u2014 and this is why it is named \"linear time\" \u2014 satisfiability is checked on the run with no possibility of switching to another run during the checking. On the other hand, CTL semantics checks a formula on all possible runs and will try either all possible runs (A operator) or only one run (E operator) when facing a branch. \nIn practice this means that some formulae of each language cannot be stated in the other language. For example, the reset property (an important reachability property for circuit design) states that there is always a possibility that a state can be reached during a run, even if it is never actually reached (AG EF reset). LTL can only state that the reset state is actually reached and not that it can be reached. \nOn the other hand, the LTL formula $\\Diamond\\Box s$ cannot be translated into CTL. This formula denotes the property of stability : in each execution of the program, s will finally be true until the end of the program (or forever if the program never stops). CTL can only provide a formula that is too strict (AF AG s) or too permissive (AF EG s). The second one is clearly wrong. It is not so straightforward for the first. But AF AG s is erroneous. Consider a system that loops on A1, can go from A1 to B and then will go to A2 on the next move. Then the system will stay in A2 state forever. Then \"the system will finally stay in a A state\" is a property of the type $\\Diamond\\Box s$. It is obvious that this property holds on the system. However, AF AG s cannot capture this property since the opposite is true : there is a run in which the system will always be in the state from which a run finally goes in a non A state.\nI don't know if this answers to your question, but I would like to add some comments.\nThere is a lot of discussion of the best logic to express properties for software verification... but the real debate is somewhere else. LTL can express important properties for software system modelling (fairness) when the CTL must have a new semantics (a new satisfiability relation) to express them. But CTL algorithms are usually more efficient and can use BDD-based algorithms. So... there is no best solution. Only two different approaches, so far.\nOne of the commenters suggests Vardi's paper \"Branching versus Linear Time: Final Showdown\".", "meta": {"post_id": 6735, "input_score": 14, "output_score": 23, "post_title": "What is the difference between LTL and CTL?"}}
{"input": "In one sentence: would the existence of a hierarchy for $\\mathsf{BPTIME}$ imply any derandomization results? \nA related but vaguer question is: does the existence of a hierarchy for $\\mathsf{BPTIME}$ imply any difficult lower bounds? Does the resolution of this problem hit against a known barrier in complexity theory?\nMy motivation for this question is to understand the relative difficulty (with respect to other major open problems in complexity theory) of showing a hierarchy for $\\mathsf{BPTIME}$. I am assuming that everyone believes that such a hierarchy exists, but please correct me if you think otherwise.\nSome background: $\\mathsf{BPTIME}(f(n))$ contains those languages whose membership can be decided by a probabilistic Turning machine in time $f(n)$ with bounded probability of error. More precisely, a language $L \\in \\mathsf{BPTIME}(f(n))$ if there exists a probabilistic Turing machine $T$ such that for any $x \\in L$ the machine $T$ runs in time $O(f(|x|))$ and accepts with probability at least $2/3$, and for any $x \\not \\in L$, $T$ runs in time $O(f(|x|))$ and rejects with probability at least $2/3$. \nUnconditionally, it is open whether $\\mathsf{BPTIME}(n^c) \\subseteq \\mathsf{BPTIME}(n)$ for all $c > 1$. Barak showed that there exists a strict hierarchy for $\\mathsf{BPTIME}$ for machines with $O(\\log n)$ advice. Fortnow and Santhanam improved this to 1 bit of advice. This leads me to think that a proving the existence of a probabilistic time hierarchy is not that far off. On the other hand, the result is still open and I cannot find any progress after 2004. References, as usual, can be found in the Zoo.\nThe relation to derandomization comes from Impagliazzo and Wigderson's results: they showed that under a plausible complexity assumption, $\\mathsf{BPTIME}(n^d) \\subseteq \\mathsf{DTIME}(n^c)$ for any constant $d$ and some constant $c$. By the classical time-hierarchy theorems for deterministic time, this implies a time hierarchy for probabilistic time. I am asking the converse question: does a probabilistic hiearchy hit against a barrier related to proving derandomization results?\n\nEDIT: I am accepting Ryan's answer as a more complete solution.\nIf anyone has observations about what stands between us and proving the existence of a hierarchy for probabilistic time, feel free to answer/comment. Of course, the obvious answer is that $\\mathsf{BPTIME}$ has a semantic definition that defies classical techniques. I am interested in less obvious observations.", "output": "Let PTH be the hypothesis that there exists a probabilistic time hierarchy. Suppose the answer to your question is true, i.e., \"PTH implies $BPP \\subseteq TIME[2^{n^{c}}]$\" for some fixed $c$. Then, $EXP \\neq BPP$ would be unconditionally true. Consider two cases:\n\nIf PTH is false, then $EXP \\neq BPP$. This is the contrapositive of what Lance noted.\nIf PTH is true, then \"PTH implies $BPP \\subseteq TIME[2^{n^{c}}]$\" so again $EXP \\neq BPP$.\n\nIn fact, even an infinitely-often derandomization of BPP under PTH would entail $EXP \\neq BPP$ unconditionally. So whatever barriers apply to proving $EXP \\neq BPP$, they apply to proving statements of the kind \"PTH implies derandomization\".", "meta": {"post_id": 6748, "input_score": 31, "output_score": 24, "post_title": "Hierarchy for BPP vs derandomization"}}
{"input": "$\\mathsf{NC}$ captures the idea of efficiently parallelizable, and one interpretation of it is problems that are solvable in time $O(\\log^c n)$ using $O(n^k)$ parallel processors for some constants $c$, $k$. My question is if there is an analogous complexity class where time is $n^c$ and number of processors is $2^{n^k}$. As a fill-in-the-blank question:\n\n$\\mathsf{NC}$ is to $\\mathsf{P}$ as __ is to $\\mathsf{EXP}$\n\nIn particular, I am interested in a model where we have an exponential number of computers arranged in a network with polynomially bounded degree (lets say the network is independent of the input/problem or atleast somehow easy to construct, or any other reasonable uniformity assumption). At each time step:\n\nEvery computer reads the polynomial number of polynomial sized messages it received in the previous time step.\nEvery computer runs some polytime computation that can depend on these messages.\nEvery computer passes a message (of polylength) to each of its neighbours.\n\nWhat is the name of a complexity class corresponding to these sort of models? What is a good place to read about such complexity classes? Are there any complete-problems for such a class?", "output": "As Ryan says, this class is PSPACE. This class is often called NC(poly) in the literature. Here is a direct quote from the QIP = PSPACE paper:\n\nWe consider a scaled-up variant of NC, which is the complexity class NC(poly) that consists of all functions computable by polynomial-space uniform families of Boolean circuits having\n  polynomial-depth. (The notation NC(2poly) has also previously been used for this class [11].) For decision problems, it is known that NC(poly) = PSPACE [10]. \n[10]  A. Borodin. On relating time and space to size and depth. SIAM Journal on Computing, 6:733\u2013\n  744, 1977.\n[11]  A. Borodin, S. Cook, and N. Pippenger.  Parallel computation for well-endowed rings and space-bounded probabilistic machines. Information and Control, 58:113\u2013136, 1983.\n\nOne way to see this is to prove both inclusions directly. To see that NC(poly) is in PSPACE, note that we can compute the output of the final gate recursively, and we'll only require a stack of size equal to the depth of the circuit, which is polynomial. To show that PSPACE is in NC(poly), note that QBF, which is PSPACE-complete, can be written as a polynomial depth circuit with exponentially many gates in the usual way -- the exists quantifier is an OR gate, the forall quantifier is an AND gate. Since there are only polynomially many quantifiers, this is a polynomial depth circuit.", "meta": {"post_id": 6753, "input_score": 24, "output_score": 25, "post_title": "What is the big version of NC?"}}
{"input": "Is the following manuscript publically available?\n\nDana Scott, 1969, A theory of computable functions of higher type. Unpublished seminar notes, 7 pages, University of Oxford.\n\nThere is a discussion of this paper in section 8.1.2, Types as sets, in Cardone & Hindley, 2006 History of Lambda-calculus and Combinatory Logic; additionally section 10.1, Domain theory, traces back to this manuscript some crucial order-theoretic insights.", "output": "Published as:\nScott, D. A Type-Theoretical Alternative to ISWIM, CUCH, OWHY.\n   Theoretical Computer Science, vol. 121 (1993), pp. 411 - 440.\nSee also:\nScott, D. Some Reflections on Strachey and his Work. in: A Special Issue\n   Dedicated to Christopher Strachey, edited by O. Danvy and\n   C. Talcott.  Higer-Order and Symbolic Computation, vol. 13 (2000),\n   pp. 103-114.\nand:\nGordon D. Plotkin, Set-theoretical and other elementary models of the \u03bb-calculus,\n   Theoretical Computer Science, vol. 121 (1993), pp. 351-409.", "meta": {"post_id": 6952, "input_score": 16, "output_score": 37, "post_title": "Seeking Scott's original LCF paper"}}
{"input": "It is sometimes claimed that Ketan Mulmuley's Geometric Complexity Theory is the only plausible program for settling the open questions of complexity theory like P vs. NP question. There has been several positive commentaries from famous complexity theorists about the program. According to Mulmuley it will take a long time to achieve the desired results.  Entering the area is not easy for general complexity theorists and needs considerable efforts to get a handle on algebraic geometry and representation theory.\n\nWhy is GCT considered to be capable of settling P vs. NP? What is the value of the claim if it is expected to take more than 100 years to reach there? What are its advantages to other current approaches and those that may rise in the next 100 years?\nWhat is the current state of the program?\nWhat is the next target of the program?\nHas there been any fundamental criticism of the program?\n\nI would prefer answers that are understandable by a general complexity theorist with the minimum background from algebraic geometry and representation theory assumed.", "output": "As pointed out by many others, much has already been said on many of these questions by Mulmuley, Regan, and others. I will offer here just a brief summary of what I think are some key points that haven't yet been mentioned in the comments.\n\nAs to why GCT is considered plausibly capable of showing $P \\neq NP$ many answers have already been given elsewhere and in the comments above, though I think no one has yet mentioned that it appears to avoid the known barriers (relativization, algebrization, natural proofs). As to its value - I think even if it takes us 100 years, we will learn something new about complexity along the way by studying it from this angle.\n\nSome progress is being made on understanding the algebraic varieties, the representations, and the algorithmic questions that arise in GCT. The principal researchers I know of who have done work on this are (in no particular order): P. Burgisser, C. Ikenmeyer, M. Christandl, J. M. Landsberg, K. V. Subrahmanyan, J. Blasiak, L. Manivel, N. Ressayre, J. Weyman, V. Popov, N. Kayal, S. Kumar, and of course K. Mulmuley and M. Sohoni.\nMore concretely, Burgisser and Ikenmeyer just presented (STOC 2011) some modest lower bounds on matrix multiplication using the GCT approach ($n^2 + 2$, compared to the currently best known $\\frac{3}{2}n^2 +O(n)$). Although these lower bounds are not new bounds, they at least give some proof-of-concept, in that the representation-theoretic objects hypothesized to exist in GCT do exist for these modest lower bounds on this model problem. \nN. Kayal has a couple papers on the algorithmic question of testing when one polynomial is in the orbit of another or is a projection of another. He shows that in general these problems are NP-hard but that for special functions like permanent, determinant, and elementary symmetric polynomials, these problems are decidable in P. This is a step towards some of Mulmuley's conjectures (that certain harder problems - deciding orbit closure - are in P for special functions such as determinant). \n\nI don't have much more specific to say on this than the answer to 2.\nAs far as I know there has not been fundamental criticism, in the sense that I have not seen any criticism which really discredits the program in any way. There has certainly been discussion about why such techniques should be necessary, the value of the program given the long time horizons expected, etc., but I would characterize these more as healthy discussion than fundamental criticism.", "meta": {"post_id": 6959, "input_score": 38, "output_score": 23, "post_title": "Mulmuley's GCT program"}}
{"input": "I wonder why computer scientist have chosen recursor instead of iterator (or tail recursor if you like) in primitive recursion, given that function defined in terms of iteration behaves more efficiently than that in terms of recursion.\nEDIT:\nLet us go further, do you think iteration would be better than recursion to complexity?", "output": "Iterators of any kind are just a form of recursion, i.e., a thing \"using itself\". For example, the basic equation governing the while loop is\n\n(while b do C)  =  (if b then (C; while b do C))\n\nYou may think I am doing something exotic, but as soon as you try to explain what recursion and iteration mean, you will end up writing such equations. For example, people tend to explain the while loop by saying things like \"and so on\" (imprecise) or \"do C while b\" (not explaining anything), or \"keep doing\" (circular explanation). The above equation tells you everything there is to know about the while loop. Similar arguments can be made about other forms of iteration.\nThe above equation is recursive, as the defined term appears on both sides. The general form is $$x = \\phi(x),$$ which of course is just a general recursive definition of $x$. In this sense iteration is just a special form of recursion. So as far as theory is concerned, there is pratically no difference between recursion and iteration, except that the latter is a special case of the former. And both concepts are special cases of fixed point equations, a very important and general mathematical concept. This answers why \"they chose recursor instead of iterator\".\nYour claim that iteration is more efficient than recursion is bogus. Modern programming languages are quite efficient at both of these tasks. In any case, it is not the job of humans to think about low-level details of execution of programs (maybe that was the case in the 1960's when the total amount of CPU power and memory on the planet was comparable to what kids carry in their pockets these days). We have better things to do as programmers, such as how to write programs most efficiently and how to make sure they are actually correct.", "meta": {"post_id": 7029, "input_score": 5, "output_score": 31, "post_title": "Why have computer scientists chosen recursor instead of iterator in primitive recursion?"}}
{"input": "This may be considered a stupid question. I am not a computer science major (and I'm not a mathematics major yet, either), so please excuse me if you think that the following questions display some major erroneous assumptions.\nWhile there are plans to formalize Fermat's Last Theorem (see this presentation), I have never read or heard that a computer can prove even a \"simple\" theorem like Pythagoras'. \nWhy not? What is (/are) the main difficulty(/ies) behind establishing a fully autonomous proof by a computer, aided only by some \"built-in axioms\"? \nA second question I would like to ask is the following: Why are we able to formalize many proofs, while it is currently impossible for a computer to prove a theorem on its own? Why is that \"harder\" ?", "output": "While there are plans to formalize Fermat's Last Theorem (see this presentation), I have never read or heard that a computer can prove even a \"simple\" theorem like Pythagoras'. \n\nIn 1949 Tarski proved that almost everything in The Elements lies within a decidable fragment of logic, when he showed the decidability of the first-order theory of real closed fields. So the Pythagorean theorem in particular is not talked about much because it's not especially hard. \nIn general, the thing that makes theorem proving hard is induction. First-order logic without induction has a very useful property called the subformula property: true formulas $A$ have proofs involving only the subterms of $A$. This means that it's possible to build theorem provers which can decide what to prove next based on an analysis of the theorem they are instructed to prove. (Quantifier instantiation can make the right notion of subformula a bit more subtle, but we have reasonable techniques to cope with this.) \nHowever, the addition of the induction schema to the axioms breaks this property. The only proof of a true formula $A$ may require doing a proof $B$ which is not syntactically a subformula of $A$. When we run into this in a paper proof, we say we have to \"strengthen the induction hypothesis\". This is quite hard for a computer to do, because the appropriate strengthening can require both significant domain-specific information, and an understanding of why you're proving a particular theorem. Without this information, truly relevant generalizations can get lost in a forest of irrelevant ones.", "meta": {"post_id": 7129, "input_score": 18, "output_score": 23, "post_title": "Why is it so difficult for a computer to prove something?"}}
{"input": "Are there any references that provide details about circuit lower bounds for specific hard problems arising in cryptography such as integer factoring, prime/composite discrete logarithm problem and its variant over group of points of elliptic curves (and their higher dimensional abelian varieties) and the general hidden subgroup problem?\nSpecifically do any of these problems have more than a linear complexity lower bound?", "output": "@Suresh: following your advice, here is my \"answer\". The status of circuit lower bounds is quite depressing. Here are the \"current records\":\n\n  $4n-4$ for circuits over $\\{\\land,\\lor,\\neg\\}$, and $7n-7$\nfor circuits over $\\{\\land,\\neg\\}$ and $\\{\\lor,\\neg\\}$\n  computing $\\oplus_n(x)=x_1\\oplus x_2\\oplus\\cdots\\oplus x_n$;\nRedkin (1973). These bounds are tight.\n\n $5n-o(n)$ for circuits over the basis with all\n  fanin-2 gates, except the parity and its negation; Iwama and\n  Morizumi (2002).\n\n  $3n-o(n)$ for general circuits over the basis\n  with all fanin-2 gates; Blum (1984). Arist Kojevnikov and Sasha Kulikov from Petersburg have found a simpler proof of a\n$(7/3)n-o(1)$ lower bound. The advantage of their proof is its simplicity, not numerical. Later they gave a simple proof of $3n-o(1)$ lower bound for general circuits (all fanin-2 gates are allowed). Albeit for very complicated functions - affine dispersers. Papers are online  here.\n\n $n^{3-o(1)}$ for formulas over\n  $\\{\\land,\\lor,\\neg\\}$; Hastad (1998).\n\n  $\\Omega(n^2/\\log n)$ for general fanin-$2$ formulas,\n$\\Omega(n^2/\\log^2 n)$ for deterministic branching programs, and\n$\\Omega(n^{3/2}/\\log n)$ for nondeterministic branching programs;\nNechiporuk~(1966).\n\nSo, your question \"Specifically do any of these problems have more than a linear complexity lower bound?\" remains widely open (in the case of circuits). My appeal to all young researchers: go forward, these \"barriers\" are not unbreakable! But try to think in a \"non-natural way\", in the sense of Razborov and Rudich.", "meta": {"post_id": 7388, "input_score": 20, "output_score": 27, "post_title": "Is there a better than linear lower bound for factoring and discrete log?"}}
{"input": "SAT solvers are very important in algebraic attacks, for example walksat and minisat.\nHowever, when solving the benchmark problems available here there is an enormous performance difference between the two - Walksat is much faster than minisat for these problems. Why is this?\nThis implementation of walksat appears to have some performance improvements - is there any reason it wasn't included in the international SAT Competitions?", "output": "Yes, there is a major difference between MiniSAT and WalkSAT. First, let's clarify - MiniSAT is a specific implementation of the generic class of DPLL/CDCL algorithms which use backtracking and clause learning, whereas WalkSAT is the general name for an algorithm which alternates between greedy steps and random steps.\nIn general DPLL/CDCL is much faster on structured SAT instances while WalkSAT is faster on random k-SAT. Industrial and applied SAT instances tend to have a lot of structure, so DPLL/CDCL is dominant in most modern SAT solvers. Instance to instance one technique may win out, though, which is one reason why portfolio solvers have become popular.\nI take a lot of issue with your claim that WalkSAT is much faster than MiniSAT on the instances on that page. For one thing, there are gigabytes of SAT instances there - how many did you try comparing them on? WalkSAT is not at all competitive on most structured instances which is why it's not often seen in competitions.\nOn a side note - Vijay is right that MiniSAT is still relevant. Actually, because it's open source and well-written, MiniSAT is the solver to beat in order to show that a given optimization has promise. Many people tweak MiniSAT itself to showcase their optimizations - take a look at the \"MiniSAT hack\" category in the recent SAT competitions.", "meta": {"post_id": 7469, "input_score": 26, "output_score": 36, "post_title": "Why is there an enormous difference between SAT solvers?"}}
{"input": "The Valiant-Vazirani theorem says that if there is a polynomial time algorithm (deterministic or randomized) for distinguishing between a SAT formula that has exactly one satisfying assignment, and an unsatisfiable formula - then NP=RP. This theorem is proved by showing that UNIQUE-SAT is NP-hard under randomized reductions.\nSubject to plausible derandomization conjectures, the Theorem can be strengthened to \"an efficient solution to UNIQUE-SAT implies NP = P\". \nMy first instinct was to think that implied there exists a deterministic reduction from 3SAT to UNIQUE-SAT, but it's not clear to me how this particular reduction can be derandomized. \nMy question is: what is believed or known about \"derandomizing reductions\"? Is it/should it be possible? What about in the case of V-V? \nSince UNIQUE-SAT is complete for PromiseNP under randomized reductions, can we use a derandomization tool to show that \"a deterministic polynomial time solution to UNIQUE-SAT implies that PromiseNP = PromiseP?", "output": "Just for reference, I stumbled across this really interesting paper today, which gives evidence that a deterministic reduction is unlikely: \n\nDell, H., Kabanets, V., Watanabe, O., & van Melkebeek, D. (2012). Is the Valiant-Vazirani Isolation Lemma Improvable? ECCC TR11-151\n\nThey argue that this is not possible unless NP is contained in P/poly.", "meta": {"post_id": 7552, "input_score": 31, "output_score": 22, "post_title": "Derandomizing Valiant-Vazirani?"}}
{"input": "What is the average number of publications (including conference proceedings), per year, for CS postdoctoral researchers in the US? What are the ways to find out or estimate this number?", "output": "The main motive behind this question is to understand where am I standing with my own performance and productivity.\nThen you're asking the wrong question.  The right metric to examine isn't the number of publication, but rather your visibility and reputation (and ultimately impact) within the research community.  If the intellectual leaders of your target subcommunity are eager to write you good recommendation letters, it doesn't matter whether you publish one paper a year or ten.  Similarly, if the intellectual leaders in your target subcommunity are not eager to write you good recommendation letters, it doesn't matter whether you publish one paper a year or ten.", "meta": {"post_id": 7559, "input_score": 9, "output_score": 23, "post_title": "The average number of annual publications for CS postdocs"}}
{"input": "As stated in the title, I wonder any relation and difference between CIC and ITT. Could someone explain or point to me some literature that compares these two systems? Thanks.", "output": "I've already answered somewhat, but I'll try to give a more detailed overview of the type theoretical horizon, if you will.\nI'm a bit fuzzy on the historical specifics, so more informed readers will have to forgive me (and correct me!). The basic story is that Curry had uncovered the basic correspondence between simply-typed combinators (or $\\lambda$-terms) and propositional logic, which was extended by Howard to cover first-order logic, and IIRC independently discovered by de Bruijn in investigations around the hugely influential Automath system.\nThe Automath system was a refinement of Church's simple type theory which itself was a dramatic simplification of Russel and Whitehead's type theory with universes and the axiom of reducibility. This was relatively well-known logical terrain by the 1960s.\nHowever, giving a coherent, simple, foundational system that encompassed both proof and term systems was still a very open question by 1970, and a first answer was given by Per Martin-L\u00f6f. He gives a very philosophical overview On the Meaning of the Logical Constants and the Justification of Logical Laws. He reasons that both in logic and mathematics, the meaning of constructions can be given by examining the introduction rules which allow the formation of those constructions as judgements, e.g. for conjunction\n$$ \\frac{\\vdash A\\quad \\vdash B}{\\vdash A\\wedge B}$$\nDetermines the corresponding elimination rule. He then gave a very powerful foundational system based on such judgements, allowing him to give a foundational system similar to Automath using very few syntactic constructions. Girard found that this system was contradictory, prompting Martin-L\u00f6f to adopt \"Russel-style\" predicative universes, severely limiting the expressiveness of the theory (by effectively removing the axiom of reducibility) and making it slightly more complex (but had the advantage of making it consistent).\nThe elegant constructions allowing for the definition of the logical symbols didn't work anymore though, which prompted M-L to introduce them in a different form, as inductively defined families. This is a very powerful idea, as it allows defining everything from judgmental equality and logical operators to natural numbers and functional data-types as they appear in computer science. Note that each family we add is akin to adding a number of axioms, which need to be justified as consistent in each instance. This system (dependent types + universes + inductive families) is usually what is referred to as ITT.\nHowever there was some lingering frustration, as the powerful but simple foundational system was inconsistent, and the resulting system was more complex, and somewhat weak (in the sense that it was difficult to develop much of the modern mathematical framework in it). Enter Thierry Coquand, who with his supervisor Gerard Huet, introduced the Calculus of Constructions (CoC), which mostly solved these issues: a unified approach to proofs and data-types, a powerful (impredicative) foundational system and the ability to define \"constructions\" of the logical or mathematical variety. This eventually matured into an actual implementation of a system designed as a modern alternative to Automath, culminating in the Coq system we know and love.\nI highly suggest this foundational paper on CoC, as Thierry knows a ridiculous amount about the historical development of type theory, and probably explains this much better than I. You might also want to check out his article on type theory, though it doesn't explain the C-H correspondence in much detail.", "meta": {"post_id": 7561, "input_score": 37, "output_score": 29, "post_title": "What's the relation and difference between Calculus of Inductive Constructions and Intuitionistic Type Theory?"}}
{"input": "I haven't managed to find this data structure, but I'm not an expert in the field.\nThe structure implements a set, and is basically an array of comparable elements with an invariant. The invariant is the following (defined recursively):\nAn array of length 1 is a merge-array.\nAn array of length 2^n (for n > 0) is a merge-array iff:\n\nthe first half is a merge-array and the second half is empty\nor\nthe first array is full and sorted, and the second half is a merge-array.\n\nNote that if the array is full, it is sorted.\nTo insert an element, we have two cases:\n\nIf the first half is not full, insert recursively in the first half.\nIf the first half is full, insert recursively in the second half.\nAfter the recursive step, if the whole array is full, merge the\nhalves (which are sorted), and resize it to the double of its original\nlength.\n\nTo find an element, recurse in both halves, using binary search\nwhen the array is full. (This should be efficient since there are\nat most $O(\\log(n))$ ascending fragments).\nThe structure can be thought as a static version of mergesort.\nIt's not clear what one should do to erase an element.\nEdit: after improving my understanding of the structure.", "output": "You're describing the classical Bentley-Saxe logarithmic method, applied to static sorted arrays.  The same idea can be used to add support for insertions to any static data structure (no insertions or deletions) for any decomposable searching problem.  (A search problem is decomposable if the answer for any union $A\\cup B$ can be computed easily from the answers for the sets $A$ and $B$.)  The transformation increases the amortized query time by a factor of $O(\\log n)$ (unless it was already bigger than some polynomial in $n$), but increases the space by only a constant factor.  Yes, it can be deamortized, thanks to Overmars and van Leeuwen, but you really don't want to do that if you don't have to.\nThese notes cover the basics.\nCache-oblivious lookahead arrays are the mutant offspring of Bentley-Saxe and van Emde Boas trees on steroids.", "meta": {"post_id": 7642, "input_score": 27, "output_score": 31, "post_title": "I dreamt of a data structure, does it exist?"}}
{"input": "It is known via the universal approximation theorem that a neural network with even a single hidden layer and an arbitrary activation function can approximate any continuous function.\nWhat other models are there that are also universal function approximators", "output": "This is treated extensively in the statistics literature, under the topic of regression.  Two standard references here are Wasserman's book \"all of nonparametric statistics\" and Tsybakov's \"introduction to nonparametric estimation\".  I'll talk briefly about some of the standard stuff, and try to give pointers outside of statistics (this is a common topic and different fields have different cultures: prove different kinds of theorems, make different assumptions).\n\n(Kernel regressors, sometimes called the Nadaraya-Watson Estimator.)  Here you write the function at any point as a weighted combination of nearby values. More concretely, \nsince this is in the statistics literature, you typically suppose you have some examples $((x_i,f(x_i)))_{i=1}^n$ drawn from some distribution,\nand fix some kernel $K$ (can think of this as a gaussian, but zero mean is what matters most), and write\n$$\r\n\\hat f(x) := \\sum_i f(x_i) \\left(\\frac{ K(c_n(x-x_i)) }{ \\sum_j K(c_n(x-x_j))}\\right),\r\n$$\nwhere $c_n\\to\\infty$ (you are more sensitive to small distances as $n$ increases).\nThe guarantee is that, as $n\\to\\infty$, a probilistic criterion of distortion\n(expectation of sup-norm, high probability, whatever) goes to zero.\n(It hardly matters what $K$ looks like---it matters more how you choose $c_n$.)\n(Basis methods.)  A similar thing is to choose some family of \"basis functions\", things like Wavelets or piecewise linear functions, but really anything that forms a (possibly overcomplete) basis for the vector space $L^2$, and determine a weighted linear combination of scaled and translated elements. \nThe techniques here differ drastically from (1.); rather than plopping down basis functions centered at data points, you carefully compute the weight and location of each in order to minimize some distortion criterion.  (Typically, their quantity is fixed a priori.) One approach is \"basis pursuit\", where you greedily add in new functions while trying to minimize some approximation error between $\\hat f$ and $f$.  To get a sense of the diversity of approaches here, a neat paper is Rahimi & Recht's \"uniform approximation of functions with random bases\".  Perhaps I should say that the grand-daddy of all of these is the Fourier expansion; there's a lot of good material on this in Mallat's book on Wavelets.\n(Tree methods.)  Another way is to look at a function as a tree; at each level, you are working with some partition of the domain, and return, for instance, the average point.  (Each pruning of the tree also gives a partition.)  In the limit, the fineness of this partition will no longer discretize the function, and you have reconstructed it exactly.  How best to choose this partition is a tough problem. (You can google this under \"regression tree\".)\n(Polynomial methods; see also splines and other interpolating techniques.)  By Taylor's theorem, you know that you can get arbitrarily close to well behaved functions.  This may seem like a very basic approach (i.e., just use the Lagrange interpolating polynomial), but where things get interesting is in deciding which points to interpolate.  This was investigated extensively in the context of numerical integration; you can find some amazing math under the topics of \"clenshaw-curtis quadrature\" and \"gaussian quadrature\".  I'm throwing this in here because the types of assumptions and guarantees here are so drastically different than what appears above.  I like this field but these methods suffer really badly from the curse of dimension, at least I think this is why they are less discussed than they used to be (if you do numeric integration with mathematica, I think it does quadrature for univariate domains, but sampling techniques for multivariate domains).\n\nConsidering various restrictions to your function class, you can instantiate the above to get all sorts of other widely-used scenarios.  For instance, with boolean valued functions, thresholding (1.) will look a lot like a nearest-neighbor estimator, or an SVM with some local kernel (gaussian).  A lot of the above stuff suffers from curse of dimension (bounds exhibit exponential dependence on the dimension).  In machine learning you get around this either by explicitly constraining your class to some family (i.e., \"parametric methods), or by an implicit constraint, usually something relating the quality of the approximants to the target function complexity (i.e., an analog of the weak learning assumption in boosting).\nBy the way, my favorite theorem related to neural net approximation  is Kolmogorov's superposition theorem (from 1957!).  It says that any multivariate continuous function $f:\\mathbb{R}^d \\to \\mathbb{R}$ has the form\n$$\r\nf(x) = \\sum_{j=0}^{2d}h_j\\left(\\sum_{i=1}^d g_{j,i}(x_i)\\right),\r\n$$\nwhere each $g_{j,i} : \\mathbb{R}\\to\\mathbb{R}$ and $h_j:\\mathbb{R}\\to\\mathbb{R}$ is (univariate) continuous.  Note that unlike neural nets, the $g$'s and $h$'s may all differ.  But even so, given that there are only $\\Theta(d^2)$ functions floating around, I find this totally amazing.\n(You only asked about function classes, but I figured you'd be interested in methods as well.. if not.. oops)", "meta": {"post_id": 7894, "input_score": 18, "output_score": 27, "post_title": "Universal Function approximation"}}
{"input": "Let PRIMES (a.k.a. primality testing) be the problem: \n\nGiven a natural number $n$, is $n$ a prime number?\n\nLet FACTORING be the problem: \n\nGiven natural numbers $n$, $m$ with $1 \\leq m \\leq n$, does $n$ have a factor $d$ with $1 < d < m$?\n\nIs it known whether PRIMES is P-hard? How about FACTORING? \nWhat are the best known lowerbounds for these problems?", "output": "Factoring can be achieved by using a polylog $n$ depth quantum circuit, and ZPP pre- and post-processing; see this paper. If it were P-hard, any algorithm in P could be done with polylog $n$ depth quantum circuit and the same pre- and post-processing steps. I believe these steps are modular exponentiation and continued fractions, which to me seem unlikely to be powerful enough to solve P-complete problems, even with the addition of a polylog $n$ depth quantum circuit.", "meta": {"post_id": 8000, "input_score": 42, "output_score": 30, "post_title": "Are the problems PRIMES, FACTORING known to be P-hard?"}}
{"input": "Inspired by the question is factoring known to be P-hard, I wonder what the current similar state of knowledge is about the hardness of graph isomorphism. I am sure that it is currently not known if GI is in P, but:\n\nwhat is the currently known largest class that GI is harder than?\n\n(it was not answered at a similar sounding question)\nTo address some of the comments, I want to know the currently known maximal class(es) that GI, the problem is complete for. Known algorithms for GI are upper-bounded by superpolynomial functions, and it is a member of NP. But it is not known that GI is P-hard. I'd like to know any classes C for which it -is- known it is C-hard, and hopefully as inclusive as possible.", "output": "Graph Isomorphism is hard for DET, the class of problems which are $NC^1$ reducible to the determinant. See \"On the Hardness of Graph Isomorphism\" by Jacobo Toran. http://epubs.siam.org/sicomp/resource/1/smjcat/v33/i5/p1093_s1?isAuthorized=no\nIt seems this is the strongest hardness result to date.", "meta": {"post_id": 8034, "input_score": 22, "output_score": 23, "post_title": "What is the current known hardness of Graph Isomorphism?"}}
{"input": "The Satisfiability problem is, of course, a fundamental problem in theoretical CS. I was playing with one version of the problem with infinitely many variables. $\\newcommand{\\sat}{\\mathrm{sat}} \\newcommand{\\unsat}{\\mathrm{unsat}}$\nBasic Setup. Let $X$ be a nonempty and possibly infinite set of variables. A literal is either a variable $x \\in X$ or its negation $\\neg x$. A clause $c$ is a disjunction of finite number of literals. Finally, we define a formula $F$ as a set of clauses. \nAn assignment of $X$ is a function $\\sigma : X \\to \\{0,1\\}$. I will not explicitly define the condition for when an assignment $\\sigma$ satisfies a clause; it is slightly cumbersome, and is the same as in standard SAT. Finally, an assignment satisfies a formula if it satisfies every constituent clause. Let $\\sat(F)$ be the set of satisfying assignments for $F$, and let $\\unsat(F)$ be the complement of $\\sat(F)$. \nA topological space. \nOur goal is to endow the space of all assignments of $X$, call this $\\Sigma$, with a topological structure. Our closed sets are of the form $\\sat(F)$ where $F$ is a formula. We can verify that this is indeed a topology:\n\nThe empty formula $\\emptyset$ containing no clauses is satisfied by all assignments; so $\\Sigma$ is closed.\nThe formula $\\{ x, \\neg x \\}$ for any $x \\in X$ is a contradiction. So $\\emptyset$ is closed.\nClosure under arbitrary intersection. Suppose $F_{i}$ is a formula for each $i \\in I$. Then $\\sat \\left(\\bigcup_{i \\in I} F_i\\right) = \\bigcap_{i \\in I} \\sat(F_i)$.\nClosure under finite union. Suppose $F$ and $G$ are two formulas, and define\n$$\r\nF \\vee G := \\{ c \\vee d \\,:\\, c \\in F, d \\in G \\}.\r\n$$ \nThen $\\sat(F \\vee G) = \\sat(F) \\cup \\sat(G)$.This needs an argument, but I'll skip this.\n\nCall this topology $\\mathcal T$, the \"satisfiability topology\"(!) on $\\Sigma$. Of course, the opens sets of this topology are of the form $\\unsat(F)$. Moreover, I observed that the collection of open sets\n$$\r\n\\{ \\unsat(c) \\,:\\, c \\text{ is a clause} \\}\r\n$$\nforms a basis for $\\mathcal T$. (Exercise!) \nCompact? I feel that this is an interesting, if not terribly useful, way to look at things. I want to understand whether this topological space possesses traditional interesting properties like compactness, connectedness etc. In this post, we will restrict ourselves to compactness:\n\nLet $X$ be a countably infinite collection of variables.1 Is $\\Sigma$ compact under $\\mathcal T$? \n\nOne can prove the following\n\nProposition. $\\mathcal T$ is compact if and only for all unsatisfiable formulas $F$, there exists a finite unsatisfiable subformula $\\{ c_1, c_2, \\ldots, c_m \\} \\subseteq F$.\n\n(Not-so-hard exercise!) After several days of thinking, I do not have much progress in answering this question. I also do not have strong evidence for or against compactness. Can you suggest some approach? \nFinally, as a bonus question: \n\nHas such a structure been studied before? \n\n1The restriction to countable $X$ is just for simplicity; it also feels like the next natural step from finite number of variables.", "output": "What you are doing is deriving a topological representation of a Boolean algebra. The study of representations of Boolean algebras goes back at least to Lindenbaum and Tarski who proved (in 1925, I think) that the complete, atomic Boolean algebras are isomorphic to powerset lattices. \nThere are however, Boolean algebras that are not complete and atomic. For example, the sequence $x_1, x_1 \\land x_2, \\ldots$, is a descending chain that has no limit in the Boolean algebra defined over formulas. The question of whether arbitrary Boolean algebras, such as the one you mention, also had set-based representations was solved by Marshall Stone, who put forth the maxim \"always topologize\" (Marshall H. Stone. The representation of Boolean algebras, 1938).\n\nStone's Representation Theorem for Boolean Algebras Every Boolean algebra is isomorphic to the lattice of clopen subsets of a topological space.\n\nThe main idea is to consider what in your case are the satisfying assignments to a formula. In the general case, you consider  homomorphisms from a Boolean algebra into the two element Boolean algebra (the truth values). The inverse of $\\mathit{true}$ gives you the sets of satisfying assignments, or what are called ultrafilters of the Boolean algebra. From these, one can obtain a topology called the spectrum or Stone space of a Boolean algebra. Stone provide the answer to your question too.\n\nThe Stone space of a  Boolean algebra is a compact, totally disconnected Hausdorff space.  \n\nThere have been several results that extend and generalise Stone's representation in various directions. A natural question is to ask if other families of lattices have such representations. Stone's results also apply to distributive lattices. Topological representations for arbitrary lattices were given by Alasdair Urquhart in 1978. Distributive lattices enjoy greater diversity in structure, compared to Boolean algebras and are of great interest. A different  representation for the distributive case was given by Hilary Priestley in 1970, using the idea of an ordered topological space. Instead of set-based representations, we can find poset-based representations and topologies.\nThe constructions in these papers have one remarkable property. Stone's construction maps not just Boolean algebras to topological spaces: structural relationships relating Boolean algebras translate into structural properties between the resulting topologies. It is a duality between categories. The entire gamut of such results is called Stone Duality. Informally, dualities give us precise translations between mathematical universes: the combinatorial world of sets, the algebraic world of lattices, the spatial world of topology and the deductive world of logic. Here are a few starting points that may help.\n\nChapter 11 of Introduction to Lattices and Order, by Davey and Priestley covers Stone's theorem.\nMatthew Gwynne's slides  cover the theorem and give a proof of compactness. Matthew (in the comments) also suggests Introduction to Boolean Algebras by Paul Halmos.\nIn moving from propositional logic to modal logic, the Boolean algebra is extended with a join-preserving operator and topology with an interior.  J\u00f3nsson and Tarski's 1952 paper, Boolean Algebras with Operators is extremely readable and consistent with modern notation. \nChapter 5 of Modal Logic by Blackburn, de Rijke and Venema covers Stone's theorem and its extension to Boolean algebras with operators.\nStone Spaces by Peter Johnstone reviews such results for various other kinds of algebras.", "meta": {"post_id": 8095, "input_score": 19, "output_score": 22, "post_title": "A topological space related to SAT: is it compact?"}}
{"input": "Inspired by the extensive hierarchies present in complexity theory, I wondered if such hierarchies were also present for type systems. However, the two examples I've found so far are both more like checklists (with orthogonal features) rather than hierarchies (with successively more and more expressive type systems).\nThe two examples I have found are the Lambda cube and the concept of k-ranked polymorphism. The first one is a checklist with three options, the second is a real hierarchy (though k-ranked for specific values of k is uncommon I believe). All other type system features I know of are mostly orthogonal.\nI'm interested in these concepts because I'm designing my own language and I'm very curious how it ranks among the currently existing type systems (my type system is somewhat unconventional, as far as I know).\nI realise that the concept of 'expressiveness' might be a bit vague, which may explain why type systems seem like checklists to me.", "output": "There are several senses of \"expressiveness\" that you might want for a type system.  \n\nWhat mathematical functions can you express in a particular type system.  For example, in the simply typed lambda calculus, not all computable functions can be expressed.  The same is true of System $F$, but strictly more functions can be expressed.  This is not very interesting once you get to type systems for Turing-complete languages.\nCan system $A$ typecheck every program written in system $B$.  This is basically what cody's first notion of strength is about for PTSs.  Again, System $F$ is stronger than the STLC in this ordering, since every STLC program types in System $F$.  Similarly, a system with subtyping will be stronger than a system without.\nAre there local transformations (in the sense of Felleisen's paper On the expressive power of programming languages) that allow a program that types in system $A$ to type in system $B$, but not vice versa.  \nDoes one type system guarantee stronger properties than another.  For example, linear type systems just reject more programs, but that allows them to make stronger statements about the programs they do accept.\n\nUnfortunately, I don't believe that there's been work on categorizing or formalizing these notions, with the exception of Barendregt's lambda-cube, as @cody discusses.", "meta": {"post_id": 8234, "input_score": 24, "output_score": 23, "post_title": "Is there an expressiveness hierarchy for type systems?"}}
{"input": "I think I'm not understanding it, but $\\eta$-conversion looks to me as a $\\beta$-conversion that does nothing, a special case of $\\beta$-conversion where the result is just the term in the lambda abstraction because there is nothing to do, kind of a pointless $\\beta$-conversion.\nSo maybe $\\eta$-conversion is something really deep and different from this, but, if it is, I don't get it, and I hope you can help me with it.\n(Thank you and sorry, I know this is part of the very basics in lambda calculus)", "output": "Update [2011-09-20]: I expanded the paragraph about $\\eta$-expansion and extensionality. Thanks to Anton Salikhmetov for pointing out a good reference.\n$\\eta$-conversion $(\\lambda x . f x) = f$ is a special case of $\\beta$- conversion only in the special case when $f$ is itself an abstraction, e.g., if $f = \\lambda y . y y$ then $$(\\lambda x . f x) = (\\lambda x . (\\lambda y . y y) x) =_\\beta (\\lambda x . x x) =_\\alpha f.$$ But what if $f$ is a variable, or an application which does not reduce to an abstraction?\nIn a way $\\eta$-rule is like a special kind of extensionality, but we have to be a bit careful about how that is stated. We can state extensionality as:\n\nfor all $\\lambda$-terms $M$ and $N$, if $M x = N x$ then $M = N$, or\nfor all $f, g$ if $\\forall x . f x = g x$ then $f = g$.\n\nThe first one is a meta-statement about the terms of the $\\lambda$-calculus. In it $x$ appears as a formal variable, i.e., it is part of the $\\lambda$-calculus. It can be proved from $\\beta\\eta$-rules, see for example Theorem 2.1.29 in \"Lambda Calculus: its Syntax and Semantics\" by Barendregt (1985). It can be understood as a statement about all the definable functions, i.e., those which are denotations of $\\lambda$-terms.\nThe second statement is how mathematicians usually understand mathematical statements. The theory of $\\lambda$-calculus describes a certain kind of structures, let us call them \"$\\lambda$-models\". A $\\lambda$-model might be uncountable, so there is no guarantee that every element of it corresponds to a $\\lambda$-term (just like there are more real numbers than there are expressions describing reals). Extensionality then says: if we take any two things $f$ and $g$ in a $\\lambda$-model, if $f x = g x$ for all $x$ in the model, then $f = g$. Now even if the model satisfies the $\\eta$-rule, it need not satisfy extensionality in this sense. (Reference needed here, and I think we need to be careful how equality is interpreted.)\nThere are several ways in which we can motivate $\\beta$- and $\\eta$-conversions. I will randomly pick the category-theoretic one, disguised as $\\lambda$-calculus, and someone else can explain other reasons.\nLet us consider the typed $\\lambda$-calculus (because it is less confusing, but more or less the same reasoning works for the untyped $\\lambda$-calculus). One of the basic laws that should holds is the exponential law $$C^{A \\times B} \\cong (C^B)^A.$$ (I am using notations $A \\to B$ and $B^A$ interchangably, picking whichever seems to look better.) What do the isomorphisms $i : C^{A \\times B} \\to (C^B)^A$ and $j : (C^B)^A \\to C^{A \\times B}$ look like, written in $\\lambda$-calculus? Presumably they would be $$i = \\lambda f : C^{A \\times B} . \\lambda a : A . \\lambda b : B . f \\langle a, b \\rangle$$ and $$j = \\lambda g : (C^B)^A . \\lambda p : A \\times B . g (\\pi_1 p) (\\pi_2 p).$$\nA short calculation with a couple of $\\beta$-reductions (including the $\\beta$-reductions $\\pi_1 \\langle a, b \\rangle = a$ and $\\pi_2 \\langle a, b \\rangle = b$ for products) tells us that, for every $g : (C^B)^A$ we have $$i (j g) = \\lambda a : A . \\lambda b : B . g a b.$$\nSince $i$ and $j$ are inverses of each other, we expect $i (j g) = g$, but to actually prove this we need to use $\\eta$-reduction twice: $$i(j g) = (\\lambda a : A . \\lambda b : B . g a b) =_\\eta (\\lambda a : A . g a) =_\\eta g.$$\nSo this is one reason for having $\\eta$-reductions. Exercise: which $\\eta$-rule is needed to show that $j (i f) = f$?", "meta": {"post_id": 8259, "input_score": 23, "output_score": 24, "post_title": "What's the point of $\\eta$-conversion in lambda calculus?"}}
{"input": "I have some experience in scientific computing, and have extensively used kd-trees for BSP (binary space partitioning) applications. I have recently become rather more familiar with octrees, a similar data structure for partitioning 3-D Euclidean spaces, but one that works at fixed regular intervals, from what I gather.\nA bit of independence research seems to indicate that kd-trees are typically superior in performance for most datasets -- quicker to construct and to query. My question is, what are the advantages of octrees in spatial/temporal performance or otherwise, and in what situations are they most applicable (I've heard 3D graphics programming)? A summary of the advantages and problems of both types would me most appreciated.\nAs an extra, if anyone could elaborate on the usage of the R-tree data structure and its advantages, I would be grateful for that too. R-trees (more so than octrees) seem to be applied quite similarly to kd-trees for k-nearest-neighbour or range searches.", "output": "The cells in a $kD$-tree can have high aspect ratio, whereas octree cells are guaranteed to be cubical. Since this is a theory board, I'll give you the theoretical reason why high aspect ratio is a problem: it makes it impossible to use volume bounds to control the number of cells that you have to examine when solving approximate nearest neighbor queries.\nIn more detail: if you ask for an $\\epsilon$-approximate nearest neighbor to a query point $q$, and the actual nearest neighbor is at distance $d$, you typically end up with a search that examines every data structure cell that reaches from the inside to the outside of an annulus or annular shell with inner radius $d$ and outer radius $(1+\\epsilon)d$. If the cells have bounded aspect ratio, as they are in a quadtree, then there can be at most $1/\\epsilon^{d-1}$ such cells, and you can prove good bounds on the time for the query. If the aspect ratio is not bounded, as in a $kD$-tree, these bounds do not apply.\n$kD$-trees have a different advantage over quadtrees, in that they are guaranteed to have at most logarithmic depth, which also contributes to the time for a nearest neighbor query. But  the depth of a quadtree is at most the number of bits of precision of the input which is generally not large, and there are theoretical methods for controlling the depth to be essentially logarithmic (see the skip quadtree data structure).", "meta": {"post_id": 8470, "input_score": 44, "output_score": 30, "post_title": "Why would one ever use an Octree over a KD-tree?"}}
{"input": "Related problem: Veblen\u2019s Theorem states that \"A graph admits a cycle decomposition if and only if it is even\". The cycles are edge disjoint, but not necessarily node disjoint. Put another way, \"The edge set of a graph can be partitioned into cycles if and only if every vertex has even degree.\"\nMy Problem: I wonder has anybody studied the partition a graph into node-disjoint cycles. That is, partition the vertices $V$ of a graph $G$ into $V_1, V_2, \\cdots, V_k$, and each subgraph induced by $V_i$ is hamiltonian. \nIs it NP-hard or easy?\nMore related problem: \nPartition into triangle is NP-complete. (Page 68 of \"Computers and intractability\")\nThank you for your advise in advance. ^^", "output": "A partition into vertex-disjoint cycles is the same thing as a 2-regular subgraph, more commonly known as a 2-factor. It can be found (if it exists) in polynomial time by an algorithm based on matching. E.g. see this link.\nETA Nov 2013: It seems from comments below that the reduction from the source linked above is wrong. However, the statement that the problem can be reduced to perfect matching remains correct. The correct reduction is in W. T. Tutte (1954), \"A short proof of the factor theorem for finite graphs\", Canadian J. Math. 6: 347\u2013352.\nReplace each vertex $v$ with degree $d$ by a complete bipartite graph $G_v=K_{d,\\,d-2}$, and represent each edge $uv$ of the original graph by an edge from one vertex of $G_u$ to one vertex of $G_v$ (on the side of the bipartition with $d$ vertices) in such a way that each vertex of $G_v$ on that side of the bipartition has exactly one such edge incident to it.\nThen a perfect matching in the modified graph has to match the $d-2$ vertices on their side of the bipartition of $G_v$ with $d-2$ out of the $d$ vertices on the other side, leaving exactly two free vertices that need to be matched with their neighbors in other subgraphs $G_u$. In this way, the perfect matchings of the modified graph correspond 1-for-1 with cycle covers of the original graph.", "meta": {"post_id": 8563, "input_score": 21, "output_score": 24, "post_title": "Partition a graph into node-disjoint cycles"}}
{"input": "I had done some search on this but I was not able to find an answer either way.\nHuck answered it fully. Thanks :)", "output": "Here's a simple argument that shows that QP is not known to be in PSPACE:\nAssume $QP \\subseteq PSPACE$. Then we have $P \\subsetneq QP \\subseteq PSPACE$, where the first inclusion is proper by the time hierarchy theorem.\nThis separates $P$ from $PSPACE$, which is not known to hold, so $QP \\subseteq PSPACE$ must also not be known to hold.\nIndeed we have that $PSPACE \\subseteq QP \\Rightarrow PSPACE \\subsetneq EXP$, but $QP \\nsubseteq PSPACE$ does not separate the two classes by the THT (as stated in the question).", "meta": {"post_id": 8598, "input_score": 14, "output_score": 28, "post_title": "Is Quasi-polynomial time in PSPACE?"}}
{"input": "What is the complexity of deciding whether an $\\mathsf{NC}^0$ circuit\nwith $n$ input bits and $n$ output bits computes  a permutation \nof $\\{0,1\\}^n$? in the other words, whether every bit strings in \n$\\{0,1\\}^n$ is an output of the circuit for some input?\nIt looks like a problem which has been studied, \nbut I cannot find any references.", "output": "Hardness\nFollowing your comment on the question, we will call a circuit where each output bit depends on at most k input bits a \u201cNC0k circuit.\u201d  Using this term, your problem is coNP-complete in case of NC05 circuits.  That is, the following problem is coNP-complete.\nInstance: A Boolean circuit C with n input bits and n output bits where each output bit depends on at most five input bits.\nQuestion: Is the mapping from {0,1}n to itself computed by C bijective?\nAs Kaveh commented, it is clearly in coNP, even without the bound on the number of input bits on which each output bit depends.  To prove the coNP-hardness, we will reduce 3SAT to the complement of the current problem.  The key idea of the reduction is the same as the one used in the paper [Dur94] by Durand, which I mentioned in a comment on the question, but the whole reduction is much simpler in our case.\nGiven a 3CNF formula \u03c6 with n variables and m clauses, we construct a Boolean circuit C with (n+m) input bits and (n+m) output bits as follows.  We label the input bits as x1, \u2026, xn, y1, \u2026, ym, and the output bits as x\u20321, \u2026, x\u2032n, z1, \u2026, zm.  We consider that the input bits x1, \u2026, xn specify a truth assignment to the n variables in \u03c6.\n\nx\u2032i = xi for 1\u2264i\u2264n.  That is, the first n bits of input are always copied to the first n bits of output.\nFor 1\u2264i\u2264m, if the ith clause of \u03c6 is satisfied, then zi = yi \u2295 yi+1, where the subscript is interpreted modulo m.  Otherwise, zi = yi.\n\nNote that each output bit depends on at most five input bits.  I omit the proof of the correctness of the reduction, but the key idea (which I borrowed from [Dur94]) is that if \u03c6 is satisfiable and input bits x1, \u2026, xn are set to a satisfying assignment of \u03c6, then the m output bits z1, \u2026, zm are constrained to have the even parity, and therefore the circuit cannot be a permutation.  On the other hand, if input bits x1, \u2026, xn are set to a non-satisfying assignment of \u03c6, then output bits z1, \u2026, zm can be set to anything; because of this, if \u03c6 is unsatisfiable, then the circuit is a permutation.\nTractability\nOn the tractable side, your problem is in P in case of NC02 circuits.  This is shown as follows.  In general, each output bit in a Boolean circuit for a permutation is balanced; i.e., exactly half of the input strings set the output bit to 1.  However, every balanced Boolean function from {0,1}2 to {0,1} is affine; i.e., a copy of a single input bit, the XOR of the two input bits, or the negation of them.  Therefore, we can first check that each output bit is balanced, and then check the bijectivity by the Gaussian elimination.\nI do not know the complexity in case of NC03 circuits or in case of NC04 circuits.\nReferences\n[Dur94] Bruno Durand.  Inversion of 2D cellular automata: some complexity results.  Theoretical Computer Science, 134(2):387\u2013401, Nov. 1994.  DOI: 10.1016/0304-3975(94)90244-5.", "meta": {"post_id": 8664, "input_score": 27, "output_score": 29, "post_title": "Deciding if a given $\\mathsf{NC}^0$ circuit computes a permutation"}}
{"input": "Why are regular languages (and from that regular expressions) called \"regular\"? There is lot of regularity also in context-free languages other types of languages.\nI suppose that, in the beginning, the adjective \"regular\" has been used to differentiate that type of languages from other \"non-regular\" or somehow abnormal languages. If so, what where these other types, and what was their non-regularity?", "output": "A quick check of the sources reveals that Chomsky called the levels of his hierarchy just \u201ctype 0, type 1, type 2, type 3\u201d. He mentions in a footnote that his type 3 corresponds to \u201cregular events\u201d of Kleene. Kleene wrote there: We shall presently describe a class of events which we will call \"regular events.\" (We would welcome any suggestions as to a more descriptive term.)\nIt would thus appear that the term is a historical accident, and in any case has no bearing on the relation of regular languages to context-free languages.", "meta": {"post_id": 8739, "input_score": 29, "output_score": 40, "post_title": "Why are regular languages called \"regular\"?"}}
{"input": "During my work i came up with the following problem:\nI am trying to find an $n \\times n$ $(0,1)$-matrix $M$, for any $n > 3$, with the following properties:\n\nThe determinant of $M$ is even.\nFor any non-empty subsets $I,J\\subseteq\\{1,2,3\\}$ with $|I| = |J|$, the submatrix $M^I_J$ has odd determinant if and only if $I=J$.  \n\nHere $M^I_J$ denotes the submatrix of $M$ created by removing the rows with indices in $I$ and the columns with indices in $J$.\nSo far, I tried to find such a matrix via random sampling but I am only able to find a matrix that has all properties except the first one, i.e., the matrix always has an odd determinant. I tried various dimensions and different input/output sets without any success. So this makes me think: \nIs that there is a dependency among the requirements, which prevents them from being simultaneously true?\nor\nIs it possible that such a matrix exists and can someone give me an example?\nThanks,\nEtsch", "output": "No such matrix exists.\nThe Desnanot-Jacobi identity says that for $i \\neq j$, \n$$\r\n\\det M_{ij}^{ij} \\det M = \\det M_i^i \\det M_j^j -\\det M_i^j \\det M_j^i\r\n$$\nso using this, we get\n$$\r\n\\det M_{12}^{12} \\det M = \\det M_{1}^{1} \\det M_{2}^{2} - \\det M_{1}^{2} \\det M_{2}^{1}\r\n$$\nBut your requirements force the left-hand-side to be 0 (mod 2) and the right-hand-side to be 1 (mod 2), showing they are incompatible.", "meta": {"post_id": 8883, "input_score": 10, "output_score": 22, "post_title": "Can such a matrix exist?"}}
{"input": "Are there any toy examples that provide 'essential' insights into understanding the three known barriers to $P = NP$ problem - relativization, natural proofs and algebrization?", "output": "Let me give a toy example of the relativization barrier. The canonical example is the time hierarchy theorem that ${\\bf TIME}[t(n)] \\subsetneq {\\bf TIME}[t(n)^2]$. The proof (by diagonalization) is only a little more involved than the proof that the halting problem is undecidable: we define an algorithm $A(x)$ which simulates the $x$th algorithm $A_x$ on input $x$ directly step-for-step for $t(|x|)$ steps, then outputs the opposite value. Then we argue that $A$ can be implemented to run in $t(|x|)^2$ time. \nThe argument works equally well if we equip all algorithms with access to an arbitrary oracle set $O$, which we assume we can ask membership queries to, in one step of computation. A step-for-step simulation of $A_x^O$ can also be carried out by $A$, as long as $A$ has access to the oracle $O$ too. In notation, we have ${\\bf TIME}^O[t(n)] \\subsetneq {\\bf TIME}^O[t(n)^2]$ for all oracles $O$. In other words, the time hierarchy relativizes.\nWe can define oracles for nondeterministic machines in a natural way, so it makes sense to define classes $P^O$ and $NP^O$ with respect to oracles. But there are oracles $O$ and $O'$ relative to which $P^O = NP^O$ and $P^{O'} \\neq NP^{O'}$, so this kind of direct simulation argument in the time hierarchy theorem won't work for resolving $P$ versus $NP$. Relativizing arguments are powerful in that they are widely applicable and have led to many great insights; but this same power makes them \"weak\" with respect to questions like $P$ versus $NP$. \nThe above is, of course, a toy example -- there are many other more complicated examples of arguments in complexity which still relativize (i.e., hold up when arbitrary oracles are introduced).", "meta": {"post_id": 8902, "input_score": 29, "output_score": 26, "post_title": "Toy examples for barriers to $P \\ne NP$"}}
{"input": "The state of our knowledge about general arithmetic circuits seems to be similar to the state of our knowledge about Boolean circuits, i.e. we don't have good lower-bounds. On the other hand we have exponential size lower-bounds for monotone Boolean circuits. \n\nWhat do we know about monotone arithmetic circuits? \n  Do we have similar good lower-bounds for them? \n  If not, what is the essential difference that doesn't allow us to get similar lower-bounds for monotone arithmetic circuits?\n\nThe question is inspired by comments on this question.", "output": "Lower bounds for monotone arithmetic circuits come easier because they forbid cancellations. On the other hand, we can prove exponential lower bounds for circuits computing boolean functions even if any monotone real-valued functions $g:R\\times R\\to R$ are allowed as gates (see e.g. Sect. 9.6 in the book).\nEven though monotone arithmetic circuits are weaker than monotone boolean circuits (in the latter we have cancellations $a\\land a=a$ and $a\\lor (a\\land b)=a$), these circuits are interesting because of their relation to dynamic programming (DP) algorithms. Most of such algorithms can be simulated by circuits over semirings $(+,\\min)$ or $(+,\\max)$. Gates then correspond to subproblems used by the algorithm. What Jerrum and Snir (in the paper by V Vinay) actually prove is that any DP algorithm for the Min Weight Perfect Matching (as well as for the TSP problem) must produce exponentially many subproblems. But the Perfect Mathching problem is not of \"DP flawor\" (it does not satisfy Bellman's Principle of Optimality). Linear programming (not DP) is much more suited for this problem.\nSo what about optimization problems that can be solved by reasonably small DP algorithms - can we prove lower bounds also for them? Very interesting in this respect is an old result of Kerr (Theorem 6.1 in his phd). It implies that the classical Floyd-Warshall DP algorithm for the All-Pairs Shortest Paths problem (APSP) is optimal: $\\Omega(n^3)$ subproblems are necessary. Even more interesting is that Kerr's argument is very simple (much simpler than that Jerrum and Snir used): it just uses the distributivity axiom\n$a+\\min(b,c)=\\min(a,b)+\\min(a,c)$, and the possibility to \"kill\" min-gates by setting one of its arguments to $0$.This way he proves that $n^3$ plus-gates are necessary to multiply two $n\\times n$ matrices over the semiring $(+,\\min)$. In Sect. 5.9 of the book by Aho, Hopcroft and Ullman it is shown that this problem is equivalent to APSP problem.\nA next question could be: what about the Single-Source Shortest Paths (SSSP) problem? Bellman-Ford DP algorithm for this (seemingly \"simpler\") problem also uses $O(n^3)$ gates. Is this optimal? So far, no separation between these two versions of the shortest path problem are known; see an interesting paper of Virginia and Ryan Williams along these lines. So, an $\\Omega(n^3)$ lower bound in $(+,\\min)$-circuits for SSSP would be a great result. Next question could be: what about lower bounds for Knapsack?  In this draft lower bounds for Knapsack are proved in weaker model of $(+,\\max)$ circuits where the usage of $+$-gates is restricted; in Appendix Kerr's proof is reproduced.", "meta": {"post_id": 8918, "input_score": 23, "output_score": 25, "post_title": "Monotone arithmetic circuits"}}
{"input": "Shiva Kintali has just announced a (cool!) result that graph isomorphism for bounded treewidth graphs of width $\\geq 4$ is $\\oplus L$-hard.  Informally, my question is, \"How hard is that?\"\nWe know that nonuniformly $NL \\subseteq \\oplus L$, see the answers to this question.  We also know that it is unlikely that $\\oplus L = P$, see the answers to this question.  How surprising would it be if $L=\\oplus L$?  I have heard many people say that $L=NL$ would not be shocking the way $P=NP$ would.\n\nWhat are the consequences of $L=\\oplus L$?\n\nDefinition: $\\oplus L$ is the set of languages recognized by a non-deterministic Turing machine which can only distinguish between an even number or odd number of \"acceptance\" paths (rather than a zero or non-zero number of acceptance paths), and which is further restricted to work in logarithmic space.", "output": "Wigderson proved that $NL/poly \\subseteq \\oplus L/poly$. By standard arguments, $L = \\oplus L$ would imply $L/poly = NL/poly$. (Take a machine $M$ in $NL/poly$. It has an equivalent machine $M'$ in $\\oplus L/poly$. Take the $\\oplus L$ language of instance-advice pairs $S = \\{(x,a)~|~M'(x,a)~\\textrm{accepts}\\}$. If this language is in $L$, then by hardcoding the appropriate advice $a$ we get an $L/poly$ machine equivalent to $M$.) \nI think that would be surprising: nondeterministic branching programs would be equivalent to deterministic branching programs (up to polynomial factors).", "meta": {"post_id": 8991, "input_score": 26, "output_score": 23, "post_title": "What are the consequences of $L = \\oplus L$?"}}
{"input": "I am interested in a SAT variation where the CNF formula is monotone (no variables are negated). Such a formula is obviously satisfiable.\nBut say the number of true variables is a measure of how good our solution is.  So we have the following problem:\nMINIMUM TRUE MONOTONE 3SAT\nINSTANCE: Set U of variables, collection C of disjunctive clauses of 3 literals, where a literal is a variable (not negated).\nSOLUTION: A truth assignment for U that satisfies C.\nMEASURE:  The number of variable that are true.\nCould someone give me some helpful remarks on this problem?", "output": "This problem is the same as the Vertex Cover problem for $3$-uniform hypergraphs: \ngiven a collection $H$ of subsets of $V$ of size $3$ each, find a minimal subset $U\\subseteq V$ that intersects each set in $H$.\nIt is therefore NP-hard, but fixed parameter tractable. \nIt is also NP-hard to approximate to within a factor of $2-\\epsilon$ for every $\\epsilon>0$. This was shown in the following paper:\nIrit Dinur, Venkatesan Guruswami, Subhash Khot and Oded Regev.\nA New Multilayered PCP and the Hardness of Hypergraph Vertex Cover,\nSIAM Journal on Computing, 34(5):1129\u20131146, 2005.", "meta": {"post_id": 9084, "input_score": 12, "output_score": 21, "post_title": "Minimum True Monotone 3SAT"}}
{"input": "I will be attending my first computer science conference and after reading the advice for how to improve conferences I noticed the several suggestions were about grad students attending their first conference.\nWhat advice do you have for a grad student attending his first conference and what should his focus be.", "output": "Talk to people, even if they are scary big names. \nAttend all the keynote/invited presentations.\nAttend the talks most relevant to you.\nDon't be afraid to ask questions.\nAttend the social events, meet other graduate students, have fun.\nTalk enthusiastically about your research. \nMake sure you have a 1 minute pitch describing your work, plus a 5 minute description, and also be prepared to enter into a more detailed discussion.\nAsk people about their research.   Simply asking what are you working on? will get the conversation started.\nBe open to possible collaborations, and follow up after the conference.", "meta": {"post_id": 9091, "input_score": 25, "output_score": 29, "post_title": "Advice for attending my first TCS conference"}}
{"input": "This question may not be technical. As a non-native speaker and a TA for algorithm class, I always wondered what gadget means in 'clause gadget' or 'variable gadget'. The dictionary says a gadget is a machine or a device, but I'm not sure what colloquial meaning it has in the context of NP-complete proof.", "output": "A \"gadget\" is a small specialized device for some particular task. In NP-hardness proofs, when doing a reduction from problem A to problem B, the colloquial term \"gadget\" refers to small (partial) instances of problem B that are used to \"simulate\" certain objects in problem A. For example, when reducing 3SAT to 3-COLORING, clause gadgets are small graphs that are used to represent the clauses of the original formula and variable gadgets are small graphs that are used to represent the variables of the original formula. In order to ensure that the reduction is correct, the gadgets have to be graphs that can be 3-colored in very specific ways. Hence we think of these small graphs as devices that perform a specialized task.\nIn many cases, the main difficulty of proving NP-hardness is constructing appropriate gadgets. Sometimes these gadgets are complicated and moderately large. The creative process of creating such gadgets is sometimes called \"gadgeteering.\"", "meta": {"post_id": 9173, "input_score": 15, "output_score": 27, "post_title": "What does 'gadget' mean in NP-hard reduction?"}}
{"input": "Would there be any major consequences if SAT had at most subexponential unsat proofs or even more strongly, SAT had subexponential-time algorithms?", "output": "If SAT had a subexponential-time algorithm, the you would disprove the exponential time hypothesis. \nFor fun consequences: if you showed that circuit SAT over AND,OR,NOT with $n$ variables and $poly(n)$ circuit gates can be solved faster than the trivial $2^n poly(n)$ approach, then by Ryan Williams' paper you show that $NEXP \\not\\subseteq P/poly$.", "meta": {"post_id": 9237, "input_score": 14, "output_score": 21, "post_title": "Consequences of sub-exponential proofs/algorithms for SAT"}}
{"input": "We \"know\" that $\\mathsf{SC}$ is named for Steve Cook and $\\mathsf{NC}$ is named for Nick Pippenger. If I'm not mistaken, Steve Cook named NC in honor of Nick Pippenger, and I was told that the reverse is true as well. However, I wasn't able to find any evidence of this latter fact in either Steve Cook's paper on DCFLs or Nisan's proof that $\\mathsf{RL} \\subseteq \\mathsf{SC}$.\nIs there any documented evidence of the latter claim, or is this merely \"in the air\" ? \np.s I'm asking because I was browsing examples of Stigler's Law of Eponymy, and was wondering about what I'll call \"Stigler Reciprocity\": where something invented by A is named after B and vice versa. An example of this is Cartan Matrices and Killing forms.", "output": "The following is according to Nick Pippenger:\n\nThe relevant references are as follows.  Steve described NC as Nick's Class in his paper \"Deterministic CFL's Are Accepted Simultaneously in Polynomial Time and Log Squared Space\" (ACM STOC, 11 (1979) 338-345)  on SC, and I described SC as Steve's Class in my paper \"Simultaneous Resource Bounds'' (IEEE FOCS, 20 (1979) 307-311)  on NC.  But the names originated about a year-and-a-half earlier, when I visited the University of Toronto CS Department (January through June, 1978).  That's when the study of the two classes began, with Steve defining SC and me defining NC, and various people in the department (I think Allan Borodin was the first) using the two names.  The following fall, Steve submitted the paper cited above. I was on the program committee for that STOC, and not allowed to submit papers to it, so my paper appeared in the following FOCS conference.\nBest wishes,\nNick", "meta": {"post_id": 9298, "input_score": 33, "output_score": 29, "post_title": "\"Steve's class\": origin of SC"}}
{"input": "The definition of Ramsey numbers is the following: \nLet $R(a,b)$ be a positive number such that every graph of order at least $R(a,b)$ contains either a clique on $a$ vertices or a stable set on $b$ vertices.\nI am working on some extension of Ramsey Numbers. While the study has some theoretical interest, it would be important to know the motivation of these numbers. More specifically I am wondering the (theoretical or practical) applications of Ramsey numbers. For instance, are there any solution methodology for a real life problem that uses Ramsey numbers? Or similarly, are there any proofs of some theorems based on Ramsey numbers?", "output": "Applications of Ramsey theory to CS, Gasarch", "meta": {"post_id": 9500, "input_score": 14, "output_score": 22, "post_title": "Application of Ramsey Numbers"}}
{"input": "Since it does not allow nonterminating computation, Coq is necessarily not Turing-complete. What is the class of functions that Coq can compute? (is there an interesting characterization thereof?)", "output": "Benjamin Werner has proved the mutual interpretability of ZFC with countably many inaccessibles and the Calculus of Inductive Constructions, in his paper Sets in Types, Types in Sets.  \nThis means, roughly, that any function which can be shown to be total in ZFC with countably many inaccessibles can be defined in Coq. So unless you are a set theorist working on large cardinals, it is unlikely that any computable function you have ever wanted cannot be defined in Coq.", "meta": {"post_id": 9775, "input_score": 25, "output_score": 21, "post_title": "Class of functions computable by Coq"}}
{"input": "What is the possibility for a computer scientist to change his field into a pure mathematician ? and what's the most smooth way to do it ? any examples for people who could make it ?", "output": "Theoretical computer scientists are already mathematicians.  So you don't need to do anything!\nYour later comment suggests that you're really asking about changing from one area of mathematics (like complexity theory) to another (like functional analysis).  The only way to do it is to just do it.  You want to be an analyst?  Great!  Just start doing analysis!  Read analysis books and papers, solve analysis problems, talk to lots of analyst faculty and students, attend analysis seminars, go to analysis conferences, ask analysis questions on MathOverflow, and so on.  Act like an analyst long enough (and well enough) and you'll become one.\nIn that respect, becoming a functional analyst is not so different from becoming anything else.  Want to be a programmer?  Program!  Want to be a writer?  Write!  Want to be a painter?  Paint!  Want to be a functional analyst?  Analyze functions!  (Meanwhile, don't forget to earn enough money to eat, and do not blow off the stupid administrative hurdles.)\nAnd yes, lots of people successfully change fields/careers.  For example, Joan Birman started her academic career in physics, worked for several years as a systems analyst in the aircraft industry, spent several more years at home raising kids, went back to grad school in mathematics in her 40s, and became one of the most influential researchers in modern low-dimensional topology and geometric group theory.  For other examples, see these questions on MathOverflow.\nOne last suggestion: You might find the transition somewhat smoother (possibly even real-analytic) if you drop your prejudices about \"pure\" versus \"applied\" mathematics.  Forget about the labels; just do the work.", "meta": {"post_id": 10170, "input_score": 9, "output_score": 21, "post_title": "About switching from a computer scientist to a mathematician"}}
{"input": "ST-Connectivity is the problem of determining whether there exists a directed path between two distinguished vertices $s$ and $t$ in a directed graph $G(V,E)$. Whether this problem can be solved in logspace, is a long-standing open problem. This is called the $NL$ vs $L$ problem.\n\nWhat is the complexity of ST-Connectivity, when the underlying undirected graph of $G$ has bounded treewidth.\n\nIs it known to be NL-hard ? Is there a $o({\\log}^2n)$ upper bound known ?", "output": "It appears the problem is in L by [EJT10] and thus L-complete under $\\text{NC}^1$ reducibility by [CM87]. See page 2 of [EJT10]:\n\nApplying Theorem I.3 to the formula $\\phi(X)$ expressing that $X$ is a\n  simple path from $s$ to $t$ shows that the problem $\\{(G,s,t) \\text{ }\n  | \\text{ tw$(G) \\leq k$, there is a path from $s$ to $t$ in $G$}\\}$\n  lies in L\n\nActually this result applies to all problems on bounded treewidth graphs which can be formulated in monadic second-order logic in L.\n[EJT10] Michael Elberfeld, Andreas Jakoby, and Till Tantau. Logspace versions of the theorems of Bodlaender and Courcelle. In Proceedings of the 51st Annual Symposium on Foundations of Computer Science (FOCS), pages 143\u2013152, 2010.\n[CM87] Stephen A. Cook, Pierre McKenzie: Problems Complete for Deterministic Logarithmic Space. J. Algorithms 8(3): 385-394 (1987)", "meta": {"post_id": 10485, "input_score": 31, "output_score": 25, "post_title": "Treewidth and the NL vs L Problem"}}
{"input": "When tinkering with noncanonical LR parsing, I thought up a parsing method (with infinitely sized tables, which makes it somewhat unpractical) capable of parsing exactly the unambiguous grammars in $O(n^2)$ time, and I wondered if it is possible to do better:\n\nCan all unambiguous grammars be parsed in linear time?\n\nI'm quite sure I read somewhere that this is the case, but it doesn't come up when searching the internet. The same question was asked here, but no answer was given as far as I know.", "output": "Unambiguous context-free parsing is in $O(n^2)$ using Earley's algorithm.  Whether there exists a parsing algorithm working in linear-time on all the unambiguous context-free grammars is an open problem.  One of the most advanced statements of this kind is due to Leo [1991], who showed that a variant of Earley parsing works in linear time for all LRR grammars.\n[Leo 1991] Joop M. I. M. Leo.  A general context-free parsing algorithm running in linear time on every LR($k$) grammar without using lookahead, Theoretical Computer Science 82(1):165--176. doi: 10.1016/0304-3975(91)90180-A", "meta": {"post_id": 10486, "input_score": 23, "output_score": 24, "post_title": "Can all unambiguous grammars be parsed in linear time?"}}
{"input": "When someone develops a new theory on computer science, specifically in artificial intelligence domain, which is barely on schetch (so there are no measurements, nor simulations, nor finished code or ready application) with just a mathematical and conceptual description, in which scientific journals people use to publish these theories/concepts?", "output": "I can think of two cases where this (more or less) happened.\nValiant published his first paper on PAC learning in Communications of the ACM 27 (1984). Charlie Bennett got Stephen Wiesner's paper on quantum cryptography published in SIGACT News 15 (1983). I believe that at the time of publication, the editors had more latitude in accepting articles without extensive peer review than in the standard model of refereed journals. \nIn both cases, the idea turned out to be enormously valuable, and I am sure the prestige of Valiant and of Bennett helped the work get published. In both cases, the research was quite a bit better worked out than \"barely a sketch\", but it was still very sketchy, and not completely convincing to contemporary researchers.\nIf you are an unknown researcher, in order to get anybody to pay attention, you probably need to work out your ideas at least as well as they were worked out in these two cases, and even then I am not sure whether you could get sketchy ideas published without having the backing of a respected researcher (as Wiesner did).v\nRalph Merkle did not succeed in getting his sketchy ideas on what was to become public-key cryptography published until after Diffie, Hellman, Rivest, Shamir and Adelman had worked out the sketchy ideas in enough detail to convince everybody they were worthwhile. Fortunately, somebody put him in touch with Diffie and Hellman, who were clever enough to see the value of his ideas, talented enough to work them out in some detail, and honest enough to give him his fair share of the credit. See this article.", "meta": {"post_id": 10519, "input_score": 3, "output_score": 21, "post_title": "New theories and publications on computer science"}}
{"input": "Are there any (functional?) programming languages where all functions have a canonical form? That is, any two functions that return the same values for all set of input is represented in the same way, e.g. if f(x) returned x + 1, and g(x) returned x + 2, then f(f(x)) and g(x) would generate indistinguishable executables when the program is compiled.\nPerhaps more importantly, where/how might I find more information on canonical representation of programs (Googling \"canonical representation programs\" has been less than fruitful)? It seems like a natural question to ask, and I'm afraid that I just don't know the proper term for what I am looking for. I'm curious as to whether it is possible for such a language to be Turing complete, and if not, how expressive a programming language you can have, while still retaining such a property.\nMy background is rather limited, so I would prefer sources with fewer prerequisites, but references to more advanced sources may be cool too, as that way I'll know what I want to work towards.", "output": "The extent to which this is possible is actually a major open question in the theory of the lambda calculus. Here's a quick summary of what's known:\n\nThe simply-typed lambda calculus with unit, products, and function space does have a simple canonical forms property. Two terms are equal if and only if they have the same beta-normal, eta-long form. Computing these normal forms is also quite straightforward.\nThe addition of sum types greatly complicates matters. The equality problem is still decidable (the keyword to search for is \"coproduct equality\"), but the known algorithms work for extremely tricky reasons and to my knowledge there is no totally satisfying normal form theorem. Here are the four approaches I know of:\n\nNeil Ghani, Beta-Eta Equality for Coproducts, TLCA 1995.\nVincent Balat, Roberto di Cosimo, Marcelo Fiore, Extensional normalisation and type-directed partial evaluation for typed lambda calculus with sums, POPL 2004.\nSam Lindley, Extensional Rewriting with Sums, TLCA 2007.\nArbob Ahmad, Daniel R. Licata, and Robert Harper, A Proof-Theoretic Decision Procedure for the Finitary Lambda-Calculus. WMM 2007.\n\nThe addition of unbounded types, such as natural numbers, makes the problem undecidable. Basically, you can now encode Hilbert's tenth problem.\nThe addition of recursion makes the problem undecidable, because having normal forms makes equality decidable, and that would let you solve the halting problem.", "meta": {"post_id": 10608, "input_score": 31, "output_score": 41, "post_title": "Programming languages with canonical functions"}}
{"input": "It is known that with a countable set of algorithms (characterised by a G\u00f6del number), we cannot compute (build a binary algorithm which checks belonging) all subsets of N.\nA proof could be summarized as: if we could, then the set of all subsets of N would be countable (we could associate to each subset the G\u00f6del number of the algorithm which computes it). As this is false, it proves the result.\nThis is a proof I like as it shows that the problem is equivalent to the subsets of N not being countable.\nNow I'd like to prove that the halting problem is not solvable using only this same result (uncountability of N subsets), because I guess those are very close problem. Is it possible to prove it this way ?", "output": "The halting theorem, Cantor's theorem (the non-isomorphism of a set and its powerset), and Goedel's incompleteness theorem are all instances of the Lawvere fixed point theorem, which says that for any cartesian closed category, if there is an epimorphic map $e : A \\to (A \\Rightarrow B)$ then every $f : B \\to B$ has a fixed point.\n\nLawvere, F. William. Diagonal Arguments and Cartesian Closed Categories. Lecture Notes in Mathematics, 92 (1969), 134-145.\n\nFor a nice introduction to these ideas, see this blog post of Andrej Bauer.", "meta": {"post_id": 10635, "input_score": 30, "output_score": 42, "post_title": "Halting problem, uncomputable sets: common mathematical proof?"}}
{"input": "The AND&OR gate is a gate which is given two inputs and returns their AND and their OR. Are circuits made only out of the AND&OR gate, without fanout, capable of doing arbitrary computations? More precisely, is polynomial time computation logspace reducible to AND&OR circuits?\nMy motivation for this problem is rather strange. As described here, this question is important for computation inside the computer game Dwarf Fortress.", "output": "If I don't misunderstand what you mean by AND&OR gate, it is basically a comparator gate which takes two input bits $x$ and $y$ and produces two output bits $x\\wedge y$ and $x\\vee y$. The two output bits $x\\wedge y$ and $x\\vee y$ are basically min$(x,y)$ and max$(x,y)$. \nComparator circuits are built by composing these comparator gates together but allowing no more fan-outs other than the two outputs produced by each gate. Thus, we can draw comparator  circuits using the notations below (similarly to how we draw sorting networks).\n\nWe can define the comparator circuit value problem (CCV) as follows: given a comparator circuit with specified Boolean inputs, determine the output value of a designated wire. By taking the closure of this CCV problem under logspace reductions, we get the complexity class CC, whose complete problems include natural problems like lex-first maximal matching, stable marriage, stable roomate. \nIn this recent paper, Steve Cook, Yuval Filmus and I showed that even when we use AC$^0$ many-one closure, we still get the same class CC. To the best of our knowledge at this point, NL $\\subseteq$ CC $\\subseteq$ P. In our paper, we provided evidence that CC and NC are incomparable (so that CC is a proper subset of P), by giving oracle settings where relativized CC and relativized NC are incomparable. We also gave evidence that CC and SC are incomparable.", "meta": {"post_id": 10837, "input_score": 22, "output_score": 23, "post_title": "Are AND&OR circuits P-complete?"}}
{"input": "I wonder how to find the girth of a sparse undirected graph. By sparse I mean $|E|=O(|V|)$. By optimum I mean the lowest time complexity.\nI thought about some modification on Tarjan's algorithm for undirected graphs, but I didn't find good results. Actually I thought that if I could find a 2-connected components in $O(|V|)$, then I can find the girth, by some sort of induction which can be achieved from the first part. I may be on the wrong track, though. Any algorithm asymptotically better than $\\Theta(|V|^2)$ (i.e. $o(|V|^2)$) is welcome.", "output": "Here's what I know about the girth problem in undirected unweighted graphs.\nFirst of all, if the girth is even, you can determine it in $O(n^2)$ time- this is an old result of Itai and Rodeh (A. Itai and M. Rodeh. Finding a minimum circuit in a graph. SIAM J. Computing, 7(4):413\u2013423, 1978.). The idea there is: for each vertex in the graph, start a BFS until the first cycle is closed (then stop and move on to the next vertex); return the shortest cycle found. If the girth is even the shortest cycle found will be the shortest cycle. In particular if your graph is bipartite this will always compute the girth. If the girth $g$ is odd, however, you'll find a cycle of length $g$ or $g+1$, so you may be off by $1$.\nNow, the real problem with odd girth is that inevitably your algorithm would have to be able to detect if the graph has a triangle. The best algorithms for that use matrix multiplication: $O($ min{$n^{2.38}, m^{1.41})$ time for graphs on $n$ nodes and $m$ edges.\nItai and Rodeh also showed that any algorithm that can find a triangle in dense graphs can also compute the girth, so we have an $O(n^{2.38})$ time girth algorithm. However, the runtime for the girth in sparse graphs is not as good as that for finding triangles. The best we know in general is $O(mn)$. In particular, what seems to be the hardest is to find a $o(n^2)$ time algorithm for graphs with $m=O(n)$.\nIf you happen to care about approximation algorithms, Liam Roditty and I have a recent paper in SODA'12 on that: Liam Roditty, V. Vassilevska Williams: Subquadratic time approximation algorithms for the girth. SODA 2012: 833-845.\nThere we show that a $2$-approximation can be found in subquadratic time, and some other results concerning additive approximations and extensions. Generally speaking, because of a theorem of Bondy and Simonovits, when you have densish graphs, say on $n^{1+1/k}$ edges, they already contain short even cycles, say roughly $2k$. So the denser the graph is, the easier it is to find a good approximation to the girth. When the graph is very sparse, the girth can be essentially arbitrarily large.", "meta": {"post_id": 10983, "input_score": 14, "output_score": 28, "post_title": "Optimal algorithm for finding the girth of a sparse graph?"}}
{"input": "In his celebrated paper \"Conjugate Coding\" (written around 1970), Stephen Wiesner proposed a scheme for quantum money that is unconditionally impossible to counterfeit, assuming that the issuing bank has access to a giant table of random numbers, and that banknotes can be brought back to the bank for verification.  In Wiesner's scheme, each banknote consists of a classical \"serial number\" $s$, together with a quantum money state $|\\psi_s\\rangle$ consisting of $n$ unentangled qubits, each one either\n$$|0\\rangle,\\ |1\\rangle,\\ |+\\rangle=(|0\\rangle+|1\\rangle)/\\sqrt{2},\\ \\text{or}\\ |-\\rangle=(|0\\rangle-|1\\rangle)/\\sqrt{2}.$$\nThe bank remembers a classical description of $|\\psi_s\\rangle$ for every $s$.  And therefore, when $|\\psi_s\\rangle$ is brought back to the bank for verification, the bank can measure each qubit of $|\\psi_s\\rangle$ in the correct basis (either $\\{|0\\rangle,|1\\rangle\\}$ or ${|+\\rangle,|-\\rangle}$), and check that it gets the correct outcomes.\nOn the other hand, because of the uncertainty relation (or alternatively, the No-Cloning Theorem), it's \"intuitively obvious\" that, if a counterfeiter who doesn't know the correct bases tries to copy $|\\psi_s\\rangle$, then the probability that both of the counterfeiter's output states pass the bank's verification test can be at most $c^n$, for some constant $c<1$.  Furthermore, this should be true regardless of what strategy the counterfeiter uses, consistent with quantum mechanics (e.g., even if the counterfeiter uses fancy entangled measurements on $|\\psi_s\\rangle$).\nHowever, while writing a paper about other quantum money schemes, my coauthor and I realized that we'd never seen a rigorous proof of the above claim anywhere, or an explicit upper bound on $c$: neither in Wiesner's original paper nor in any later one.\nSo, has such a proof (with an upper bound on $c$) been published?  If not, then can one derive such a proof in a more-or-less straightforward way from (say) approximate versions of the No-Cloning Theorem, or results about the security of the BB84 quantum key distribution scheme?\nUpdate: In light of the discussion with Joe Fitzsimons below, I should clarify that I'm looking for more than just a reduction from the security of BB84.  Rather, I'm looking for an explicit upper bound on the probability of successful counterfeiting (i.e., on $c$)---and ideally, also some understanding of what the optimal counterfeiting strategy looks like.  I.e., does the optimal strategy simply measure each qubit of $|\\psi_s\\rangle$ independently, say in the basis\n$$\\{ \\cos(\\pi/8)|0\\rangle+\\sin(\\pi/8)|1\\rangle, \\sin(\\pi/8)|0\\rangle-\\cos(\\pi/8)|1\\rangle \\}?$$\nOr is there an entangled counterfeiting strategy that does better?\nUpdate 2: Right now, the best counterfeiting strategies that I know are (a) the strategy above, and (b) the strategy that simply measures each qubit in the $\\{|0\\rangle,|1\\rangle\\}$ basis and \"hopes for the best.\"  Interestingly, both of these strategies turn out to achieve a success probability of (5/8)n.  So, my conjecture of the moment is that (5/8)n might be the right answer.  In any case, the fact that 5/8 is a lower bound on c rules out any security argument for Wiesner's scheme that's \"too\" simple (for example, any argument to the effect that there's nothing nontrivial that a counterfeiter can do, and therefore the right answer is c=1/2).\nUpdate 3: Nope, the right answer is (3/4)n!  See the discussion thread below Abel Molina's answer.", "output": "It seems like this interaction can be modeled in the following way:\n\nAlice prepares one of the states $|000\\rangle$, $|101\\rangle$,$(|0\\rangle+|1\\rangle)|10\\rangle/\\sqrt{2}$, $(|0\\rangle-|1\\rangle)|11\\rangle/\\sqrt{2}$, according to a certain probability distribution, and sends the first qubit to Bob.\nBob performs an arbitrary quantum channel that sends his qubit to two qubits, which are then returned to Alice.\nAlice performs a projective measurement on the four qubit on her possession. \n\nIf I am not wrong about this (and sorry if I am), this falls within the formalism from Gutoski and Watrous presented here and here, which implies that:\n\nFrom Theorem 4.9 in the second of those, it is optimal to Bob to act independently  when Alice repeats this process with several qubits in an independent way, if the objective of Bob is to always fool Alice.\nIt is possible to obtain the value of c from a small semidefinite program. You can find more details of how to obtain this program in Section 3 here. See the comments for the cvx code for the program and its value.", "meta": {"post_id": 11363, "input_score": 54, "output_score": 34, "post_title": "Rigorous security proof for Wiesner's quantum money?"}}
{"input": "This is related to the question Is the Witness Size of Membership for Every NP Language Already Known?\nSome natural $\\mathsf{NP}$(-complete) problems have linear length witnesses: a satisfying assignment for $SAT$, a sequence of vertices for $HAMPATH$, etc.\nConsider the complexity class \"$\\mathsf{NP}$ restricted to linear length witnesses\". Formal definition of this complexity class, call it $\\mathcal{C}$: $L\\in\\mathcal{C}$ if $\\exists L'\\in\\mathsf{P}\\colon (x\\in L \\iff \\exists w\\in\\{0, 1\\}^{O(|x|)}\\colon (x, w)\\in L')$.\nIs this a known complexity class? What are its properties?", "output": "The class ${\\cal C}$ you are proposing is probably not $NP$. (If ${\\cal C} = NP$, then every $NP$ language would have linear-size witnesses, which would imply that every $NP \\subseteq TIME[2^{O(n)}]$ and $NP \\neq EXP$, among other things). \nIt is very natural to consider such classes; they arise in several settings. In this paper, Rahul Santhanam (implicitly) proposed the notation $TIGU(t(n),g(n))$ for time-$t(n)$ computation with $g(n)$-guess bits. Hence ${\\cal C} = \\bigcup_{k} TIGU(n^k,kn)$. In this paper, I defined an analogous class $NTIBI[t(n),b(n)]$. (NTIBI stands for \"nondeterministic time and bits\".) Also, Cai and Chen would call your class $GC(O(n), P)$ (GC stands for \"Guess and Check\", cf. L. Cai and J. Chen. On the amount of nondeterminism and the power of verifying. SIAM Journal on Computing, 1996). Finally, if you search for \"bounded nondeterminism\" you may find three more notations for the same class...", "meta": {"post_id": 11422, "input_score": 25, "output_score": 28, "post_title": "What is $\\mathsf{NP}$ restricted to linear size witnesses?"}}
{"input": "Is there an example of a natural problem that's in BPP but that's not known to be in RP or co-RP?", "output": "Moved my comment here after Suresh's request.\nAn example of a natural problem for which we only know algorithms that require error on both sides is the following: given three algebraic circuits, decide whether exactly two of them are identical. This comes from the fact that deciding whether two algebraic circuits are identical is in co-RP.\nReference: see the post How Many Sides to Your Error? (Dec 2, 2008) about the very same question on Lance Fortnow's blog and the comments below his post for a discussion about the naturalness of the problem.", "meta": {"post_id": 11425, "input_score": 21, "output_score": 22, "post_title": "Problem in BPP but not known to be in RP or co-RP"}}
{"input": "If I have an one-bit uniform random generator, how can I use it to generate a permutation uniformly for the sequence {1, 2, ..., n}.\nI have a solution:  run the one-bit random generator n*n times to decide if each pair of elements will be exchanged.\nThe complexity is O(n*n).\nI want to know if there more efficiency solution? What is the lower bound for this problem?", "output": "Your solution does not work (or I don't understand it): the resulting permutation would not be uniformly random.\nTo Sasho Nikolov, this is a research topic and is actually the topic (among others) of a paper I have recently submitted, where I provide an optimal algorithm. I can give you an idea of the lower bound. Indeed, you would have to distinguish between n! different permutations, so theoretically you would need at least log2(n!) bits exactly. But Knuth and Yao show in their seminal paper (\"The complexity of nonuniform random number\"), that because of \"rounding errors\" (to simplify), the actually random-bit complexity is between log2(n!) and log2(n!) + 2, that those are the best bounds, and in addition they provide an exact expression in terms of entropy of the distribution (in this case the uniform distribution).\nIt can (and has) been shown that the exact complexity involves fluctuations periodic in log2(n), much like the average complexity of divide-and-conquer algorithms such as QuickSort. (Such details are routinely hidden by the traditional sledge-hammer approach known as the \"Master theorem\" :-).\n\nNow, supposing you have your random number X, the bijection between the number and the corresponding permutation is a subproblem of what is more largely referred to as \"unranking\". Martinez and Molinero have devised a nice general framework based on a popular random generation framework introduced by Wilf and Nijenhuis and formalized by Flajolet et al.. But for permutations it is a much simpler problem: you consider the factorial-base expansion of X to get the random integers needed for the Fisher-Yates algorithm. See the following for more info:\nhttp://en.wikipedia.org/wiki/Factorial_number_system\nhttp://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle\nEDIT: added the image which shows the optimal number of expected random bits needed to distinguish between N choices.", "meta": {"post_id": 11894, "input_score": 9, "output_score": 22, "post_title": "How to generate a permutation uniformly by repeating using an one-bit uniform random generator?"}}
{"input": "Recently I stumbled upon quite an interesting theoretical construct. A so called  G\u00f6del machine\nIt's a general problem solver which is capable of self-optimization. It's suitable for reactive environments.\nAs I understand, it can be implemented as a program for universal Turing machine, although it's requirements go far beyond hardware currently available. I couldn't find many details, though. \nCan such machines be built in practice? Are they at least feasible in our Universe?", "output": "Can such machines be built in practice? \nYes. By \"machine\", Schmidhuber just means \"computer program\".\nAre they at least feasible in our Universe?\nNot in their current form -- the algorithms are too inefficient. \n\nFrom a ten thousand meter perspective, J\u00fcrgen Schmidhuber (and former students, like Marcus Hutter) have been investigating the idea of combining Levin search with Bayesian reasoning to work out algorithms for general problem-solving. \nThe basic idea behind Levin search is that it's possible to use dovetailing and Goedel codes to give a single algorithm which is, up to constant factors, optimal. Loosely, you fix a Godel encoding of programs, and then run a Turing machine that runs the $n$-th program once every $2^{n}$ steps. This means that if the $n$-th program is optimal for some problem, then Levin search will \"only\" be a constant factor of $2^n$ times slower. \nThey have done a fair amount of work on making the constant factors less stupendously, horrifically awful, and are optimistic that this kind of scheme can work in practice. I am (based on my experience in automated theorem proving) very skeptical, since good data structures are critical to theorem proving, and Goedel encodings are terrible data structures. \nBut you don't know it can't work until you try to make it work! After all, we already live in a world where people solve problems by reduction to SAT.", "meta": {"post_id": 11927, "input_score": 18, "output_score": 22, "post_title": "Feasibility of G\u00f6del machines"}}
{"input": "I am looking for sources about formalized notion of programs. This seems to be closely related to Curry-Howard correspondence, but one could also track this back to Universal Turing Machines and its ability to read description and input of any TM.\nWhen reading about Curry-Howard correspondece I feel that the primordiality of UTM-s can harm research on programs with the unique conclusion that any program can be reduced to symbols, states and rules. Does there exist the opposite approach, where high-level computation systems are defined and examined? What are good resources about it?", "output": "What you want exists, and is an enormous area of research: it's the entire theory of programming languages. \nLoosely speaking, you can view computation in two ways. You can think of machines, or you can think of languages. \nA machine is basically some kind of finite control augmented with some (possibly unbounded) memory. This is why introductory TOC classes go from finite automata to pushdown automata to Turing machines --- each class takes a finite control and adds some more memory to it. (Nowadays, the finite control is often  limited even more, as in circuit models.)  The essential thing is that the finite control is given up front, and all at once. \nA language is a way of specifying a whole family of controls, in a compositional way. You have primitive forms for basic controls, and operators for building up larger controls from smaller ones. The primordial language, the lambda-calculus, in fact specifies nothing but control -- the only things you can define are function abstractions, applications, and variable references. \nYou can go back and forth between these two views: the $snm$-theorem is essentially a proof that Turing machines can implement function abstraction and application, and Church encodings demonstrate that the lambda-calculus can encode data. But there's nontrivial content in both of these theorems, and so you should not make the mistake of thinking that the two ways of understanding computation are the same.\nResearchers in complexity and algorithms typically take machines as fundamental, because they are interested in costs and in feasibility results. To exaggerate a bit, the basic research question they have is: \n\nWhat is the least powerful machine that can solve a certain kind of problem? \n\nLanguage researchers take languages as fundamental, because we are interested in expressiveness and impossibility results. With a similar exaggeration, our basic research question is: \n\nWhat is the most expressive language that rules out a certain kind of bad behavior?\n\nAs an aside, note how the two goods each kind of theoretician values are directly in conflict! Good work in algorithms and complexity lets you solve a harder problem, using less resources. Good work in languages lets programmers do more things, while forbidding more bad behaviors. (This conflict is basically why research is hard.)\nNow, you might ask why more Theory A types don't use languages, or why more Theory B researchers don't use machines. The reason arises from the shape of the basic research question. \nNote that the stylized basic research question in algorithms/complexity is a lower bound question -- you want to know that you have the best solution, and that there is no possible way to do better, no matter how clever you are. A language definition fixes the means of program composition, and so if you prove that a lower bound with a language model, then you might be left with the question of whether it might not somehow be possible to do better if you extended your language with some new feature. A machine model gives you the whole control in one go, and so you know everything the machine can possibly do right from the outset. \nBut machine specifications are exactly the wrong thing for saying interesting things about blocking bad behavior. A machine gives you a whole control up-front, but knowing that one particular program is okay or bad doesn't help you when you want to extend it or use it as a subroutine -- as Perlis's epigram states, \"Every program is a part of some other program and rarely fits.\" Since language researchers are interested in saying things about whole classes of programs, languages are much better suited for purpose.", "meta": {"post_id": 12255, "input_score": 8, "output_score": 21, "post_title": "Proofs techniques related to Curry\u2013Howard correspondence"}}
{"input": "What implications would a proof of the abc conjecture have for tcs?\nhttp://quomodocumque.wordpress.com/2012/09/03/mochizuki-on-abc/", "output": "Bhatnagar, Gopalan, and Lipton show that, assuming the abc conjecture, there are polynomials of degree $O((kn)^{1/2+\\varepsilon})$ representing the Threshold-of-$k$ function over ${\\mathbb Z}_6$. For fixed constant $k$, and $m$ which has $t$ prime factors, the abc conjecture implies a polynomial for Threshold-of-$k$ over $\\mathbb Z_m$ with degree $O(n^{1/t+\\varepsilon})$.\nThis presumably has relevance to the ${\\sf TC^0}$ versus $\\sf ACC^0[6]$ problem.", "meta": {"post_id": 12504, "input_score": 24, "output_score": 25, "post_title": "Implications of proof of abc conjecture for cs theory"}}
{"input": "The best upper bound known on the time complexity of multiplication is Martin F\u00fcrer's bound $n\\log n2^{O(\\log^* n)}$, which is more than linear time complexity of addition.  Do we have a proof that addition is inherently easier than multiplication?", "output": "No.\nNo unconditional better lower bound than the trivial $\\Omega(n)$ is currently known for integer multiplication. There are some conditional lower bounds though. For more on this, you can have a look at Martin F\u00fcrer's paper Faster Integer Multiplication.\nEdit following Andrej's comment: Addition can be done in time $\\mathcal O(n)$. In comparison, the best known upper bound for multiplication is (approximately) $\\mathcal O(n\\log n)$. On the other hand, no non trivial lower bound is known for multiplication, thus there is no proof that addition is faster than multiplication yet. As (too) often in complexity theory, we just don't know!", "meta": {"post_id": 12671, "input_score": 22, "output_score": 31, "post_title": "Is there a proof that addition is faster than multiplication?"}}
{"input": "Can we compute an $n$-bit threshold gate by polynomial size (unbounded fan-in) circuits of depth $\\frac{\\lg n}{\\lg \\lg n}$? Alternatively, can we count the number of 1s in the input bits using these circuits?\nIs $\\mathsf{TC^0} \\subseteq \\mathsf{AltTime}(O(\\frac{\\lg n}{\\lg  \\lg n}), O(\\lg n))$?\n\nNote that $\\mathsf{TC^0} \\subseteq \\mathsf{NC^1} = \\mathsf{ALogTime} = \\mathsf{AltTime}(O(\\lg n), O(\\lg n))$. So the question is essentially asking if we can save a $\\lg \\lg n$ factor in the depth of circuits when computing threshold gates.\n\nEdit:\nAs Kristoffer wrote in his answer we can save a $\\lg \\lg n$ factor. But can we save a little bit more? Can we replace $O(\\frac{\\lg n}{\\lg \\lg n})$ with $o(\\frac{\\lg n}{\\lg \\lg n})$?\nIt seems to me that the layered brute-force trick doesn't work for saving even $2 \\lg \\lg n$ (more generally any function in $\\lg \\lg n + \\omega(1)$).", "output": "Consider a fanin 2 circuit of $C$ depth $O(\\log n)$. Divide the layers of $C$ into $O(\\log n/\\log\\log n)$ blocks each of $\\log\\log n$ consecutive layers. We now wish to replace each block by a depth 2 circuit. Namely, each gate in the last layer of a block depends on at most $2^{\\log\\log n} = \\log n$ gates of the last layer in the block below. We can thus replace each gate in the last layer by a DNF of polynomial size with inputs being the gates in the last layer of the block below. Doing this for all gates in the last layers for all blocks and connecting these should yield the desired circuit.\nLet me note this is essentially the best one can obtain: the switching lemma allows for lower bounds all the way to depth $\\log n/ \\log\\log n$.", "meta": {"post_id": 12865, "input_score": 19, "output_score": 22, "post_title": "Can we count in depth $\\frac{\\lg n}{\\lg \\lg n}$?"}}
{"input": "I am looking for the method / correct way to approach to reduce the traveling salesman problem to an instance of traveling salesman problem which satisfies the triangle inequality, ie:\n$D(a, b) \\leq D(a, c) + D(c, b)$\nI am not sure how to attack this kind of problem, so any pointers / explanations regarding this would be helpful. Thank you.", "output": "Here is a simple reduction for the TSP problem to the metric TSP problem:\nFor the given TSP instance with $n$ cities, let $D(i,j) \\geq 0$ denote the distance between $i$ and $j$. Now let $M = \\max_{i,j} D(i,j)$. Define the metric TSP instance by the distances $D'(i,j) := D(i,j)+M$. To see that this gives a metric TSP instance, let $i,j,k$ be arbitrary. Then $D'(i,j) + D'(j,k) = D(i,j) + D(j,k) + 2M \\geq 2M \\geq D(i,k) + M = D'(i,k)$. Since any tour uses exactly $n$ edges, the transformation adds exactly $nM$ to any tour, which shows the correctness of the reduction.\nRemark: We can of course also allow for negative distances in the original TSP instance if you prefer by changing the reduction slightly.", "meta": {"post_id": 12885, "input_score": 6, "output_score": 21, "post_title": "Guidelines to reduce general TSP to Triangle TSP"}}
{"input": "Is there a useful description of futures or promises in terms of category theory? In particular, what could the categorical dual of Future be?", "output": "As it happens, I'm writing a paper about this now. IMO, a good way to think about futures or promises is in terms of the Curry-Howard correspondence for temporal logic. \nBasically, the idea behind futures is that it is a data structure representing a computation that is in progress, and upon which you can synchronize. In terms of temporal logic, this is the eventually operator $\\Diamond A$. This has a monadic structure:\n$$\n\\begin{array}{lcl}\n\\mathrm{return} & : & A \\to \\Diamond A \\\\\n\\mathrm{bind} & : & (A \\to \\Diamond{B}) \\to \\Diamond{A} \\to \\Diamond{B}\n\\end{array}\n$$\nin which the $\\mathrm{return}$ operation spawns a process that immediately returns its argument, and $\\mathrm{bind}$ creates a new process which waits for $a$'s value, applies $f$ to that value, and then waits for the $B$-value before returning. The Promises/A proposal for CommonJS calls the monadic bind  operation then, and Scala 2.10 just gives it the standard monadic interface. \nThe dual to the eventually operator $\\Diamond{A}$ is the always operator $\\Box{A}$ of temporal logic, which says that at every instant, you get an $A$. When you pass from a Kripke semantics of temporal logic (where you just model provability) to a categorial semantics of a $\\lambda$-calculus (where you model lambda-terms/proofs also), it turns out there are actually multiple ways to do this.\nThe simplest thing you can do is to take $\\Box{A} \\triangleq A$, on the grounds that once you have an $A$, you always have it. This works, but is kind of boring, IMO. :) \nThe most natural (IMO) thing to do is to take $\\Box{A} \\triangleq \\mathsf{Stream}\\;A$, which permits you to get a (potentially different) $A$ at each instant. Then, you can see the comonadic style of functional  reactive programming (FRP) (first proposed by Tarmo Uustalu and Varmo Vene) as the dual to monadic style of programming with futures. \nHowever, the comonadic $\\lambda$-calculus as they suggest, despite its elegance, causes a serious loss of expressiveness relative to programming explicitly with streams, since the category of free coalgebras they use turns out to have too few global elements to denote many interesting programs, especially fixed points.\nNick Benton and I have argued for programming explicitly with streams in our paper Ultrametric Semantics of Reactive Programs. Subsequently, Alan Jeffrey suggested using LTL as a type system in his paper LTL types FRP, an observation that Wolfgang Jeltsch also made in his paper Towards a Common Categorical Semantics for Linear-Time Temporal Logic and Functional Reactive Programming. \nThe difference between the view Nick and I take, and the one that Alan and Wolfgang take is best understood (IMO) by comparing the construction given in Birkedal et al.'s First steps in synthetic guarded domain theory: step-indexing in the topos of trees with Alan's paper. The topos of trees (presheaves over the natural numbers ordered by size) is very similar to category of ultrametric spaces Nick and I used, but much easier to compare with  Alan's category (presheaves over a discrete category of time), since these are both presheaf categories. \nIf you're interested in futures specifically for concurrency, then it might be a better idea to look at CTL rather than LTL, though. AFAIK, that's presently unexplored territory! \nEDIT: here's a link to the draft. The paper is mostly about implementing typed FRP, so the language is synchronous. But most of the discussion of futures/events in section 3.3 should basically apply to truly concurrent languages as well.", "meta": {"post_id": 14289, "input_score": 23, "output_score": 25, "post_title": "How are Futures described in terms of category theory?"}}
{"input": "I am reading the classic \"Hardness vs Randomness\" by Nisan and Wigderson.  Let $B=\\{0,1\\}$, and fix a function $l\\colon \\mathbb{N} \\to \\mathbb{N}$.  They define a family of functions $G = \\{G_n : B^{l(n)} \\to B^n\\}$ to be pseudorandom in case for every circuit of size $n$ we have\n$(*) \\ \\ | P(C(x) = 1) - P(C(G(y))=1) | < 1/n$\n(where $x \\in B^{n},y \\in B^{l(n)}$ are uniform random variables).\nI understand that I am to think of $x$ and $y$ as random variables, and that I want to compare the distance between $x$ and $G(y)$ as random variables.  I get the intuition that circuits are being used as sort of \"tests\" in to see if $G$ can be \"figured out.\"  What I am really struggling with is why the condition $(*)$ is the right one.  Does anyone have any advice on how to think of this definition?", "output": "There are two aspect that need to be mentioned.  \nThe first is the general idea of defining a PRG by having its output look different than uniform to small circuits. This idea goes back to Yao and is really the strongest possible definition you can ask for when aiming explicitly at pseudo-randomness for computationally-bounded observers.  \nThe second aspect is the choice of parameters where we limit the circuit size to be $n$ and the acceptance probability difference to be $1/n$, where $n$ is also the PRG output size. This choice is somewhat different than the usual crypto one where the circuit size is $poly(n)$ and the probability difference is required to be smaller than any $poly(n)$.  In our case specific parameters (rather than $poly(n)$) were needed as to get the tightest results including, in particular polynomial simulations.  While in principle one could have 3 different parameters, it turned out that our results had these working essentially in the same way so we folded them to a single one (in addition to the input size $l(n)$ which was viewed as a function of $n$).", "meta": {"post_id": 14320, "input_score": 16, "output_score": 21, "post_title": "What is the motivation behind the definition of pseudorandom in Nisan/Wigderson?"}}
{"input": "What is the complexity class associated with exhaustive search algorithms? (if there is one)\nIs it NP or PSPACE?\nAre there restricted models of computation capturing the class of exhaustive search algorithms similar to models for greedy and dynamic programming?", "output": "It's a little vague, but I like the question. I wrote a paper about it a LONG time ago. \nMaybe this will help the Anonymous questioner: \nBrute Force Search and Oracle-Based Computation \nHere's a summary. Informally, if you do not keep any scratch work from previous trials, and just try all possible solutions in lexicographical order until a desired solution is found, then brute force corresponds precisely to $P^{NP}$. If you keep around even $3$ bits of scratch work from one possible solution to the next, then you can do $PSPACE$, via Barrington's theorem. There are other possibilities, such as what happens when you don't run in lex order but according to some other efficiently computable list of all strings.\n[WARNING WARNING WARNING: It's likely that I disagree with almost all opinions stated in this paper. It was written about 10 years ago, by someone with the same name but who is essentially a different person.]", "meta": {"post_id": 14404, "input_score": 14, "output_score": 21, "post_title": "Complexity class associated with exhaustive search"}}
{"input": "Cubic graphs are graphs where every vertex has degree 3. They have been extensively studied and I'm aware that several NP-hard problems remain NP-hard even restricted to subclasses of cubic graphs, but some others get easier. A superclass of cubic graphs is the class of graphs with maximum degree $\\Delta \\leq 3$.\n\nIs there any problem that can be solve in polynomial time for cubic graphs but that is NP-hard for graphs with maximum degree $\\Delta \\leq 3$?", "output": "Here's a reasonably natural one: on an input $(G,k)$, determine whether $G$ has a connected regular subgraph with at least $k$ edges. For 3-regular graphs this is trivial, but if max degree is 3 and the input is connected, not a tree, and not regular, then the largest such subgraph is the longest cycle, so the problem is NP-complete.", "meta": {"post_id": 14457, "input_score": 27, "output_score": 27, "post_title": "Is there a problem that is easy for cubic graphs but hard for graphs with maximum degree 3?"}}
{"input": "Most sites I have visited reading on this interesting topic state something along the lines\n\n\"the only powers of two (other than 2 itself) that occur in this sequence are those with prime exponent\" (MathWorld)\n\nor\n\n\"After 2, this sequence contains the following powers of 2: [...] which are the prime powers of 2.\" (Wikipedia)\n\nThese careful formulations would imply that the set of powers of 2 generated in the sequence is a subset of prime powers of 2.\nHowever, the OEIS seems absolutely certain that the two sets are equal: http://oeis.org/A034785\nThis result is also cited on other sites I do not consider very reliable for exact wording, like\nhttp://esolangs.org/wiki/Fractran.\nHonestly, I have not understood the internal mechanics of PRIMEGAME enough to answer my own question yet. However, I think it makes a significant difference in the interestingness of PRIMEGAME. Why would sites like MathWorld not state the full fact?", "output": "Yes, PRIMEGAME outputs $2^k$ if and only if $k$ is prime.\nConway's original paper is well worth reading if you can track it down.  You can also find a very clear exposition in Richard Guy's paper Conway's prime producing machine (Mathematics Magazine 56(1):26\u201333, 1983), including the wonderful cartoon below. (Yes, that's Conway with the Alexander horns, referring to a famous drawing by Simon Fraser.)  Conway himself posted a concise proof on the math-fun mailing list.  There's also a brief explanation at the OEIS blog.", "meta": {"post_id": 14726, "input_score": 17, "output_score": 26, "post_title": "Does Conway's PRIMEGAME generate all prime powers of 2?"}}
{"input": "Many believe that $\\mathsf{BPP} = \\mathsf{P} \\subseteq \\mathsf{NP}$. However we only know that $\\mathsf{BPP}$ is in the second level of polynomial hierarchy, i.e. $\\mathsf{BPP}\\subseteq \\Sigma^ \\mathsf{P}_2 \\cap \\Pi^ \\mathsf{P}_2$. A step towards showing $\\mathsf{BPP} = \\mathsf{P}$ is to first bring it down to the first level of the polynomial hierarchy, i.e. $\\mathsf{BPP} \\subseteq \\mathsf{NP}$.\nThe containment would mean that nondeterminism is at least as powerful as randomness for polynomial time.\nIt also means that if for a problem we can find the answers using efficient (polynomial time) randomized algorithms then we can verify the answers efficiently (in polynomial time) .\n\nAre there any known interesting consequences for $\\mathsf{BPP} \\subseteq \\mathsf{NP}$?\nAre there any reasons to believe that proving $\\mathsf{BPP} \\subseteq \\mathsf{NP}$ is out of reach right now (e.g. barriers or other arguments)?", "output": "For one, proving $BPP \\subseteq NP$ would easily imply that $NEXP \\neq BPP$, which already means that your proof can't relativize.\nBut let's look at something even weaker: $coRP \\subseteq NTIME[2^{n^{o(1)}}]$. If that is true, then polynomial identity testing for arithmetic circuits is in nondeterministic subexponential time. By Impagliazzo-Kabanets'04, such an algorithm implies circuit lower bounds: either the Permanent does not have poly-size arithmetic circuits, or $NEXP \\not\\subset P/poly$. \nI personally don't know why it looks \"out of reach\" but it does seem hard to prove. Certainly some genuinely new tricks will be needed to prove it.", "meta": {"post_id": 14994, "input_score": 36, "output_score": 39, "post_title": "Consequences of $\\mathsf{NP}$ containing $\\mathsf{BPP}$"}}
{"input": "It seems that Geometric Complexity Theory requires much knowledge of pure maths such as algebraic geometry, representation theory. \nWhile I am a CS student and do NOT have classes of very abstract and pure mathematics, I am interested in this program.\nIs there a list of \"minimum knowledge\" for learning this theory ?   \nThis list includes lecture notes of CS or math departments, surveys of any journal or conferences, and text books of pure math.\n[EDIT: Added later] Thank you for your comments.\nGeneral theory of computing: I read Sipser's book with the title \"Introduction to the Theory of Computation\"\nComplexity Theory :In particular, I am interested in concrete models for lower bounds of complexity. Thus I read the part of the \"concrete lower bounds\" in Arora-Barak's text book. I also have basic knowlede in the several chapers of the communication complexity book written by Nisan.\nBasic Mathematics : I have learnt about proof-based linear algebra such as general definition of the vector space etc and precicely argument of calculas based on epsilon-delta argument. \nAlgebra: I have learned about definition and examples of group, ring, and field. I had a class for cs students, and have not learned about general thoery of this algebraic systems.", "output": "The short answer: the really minimum knowledge of math to understand the first half of the plan of GCT, once you've seen a little of groups, rings, and fields, is basically laid out in Chapter 3 of my thesis (shameless self plug). That chapter is, however, incomplete, in that I don't get to the representation theory part of things. The representation theory is crucial for the second half of the plan (which is why I'm working on extending that chapter to include it).\nIf you really want to get into GCT, Symmetry, Representations, and Invariants by Goodman and Wallach and Actions and Invariants of Algebraic Groups by W. Ferrers Santos are both relatively self-contained and have lots of good information that is pertinent to GCT. I'm not sure if they're the best sources to learn from, as I only learned about them after I had learned much of this material, but they are good in terms of the ratio of what they cover to what's relevant to GCT. Fulton and Harris is great for representation theory and lots of the examples/exercises in the book are relevant to GCT.\nThe longer answer: it really depends on what/how much you want to learn about GCT, as Vijay pointed out. The topics below are just what I think is the background needed, since that was the question. I'm not sure this is a complete list - I would recommend trying to read some of the papers on GCT, and when you get lost go look for background material. As you're learning the background material, every so often come back to the GCT papers and see if you can follow further.\n(Depending on what you want to learn, I would actually disagree with Zeyu that you should try some graduate commutative algebra first, though at some point in learning GCT this will become necessary.)\nIf you want to understand, for example, Mulmuley's recent FOCS paper, you'll want to understand:\n\nthe hardness vs. randomness principle (see Impagliazzo--Kabanets, and also perhaps Bill Gasarch's list of papers on hardness v randomness) \nbasic algebraic geometry up to Hilbert's Nullstellensatz and Noether's Normalization Lemma. These can be found in any basic textbook on algebraic geometry and probably in most lecture notes on it.\nsome classical invariant theory (you don't really need geoemtric invariant theory, schemes and the Mumford-Fogarty-Kirwan book for this paper). Sturmfels' book Algorithms in Invariant Theory comes to mind.\nFor certain results in the paper, but by no means for the paper in general, you might want some of (and these references can also be found in the paper): representation theory of $SL_n$ as in Fulton and Harris,  results on matrix invariants [Artin, Procesi, Razymslov], ...\n\nIf you want to understand the general outline of the GCT approach but in some mathematical detail, I'd suggest:\n\nThe permanent versus determinant problem. #P-completeness of permanent and GapL-completeness of determinant. Agrawal has a good survey (only very slightly outdated)  on this, and the proofs of completeness can be found in Burgisser's book Completeness and Reductions in Algebraic Complexity Theory.\nGroups and group actions (algebraic groups and algebraic group actions are helpful, but not necessary at this level). You should understand the Orbit-Stabilizer Theorem.\nAffine algebraic geometry through Hilbert's Nullstellensatz. Basically you just need to understand the correspondence between affine algebraic varieties and their coordinate rings.\nBasic representation theory of $GL_n$ as in Fulton and Harris. Aside from basic definitions, you need to know complete reducibility of these representations, and the fact that representations of $GL_n$ are classified by partitions, but you don't necessarily need to know the proof/constructions of the latter.\n\nIf you want to understand deeply what's going on (and I'm not sure I can claim to be there yet, but I think I know what I need to know to get there), you should probably also understand:\n\nThe structure of reductive algebraic groups and orbit closures in their representations. I like the book by W. Ferrers Santos for this, but also Linear Algebraic Groups by Borel, The Classical Groups by Weyl, and other classics.\nThe Luna-Vust machinery (Luna's Slice Theorem, Luna-Vust complexity)\nTannakian Duality (see the paper by Deligne--Milne; this will be tough reading without some background in category theory and affine algebraic groups). This essentially says that \"(pro-)affine algebraic groups are determined by their representations.\" I don't think you need the whole paper, so much as how to recover a group from its category of representations (Cor. 3.4).\nMore representation theory, especially as applied to the coordinate rings of algebraic groups and their orbit closures. I really like the book by Goodman and Wallach for this, particularly because it's basically self-contained, and it has a lot of exactly what you need to understand GCT. (Also, many of the expository/side sections and exercises in Fulton and Harris are right on the mark for GCT, especially those about Littlewood-Richardson and Kronecker coefficients.)\n\nIf you want to actually work on the representation theory, you probably want to understand more algebraic combinatorics / combinatorial representation theory. I don't really know all the right references for this, but certainly understanding the Littlewood-Richardson rule is a must, and Fulton's book Young Tableaux is good for this. \nThe most recent papers on this side of things that I know of are Blasiak, Kumar, and Bowman, De Visscher, and Orellana.\nDepending on what direction you want to go in, you may also want to look into quantum groups, though this isn't necessarily necessary (note: these are not a special case of groups, but rather a generalization in a certain direction).\nOn the more geometric side of things, you'll want to look into things like differential geometry for tangent and osculating spaces, curvature, dual varieties, and the like, which are underlying the best known lower bound on perm vs. det due to Mignon--Ressayre and followed by Landsberg--Manivel--Ressayre. (Mignon--Ressayre can be understood without any of these things, but you can view their paper loosely as studying the curvature of certain varieties; for a less loose view, see the use of dual varieties in Landsberg--Manivel--Ressayre.) (See also Cai, Chen, and Li, which extends Mignon--Ressayre to all odd characteristics.) See also Landsberg and Kadish.\nIf you're interested in the GCT approach to matrix multiplication, it's all about tensor rank, border rank, and secant varieties. I'd suggest looking at the papers by Burgisser--Ikenmeyer, Landsberg and Ottaviani, Landsberg, Landsberg's survey and book. Of course, it would also be good to know the classical stuff on matrix multiplication (both upper and lower bounds), but that's a whole separate can of worms.", "meta": {"post_id": 15025, "input_score": 40, "output_score": 47, "post_title": "Prerequisite for learning GCT"}}
{"input": "Does every Turing-recognizable undecidable language have a NP-complete subset?\nThe question could be seen as a stronger version of the fact that every infinite Turing-recognizable language has an infinite decidable subset.", "output": "No.\nTuring-recognizable undecidable languages can be unary (define $x \\not\\in L$  unless $x = 0000\\ldots 0$, so the only difficult strings are composed solely of 0's). Mahaney's theorem says that no unary language can be NP-complete unless P=NP.", "meta": {"post_id": 16182, "input_score": 10, "output_score": 22, "post_title": "Does every Turing-recognizable undecidable language have a NP-complete subset?"}}
{"input": "What would be a good informal/intuitive proof for 'hitting the point home' about LP duality? How best to show that the minimized objective function is indeed the minimum with an intuitive way of understanding the bound?\nThe way I was taught Duality only led to one understanding which I am sure is shared by a LOT of people I know: For every corresponding minimization problem there is an equivalent maximization problem that can be derived by inverting the inequality constraints. Period. This  \"conclusion\" of duality is what seems to stick but not \"why is this so\" (i.e. how/why is there a bound on the optimal solution).\nIs there a way of playing with the inequalities just to 'show' the lower/upper bound on the optimum which could be a motivation for the proof?\nI've gone through Chvatal's book as well as a few others but found nothing that could be understood by absolute noobs to LP. The closest that I got was from Vazirani's book on algorithms, where he talks about 'multiplying the inequalities with some magic numbers that show the bound' - I'm not sure how to reproduce the effect for an arbitrary LP.", "output": "Per OP's wish, here's the math.SE answer I link to in my comment above.\n\nMaybe it's worthwhile to talk through where the dual comes from on an example problem.  This will take a while, but hopefully the dual won't seem so mysterious when we're done.\nSuppose with have a primal problem as follows.\n$$\n        Primal =\\begin{Bmatrix}\n        \\max \\ \\ \\ \\  5x_1 - 6x_2  \\\\\n        \\ \\ \\  s.t. \\ \\ \\ \\ 2x_1 -x_2 = 1\\\\\n        \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ x_1 +3x_2 \\leq9\\\\\n        \\ \\ \\ \\ x_1 \\geq 0\\\\\n        \\end{Bmatrix}\n$$\n\nNow, suppose we want to use the primal's constraints as a way to find an upper bound on the optimal value of the primal.  If we multiply the first constraint by $9$, the second constraint by $1$, and add them together, we get $9(2x_1 - x_2) + 1(x_1 +3 x_2)$ for the left-hand side and $9(1) + 1(9)$ for the right-hand side.  Since the first constraint is an equality and the second is an inequality, this implies $$19x_1 - 6x_2 \\leq 18.$$\nBut since $x_1 \\geq 0$, it's also true that $5x_1 \\leq 19x_1$, and so $$5x_1 - 6x_2 \\leq 19x_1 - 6x_2 \\leq 18.$$\nTherefore, $18$ is an upper-bound on the optimal value of the primal problem.\nSurely we can do better than that, though.  Instead of just guessing $9$ and $1$ as the multipliers, let's let them be variables.  Thus we're looking for multipliers $y_1$ and $y_2$ to force $$5x_1 - 6x_2 \\leq y_1(2x_1-x_2) + y_2(x_1 + 3x_2) \\leq y_1(1) + y_2(9).$$\nNow, in order for this pair of inequalities to hold, what has to be true about $y_1$ and $y_2$?  Let's take the two inequalities one at a time.\n\nThe first inequality: $5x_1 - 6x_2 \\leq y_1(2x_1-x_2) + y_2(x_1 + 3x_2)$\nWe have to track the coefficients of the $x_1$ and $x_2$ variables separately.  First, we need the total $x_1$ coefficient on the right-hand side to be at least $5$.  Getting exactly $5$ would be great, but since $x_1 \\geq 0$, anything larger than $5$ would also satisfy the inequality for $x_1$.  Mathematically speaking, this means that we need $2y_1 + y_2 \\geq 5$.\nOn the other hand, to ensure the inequality for the $x_2$ variable we need the total $x_2$ coefficient on the right-hand side to be exactly $-6$.  Since $x_2$ could be positive, we can't go lower than $-6$, and since $x_2$ could be negative, we can't go higher than $-6$ (as the negative value for $x_2$ would flip the direction of the inequality).  So for the first inequality to work for the $x_2$ variable, we've got to have $-y_1 + 3y_2 = -6$.\n\nThe second inequality: $y_1(2x_1-x_2) + y_2(x_1 + 3x_2) \\leq y_1(1) + y_2(9)$\nHere we have to track the $y_1$ and $y_2$ variables separately.  The $y_1$ variables come from the first constraint, which is an equality constraint.  It doesn't matter if $y_1$ is positive or negative, the equality constraint still holds.  Thus $y_1$ is unrestricted in sign.  However, the $y_2$ variable comes from the second constraint, which is a less-than-or-equal to constraint.  If we were to multiply the second constraint by a negative number that would flip its direction and change it to a greater-than-or-equal constraint.  To keep with our goal of upper-bounding the primal objective, we can't let that happen.  So the $y_2$ variable can't be negative.  Thus we must have $y_2 \\geq 0$.\nFinally, we want to make the right-hand side of the second inequality as small as possible, as we want the tightest upper-bound possible on the primal objective.  So we want to minimize $y_1 + 9y_2$.\n\nPutting all of these restrictions on $y_1$ and $y_2$ together we find that the problem of using the primal's constraints to find the best upper-bound on the optimal primal objective entails solving the following linear program:\n$$\\begin{align*}\n\\text{Minimize }\\:\\:\\:\\:\\: y_1 + 9y_2& \\\\\n\\text{subject to }\\:\\:\\:\\:\\: 2y_1 + y_2& \\geq 5 \\\\\n                   -y_1 + 3y_2& = -6\\\\\n                   y_2 & \\geq 0.\n\\end{align*}$$\nAnd that's the dual.\n\nIt's probably worth summarizing the implications of this argument for all possible forms of the primal and dual.  The following table is taken from p. 214 of Introduction to Operations Research, 8th edition, by Hillier and Lieberman.  They refer to this as the SOB method, where SOB stands for Sensible, Odd, or Bizarre, depending on how likely one would find that particular constraint or variable restriction in a maximization or minimization problem.\n             Primal Problem                           Dual Problem\n             (or Dual Problem)                        (or Primal Problem)\n\n             Maximization                             Minimization\n\nSensible     <= constraint            paired with     nonnegative variable\nOdd          =  constraint            paired with     unconstrained variable\nBizarre      >= constraint            paired with     nonpositive variable\n\nSensible     nonnegative variable     paired with     >= constraint\nOdd          unconstrained variable   paired with     = constraint\nBizarre      nonpositive variable     paired with     <= constraint", "meta": {"post_id": 16206, "input_score": 21, "output_score": 21, "post_title": "An intuitive/informal proof for LP Duality?"}}
{"input": "Is it possible to algorithmically test if a computable number is rational or integer? \nIn other words, would it be possible for a library that implements computable numbers to provide the functions isInteger or isRational?\nI am guessing that it is not possible, and that this is somehow related to the fact that it is not possible to test if two numbers are equal, but I don't see how to prove it.\nEdit: A computable number $x$ is given by a function $f_x(\\epsilon)$ that can return a rational approximation of $x$ with precision $\\epsilon$: $|x - f_x(\\epsilon)| \\leq \\epsilon$, for any $\\epsilon > 0$. Given such function, is it possible to test if $x \\in \\mathrm{Q}$ or $x \\in \\mathrm{Z}$?", "output": "It is easy to get confused about what it means to \"represent\" or \"implement\" a real number. In fact, we are witnessing a discussion in the comments where the representation is contentious. So let me address this first.\nHow do we know that an implementation is correct?\nThe theory which explains how to represent things in a computer is realizability. The basic idea is that, given a set $X$, we pick a datatype $\\tau$ and to every $x \\in X$ a set of values of type $\\tau$ which realize it. We write $v \\vdash x \\in X$ when $v$ is a value that realizes $x$. For example (I shall use Haskell for no good reason), a sensible implementation of $\\mathbb{N}$ might be the datatype Integer where $v \\vdash k \\in \\mathbb{N}$ when $v$ evaluates to the numeral $\\overline{k}$ (thus in particular -42 does not represent a natural number, and neither does a diverging program). But some joker could walk by and suggest that we use Bool to represent natural numbers with $\\mathtt{True} \\vdash 42 \\in \\mathbb{N}$ and $\\mathtt{False} \\vdash n \\in \\mathbb{N}$ for $n \\neq 42$. Why is this incorrect? We need a criterion.\nIn the case of \"joker numbers\" the easy observation is that addition cannot be implemented. Suppose I tell you I have two numbers, both represented by $\\mathtt{False}$. Can you give a realizer for their sum? Well, that depends on whether the sum is 42, but you cannot tell. Since addition is an \"essential part of what natural numbers are\", this is unacceptable. In other words, implementation is not about sets, but about structures, i.e., we have to represent sets in such a way that it is possible to also implement the relevant structure. Let me stress this:\n\nWe implement structures, not bare sets. Therefore, we have to be able to implement the entire structure, together with operations and all the axioms, in order for the implementation to be correct.\n\nIf you do not abide by this principle, then you have to suggest an alternative mathematical criterion of correctness. I do not know of one.\nExample: representation of natural numbers\nFor natural numbers the relevant structure is described by Peano axioms, and the crucial axiom that has to be implemented is induction (but also $0$, successor, $+$ and $\\times$). We can compute, using realizability, what the implementation of induction does. It turns out to be a map (where nat is the yet unknown datatype which represents natural numbers)\n\ninduction : 'a -> (nat -> 'a -> 'a) -> 'nat -> 'a\n\nsatisfying induction x f zero = x and induction x f (succ n) = f n (induction x f n). All this comes out of realizability. We have a criterion: an implementation of natural numbers is correct when it allows an implementation of Peano axioms. A similar result would be obtained if we used the characterization of numbers as the initial algebra for the functor $X \\mapsto 1 + X$.\nCorrect implementation of real numbers\nLet us turn attention to the real numbers and the question at hand. The first question to ask is \"what is the relevant structure of the real numbers?\" The answer is: Archimedean Cauchy complete ordered field. This is the established meaning of \"real numbers\". You do not get to change it, it has been fixed by others for you (in our case the alternative Dedekind reals turn out to be isomorphic to the Cauchy reals, which we are considering here.) You cannot take away any part of it, you are not allowed to say \"I do not care about implementing addition\", or \"I do not care about the order\". If you do that, you must not call it \"real numbers\", but something like \"real numbers where we forget the linear order\".\nI am not going to go into all the details, but let me just explain how the various parts of the structure give various operations on reals:\n\nthe Archimedean axiom is about computing rational approximations of reals\nthe field structure gives the usual arithmetical operations\nthe linear order gives us a semidecidable procedure for testing $x < y$\nthe Cauchy completeness gives us a function lim : (nat -> real) -> real which takes a (representation of) rapid Cauchy sequence and returns its limit. (A sequence $(x_n)_n$ is rapid if $|x_n - x_m| \\leq 2^{-\\min(n,m)}$ for all $m, n$.)\n\nWhat we do not get is a test function for equality. There is nothing in the axioms for reals which asks that $=$ be decidable. (In contrast, the Peano axioms imply that the natural numbers are decidable, and you can prove that by implementing eq : nat -> nat -> Bool using only induction as a fun exercise).\nIt is a fact that the usual decimal representation of reals that humanity uses is bad because with it we cannot even implement addition. Floating point with infinite mantissa fails as well (exercise: why?). What works, however is signed digit representation, i.e., one in which we allow negative digits as well as positive ones. Or we could use sequences of rationals which satisfy the rapid Cauchy test, as stated above.\nThe Tsuyoshi representation also implements something, but not $\\mathbb{R}$\nLet us consider the following representation of reals: a real $x$ is represented by a pair $(q,b)$ where $(q_n)_n$ is a rapid Cauchy sequence converging to $x$ and $b$ is a Boolean indicating whether $x$ is an integer. For this to be a representation of the reals, we would have to implement addition, but as it turns out we cannot compute the Boolean flags. So this is not a representation of the reals. But it still does represent something, namely the subset of the reals $\\mathbb{Z} \\cup (\\mathbb{R} \\setminus \\mathbb{Z})$. Indeed, according to the realizability interpretation a union is implemented with a flag indicating which part of the union we are in. By the way, $\\mathbb{Z} \\cup (\\mathbb{R} \\setminus \\mathbb{Z})$ is a not equal to $\\mathbb{R}$, unless you believe in excluded middle, which cannot be implemented and is therefore quite irrelevant for this discussion. We are of forced by computers to do things intuitionistically.\nWe cannot test whether a real is an integer\nFinally, let me answer the question that was asked. We now know that an acceptable representation of the reals is one by rapid Cauchy sequences of rationals. (An important theorem states that any two representations of reals which are acceptable are actually computably isomorphic.)\nTheorem: Testing whether a real is an integer is not decidable.\nProof. Suppose we could test whether a real is an integer (of course, the real is realized by a rapid Cauchy sequence). The idea, which will allow you to prove a much more general theorem if you want, is to construct a rapid Cauchy sequence $(x_n)_n$ of non-integers which converges to an integer. This is easy, just take $x_n = 2^{-n}$. Next, solve the Halting problem as follows. Given a Turing machine $T$, define a new sequence $(y_n)_n$ by\n$$y_n = \\begin{cases}\nx_n & \\text{if $T$ has not stopped within $n$ steps}\\\\\nx_m & \\text{if $T$ stopped in step $m$ and $m \\leq n$}\n\\end{cases}$$\nThat is, the new sequence looks like the sequence $(x_n)_n$ as long as $T$ runs, but then it gets \"stuck\" at $x_m$ if $T$ halts in step $m$. Very importantly, the new sequence is also a rapid Cauchy sequence (and we can prove this without knowing whether $T$ halts). Therefore, we can compute its limit $z = \\lim_n y_n$, because our representation of reals is correct. Test whether $z$ is an integer. If it is, then it must be $0$ and this only happens if $T$ runs forever. Otherwise, $z$ is not an integer, so $T$ must have stopped. QED.\nExercise: adapt the above proof to show that we cannot test for rational numbers. Then adapt it to show we cannot test for anything non-trivial (this is a bit harder).\nSometimes people get confused about all this testing business. They think we have proved that we can never test whether a real is an integer. But surely, 42 is a real and we can tell whether it is an integer. In fact, any particular real we come up with, $\\sin 11$, $88 \\ln 89$, $e^{\\pi \\sqrt{163}}$, etc., we can perfectly well tell whether they are integers. Precisely, we can tell because we have extra information: these reals are not given to us as sequences, but rather as symbolic expressions from which we can compute the Tsuyoshi bit. As soon as the only information we have about the real is a sequence of rational approximations converging to it (and I do not mean a symbolic expression describing the sequence, but a black box which outputs the $n$-th term on input $n$) then we will be just as helpless as machines.\nThe moral of the story\nIt makes no sense to talk about implementation of a set unless we know what sort of operations we want to perform on it.", "meta": {"post_id": 16512, "input_score": 22, "output_score": 42, "post_title": "Is it possible to test if a computable number is rational or integer?"}}
{"input": "I hope this is not a politically incorrect question to ask, but for a PhD student who usually publishes at CCC/ITCS/ICALP (and occasionally at FOCS/STOC), could it be harmful (career-wise) to publish less significant works in less prestigious conferences (e.g. MFCS, FCT, STACS, IPL)? Could it be better to just leave such papers laying at ECCC/arXiv?", "output": "I was just referred to this question by graduate students that, in my opinion, were far too influenced by the answers. So let me start with two generic advises.\n\nTo the aspiring scientist: Don't assign too much weight to any answer on such matters, and don't assume that a small and highly non-random sample represents the common views among senior (or non-senior) people in the community. In general, think for yourself!\nSee http://www.wisdom.weizmann.ac.il/~oded/advice.html for more details...\nTo the senior scientist: Be careful about what you say, since it may be misinterpreted in harmful ways and/or have more impact than what you intend and/or perceive.\n\nRe the discussion itself, I think that the idea that credits are non-monotone is not only utterly non-intuitive but also utterly wrong, and I am talking as a person who sat on numerous committees that took various career decisions. A person who has $X$ fundamental contributions, $Y$ important contributions, and $Z+1$ nice/legitimate contribution is ranked higher than one who has $(X,Y,Z)$, regardless of the numerical values of $X,Y,Z$ and assuming that quality captured by the $(X,Y,Z)$ triples is exactly the same. Trade-offs between different types is a different question, ditto re how much credit does each increase give...\nIn other words, for any set of works $S$ and any additional work $a$, \nthe credit of $S \\cup \\{a\\}$ is (strictly) bigger than to $S$ [i.e., strict monotonicity].\nIn my opinion, people who claim the opposite just assume that a larger number $Z$ implies a decrease in what the value of $X$ (or $Y$) could have been. But this assumption may be wrong and more importantly is irrelevant to the comparison at hand. That is, if you compare a case of $(X,Y,Z)$ to one of $(X,Y,Z+1)$, you must rule that the second person (called B) was able to meet the performance of the first (called A) although B also did another work of 3rd type; so B is clearly better. Indeed, you may think that B could have done better investing more energy in Type 1 (which is not always true - see below), but that's a comparison against an imaginary B, not against A. (And when you have a case of $(X,Y,Z)$ against $(X,Y,Z+10)$, the same holds is stronger terms.)\nIn addition, I think there is also a confusion between the works and the publications. If a work already exists in writing, and assuming that it has its merits, then it can only be advantageous to publish it in a adequate venue, where by adequate I mean one that is intended for works of this profile (wrt quality and scope - publication in a too prestigious conference may actually hurt, since it may generate some annoyance and even bad opinions re the author). But if one still has to develop a work from an initial idea (or \"only\" write it - which always involves some more research...), then one may consider the trade-off between the amount of time required versus the importance of the work.\nFinally, as I hinted above, it is not clear that one is better off aiming all the time at Type 1 (i.e., fundamental work). Firstly, this is infeasible and thus problematic/harmful. Secondly, and more importantly, one is always better off following the inherent logic of his/her own interests and ideas/feelings, and aiming to do as well as possible. See more in the aforementioned webpage.\nOded Goldreich", "meta": {"post_id": 16608, "input_score": 24, "output_score": 40, "post_title": "Is it sometimes better to not publish at all?"}}
{"input": "How can we express \"$P=PSPACE$\" as a first-order formula?\nWhich level of the arithmetic hierarchy contains this formula (and what is the currently known minimum level of the hierarchy that contains it)?\n\nFor reference, see this blog post by Lipton.", "output": "Andrej has already explained that $P=\\mathit{PSPACE}$ can be written as a $\\Sigma^0_2$-sentence. Let me mention that this classification is optimal in the sense that if the statement is equivalent to a $\\Pi^0_2$-sentence, then this fact does not relativize. More precisely, the set of oracles $A$ such that $P^A=\\mathit{PSPACE}^A$ is definable by a $\\Sigma^0_2$-formula with a free second-order variable $A$, but it is not definable by any $\\Pi^0_2$-formula. The argument is outlined (for $P=\\mathit{NP}$, but it works just the same for $\\mathit{PSPACE}$) in the comments at https://mathoverflow.net/questions/57348. (In fact, one can show by an elaboration of the idea that the set is $\\Sigma^0_2$-complete in the appropriate sense.)\nEDIT: The topological proof given in the linked comment is short, but it may appear tricky. Here is a direct forcing argument.\n$P^A\\ne\\mathit{PSPACE}^A$ can be written as a $\\Pi^0_2$-formula of the form $\\phi(A)=\\forall x\\,\\exists y\\,\\theta(A,x,y)$, where $\\theta$ is $\\Delta^0_0$. Assume for contradiction that $P^A=\\mathit{PSPACE}^A$ is also equivalent to a $\\Pi^0_2$-formula $\\psi(A)=\\forall x\\,\\exists z\\,\\eta(A,x,z)$. Fix oracles $B$, $C$ such that $P^B\\ne\\mathit{PSPACE}^B$ and $P^C=\\mathit{PSPACE}^C$.\nSince $\\phi(B)$, there exists $y_0$ such that $\\theta(B,0,y_0)$. However, $\\theta$ is a bounded formula, hence the evaluation of the truth value of $\\theta(B,0,y_0)$ only uses a finite part of the oracle. Thus, there exists a finite part $b_0$ of $B$ such that $\\theta(A,0,y_0)$ for every oracle $A$ extending $b_0$.\nLet $C[b_0]$ denote the oracle which extends $b_0$, and agrees with $C$ where $b_0$ is undefined. Since $P^A$ and $\\mathit{PSPACE}^A$ are unaffected by a finite change in the oracle, we have $\\psi(C[b_0])$. By the same argument as above, there exists $z_0$ and a finite part $c_0$ of $C[b_0]$ such that $\\eta(A,0,z_0)$ for every $A$ extending $c_0$. We may assume that $c_0$ extends $b_0$.\nContinuing in the same fashion, we construct infinite sequences of numbers $y_0,y_1,y_2,\\dots$, $z_0,z_1,z_2,\\dots$, and finite partial oracles $b_0\\subseteq c_0\\subseteq b_1\\subseteq c_1\\subseteq b_2\\subseteq\\cdots$ such that\n\n$\\theta(A,n,y_n)$ for every oracle $A$ extending $b_n$,\n$\\eta(A,n,z_n)$ for every oracle $A$ extending $c_n$.\n\nNow, let $A$ be an oracle which extends all $b_n$ and $c_n$. Then 1 and 2 imply that $\\phi(A)$ and $\\psi(A)$ simultaneously hold, which contradicts the assumption that they are complements of each other.", "meta": {"post_id": 16628, "input_score": 9, "output_score": 21, "post_title": "How can we express \"$P=PSPACE$\" as a first-order formula?"}}
{"input": "For the longest time I have thought that a problem was NP-complete if it is both (1) NP-hard and (2) is in NP. \nHowever, in the famous paper \"The ellipsoid method and its consequences in combinatorial optimization\", the authors claim that the fractional chromatic number problem belongs to NP and is NP-hard, yet is not known to be NP-complete. On the third page of the paper, the authors write:\n\n... we note that the vertex-packing problem of a graph is in a sense equivalent to the fractional chromatic number problem, and comment on the phenomenon that this latter problem is an example of a problem in $\\mathsf{NP}$ which is $\\mathsf{NP}$-hard but (as for now) not known to be $\\mathsf{NP}$-complete.\n\nHow is this possible? Am I missing a subtle detail in the definition of NP-complete?", "output": "It seems the issue is the kind of reductions used for each of them, and they are using different ones: they probably mean \"$\\mathsf{NP}$-hard w.r.t. Cook reductions\" and \"$\\mathsf{NP}$-complete w.r.t. Karp reductions\". \nSometimes people use the Cook reduction version of $\\mathsf{NP}$-hardness because it is applicable to more general computational problems (not just decision problems). Although the original definition of both $\\mathsf{NP}$-hardness and $\\mathsf{NP}$-completeness used Cook reductions (polynomial-time Turing reductions) it has become uncommon to use Cook reductions for $\\mathsf{NP}$-completeness (unless it is stated explicitly). I don't recall any recent paper that has used $\\mathsf{NP}$-complete to mean $\\mathsf{NP}$-complete w.r.t. Cook reductions. (As a side note the first problem that to be proven to $\\mathsf{NP}$-hard was TAUT not SAT and the completeness for SAT is implicit in that proof.)\nNow if you look at section 7 of the paper, bottom of page 195, you will see that they mean $\\mathsf{NP}$-hardness w.r.t. Turing reductions.\nSo what they mean here is that the problem is in $\\mathsf{NP}$, is hard for $\\mathsf{NP}$ w.r.t. Cook reductions, but it is unknown to be hard for $\\mathsf{NP}$ w.r.t. Karp reductions (polynomial-time many-one reductions).", "meta": {"post_id": 16983, "input_score": 15, "output_score": 28, "post_title": "How can a problem be in NP, be NP-hard and not NP-complete?"}}
{"input": "I was recently reading The Two Dualities of Computation: Negative and Fractional Types.  The paper expands on sum-types and product-types, giving semantics to the types a - b and a/b.\nUnlike addition and multiplication, there are not one but two inverses of\nexponentiation, logarithms and rooting.  If function types (a \u2192 b) are\ntype-theoretic exponentiation, given the type a \u2192 b (or b^a) what does it mean to have\nthe type logb(c) or the type a\u221ac?\nDoes it make sense to extend logarithms and roots to types at all?\nIf so, has there been any work in this area, and what are some good directions on how to comprehend the repercussions?\nI tried looking up information on this via logic, hoping the Curry-Howard correspondence could help me, but to no avail.", "output": "A type $C$ has a logarithm to base $X$ of $P$ exactly when $C \\cong P\\to X$. That is, $C$ can be seen as a container of $X$ elements in positions given by $P$. Indeed, it's a matter of asking to what power $P$ we must raise $X$ to obtain $C$.\nIt makes sense to work with $\\mathop{log}F$ where $F$ is a functor, whenever the logarithm exists, meaning $\\mathop{log}\\!_X(F\\:X)$. Note that if $F\\:X\\cong \\mathop{log}F\\to X$, then we certainly have $F\\:1\\cong 1$, so the container tells us nothing interesting other than its elements: containers with a choice of shapes do not have logarithms.\nFamiliar laws of logarithms make sense when you think in terms of position sets\n$$\\begin{array}{rcl@{\\qquad}l}\n \\mathop{log} (\\mathop{K}1) &=& 0   & \\mbox{no positions in empty container}\\\\\n \\mathop{log} I &=& 1 & \\mbox{container for one, one position}\\\\\n\\mathop{log} (F\\times G) &=& \\mathop{log}F+\\mathop{log}G &\n  \\mbox{pair of containers, choice of positions} \\\\\n\\mathop{log} (F\\cdot G) &=& \\mathop{log}F\\times\\mathop{log}G &\n  \\mbox{container of containers, pair of positions}\n\\end{array}$$\nWe also gain $\\mathop{log}\\!_X(\\nu Y. T) = \\mu Z. \\mathop{log}\\!_X T$ where $Z=\\mathop{log}\\!_XY$ under the binder. That is, the path to each element in some codata is defined inductively by iterating the logarithm. E.g.,\n$$\\mathop{log}\\mathop{Stream} = \\mathop{log}\\!_X(\\nu Y. X\\times Y) = \\mu Z. 1 + Z = \\mathop{Nat}$$\nGiven that the derivative tells us the type in one-hole contexts and the logarithm tells us positions, we should expect a connection, and indeed\n$$F\\:1\\cong 1 \\;\\Rightarrow\\; \\mathop{log}F\\cong \\partial F\\:1$$\nWhere there is no choice of shape, a position is just the same as a one-hole context with the elements rubbed out. More generally, $\\partial F\\:1$ always represents the choice of an $F$ shape together with an element position within that shape.\nI'm afraid I have less to say about roots, but one could start from a similar definition and follow one's nose. For more uses of logarithms of types, check Ralf Hinze's \"Memo functions, polytypically!\". Gotta run...", "meta": {"post_id": 17006, "input_score": 27, "output_score": 40, "post_title": "What is the logarithm or root operation in type-space?"}}
{"input": "In a talk by Razborov, a curious little statement is posted.\n\nIf FACTORING is hard, then Fermat\u2019s little theorem is not provable in $S_{2}^{1}$.\n\nWhat is $S_{2}^{1}$ and why are current proofs not in $S_{2}^{1}$?", "output": "$S^1_2$ is a theory of bounded arithmetic, that is, a weak axiomatic theory obtained by severely restricting the schema of induction of Peano arithmetic. It is one of the theories defined by Sam Buss in his thesis, other general references include Chapter V of H\u00e1jek and Pudl\u00e1k\u2019s Metamathematics of first-order arithmetic, Kraj\u00ed\u010dek\u2019s \u201cBounded arithmetic, propositional logic, and complexity theory\u201d, Buss\u2019s Chapter II of the Handbook of proof theory, and Cook and Nguyen\u2019s Logical foundations of proof complexity.\nYou can think of $S^1_2$ as a theory of arithmetic which has induction only for polynomial-time predicates. In particular, the theory does not prove that exponentiation is a total function, the theory can prove to exist only objects of polynomial size (loosely speaking).\nAll known proofs of the Fermat Little Theorem utilize either exponential-size objects, or they rely on exact counting of sizes of bounded sets (which is probably not definable by a bounded formula, i.e., in the polynomial hierarchy, because of Toda\u2019s theorem).\nThe result on FLT, $S^1_2$, and factoring stems from Kraj\u00ed\u010dek and Pudl\u00e1k\u2019s paper Some consequences of cryptographical conjectures for $S^1_2$ and EF, and in my opinion it is fairly misleading. What Kraj\u00ed\u010dek and Pudl\u00e1k prove is that if factoring (actually, IIRC they state it for RSA instead of factoring, but it\u2019s known that a similar argument works for factoring too) is hard for randomized polynomial time, then $S^1_2$ cannot prove the statement that every number $a$ coprime to a prime number $p$ has finite exponent modulo $p$, that is, there exists $k$ such that $a^k\\equiv1\\pmod p$.\nIt\u2019s true that this is a consequence of FLT, but in fact it is a much, much weaker statement than FLT. In particular, this statement follows from the weak pigeonhole principle, which is known to be provable in a subsystem of bounded arithmetic (albeit a stronger one than $S^1_2$). Thus, Kraj\u00ed\u010dek and Pudl\u00e1k\u2019s argument shows that $S^1_2$ does not prove the weak pigeonhole principle unless factoring is easy, and as such provides a conditional separation of $S^1_2$ from another level of the bounded arithmetical hierarchy, say $T^2_2$.\nIn contrast, the actual FLT does not even seem to be provable in full bounded arithmetic $S_2=T_2$, but this is not related to cryptography. You can find some relevant discussion in my paper Abelian groups and quadratic residues in weak arithmetic.", "meta": {"post_id": 17031, "input_score": 10, "output_score": 21, "post_title": "Proofs in $S_{2}^{1}$"}}
{"input": "In a Cartesian Closed Category (CCC), there exist the so-called exponential objects, written $B^A$.  When a CCC is considered as a model of the simply-typed $\\lambda$-calculus, an exponential object like $B^A$ characterizes the function space from type $A$ to type $B$.  An exponential object is introduced by an arrow called $curry : (A \\times B \\rightarrow C) \\rightarrow (A \\rightarrow C^B)$ and eliminated by an arrow called $apply : C^B \\times B \\rightarrow C$ (which unfortunately called $eval$ in most texts on category theory).  My questions here is: is there any difference between the exponential object $C^B$, and the arrow $B \\rightarrow C$?", "output": "One is internal and the other is external.\nA category $\\mathcal{C}$ consists of objects and morphisms. When we write $f : A \\to B$ we mean that $f$ is a morphism from object $A$ to object $B$. We may collect all morphisms from $A$ to $B$ into a set of morphisms $\\mathrm{Hom}_{\\mathcal{C}}(A,B)$, called the \"hom-set\". This set is not an object of $\\mathcal{C}$, but rather an object of the category of sets.\nIn contrast, an exponential $B^A$ is an object in $\\mathcal{C}$. It is how \"$\\mathcal{C}$ thinks of its hom-sets\". Thus, $B^A$ must be equipped with whatever structure the objects of $\\mathcal{C}$ have.\nAs an example, let us consider the category of topological spaces. Then $f : X \\to Y$ is a continuous map from $X$ to $Y$, and $\\mathrm{Hom}_{\\mathsf{Top}}(X,Y)$ is the set of all such continuous maps. But $Y^X$, if it exists, is a topological space! You can prove that the points of $Y^X$ are (in bijective correspondence with) the continuous maps from $X$ to $Y$. In fact, this holds in general: the morphisms $1 \\to B^A$ (which are \"the global points of $B^A$\") are in bijective correspondence with morphisms $A \\to B$, because\n$$\\mathrm{Hom}(1, B^A) \\cong\n\\mathrm{Hom}(1 \\times A, B) \\cong\n\\mathrm{Hom}(A, B).\n$$\nSometimes we get sloppy about writing $B^A$ as opposed to $A \\to B$. In fact, often these two are synonyms, with the understanding that $f : A \\to B$ might mean \"oh by the way here I meant the other notation, so this means $f$ is a morphism from $A$ to $B$.\" For example, when you wrote down the currying morphism\n$$\\textit{curry}: (A \\times B \\to C) \\to (A \\to C^B)$$\nyou really should have written\n$$\\textit{curry}: C^{A \\times B} \\to {(C^B)}^A.$$\nSo we cannot really blame anyone for getting confused here. The inner $\\to$ is used in the internal sense, and the outer in the external.\nIf we work in simply typed $\\lambda$-calculus then everything is internal, so to speak. We have just a basic typing judgment \"$t$ has type $B$\", written as $t : B$. Because here $B$ is a type, and types correspond to objects, then we clearly have to interpet any exponentials and arrows in $B$ in the internal sense. So then, if we understand\n$$\\textit{curry}: (A \\times B \\to C) \\to (A \\to C^B)$$\nas a typing judgment in the $\\lambda$-calculus, all arrows are internal, so this is the same as\n$$\\textit{curry}: ((C^B)^A)^{C^{A \\times B}}.$$\nI hope by now it is clear why people use $B^A$ and $A \\to B$ as synonyms.", "meta": {"post_id": 17292, "input_score": 22, "output_score": 34, "post_title": "What is the difference between arrows and exponential objects in a cartesian closed category?"}}
{"input": "Given a directed cyclic graph where the weight of each edge may be negative the concept of a \"shortest path\" only makes sense if there are no negative cycles, and in that case you can apply the Bellman-Ford algorithm.\nHowever, I'm interested in finding the shortest-path between two vertices that doesn't involve cycling (ie. under the constraint that you may not visit the same vertex twice). Is this problem well studied? Can a variant of the Bellman-Ford algorithm be employed, and if not is there another solution?\nI'm also interested in the equivalent all-pairs problem, for which I might otherwise apply Floyd\u2013Warshall.", "output": "Paths with no repeated vertices are called simple-paths, so you are looking for the shortest simple-path in a graph with negative-cycles.\nThis can be reduced from the longest-path problem.  If there were a fast solver for your problem, then given a graph with only positive edge-weights, negating all the edge-weights and running your solver would give the longest path in the original graph.\nThus your problem is NP-Hard.", "meta": {"post_id": 17462, "input_score": 15, "output_score": 28, "post_title": "Finding the shortest path in the presence of negative cycles"}}
{"input": "I posted this earlier on MSE, but it was suggested that here may be a better place to ask.\nUniversal approximation theorem states that \"the standard multilayer feed-forward network with a single hidden layer, which contains finite number of hidden neurons, is a universal approximator among continuous functions on compact subsets of Rn, under mild assumptions on the activation function.\"\nI understand what this means, but the relevant papers are too far over my level of math understanding to grasp why it is true or how a hidden layer approximates non-linear functions.\nSo, in terms little more advanced than basic calculus and linear algebra, how does a feed-forward network with one hidden layer approximate non-linear functions? The answer need not necessarily be totally concrete.", "output": "Cybenko's result is fairly intuitive, as I hope to convey below; what makes things more tricky is he was aiming both for generality, as well as a minimal number of hidden layers.  Kolmogorov's result (mentioned by vzn) in fact achieves a stronger guarantee, but is somewhat less relevant to machine learning (in particular, it does not build a standard neural net, since the nodes are heterogeneous); this result in turn is daunting since on the surface it is just 3 pages  recording some limits and continuous functions, but in reality it is constructing a set of fractals.  While Cybenko's result is unusual and very interesting due to the exact techniques he uses, results of that flavor are very widely used in machine learning (and I can point you to others).\nHere is a high-level summary of why Cybenko's result should hold.\n\nA continuous function on a compact set can be approximated by a piecewise constant function.\nA piecewise constant function can be represented as a neural net as follows.  For each region where the function is constant, use a neural net as an indicator function for that region.  Then build a final layer with a single node, whose input linear combination is the sum of all the indicators, with a weight equal to the constant value of the corresponding region in the original piecewise constant function.\n\nRegarding the first point above, this can be taken as the statement \"a continuous function over a compact set is uniformly continuous\".  What this means to us is you can take your continuous function over $[0,1]^d$, and some target error $\\epsilon>0$, then you can grid $[0,1]^d$ at scale $\\tau>0$ (ending up with roughly $(1/\\tau)^d$ subcubes) so that a function which is constant over each subcube is within $\\epsilon$ of the target function.\nNow, a neural net can not precisely represent an indicator, but you can get very close.  Suppose the \"transfer function\" is a sigmoid.  (Transfer function is the continuous function you apply to a linear combination of inputs in order to get the value of the neural net node.)  Then by making the weights huge, you output something close to 0 or close to 1 for more inputs.  This is consistent with Cybenko's development: notice he needs the functions involved to equal 0 or 1 in the limit: by definition of limit, you get exactly what I'm saying, meaning you push things arbitrarily close to 0 or 1.\n(I ignored the transfer function in the final layer; if it's there, and it's continuous, then we can fit anything mapping to $[0,1]$ by replacing the constant weights with the something in the inverse image of that constant according to the transfer function.)\nNotice that the above may seem to take a couple layers: say, 2 to build the indicators on cubes, and then a final output layer.  Cybenko was trying for two points of generality: minimal number of hidden layers, and flexibility in the choice of transfer function.  I've already described how he works out flexibility in transfer function.\nTo get the minimum number of layers, he avoids the construction above, and instead uses functional analysis to develop a contradiction.\nHere's a sketch of the argument.\n\nThe final node computes a linear combination of the elements of the layer below it, and applies a transfer function to it.  This linear combination  is a linear combination of functions, and as such, is itself a function, a function within some subspace of functions, spanned by the possible nodes in the hidden layer.\nA subspace of functions is just like an ordinary finite-dimensional subspace, with the main difference that it is potentially not a closed set; that's why cybenko's arguments all take the closure of that subspace.  We are trying to prove that this closure contains all continuous functions; that will mean we are arbitrarily close to all continuous functions.\nIf the function space were simple (a Hilbert space), we could argue as follows.  Pick some target continuous function which is contradictorily supposed to not lie in the subspace, and project it onto the orthogonal complement of the subspace.  This residual must be nonzero.  But since our subspace can represent things like those little cubes above, we can find some region of this residual, fit a little cube to it (as above), and thereby move closer to our target function.  This is a contradiction since projections choose minimal elements.  (Note, I am leaving something out here: Cybenko's argument doesn't build any little cubes, he handles this in generality too; this is where he uses a form of the Riesz representation theorem, and properties of the transfer functions (if I remember correctly, there is a separate lemma for this step, and it is longer than the main theorem).) \nWe aren't in a Hilbert space, but we can use the Hahn-Banach theorem to replace the projection step above (note, proving Hahn-Banach uses the axiom of choice).\n\nNow I'd like to say a few things about Kolmogorov's result.  While this result does not apparently need the sort of background of Cybenko's, I personally think it is much more intimidating.\nHere is why.  Cybenko's result is an approximation guarantee: it does not say we can exactly represent anything.  On the other hand, Kolmogorov's result is provides an equality.  More ridiculously, it says the size of the net: you need just $\\mathcal O(d^2)$ nodes.  To achieve this strengthening, there is a catch of course, the one I mentioned above: the network is heteregeneous, by which I mean all the transfer functions are not the same.\nOkay, so with all that, how can this thing possible work?!\nLet's go back to our cubes above.  Notice that we had to bake in a level of precision: for every $\\epsilon>0$, we have to go back and pick a more refined $\\tau >0$.  Since we are working with (finite) linear combinations of indicators, we are never exactly representing anything.  (things only get worse if you include the approximating effects of sigmoids.)\nSo what's the solution?  Well, how about we handle all scales simultaneously?  I'm not making this up: Kolmogorov's proof is effectively constructing the hidden layer as a set of fractals.  Said another way, they are basically space filling curves which map $[0,1]$ to $[0,1]^d$; this way, even though we have a combination of univariate functions, we can fit any multivariate function.  In fact, you can heuristically reason that $\\mathcal O(d^2)$ is \"correct\" via a ridiculous counting argument: we are writing a continuous function from $\\mathbb{R}^d$ to $\\mathbb R$ via univariate continuous functions, and therefore, to capture all inter-coordinate interactions, we need $\\mathcal O(d^2)$ functions...\nNote that Cybenko's result, due to using only one type of transfer function, is more relevant to machine learning.  Theorems of this type are very common in machine learning (vzn suggested this in his answer, however he referred to Kolmogorov's result, which is less applicable due to the custom transfer functions; this is weakened in some more fancy versions of Kolmogorov's result (produced by other authors), but those still involve fractals, and at least two transfer functions).\nI have some slides on these topics, which I could post if you are interested (hopefully less rambly than the above, and have some pictures; I wrote them before I was adept with Hahn-Banach, however).  I think both proofs are very, very nice.  (Also, I have another answer here on these topics, but I wrote it before I had grokked Kolmogorov's result.)", "meta": {"post_id": 17545, "input_score": 25, "output_score": 28, "post_title": "Universal Approximation Theorem \u2014 Neural Networks"}}
{"input": "First of all, my understanding on G\u00f6del's incompleteness theorem (and formal logic in general) is very naive, also is my knowledge on theoretical computer science (meaning only one graduate course taken while I'm still an undergraduate), so this question may be very naive.\nAs far as I could find, the provability of P versus NP is an open problem.\nNow:\n\nG\u00f6del's first incompleness theorem states that there may be statements that are true but not provable nor disprovable.\nIf a polynomial solution is found for an NP-complete problem, it proves that P = NP.\n\nSo, suppose that P=NP is not provable:\nThis means that no example of a polynomial solution for an NP-complete problem can be found (otherwise, this would be a proof).\nBut if no example of a polynomial solution for an NP-complete problem can be found, this means that P=NP is false (proving it, meaning the statement is provable), which leads to a contradiction, therefore P=NP should be provable.\nThis sounds like a proof of the provability of P=NP to me, but I think it's extremely likely that it is due to my lack of understanding of the logic topics involved. Could anyone please help me understand what is wrong with this?", "output": "If P=NP, there must be polynomial-time algorithms for NP-complete problems.  However, there might not be any algorithm that provably solves an NP-complete problem and provably runs in polynomial time.", "meta": {"post_id": 18791, "input_score": 11, "output_score": 21, "post_title": "On the provability of P versus NP"}}
{"input": "I am preparing for a talk aimed at undergraduate math majors, and as part of it, I am considering discussing the concept of decidability.  I want to give an example of a problem that we do not currently know to be decidable or undecidable.  There are many such problems, but none seem to stand out as nice examples so far.\nWhat is a simple-to-describe decision problem whose decidability is open?", "output": "It is unknown whether or not\nit is decidable to determine if a given shape can tile the plane,\neven for polyomino tiles.\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \n\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \n\n(Image from Wikipedia.)", "meta": {"post_id": 18846, "input_score": 103, "output_score": 22, "post_title": "A simple decision problem whose decidability is not known"}}
{"input": "What exactly is theoretical computer science? Is it learning to code in various language and making apps in platforms? Or is it just thinking about faster and faster algorithms so that you can achieve a task more efficiently by the computers? Or is it programming and thinking of new life situations which can be simulated on a computer? What exactly are we trying to do here ?\nFor example, physics is trying to find all the laws of nature that govern it; mathematics is a tautology based to model reality and used as a very precise language by other subjects.\nWhat exactly is theoretical computer science? When computers were designed by us humans for application purposes, hence it must all drop down to mathematics and physics in the end? Then where is the \"theory\" in computer science itself.\nSorry for being too naive but I want to know what does a theoretical computer scientist do ?", "output": "Your question itself is not naive but the type of answer you ask for is. It is rare for any line of work or intellectual enquiry to have an elevator pitch explanation. Not all would agree with your characterizations of mathematics and physics because they ignore the depth and nuances of those fields. \nTheoretical computer scientists are concerned with studying and applying computation. The computational perspective is a deep and all encompassing one so the study of computation is also deep and has a bearing on many other areas of study. Every single process, whether arising in nature or synthetic, manipulates information. They compute. As in mathematics, there are different languages and types of structures involved in computation, as in physics, there are fundamental laws about computation that we are trying to discover, as in chemistry, fundamental elements of computation can be classified. Theoretical computer science is broad and robust enough to be amenable to any perspective you bring to it. Some of the questions studied are:\n\nWhat is computation and how can it be characterized? (Turing machines, lambda calculi, tiling systems, register machines, DNA computers etc.)\nWhat is the computational model underlying a process? (Biological, chemical, economic, sociological processes, etc.)\nWhat is efficient computation? (complexity via time, space, communication, amortized, smoothed, etc.)\nWhat are characterizations of efficient computation? (Turing machines, algebraic notions, logic, type systems, etc.)\nWhat is the most efficient way to  compute a solution to a problem? (algorithms)\nHow efficient are existing algorithmic processes (analysis of algorithms, statistical phenomena, market equillibria, etc.)\n\nThese are a small and non-representative sample of the questions that one may ask. As in any field, answers to some questions generate new questions and drive enquiry about other questions. You can find a rather dated view of the field by browsing the articles in the Handbook of Theoretical Computer Science. \n\nHandbook of Theoretical Computer Science, Volume A: Algorithms and Complexity, 1990\nHandbook of Theoretical Computer Science, Volume B: Formal Models and Sematics, 1990", "meta": {"post_id": 19636, "input_score": 14, "output_score": 21, "post_title": "What is theoretical computer science?"}}
{"input": "The only definition of \"calculus\" I'm aware of is the study of limits, derivatives, integrals, etc. in analysis. In what sense is lambda calculus (or things like mu calculus) a \"calculus\"? How does it relate to calculus in analysis?", "output": "A calculus is just a system of reasoning. One particular calculus (well, actually two closely related calculi: the differential calculus and the integral calculus) has become so widespread that it is just known as \"calculus\", as if it were the only one. But, as you have observed, there are other calculi, such as the lambda calculus, mu calculus, pi calculus, propositional calculus, predicate calculus, sequent calculus and Professor Calculus.", "meta": {"post_id": 19675, "input_score": 15, "output_score": 23, "post_title": "Why is lambda calculus a \"calculus\"?"}}
{"input": "(This question is a bit of a \"survey\".)\nI'm currently working on a problem where I'm trying to partition the edges of a tournament into two sets, both of which are required to fulfill some structural properties. The problem \"feels\" quite hard, and I fully expect it to be $\\mathcal{NP}$-complete. For some reason I'm having a hard time even finding similar problems in literature.\nAn example of a problem that I would consider comparable to the one I'm dealing with:\n\nGiven a weighted tournament $G = (V,E,w)$, is there a feedback arc set in $G$ the edges of which fulfill the triangle inequality?\n\nNote the difference to the traditional feedback arc set (DFAS) problem: I don't care about the size of the set, but I do care whether the set itself has a certain structural property.\nHave you encountered any decision problems that feel similar to this? Do you remember whether they were $\\mathcal{NP}$-complete or in $\\mathcal{P}$? Any and all help appreciated.", "output": "I think there are lot of similar problems. Here are two in vertex version and one in edge version:\n1) Does a given graph have an independent feedback vertex set? (we don't care about the size of the set). \nThis problem is NP-complete; the proof can be derived from the proof of Theorem 2.1 in \nGarey, Johnson & Stockmeyer.\n2) Does a given graph have a vertex cover that induces a tree? (we don't care about the size of the set). \nThis paper \ngives an NP-completeness proof for this problem (Theorem 2); even for bipartite graphs.\n3) Does a given graph have a dominating edge set the edges of which form an induced $1$-regular subgraph? \n(also known as dominating induced matching or efficient edge dominating; the vertex version is given in the \nsecond answer by Mohammad. \nAgain, we don't care about the size of the set). \nThis problem is NP-complete (well-known, first proved here), even for planar bipartite graphs. \nThe first two problems are particular examples of the problem class called stable-$\\pi$: \nLet $\\pi$ be a graph property. Does a given graph have a vertex cover satisfying $\\pi$? \nMore NP-complete cases as well as polynomially solvable cases can be found in \nthis \nand in this paper \n(and the refs given there) .", "meta": {"post_id": 19845, "input_score": 24, "output_score": 21, "post_title": "NP complete graph problems about structural properties"}}
{"input": "I'm designing a simple statically typed functional programming language as a learning experience.\nIt appears that the type system I have implemented so far could (with a little extra work) incorporate intersection and union types, e.g. you could have:\n\n<Union String Integer>\n<Union Integer Foo>\nThe intersection of the two types above would be a plain Integer\nThe union of the two types would be <Union String Integer Foo>\n\nThe fact that this is possible, of course, doesn't necessary mean it is a good design idea. In particular, I'm a somewhat concerned about the implementation difficulties of keeping the types disjoint and/or handling overlaps.\nWhat are the pros/cons of incorporating such features in the type system?", "output": "Here are a few things to keep in mind:\n\nAlthough we generally think we know what we mean by set-theoretic intersection and union, there have been several different takes on what exactly intersection and union types are.  So, it's worth pinning this down before you embark on an implementation.\nOne element which I think is awfully important for understanding intersections and unions is the concept of type refinement, essentially the idea that a program has a certain intrinsic \"archetype\" (e.g., \"foo is a function from integers to integers\"), which can then be refined to express more precise properties (e.g., \"foo takes even integers to even integers and odd integers to odd integers\"). With the concept of refinement in hand, the key property which distinguishes intersections and unions from products and sums is that the intersection/union of two types can be formed only if they refine the same archetype.  In other words, the type formation rules for intersections and unions may be expressed like so (read \"$S \\sqsubset A$\" as \"$S$ refines $A$\")\n$$\\frac{S\\sqsubset A \\quad T \\sqsubset A}{S\\cap T\\sqsubset A}\\qquad\n\\frac{S\\sqsubset A \\quad T \\sqsubset A}{S\\cup T\\sqsubset A}$$\nwhereas the formation rules for ordinary products and sums are \n$$\\frac{S\\sqsubset A \\quad T \\sqsubset B}{S* T\\sqsubset A*B}\\qquad\n\\frac{S\\sqsubset A \\quad T \\sqsubset B}{S+T\\sqsubset A+B}$$\nSince intersections and unions can be used to make more precise assertions about the run-time behavior of a program, it is natural that typing becomes sensitive to evaluation order. For example, papers (2) and (4) below explained why  the \"obvious\" (and fairly standard) typing and subtyping rules for intersections and unions are actually unsound for ML-like languages (due to the presence of side effects and non-termination). You have been warned!\nFor similar reasons, global type inference generally becomes impractical or undecidable. Indeed, the whole concept of \"principal type\" is arguably a red-herring, since a function may satisfy many different properties which are irrelevant to its intended use (e.g., \"foo takes prime integers to integers greater than 7\"). Instead, practical approaches to intersections and unions (see (3), (4)) are generally based on a combination of inference and checking.\n\nI suppose some of the above points might sound negative, though I wouldn't call them \"cons\" but merely \"realities\" of intersection and union types. On the other hand, from a language design perspective, one reason for making the effort of supporting intersections and unions (and for getting them right!) is that they allow more precise properties of programs to be expressed in a fairly incremental way, requiring a much less drastic transformation than, say, dependent type theory.\nA brief reading list:\n\nDesign of the Programming Language Forsythe by John C. Reynolds\nIntersection Types and Computational Effects by Rowan Davies and Frank Pfenning\nPractical Refinement-Type Checking by Rowan Davies (dissertation)\nTridirectional Typechecking by Joshua Dunfield and Frank Pfenning", "meta": {"post_id": 20536, "input_score": 22, "output_score": 27, "post_title": "What are the practical issues with intersection and union types?"}}
{"input": "The longest path problem is NP-hard. The (typical?) proof relies on a reduction of the Hamiltonian path problem (which is NP-complete). Note that here the path is taken to be (node-)simple. That is, no vertex can occur more than once in the path. Obviously it is thus also edge-simple (no edge will occur more than once in the path).\nSo what if we drop the requirement of finding a (node-)simple path and stick to finding an edge-simple path (trail). At first glance, since finding a Eulerian trail is much easier than finding a Hamiltonian path, one might have some hope that finding the longest trail would be easier than finding the longest path. However, I cannot find any reference proving this, let alone one that provides an algorithm.\nNote that I am aware of the argument made here:\nhttps://stackoverflow.com/questions/8368547/how-to-find-the-longest-heaviest-trail-in-an-undirected-weighted-graph\nHowever, the argument seems flawed in its current form, as it basically shows you could solve the edge-simple case by solving the node-simple case on a different graph (so the reduction is the wrong way around). It is not clear that the reduction could easily be changed to work the other way as well. (Still, it does show that at the very least the longest trails problem is not harder than the longest paths problem.)\nSo are there any known results for finding longest trails (edge-simple paths)? Complexity (class)? (Efficient) algorithm?", "output": "From the comments above: the Hamiltonian cycle problem remains NP-complete even in grid graphs with max degree 3 [1], but in these graphs every traversal of a node requires two edges and at most one edge remains unused, so a node cannot be traversed twice by an Eulerian path.\nSo apparently there is an immediate reduction from the Hamiltonian cycle problem to your problem: \ngiven a grid graph with max degree 3 $G = (V,E)$, just ask for a trail of length $|V|$.\nBut all three edges of the node at the end of the trail can be used; to avoid this situation you can pick the top-left node $u$ of the grid graph (which has degree two) and add two nodes: $V' = V \\cup \\{u',u''\\}$ and a new edges $E = E \\cup  \\{(u,u'), (u,u'')\\}$ and ask for a trail of length $|V'| = |V|+2$: informally the added edge forces $u',u''$ to be the endpoints of the trail.\n[1] Christos H Papadimitriou, Umesh V Vazirani, On two geometric problems related to the travelling salesman problem, Journal of Algorithms, Volume 5, Issue 2, June 1984, Pages 231-246, ISSN 0196-6774", "meta": {"post_id": 20682, "input_score": 14, "output_score": 21, "post_title": "Is the longest trail problem easier than the longest path problem?"}}
{"input": "Assume P $\\ne$ NP.\nLadner's Theorem says that there are NP Intermediate problems (problems in NP that are neither in P nor NP-Complete).  I have found some veiled references online that suggest (I think) that there are many \"levels\" of mutually reducible languages within NPI that definitely do not all collapse into one.\nI have some questions about the structure of these levels.\n\nAre there \"NP-Intermediate-Complete\" problems - that is, NP-Intermediate problems to which every other NP-Intermediate problem is polytime reducible?\nSort NP - P into equivalence classes, where mutual reducibility is the equivalence relation.  Now impose an ordering on these equivalence classes: $A > B$ if the problems in $B$ reduce to problems in $A$ (so clearly the NP-Complete equivalence class is the maximum element).  Is this a total ordering (i.e. the problems are arranged in an infinite descending chain)?  If not, does the \"tree structure\" of the partial ordering have a finite branching factor?\nAre there any other interesting known structural components of NP - P?  Are there any interesting open questions about the underlying structure?\n\nIf any of these are currently unknown, I would be interested to hear that as well.\nThanks!", "output": "I don't really have references for these results--they aren't hard to prove once you understand Ladner's theorem.\n\nNo, for any NP-incomplete set A there is another set B strictly between A and SAT.\nThese equivalence classes are known as polynomial-many-one degrees. You can embed any finite poset into the degrees below NP. In particular the degrees are not totally ordered or finitely branching. \nThis all depends on what you mean by \"interesting\". There is a huge theory of the degree structure of the computable sets (see Soare's book for instance) and many of those questions have not been ported down to polynomial-time sets. For instance, can you have NP sets A and B whose join is equivalent to SAT and whose meet is equivalent to the empty set?", "meta": {"post_id": 20755, "input_score": 15, "output_score": 34, "post_title": "Are there \"NP-Intermediate-Complete\" problems?"}}
{"input": "Suppose there is a graph $G=(V,E)$. I want to test if $V$ can be partitioned into two disjoint sets $V_1$ and $V_2$ such that the subgraphs induced by $V_1$ and $V_2$ are unit interval graphs.\nI know about the NP-completeness of determining interval numbers but the above problem is different.\nNow, in the literature I found this work by A. Gy\u00e1rf\u00e1s and D. West on multitrack interval graphs but I'm not sure if it is relevant to above problem.\nAny citation to existing literature on the above or similar problem would be helpful. Also please let me know if there is a formal name for the above problem.", "output": "I think, your problem is NP-complete. It is a special case of a theorem \nby Farrugia, \nstating that it is NP-hard to test if the vertex set a graph can be partitioned into \ntwo subsets $V_1,$ and $V_2$ such that $G(V_1)$ belongs to the graph class $\\mathcal{P}$ and \n$G(V_2)$ belongs to the graph class $\\mathcal{Q}$, provided $\\mathcal{P}$ and $\\mathcal{Q}$ \nare closed under taking vertex-disjoint unions and talking induced subgraphs, and at least \none of $\\mathcal{P}$ and $\\mathcal{Q}$ is non-trivial (meaning not all graphs in the class are \nedgeless).", "meta": {"post_id": 20843, "input_score": 13, "output_score": 21, "post_title": "Partition into interval graphs"}}
{"input": "What would be the nasty consequences of NP=PSPACE? I am surprised I did not found anything on this, given that these classes are among the most famous ones.\nIn particular, would it have any consequences on the lower classes?", "output": "One point which has been implicitly but not explicitly mentioned yet is that we would get $\\mathsf{NP} = \\mathsf{coNP}$. Although this is equivalent to $\\mathsf{PH}$ collapsing to $\\mathsf{NP}$, it follows directly from the fact that $\\mathsf{PSPACE}$ is closed under complement, which is trivial to prove. \nI think $\\mathsf{NP} = \\mathsf{coNP}$ is worth pointing out on its own because of the large number of surprising consequences it has: there are short proofs witnessing when a graph is not 3-colorable, *non-*Hamiltonian, when two graphs are *non-*isomorphic, ..., and (in some sense more generally) that there is some Cook-Reckhow proof system in which every propositional tautology has a polynomial-sized proof.", "meta": {"post_id": 21026, "input_score": 31, "output_score": 22, "post_title": "Consequences of NP=PSPACE"}}
{"input": "Consider optimization problems of the following form. Let $f(x)$ be a polynomial-time computable function that maps a string $x$ into a rational number. The optimization problem is this: what is the maximum value of $f(x)$ over $n$-bit strings $x$?\nLet us say that such a problem has a minimax characterization, if there is another polynomial-time computable function $g$, such that \n$$\\max_x f(x) = \\min_y g(y)$$ holds. Here $x$ runs over all $n$-bit strings, and $y$ runs over all $m$-bit strings; $n$ and $m$ may be different, but they are polynomially related. \nNumerous natural and important optimization problems have such minimax characterization. A few examples (the theorems on which the characterizations are based shown in parenthesis): \n\n Linear Programming  (LP Duality Thm),   Maximum Flow   (Max Flow Min Cut Thm),   Max Bipartite Matching   (Konig-Hall Thm),   Max Non-Bipartite Matching   (Tutte's Thm, Tutte-Berge formula),   Max Disjoint Arborescences in directed graph   (Edmond's Disjoint Branching Thm),   Max Spanning Tree Packing in undirected graph    (Tutte's Tree Packing Thm),    Min Covering by Forests   (Nash-Williams Thm),   Max Directed Cut Packing   (Lucchesi-Younger Thm),   Max 2-Matroid Intersection   (Matroid Intersection Thm),   Max Disjoint Paths   (Menger's Thm),   Max Antichain in Partially Ordered Set   (Dilworth Thm), and many others.\n\nIn all these examples, a polynomial-time algorithm is also available to find the optimum. My question: \n\nIs there any optimization problem with a minimax characterization, for which no polynomial-time algorithm has been found so far?\n\nNote: Linear Programming was in this status for about 30 years!", "output": "In some technical sense you are asking whether $P = NP \\cap coNP$.  Suppose that $L \\in NP \\cap coNP$, thus there exists poly-time $F$ and $G$ so that $x \\in L$ iff $\\exists y: F(x,y)$ and $x \\not\\in L$ iff $\\exists y: G(x,y)$.  This can be recast as a minmax characterization by\n$f_x(y) = 1$ if $F(x,y)$ and $f_x(y) = 0$ otherwise; $g_x(y) = 0$ if $G(x,y)$ and $g_x(y) = 1$\notherwise.  Now indeed we have $max_y f_x(y) = min_y g_x(y)$.\nSo in this sense, any problem known to be in $NP \\cap coNP$ but not known to be in $P$ can be turned into an answer to your question.  E.g. Factoring (say, the decision version of whether the $i$'th bit of the largest factor is 1).", "meta": {"post_id": 21060, "input_score": 26, "output_score": 23, "post_title": "Optimization problems with minimax characterization, but no polynomial-time algorithm"}}
{"input": "When we look at the book, Homotopy Type Theory - we see the following topics:\nHomotopy type theory \n2.1 Types are higher groupoids\n2.2 Functions are functors\n2.3 Type families are \ufb01brations\n2.4 Homotopies and equivalences\n2.5 The higher groupoid structure of type formers\n2.6 Cartesian product types\n2.7 S-types\n2.8 The unit type\n2.9 P-types and the function extensionality axiom\n2.10 Universes and the univalence axiom\n2.11 Identity type\n2.12 Coproducts\n2.13 Natural numbers\n2.14 Example: equality of structures\n2.15 Universal properties\n\nNow we know that not all of homotopy type theory is possible is Agda and Coq. \nMy question is: What parts of homotopy type theory are not possible in Agda or Coq?", "output": "If you look at Notes on Chapter 8 you will see what has already been formalized, and I think that's a lot. There are the Coq HoTT library and the Agda HoTT-Agda library which formalize large chunks of Homotopy Type Theory.\nTo get things done in Coq we needed a special version of Coq that was patched just for the purposes of HoTT. However, Coq is moving in the direction of supporting homotopy type theory, so before long we might be able to do it with standard Coq.\nIn Agda one has to turn on the --without-K option, otherwise Agda thinks all types are 0-types. There are some lingering doubts as to whether --without-K really gets rid of the assumption that everything is a 0-set, or perhaps one could reintroduce it into Agda with tricky uses of pattern matches.\nThe following aspects of Coq and Agda formalizations are not satisfactory:\n\nThe Univalence axiom is stated as a hypothesis. It would be better if it were built into the system. In particular we would like Coq and Agda to understand the computation rules about the Univalence axiom.\nLikewise, we have to use hacks to get workable higher-inductive types. Again, it would be better to have direct support.\n\nThe trouble with the above deficiencies is that nobody knows how to fix them even in theory. This is an active area of research.\nOther than that, I think it's fair to say that HoTT can be mostly done in Coq and Agda, just not in the optimal way.", "meta": {"post_id": 21199, "input_score": 17, "output_score": 21, "post_title": "What parts of homotopy type theory are not possible in Agda or Coq?"}}
{"input": "Is NP in $DTIME(n^{poly\\log n})$?", "output": "Another good reason to believe $NP\\not\\subseteq QP$ is that $NP\\subseteq QP$ implies $EXP=NEXP$, and the latter is thought highly unlikely. This implication can be proved by a padding argument, see, e.g., in the proof of Proposition 2 in the following paper:\nH. Buhrman and S. Homer, \"Superpolynomial circuits, almost sparse oracles and the exponential hierarchy,\" Foundations of Software Technology and Theoretical Computer Science,\nSpringer LNCS Vol. 652, 1992, pp. 116-127,  pdf", "meta": {"post_id": 21571, "input_score": 17, "output_score": 21, "post_title": "Is NP in $DTIME(n^{poly\\log n})$?"}}
{"input": "Let\n$L = \\{ n : \\text{the }n^{th}\\text{ binary digit of }\\pi\\text{ is }1 \\}$\n(where $n$ is thought of as encoded in binary).  Then what can we say about the computational complexity of $L$?  It's clear that $L\\in\\mathsf{EXP}$.  And if I'm not mistaken, the amazing \"BBP-type\" algorithms for computing the $n^{th}$ bit of $\\pi$ using quasilinear time and $(\\log n)^{O(1)}$ memory, without needing to compute the previous bits, yield $L\\in\\mathsf{PSPACE}$.\nCan we do even better, and place $L$ (say) in the counting hierarchy?  In the other direction, is there any hardness result whatsoever for $L$ (even an extremely weak one, like $\\mathsf{TC}^0$-hardness)?\nAn interesting related language is\n$L' = \\{ \\langle x,t\\rangle : x\\text{ occurs as a substring within the first }t\\text{ digits of }\\pi \\}$\n(where again, $t$ is written in binary).  We have\n$L' \\in \\mathsf{NP}^L$\nand hence $L' \\in \\mathsf{PSPACE}$; I'd be extremely interested if anything better is known.", "output": "OK, James Lee has pointed me to this 2011 paper by Samir Datta and Rameshwar Pratap, which proves that my language $L$ (encoding the digits of $\\pi$) is in the fourth level of the counting hierarchy ($\\mathsf{PH}^{\\mathsf{PP}^{\\mathsf{PP}^{\\mathsf{PP}}}}$; thanks to SamiD below for pointing out a missing $\\mathsf{PP}$ in the paper, which I'd simply repeated in my answer!).  The paper also explicitly discusses my question of lower bounds on the complexity of computing the binary digits of irrational numbers, though it only manages to prove a very weak lower bound for computing the binary digits of rational numbers.  This is exactly what I was looking for.\nUpdate (April 3): An amusing consequence of the digits of $\\pi$ being computable in the counting hierarchy is as follows.  Suppose that $\\pi$ is a normal number (whose binary expansion converges quickly to \"effectively random\"), and suppose that $\\mathsf{P} = \\mathsf{PP}$ (with the simulation involving only a small polynomial overhead).  Then it would be feasible to program your computer to find, for example, the first occurrence of the complete works of Shakespeare in the binary expansion of $\\pi$.  If that sounds absurd to you, then maybe it should be taken as additional evidence that $\\mathsf{P} \\ne \\mathsf{PP}$. :-)", "meta": {"post_id": 21787, "input_score": 36, "output_score": 30, "post_title": "Computational complexity of pi"}}
{"input": "Kurt G\u00f6del's incompleteness theorems  establish the \"inherent limitations of all but the most trivial axiomatic systems capable of doing arithmetic\". \nHomotopy Type Theory provides an alternative foundation for mathematics, a univalent foundation based on higher inductive types and the univalence axiom. \nThe HoTT book explains that types are higher groupoids, functions are functors, type families are \ufb01brations, etc. \nThe recent article \"Formally Verified Mathematics\" in CACM \nby Jeremy Avigad and John Harrison \ndiscusses HoTT with respect to \nformally verified mathematics and automatic theorem proving. \n\nDo G\u00f6del's incompleteness theorems apply to HoTT?\n\nAnd if they do,\n\nis homotopy type theory impaired by G\u00f6del's incompleteness theorem \n  (within the context of formally verified mathematics)?", "output": "HoTT \"suffers\" from G\u00f6del incompleteness, of course, since it has a computably enumerable language and rules of inference, and we can formalize arithmetic in it. The authors of the HoTT book were perfectly aware of its incompletness. (In fact, this is quite obvious, especially when half of the authors are logicians of some sort).\nBut does incompleteness \"impair\" HoTT? No more than it does any other formal system, and I think the whole issue is a bit misguided. Let me try an analogy. Suppose you have a car which can't take you everywhere on the planet. For instance, it can't climb vertically up a wall. Is the car \"impaired\"? Of course, it can't get you to the top of the Empire State building. Is the car useless? Far from it, it can take you too many other interesting places. Not to mention that the Empire State building has elevators.", "meta": {"post_id": 22130, "input_score": 15, "output_score": 33, "post_title": "Homotopy type theory and G\u00f6del's incompleteness theorems"}}
{"input": "According to (unverified) historical account, Kolmogorov thought that every language in $\\mathsf{P}$ has linear circuit complexity. (See the earlier question Kolmogorov's conjecture that $P$ has linear-size circuits.) Note that it implies $\\mathsf{P}\\neq \\mathsf{NP}$.\nKolmogorov's  conjecture, however, is viewed likely to fail. For example, Ryan Williams writes in a recent paper: \"The conjecture would be surprising, if true. For languages in $\\mathsf{P}$ requiring $n^{100^{100}}$\ntime, it appears unlikely that the complexity of such problems would magically\nshrink to $O(n)$ size, merely because a different circuit can be designed for each\ninput length.\"\nOn the other hand, Andrey Kolmogorov (1903-1987) is widely recognized as one of the leading mathematicians of the 20th century. It is rather hard to imagine that he would have proposed a completely absurd conjecture. Therefore, to understand it better, I tried to find some arguments that might actually support his surprising guess. Here is what I could think up:\nAssume $\\mathsf{P}\\not\\subseteq \\mathsf{SIZE}(lin)$. Then we can pick a language $L\\in \\mathsf{P}$, such that $L$ has superlinear complexity both in the uniform and in the non-uniform model. There are then two possibilities:\n\nThere is a known  explicit algorithm (Turing machine) that accepts $L$. From this we can construct an explicit function family that must have superlinear circuit complexity. However, this may be viewed  unlikely, since no one has been able to find such an example in more than 60 years of intense research on circuits.\nThere is no known explicit algorithm for $L$. For example, its existence is proved via non-constructive means, such as the Axiom of Choice. Or, even if the explicit algorithm exists, no one has been able to find it. Given, however, that there are infinitely many languages that can play the role of $L$, it is unlikely again that they all behave in this unfriendly way. \n\nBut then, if we dismiss both options as unlikely, the only remaining possibility is that such an $L$ does not exist. That means  $\\mathsf{P}\\subseteq \\mathsf{SIZE}(lin)$, which is precisely Kolmogorov's conjecture. \n\nQuestion: Can you think of any further argument for/against Kolmogorov's conjecture?", "output": "The footnote of my paper that you cite refers to a heuristic \"argument\" as well, at least, what we think was Kolmogorov's intuition -- the positive resolution of Hilbert's thirteenth problem. \nhttp://en.wikipedia.org/wiki/Hilbert's_thirteenth_problem\nIn particular, it was proved by Kolmogorov and Arnold that any continuous function on $n$ variables can be expressed as a composition of $O(n^2)$ \"simple\" functions: addition of two variables, and continuous functions on one variable. Hence, over the \"basis\" of one-variable continuous functions and two-variable addition, every continuous function on $n$ variables has \"circuit complexity\" $O(n^2)$.\nIt seems Kolmogorov believed there is a discrete analog, where \"continuous in $n$ variables\" becomes \"Boolean in $n$ variables and poly$(n)$-time computable\", and where the \"basis\" given above becomes two-variable Boolean functions.", "meta": {"post_id": 22431, "input_score": 19, "output_score": 22, "post_title": "Arguments for/against Kolmogorov's conjecture about the circuit complexity of P"}}
{"input": "The wise other editors at Wikipedia have declined my request to move the Wikipedia article on the Rabin\u2013Karp algorithm to what I think it should be called, the Karp\u2013Rabin algorithm, on the basis that the Rabin\u2013Karp name is used more often (false, if one goes by Google scholar's numbers), or that it sounds better out loud (really?). The original publication name order was Karp and Rabin, alphabetically as it usually is for theory papers, which is why I requested the move.\nOne major proponent of the Rabin\u2013Karp name ordering is the Cormen\u2013Leiserson\u2013Rivest\u2013Stein Introduction to Algorithms textbook. The Wikipedia outcome is unlikely to change barring significant new evidence one way or another, and it seems unlikely that either Rabin or Karp cares about $\\epsilon$ more credit, but now I'm curious: Do any readers remember the history of this and have any explanation why CLRS (or anyone else) chose the Rabin\u2013Karp name order?", "output": "I've asked Dick personally out of curiosity a few years back. He said that as far as he knows Rabin-Karp was a random switch many years after the paper was first published. He also indicated that it is his understanding that Michael would say the same thing if asked, since at some point they had talked about it.", "meta": {"post_id": 22544, "input_score": 26, "output_score": 25, "post_title": "Rabin\u2013Karp vs Karp\u2013Rabin"}}
{"input": "While answering this question on cstheory, I (informally) proved on the fly the following theorem:\nTheorem: For any fixed $l \\geq 3$ the Hamiltonian cycle probem remains NP-complete even if restricted to planar bipartite undirected graphs of maximum degree 3 that don't contain cycles of length $\\leq l$.\nIt seems very unlikely that it has not already appeared somewhere.\nBut it allows to settle many Hamiltonian cycle/path problems on graphclasses.org that are marked as \"Unknown to ISGCI\" (see for example this one); indeed a direct corollary is that Hamiltonian cycle and path problems are still NP-complete if restricted to $(H_1,...,H_k)\\text{-free}$ graphs, where each of the $H_i$ contains at least one cycle.\n\nCan you give me a reference of the paper/book where it appeared?\n\n(then I'll contact people at graphclasses.org)", "output": "This unpublished manuscript by Hougardy, Emden-Weinert and Kreuter in 1997 \nprovided a simple proof for the following result which is much stronger than the result pointed out in \nKristoffer Arnsfelt Hansen's answer:\n\nFor any given rational number $0\\le r <1/2$, the Hamiltonian cycle probem remains NP-complete even if restricted to bipartite planar $n$-vertex graphs of maximum degree 3 and girth $\\ge n^r$.\n\nThe manuscript contains also similar results for other problems such as Dominating set, Max cut, VFS, etc.", "meta": {"post_id": 24917, "input_score": 12, "output_score": 26, "post_title": "Hamiltonian cycle on graphs without small cycles"}}
{"input": "Any language which is not Turing complete can not write an interpreter for it self. I have no clue where I read that but I have seen it used a number of times. It seems like this gives rise to a kind of \"ultimate\" non Turing complete language; the one(s) that can only be interpreted by a Turing machine. These languages would not necessarily be able to compute all total functions from naturals to naturals nor would they necessarily be isomorphic (that is maybe ultimate languages A and B exists such that there exists a function F that A can compute but B cannot). Agda can interpret Godel's system T and Agda is total so that such an ultimate language should be strictly more powerful that Godel's system T it would seem. It seems to me that such a language would be at least as powerful as agda too (though I have no evidence, just a hunch).\nHas any research been done in this vein? What results are known (namely is such an \"ultimate\" language known)?\nBonus: I am worried that there exists a pathological case that can not compute functions that Godel's System T could yet can still only be interpreted by a Turing machine because it allows some really odd functions to be computed. Is this the case or can we know that such a language would be able to compute anything Godel's System T could compute?", "output": "Any language which is not Turing complete can not write an interpreter for it self.\n\nThis statement is incorrect. Consider the programming language in which the semantics of every string is \"Ignore your input and halt immediately\".  This programming language is not Turing complete but every program is an interpreter for the language.", "meta": {"post_id": 24986, "input_score": 20, "output_score": 21, "post_title": "A total language that only a Turing complete language can interpret"}}
{"input": "An important 2003 paper by Childs et al. introduced the \"conjoined trees problem\": a problem admitting an exponential quantum speedup that's unlike just about any other such problem that we know of.  In this problem, we're given an exponentially-large graph like the one pictured below, which consists of two complete binary trees of depth n, whose leaves are connected to each other by a random cycle.  We're supplied with the label of the ENTRANCE vertex.  We're also supplied with an oracle that, given as input the label of any vertex, tells us the labels of its neighbors.  Our goal is to find the EXIT vertex (which can easily be recognized, as the only degree-2 vertex in the graph other than the ENTRANCE vertex).  We can assume that the labels are long random strings, so that with overwhelming probability, the only way to learn the label of any vertex other than the ENTRANCE vertex is to be given it by the oracle.\nChilds et al. showed that a quantum walk algorithm is able simply to barrel through this graph, and find the EXIT vertex after poly(n) steps.  By contrast, they also showed that any classical randomized algorithm requires exp(n) steps to find the EXIT vertex with high probability.  They stated their lower bound as \u03a9(2n/6), but I believe that a closer examination of their proof yields \u03a9(2n/2).  Intuitively, this is because with overwhelming probability, a random walk on the graph (even a self-avoiding walk, etc.) will get stuck in the vast middle region for an exponential amount of time: any time a walker starts heading toward the EXIT, the much larger number of edges pointing away from the EXIT will act as a \"repulsive force\" that pushes it back toward the middle.\nThe way they formalized the argument was to show that, until it's visited ~2n/2 vertices, a randomized algorithm hasn't even found any cycles in the graph: the induced subgraph that it's seen so far is just a tree, providing no information whatsoever about where the EXIT vertex might be.\nI'm interested in pinning down the randomized query complexity of this problem more precisely.  My question is this:\nCan anyone come up with a classical algorithm that finds the EXIT vertex in fewer than ~2n steps---say, in O(2n/2), or O(22n/3)?  Alternatively, can anyone give a lower bound better than \u03a9(2n/2)?\n(Note that, by the birthday paradox, it's not hard to find cycles in the graph after O(2n/2) steps.  The question is whether one can use the cycles to get any clues about where the EXIT vertex is.)\nIf anyone can improve the lower bound past \u03a9(2n/2), then to my knowledge, this would provide the very first provable example of a black-box problem with an exponential quantum speedup, whose randomized query complexity is greater than \u221aN.  (Where N~2n is the problem size.)\nUpdate: I've learned from Andrew Childs that, in this note, Fenner and Zhang explicitly improve the randomized lower bound for conjoined trees to \u03a9(2n/3).  If they were willing to accept constant (rather than exponentially-small) success probability, I believe they could improve the bound further, to \u03a9(2n/2).", "output": "I think I have a deterministic algorithm that finds the exit in $O(n2^{n/2})$ oracle calls.\nFirst, find the labels for all the vertices of distance $n/2$ from the entrance. This takes $O(2^{n/2})$ queries. Then, start from the entrance and walk $n+1$ steps to get to a node $X$ of distance $n+1$ from the entrance. We will try to reach the exit from this node.\nWe have two options of where to go from $X$, and we wish to choose the one closer to the exit. To do this, pick one of the options arbitrarily, arriving at a node $Y$. Then explore all the $O(2^{n/2})$ ways of walking $n/2$ steps from $Y$. If one of them gives a label of distance $n/2$ from the entrance, we know that going from $X$ to $Y$ was the wrong choice. Otherwise, $Y$ was the right choice. Thus in $O(2^{n/2})$ we found a node $X_2$ of distance $n+2$ from the entrance.\nWe can keep proceeding this way. To find a node of distance $n+3$ from the entrance, we start at $X_2$ and walk two arbitrary steps. We then explore all options of walking $n/2$ additional steps (while never walking backwards), and check if any of them have distance $n/2$ from the entrance. This will happen if and only if the first step we walked from $X_2$ was wrong.\nGetting to the exit requires doing this $n$ times, for a total of $O(n2^{n/2})$ oracle calls. In addition, perhaps surprisingly, this algorithm is deterministic.\nEdit: Just to clarify, to get from $X_t$ to $X_{t+1}$, we walk $t$ arbitrary steps, then run a search of depth $n/2$, for a total of $t+2^{n/2}$ steps. If the first step lead away from the exit, then all the first $t$ steps did, and we therefore find a label of distance $n/2$ from the entrance. This means $t+2^{n/2}$ steps suffice for determining the next single step to take from $X_t$.", "meta": {"post_id": 25279, "input_score": 23, "output_score": 22, "post_title": "The randomized query complexity of the conjoined trees problem"}}
{"input": "This is a \"historical question\" more than it is a research question, but was the classical reduction to order-finding in Shor's algorithm for factorization initially discovered by Peter Shor, or was it previously known?  Is there a paper that describes the reduction that pre-dates Shor, or is it simply a so-called \"folk result?\"  Or was it simply another breakthrough in the same paper?", "output": "The random reduction from factorization to order-finding (mod N) was very well known to people working in number theory algorithms in the late 1970's and early 1980's.  Indeed, it appears in a paper of Heather Woll, Reductions among number theoretic problems, Information and Computation 72 (1987) 167-179, and Eric Bach and I knew it before then.\nI am mystified why Peter Shor says that order-finding is \"provably exponential on a classical computer\".  If one knows the factorization of N and also $\\varphi(N)$ (both computable in sub exponential time) and one works modulo each prime power, one can find orders.", "meta": {"post_id": 25512, "input_score": 88, "output_score": 54, "post_title": "Was the reduction in Shor's algorithm originally discovered by Shor?"}}
{"input": "Let us call a function $f(n)$ superpolynomial if $\\lim_{n\\rightarrow\\infty} n^c/f(n)=0$ holds for every $c>0$. \nIt is clear that for any language $L\\in {\\mathsf P}$ it holds that $L\\in {\\mathsf {DTIME}}(f(n))$ for every superpolynomial time bound $f(n)$. I wonder, wether the converse of this statement is also true? That is, if we know $L\\in {\\mathsf {DTIME}}(f(n))$ for every superpolynomial time bound $f(n)$, does it imply $L\\in {\\mathsf P}$? In other words, is it true that\n$${\\mathsf P} = \\cap_f {\\mathsf {DTIME}}(f(n))$$\nwhere the intersection is taken over every superpolynomial $f(n)$.", "output": "Yes. \nIn fact, by the McCreight-Meyer Union Theorem (Theorem 5.5 of McCreight and Meyer, 1969, free version here) a result of that I believe is due to Manuel Blum, there is a single function $f$ such that $\\mathsf{P} = \\mathsf{DTIME}(f(n))$. This function is necessarily superpolynomial, but \"just barely.\"\nThe theorem applies more generally to any Blum complexity measure $\\Phi$ and any union class $\\bigcup_{f \\in S} \\mathsf{BLUM}_{\\Phi}(f(n))$ where $S$ is a c.e., self bounded set of total computable functions. (A set of functions $S$ is c.e. if there is a single partial computable function $F(i,\\vec{x})$ such that $S = \\{f_i(\\vec{x}) | i \\in \\mathbb{N}\\}$ where $f_i(\\vec{x}) := F(i,\\vec{x})$. Self-bounded means that for every finite subset $S_0 \\subset S$, there is a function in $S$ that dominates all $g \\in S_0$ almost everywhere. \"$\\mathsf{BLUM}_{\\Phi}$\" is a notation I haven't seen before, but I like it :) - I'm using it for the $\\Phi$-bounded analog of a time-bounded complexity class.)", "meta": {"post_id": 25794, "input_score": 24, "output_score": 34, "post_title": "Is P equal to the intersection of all superpolynomial time classes?"}}
{"input": "Given two directed acyclic graphs $G_1$ and $G_2$, is it NP-Complete to find a one-to-one mapping $f:V(G_1) \\rightarrow V(G_2)$ such that $(v_i,v_j) \\in D(G_1)$ if and only if $(f(v_i),f(v_j)) \\in D(G_2)$?\n$D(G)$ is defined as the set of arcs in $G$.", "output": "It's GI-complete which means it's probably not NP-complete.\nReduction from undirected graph isomorphism to DAG isomorphism: given an undirected graph $(V,E)$, make a DAG whose vertices are $V\\cup E$, with an edge from $x$ to $y$ whenever $x\\in V$, $y\\in E$, and $x$ is an endpoint of $y$. (i.e. replace every undirected edge with a node and two ingoing edges)\nReduction from DAG isomorphism to undirected graph isomorphism: replace each arc $x\\rightarrow y$ in the DAG with a four-edge subgraph consisting of a triangle having $x$ as one endpoint, and a dangling edge on the triangle connected to $y$. The reduction is only ambiguous in the case of a component that's a directed cycle, and that's not a DAG.", "meta": {"post_id": 25975, "input_score": 9, "output_score": 27, "post_title": "Is DAG isomorphism NP-C"}}
{"input": "Let's suppose that $P\\ne NP$. Is that possible to solve all the instances of size $n$ of an NP-complete problem in polynomial time using some \"universal magic constant\" $C_n$ that has a polynomial length $P(n)$?\nClearly, if $P\\ne NP$ this constant can be only calculated in exponential time and the calculation must be done for each $n$.\nThanks", "output": "Probably not. What you are asking is whether NP $\\subset$ P/poly. If this were true, then the polynomial hierarchy would collapse (this is the Karp\u2013Lipton theorem), something that is widely believed not to happen.", "meta": {"post_id": 26012, "input_score": 5, "output_score": 34, "post_title": "Magic constant to solve NP-complete problem in polynomial time"}}
{"input": "Looking at the homotopy type theory blog one can easily find a lot of library formalizing most of Homotopy Type Theory in Agda and Coq. \nIs there anyone aware if there is any similar attempt to formalize HoTT in Idris?", "output": "Here is a small, incomplete, and inconsistent formalization of HoTT in Idris. It shows that you can derive a contradiction in Idris just by postulating univalence. There are two barriers to formalizing HoTT in Idris at the moment.\nBarrier 1:\nIdris has heterogeneous equality and heterogeneous equality rewriting. From the HoTT perspective this means we have access to the following rewriting principle, which is inconsistent with univalence:\n$$\n \\prod_{P \\,:\\, X \\to \\mathsf{Type}}\\ \\prod_{x\\,:\\,X}\\ \\prod_{p \\,:\\, x = x}\\ \\prod_{a,\\,b \\,:\\, P\\, x} (\\mathsf{transport}\\ P\\ p\\ a = b) \\to (a = b)  \n$$\nWith this principle, we can easily prove True = False.\nBarrier 2: \nThe pattern matching in Idris is too strong for HoTT, as Neel Krishnaswami suspected in a comment above. We can derive Streicher's K. This leads to uniqueness of identity proofs, and is therefore incompatible with univalence. We can once again show True = False.", "meta": {"post_id": 27979, "input_score": 17, "output_score": 21, "post_title": "Formalizing Homotopy Type theory in Idris"}}
{"input": "Let $L_1,L_2$ be two regular languages given by NFAs $M_1,M_2$ as input.\nAssume we would like to check whether $L_1\\cap L_2\\neq \\emptyset$. This can clearly be done by a quadratic algorithm which computes the product automaton of $M_1,M_2$, but I was wondering if anything more efficient is known.\n\nIs there a $o(n^2)$ algorithm for deciding whether $L_1\\cap L_2\\neq \\emptyset$? What is the fastest known algorithm?", "output": "Simple answer: If there does exist a more efficient algorithm that runs in $O(n^{\\delta})$ time for some $\\delta < 2$, then the strong exponential time hypothesis would be refuted.\n\nWe will prove a stronger theorem and then the simple answer will follow.\nTheorem: If we can solve the intersection non-emptiness problem for two DFA's in $O(n^{\\delta})$ time, then any problem that's non-deterministically solvable using only n bits of memory is deterministically solvable in $poly(n)\\cdot2^{(\\delta n/2)}$ time.\nJustification: Suppose that we can solve intersection non-emptiness for two DFA's in $O(n^{\\delta})$ time.  Let a non-deterministic Turing machine M with a read only input tape and a read/write binary work tape be given.  Let an input string x of length n be given.  Suppose that M doesn't access more than n bits of memory on the binary work tape.\nA computation of M on input x can be represented by a finite list of configurations.  Each configuration consists of a state, a position on the input tape, a position on the work tape, and up to n bits of memory that represent the work tape.\nNow, consider that the work tape was split in half.  In other words, we have a left section of $\\frac{n}{2}$ cells and a right section of $\\frac{n}{2}$ cells.  Each configuration can be broken up into a left piece and a right piece.  The left piece consists of the state, the position on the input tape, the position on the work tape, and the $\\frac{n}{2}$ bits from the left section.  The right piece consists of the state, the position on the input tape, the position on the work tape, and the $\\frac{n}{2}$ bits from the right section.\nNow, we build a DFA $D_1$ whose states are left pieces and a DFA $D_2$ whose states are right pieces.  The alphabet characters are instructions that say which state to go to, how the tape heads should move, and how the work tape's active cell should be manipulated.\nThe idea is that $D_1$ and $D_2$ read in a list of instructions corresponding to a computation of M on input x and together verify that it is valid and accepting.  Both $D_1$ and $D_2$ will always agree on where the tape heads are because that information is included in their input characters.  Therefore, we can have $D_1$ verify that the instruction is appropriate when the work tape position is in the left piece and $D_2$ verify when in the right piece.\nIn total, there are at most $poly(n) \\cdot 2^{n/2}$ states for each DFA and at most $poly(n)$ distinct alphabet characters.\nBy the initial assumption, it follows that we can solve intersection non-emptiness for the two DFA's in $poly(n) \\cdot 2^{(\\delta n /2)}$ time.\nYou might find this helpful: https://rjlipton.wordpress.com/2009/08/17/on-the-intersection-of-finite-automata/\n\nCNF-SAT is solvable using $k+O(\\log(n))$ bits of memory where k is the number of variables.  The preceding construction can be used to show that if we can solve intersection non-emptiness for two DFA's in $O(n^{\\delta})$ time, then we can solve CNF-SAT in $poly(n) \\cdot 2^{(\\delta k/2)}$ time.  Therefore, the simple answer holds.\nComments, corrections, suggestions, and questions are welcomed.  :)", "meta": {"post_id": 29142, "input_score": 27, "output_score": 26, "post_title": "Deciding emptiness of intersection of regular languages in subquadratic time"}}
{"input": "Does someone dare to attempt to clarify what's the relation of these fields of study or perhaps even give a more concrete answer at the level of problems? Like which includes which assuming some widely accepted formulations. If I got this correctly, when you go from SAT to SMT you're basically entering the field of CSP; vice-versa, if you limit CSP to booleans you're basically talking of SAT and maybe a few related problems like #SAT. I think this much is clear (e.g. cf Kolaitis and Vardi's chapter \"A Logical Approach to Constraint Satisfaction\" in Finite Model Theory and Its Applications by Gr\u00e4del et al.), but what's less clear to me is when are the constraints \"modulo a theory\" and when aren't they? Does SMT always imply the theory uses only equality and inequality constraints are always in the broader field of CSP? As far as I can tell, you can often introduce slack variables, so the distinction [if it exists] is less than obvious.\nThe relatively recent \"Satisfiability handbook\" (IOP Press 2009) gathers both SMT and CSP problems under its broad \"satisfiability\" umbrella, but given the way it is structured (chapters written by various authors) doesn't really help me with figuring out this. \nI would hope the terminology gets less confusing when you talk of constraint programming, which (by analogy with the term ''mathematical programming'') I hope involves minimizing/maximizing some objective function. The Wikipedia article on constraint programming is alas so vague that I can't really say if this framing happens though. What I can gather from Essentials of Constraint Programming by\nFr\u00fchwirth and Abdennadher (p. 56)  is that a \"constraint solver\" usually provides more than just a satisfiability checker, with simplification etc. being important in practice.\nAlthough this is hardly an actual CS-theory research question, I don't expect good answers to this one on the undergraduate CS.SE site given what I saw at https://cs.stackexchange.com/questions/14946/distinguish-decision-procedure-vs-smt-solver-vs-theorem-prover-vs-constraint-sol (which contains a lot of words but not what I would consider a real answer, alas).", "output": "SAT, CP, SMT, (much of) ASP all deal with the same set of combinatorial optimisation problems.\nHowever, they come at these problems from different angles and with different toolboxes.\nThese differences are largely in how each approach structures information about the exploration of the search space.\nMy working analogy is that SAT is machine code, while the others are higher level languages.\nBased on my thesis work on the structural theory of CSPs, I have come to believe that the notion of \"clause structure\" is essential in unifying all these paradigms and in understanding how they differ.\nEach clause of a SAT instance represents a forbidden partial assignment; a clause like $x_1 \\lor \\overline{x_2} \\lor x_3$ forbids the partial assignment $\\{(x_1,0),(x_2,1),(x_3,0)\\}$ that simultaneously sets $x_1$ and $x_3$ to false and $x_2$ to true.\nThe clause structure of a combinatorial optimisation problem is its representation as a SAT instance, using some suitable encoding.\nHowever, the clause structure includes all the forbidden partial assignments, not just the ones given at the start.\nThe clause structure is therefore usually too large to manipulate directly: typically it has at least exponential size in the number of variables, and may be infinite.\nHence, the clause structure has to be approximated with a limited amount of space.\nSAT/CP/SMT/ASP maintain and update a more-or-less implicit representation of an underlying clause structure.\nThis is possible because if one partial assignment is known to be in the clause structure, then this implies that many other clauses are also present.\nFor instance, the SAT clause above also forbids any partial assignment that contains it as a subset, so clauses like $x_1 \\lor \\overline{x_2} \\lor x_3 \\lor x_4$ and $x_1 \\lor \\overline{x_2} \\lor x_3 \\lor \\overline{x_4} \\lor x_5$ are all in the clause structure of that instance.\nAn approximation of the clause structure is kept to narrow down the set of solutions, and to help determine whether this set is empty.\nDuring search some partial assignments may turn out not to be contained in any solution (even if they individually satisfy each of the constraints in the instance).\nThese are known as nogoods, a term introduced by  (\"Mr GNU\") Stallman and Sussman.\nA nogood clause is therefore in the clause structure and can be included in an approximation of the clause structure, as a compact representation of many clauses that can be pruned from the search for solutions.\nAdding nogoods to the approximate clause structure retains all the solutions, but better approximates those solutions.\nSo the approximate clause structure usually changes as search progresses.\nFurther, the way the problem is modelled in one of the combinatorial optimisation approaches affects the clause structure, often quite significantly.\nFor instance, propositional variables can represent intervals such as $x \\le 5$ or points such as $x = 5$.\nHence there isn't a single general clause structure but one associated with each choice of representation, depending on what the singletons (literals) of the clause structure represent.\nConstraint programming (CP) was traditionally an AI discipline, with a focus on scheduling, timetabling, and combinatorial problems, and therefore has a central role for variables that can take more than just two values (but usually only finitely many).\nCP has emphasised efficient search and, motivated by the traditional applications, has given a central role to the all-different (injectivity) constraint, but has also developed efficient propagators for many other kinds of constraints.\nThe formal definitions of CP have been around since at least Montanari's 1974 paper Networks of constraints, with precursors going back even earlier.\nThis weight of history may have contributed to CP lagging behind other approaches in raw performance over the last decade.\nCP classically maintains an approximation of the complement of the clause structure, via a set of active domains for the variables.\nThe aim is to eliminate values from the active domains, exploring the clause structure by trying to assign candidate values to variables and backtracking when necessary.\nSatisfiability modulo theories (SMT) came out of the verification community.\nEach theory in an SMT solver forms an implicit representation of potentially infinitely many SAT clauses.\nThe theories used with SMT and the constraints used in CP reflect their different historical applications.\nMost of the theories SMT considers have to do with integer-indexed arrays, real closed fields, linear orders, and suchlike; these arise from static analysis of programs (in computer aided verification) or when formalising mathematical proofs (in automated reasoning).\nIn contrast, in timetabling and scheduling the injectivity constraint is central, and although the standard SMTLIB language has had an injectivity constraint since its inception in 2003 (via the distinct symbol), until 2010 SMT solvers only implemented distinct via a naive algorithm.\nAt that stage the matching technique from the standard CP propagator for all-different was ported across, to great effect when applied to large lists of variables; see An Alldifferent constraint solver in SMT by Bankovi\u0107 and Mari\u0107, SMT 2010.\nMoreover, most CP propagators are designed for problems with finite domains, whereas standard SMT theories deal with infinite domains (integers, and more recently reals) out of the box.\nSMT uses a SAT instance as the approximation of the clause structure, extracting nogood clauses from the theories as appropriate.\nA nice overview is Satisfiability Modulo Theories: Introduction and Applications\nby De Moura and Bj\u00f8rner,\ndoi:10.1145/1995376.1995394.\nAnswer set programming (ASP) came out of logic programming.\nDue to its focus on solving the more general problem of finding a stable model, and also because it allows universal as well as existential quantification, ASP was for many years not competitive with CP or SMT.\nFormally, SAT is CSP on Boolean domains, but the focus in SAT on clause learning, good heuristics for conflict detection, and fast ways to backtrack are quite different to the traditional CSP focus on propagators, establishing consistency, and heuristics for variable ordering.\nSAT is usually extremely efficient, but for many problems huge effort is required to first express the problem as a SAT instance.\nUsing a higher level paradigm like CP can allow a more natural expression of the problem, and then either the CP instance can be translated into SAT by hand, or a tool can take care of the translation.\nA nice overview of the nuts and bolts of SAT is On Modern Clause-Learning Satisfiability Solvers by Pipatsrisawat and Darwiche, doi:10.1007/s10817-009-9156-3.\nNow let's move on from generalities to present day specifics.\nOver the last decade some people in CP have started to focus on lazy clause generation (LCG).\nThis is essentially a way to bolt CP propagators together using more flexible SMT-like techniques rather than the rather rigid active domains abstraction.\nThis is useful because there is a long history of published CP propagators to efficiently represent and solve many kinds of problems.\n(Of course, a similar effect would be achieved by concerted effort to implement new theories for SMT solvers.)\nLCG has performance that is often competitive with SMT, and for some problems it may be superior.\nA quick overview is Stuckey's CPAIOR 2010 paper Lazy Clause Generation: Combining the power of SAT and CP (and MIP?) solving, doi:10.1007/978-3-642-13520-0_3.\nIt is also worth reading the position paper of Garcia de la Banda, Stuckey, Van Hentenryck and Wallace, which paints a CP-centric vision of The Future of Optimization Technology, doi:10.1007/s10601-013-9149-z.\nAs far as I can tell, much of the focus of recent SMT research seems to have shifted to applications in formal methods and formalised mathematics.  An example is reconstructing proofs found by SMT solvers inside proof systems such as Isabelle/HOL, by building Isabelle/HOL tactics to reflect inference rules in SMT proof traces; see Fast LCF-Style Proof Reconstruction for Z3 by B\u00f6hmer and Weber at ITP 2010.\nThe top ASP solvers have over the last few years been developed to become competitive with CP, SMT and SAT-only solvers.\nI'm only vaguely familiar with the implementation details that have allowed solvers such as clasp to be competitive so cannot really compare these with SMT and CP, but clasp explicitly advertises its focus on learning nogoods.\nCutting across the traditional boundaries between these formalisms is translation from more abstract problem representations into lower level efficiently implementable formalisms.\nSeveral of the top ASP and CP solvers now explicitly translate their input into a SAT instance, which is then solved using an off-the-shelf SAT solver.\nIn CP, the Savile Row constraint modelling assistant uses compiler design techniques to translate problems expressed in the medium level language Essence' into a lower level formalism, suitable for input to CP solvers such as Minion or MiniZinc.\nSavile Row originally worked with a CP representation as the low-level formalism but introduced SAT as a target in version 1.6.2.\nMoreover, the even higher-level language Essence can now be automatically translated into Essence' by the Conjure tool.\nAt the same time, low level SAT-only solvers like Lingeling continue to be refined each year, most recently by alternating clause learning and in-processing phases; see the brief overview What's Hot in the SAT and ASP Competitions by Heule and Schaub in AAAI 2015.\nThe analogy with the history of programming languages therefore seems appropriate.\nSAT is becoming a kind of \"machine code\", targeting a low-level model of exploration of the clauses in the clause structure.\nThe abstract paradigms are becoming more like higher level computer languages, with their own distinct methodologies and applications they are good at addressing.\nFinally, the increasingly dense collection of links between these different layers is starting to resemble the compiler optimisation ecosystem.", "meta": {"post_id": 29406, "input_score": 33, "output_score": 54, "post_title": "Constraint satisfaction problem (CSP) vs. satisfiability modulo theory (SMT); with a coda on constraint programming"}}
{"input": "I've been trying to wrap my head around the what, why and how of $\\lambda$-calculus but I'm unable to come to grips with \"why does it work\"?\n\"Intuitively\" I get the computability model of Turing Machines (TM). But this $\\lambda$-abstraction just leaves me confounded. \nLet's assume, TMs don't exist - then how can one be \"intuitively\" convinced about $\\lambda$-calculus's ability to capture this notion of computability. How does having a bunch of functions for everything and their composobility imply computability? What am I missing here? I read Alonzo Church's paper on that but I'm still confused and looking for a more \"dummed down\" understanding of the same.", "output": "You're in good company. Kurt G\u00f6del criticized $\\lambda$-calculus (as well as his own theory of general recursive functions) as not being a satisfactory notion of computability on the grounds that it is not intuitive, or that it does not sufficiently explain what is going on. In contrast, he found Turing's analysis of computability and the ensuing notion of machine totally convincing. So, don't worry.\nOn the other hand, to get some idea on how a model of computability works, it's best to write some programs in it. But you do not have to do it in pure $\\lambda$-calculus, although it's fun (in the same sort of way that firewalking is). You can use a modern descendant of $\\lambda$-calculus, such as Haskell.", "meta": {"post_id": 29458, "input_score": 13, "output_score": 22, "post_title": "How exactly does lambda calculus capture the intuitive notion of computability?"}}
{"input": "I've been reading up on Intuitionistic Type Theory (ITT) and it does make sense. But what I'm struggling to understand is \"why\" was it created in the first place?\nIntuitionistic Logic (IL) and Simply-typed $\\lambda$-calculus (STLC) and type theory in general predates the very existence of Martin-L\u00f6f himself! It seems that one can do everything in STLC that is doable in ITT (I may be wrong, but at least it feels that way).  \nSo what was \"novel\" about ITT and how exactly did (or does) it advance the theory of computation? From what I understand, he introduced the notion of \"dependent types\", but it seems they were already there in STLC, in a way. Was his ITT an attempt at abstraction to understand the underlying principles of STLC and IL together? But didn't STLC already held do that? So, just why was ITT created in the first place? What is/was the point?\nHere's an excerpt from Wikipedia: But I still don't get the reason behind its creation that didn't already exist before.\n\nMartin-L\u00f6f's first draft article on type theory dates back to 1971.\n  This impredicative theory generalized Girard's System F. However, this\n  system turned out to be inconsistent due to Girard's paradox which was\n  discovered by Girard when studying System U, an inconsistent extension\n  of System F. This experience led Per Martin-L\u00f6f to develop the\n  philosophical foundations of type theory, his meaning explanation, a\n  form of proof-theoretic semantics, which justifies predicative type\n  theory as presented in his 1984 Bibliopolis book...\n\nIt seems from the excerpt that the reason was to develop the \"philosophical foundations of type theory\" - I thought this foundation already existed (or maybe I assumed it did). Was this the main reason then?", "output": "Very briefly: the simply-typed $\\lambda$-calculus does not have  dependent types. Dependent types were proposed by de Bruijn and Howard who wanted to extend the Curry-Howard correspondence from propositional to first-order logic. The key contribution of Martin-L\u00f6f's is a novel analysis of equality.\nThere are two main ways of giving Curry-Howard style account of equality. \n\nUsing Leibniz's rule of the identity of indiscernibles to encode propositional equality . This approach is used in the calculus of constructions, but it requires impredicative universes which were rejected by Martin-L\u00f6f for philosophical reasons.\nA direct constructive characterisation of equality. Giving such a characterisation using identity types might be the main novelty of Martin-L\u00f6f's intuitionistic type theory.\n\nIdentity types appear deceptively simple today, but they refocussed the understanding of type-theory partly because they gave rise to intriguing semantical questions such as: are identity proofs unique? In some sense this question lead to homotopy type theory and the univalence axiom (which is incompatible with the uniqueness of identities). That the uniqueness of identity proofs is not derivable in Martin-L\u00f6f's intuitionistic type theory was shown \nby Hofmann and Streicher in: \"The groupoid interpretation of type theory\". Incidentally, this result also shows that pattern matching is not a conservative extension of traditional type theory.", "meta": {"post_id": 30651, "input_score": 14, "output_score": 24, "post_title": "Why was there a need for Martin-L\u00f6f to create intuitionistic type theory?"}}
{"input": "After reading the literature on type theory (especially the constructive kind - CTT) I'm left wondering \"why\" should one study type theory, specifically within the confines of \"computing\" in general?\nI understand how type systems (loosely speaking) were created to avoid various paradoxes and the correspondence between philosophy, logic, lambda-calculus and the how it comes together for CTT to serve as a foundation of mathematics. Fair enough.\nNow, functional programming (FP) languages like Haskell, Scala that can be used in large projects are based on an inconsistent logic - making any kind of (automated) formal reasoning about them nearly impossible - but that seems to be the very need/power of TT! E.g., theorem proving and proof assistants and the notion of programs as proofs. But none of this carries over to FP languages.\nSo my question is trying to understand the bigger role i.e., interplay of TT and computing taken together. Most FP languages have just \"good enough\" type systems (e.g., Haskell > Java). The problem of \"type inference\" is in some way similar to \"logical inference\" and doesn't seem all that complicated for simple types. I'm guessing things become undecidable after a particular threshold. Fair enough. I understand its need till this level. But is that it? It seems one can understand type systems/inference without really diving into the details of TT per se. \nSince FP languages don't really borrow much from TT other than \"type systems/inference\", why bother studying the theory in depth especially within computation theory? It seems that after studying a good deal of TT, for fun, I'm still left wondering \"what did I gain\" - both as a theoretician and a software practitioner? What \"is\" the aha understanding that one gains at a deeper level - since very little of TT's power/awesomeness actually gets carried over to commercially viable FP languages (and not Agda, Epigram etc.,)?\n(PS: Here's a similar question on Math.SE- but that's from a mathematical POV and I get that from that perspective. I'm struggling to see TT's importance when concerned about computing and software engineering in general)", "output": "Type theories in which every type is inhabited are far from being useless. True enough, through the eyes of logic they are inconsistent, but there are other things in life apart from logic.\nA general purpose programming language has general recursion. This allows it to populate every type, but we would not conclude from this fact that programming is a useless exercise, would we?\nIn the theory of programming languages types are used as a safety feature (\"A well typed program does not go wrong\" sad a famous man), as an organizational device, and a tool for program analysis. None of these purposes requires that there be an empty type.\nType inference is only one aspect in which type theory relates to programming languages. Some other uses of types in programming languages are:\n\nSpecification: before the programmer starts writing code they writes down the type of the program he is after. They specify (although usually not fully) what they wants. This is also useful for communication between programmers.\n\nModularization: when several pieces of software need to be assembled together we have to make sure they fit. One way of doing this is to speficy the interfaces through which the pieces connect. This can be done with types.\n\n\nDependent types appear in programming languages, but in limited form (because general dependent types cannot be handled automatically by the compiler). For instance, an ML-style module is a dependent sum, while a polymorphic type can be seen as a dependent product.\nYou ask what is gained by studying type theory? Clarity of mind where there was only Visual Basic before. Ability to write 30000 lines of code without making it look like the Flyng Spaghetti Monster. Inner peace and feeling of superiority over the unfortunate users of Lisp.", "meta": {"post_id": 30769, "input_score": 11, "output_score": 21, "post_title": "Why study type theory?"}}
{"input": "Counting triangles in general graphs can be done trivially in $O(n^3)$ time and I think that doing much faster is hard (references welcome). What about planar graphs? The following straightforward procedure shows that it can be done in $O(n\\log{n})$ time. My question is two-fold:\n\nWhat is a reference for this procedure?\nCan the time be made linear?\n\nFrom the algorithmic proof of Lipton-Tarjan's planar separator theorem we can, in time linear in the size of the graph, find a partition of vertices of the graph into three sets $A,B,S$ such that there are no edges with one endpoint in $A$ and the other in $B$, $S$ has size bounded by $O(\\sqrt{n})$ and both $A,B$ have sizes upper bounded by $\\frac{2}{3}$ of the number of vertices. Notice that any triangle in the graph either lies entirely inside $A$ or entirely inside $B$ or uses at least one vertex of $S$ with the other two vertices from $A \\cup S$ or both from $B \\cup S$. Thus it suffices to count the number of triangles in the graph on $S$ and the neighbours of $S$ in $A$ (and similarly for $B$). Notice that $S$ and its $A$-neighbours induce a $k$-outer planar graph (the said graph is a subgraph of a planar graph of diameter $4$). Thus counting the number of triangles in such a graph can be done directly by dynamic programming or by an application of Courcelle's theorem (I know for sure that such a counting version exists in the Logspace world by Elberfeld et al and am guessing that it also exists in the linear time world) since forming an undirected triangle is an $\\mathsf{MSO}_1$ property and since a bounded width tree decomposition is easy to obtain from an embedded $k$-outer planar graph.\nThus we have reduced the problem to a pair of problems which are each a constant fraction smaller at the expense of a linear time procedure. \nNotice that the procedure can be extended to find the count of the number of instances of any fixed connected graph inside an input graph in $O(n\\log{n})$ time.", "output": "The number of occurrences of any fixed subgraph H in a planar graph G can be counted in O(n) time, even if H is disconnected. This, and several related results, are described in the paper Subgraph Isomorphism in Planar Graphs and Related Problems by David Eppstein of 1999; see Theorem 1. The paper indeed uses treewidth techniques.", "meta": {"post_id": 30820, "input_score": 18, "output_score": 22, "post_title": "Time complexity of counting triangles in planar graphs"}}
{"input": "Imagine, we defined natural numbers in dependently typed lambda calculus as Church numerals. They might be defined in the following way:\nSimpleNat = (R : Set) \u2192 R \u2192 (R \u2192 R) \u2192 R\n\nzero : SimpleNat\nzero = \u03bb R z _ \u2192 z\n\nsuc : SimpleNat \u2192 SimpleNat\nsuc sn = \u03bb R z s \u2192 s (sn R z s)\n\nSimpleNatRec : (R : Set) \u2192 R \u2192 (R \u2192 R) \u2192 SimpleNat \u2192 R\nSimpleNatRec R z s sn = sn R z s\n\nHowever, it seems that we can't define Church numerals with the following type of Induction principle:\nNatInd : (C : Nat -> Set) -> (C zero) -> ((n : Nat) -> C n -> C (suc n)) -> (n : Nat) -> (C n)\n\nWhy is it so? How can I prove this? It seems that the problem is with defining a type for Nat which becomes recursive. Is it possible to amend lambda calculus to allow this?", "output": "The question you are asking is interesting and known. You are using the so-called impredicative encoding of the natural numbers. Let me explain a bit of the background.\nGiven a type constructor $T : \\mathsf{Type} \\to \\mathsf{Type}$, we might be interested in the \"minimal\" type $A$ satisfying $A \\cong T(A)$. In terms of category theory $T$ is a functor and $A$ is the initial $T$-algebra. For example, if $T(X) = 1 + X$ then $A$ corresponds to the natural numbers. If $T(X) = 1 + X \\times X$ then $A$ is the type of finite binary trees.\nAn idea with long history is that the initial $T$-algebra is the type\n$$A \\mathrel{{:}{=}} \\prod_{X : \\mathsf{Type}} (T(X) \\to X) \\to X.$$\n(You are using Agda notation for dependent products, but I am using a more traditional mathematical notation.) Why should this be? Well, $A$ essentially encodes the recursion principle for the initial $T$-algebra: given any $T$-algebra $Y$ with a structure morphism $f : T(Y) \\to Y$, we get an algebra homomorphism $\\phi : A \\to Y$ by\n$$\\phi(a) = a \\, Y \\, f.$$\nSo we see that $A$ is weakly initial for sure. For it to be initial we would have to know that $\\phi$ is unique as well. This is not true without further assumptions, but the details are technical and nasty and require reading some background material. For instance, if we can show a satisfactory parametricty theorem then we win, but there are also other methods (such as massaging the definition of $A$ and assuming the $K$-axiom and function extensionality).\nLet us apply the above to $T(X) = 1 + X$:\n$$\\mathsf{Nat} =\n  \\prod_{X : \\mathsf{Type}} ((1 + X) \\to X) \\to X =\n  \\prod_{X : \\mathsf{Type}} (X \\times (X \\to X)) \\to X = \\\\\n  \\prod_{X : \\mathsf{Type}} X \\to (X \\to X) \\to X.\n$$\nWe got Church numerals! And we also understand now that we will get a recursion principle for free, because the Church numerals are the recursion principle for numbers, but we will not get induction without parametricity or a similar device.\nThe tehcnical answer to your question is this: there exist models of type theory in which the type SimpleNat contains exotic elements that do not correspond to numerals, and moreover, these elements break the induction principle. The type SimpleNat in these models is too big and is only a weak initial algebra.", "meta": {"post_id": 30923, "input_score": 21, "output_score": 24, "post_title": "Why it's impossible to declare an induction principle for Church numerals"}}
{"input": "Wikipedia listed four problems that are in $BQP$ but conjectured to be outside $P$: Integer factorization; Discrete logarithm; Simulation of quantum systems; Computing the Jones polynomial at certain roots of unity.\nAre there any other such problems?", "output": "To have a list of such problems, you can look at the list of superpolynomial speed improvement at the quantum algorithm zoo (QAZ). The list below is based on  this (see QAZ for precise definitions and references. This is another way to say I don\u2019t even pretend to understand many of the problems of this list!)\nAlgebraic and Number Theoretic Problems\nIf I\u2019m not mistaken, all problems listed before the Abelian hidden subgroup problem are special cases of it.\n\nFactorization\nDiscrete logarithm\nPell\u2019s Equation. Factoring reduces to Pell\u2019s equation.\nPrincipal Ideal Ideal problem. Pell\u2019s equation reduces to this problem, which therefore at least as hard as factoring.\nUnit Group problem\nClass Group problem\nGau\u00df Sums estimation\nMatrix Elements of Group Representations\nGroup Order and Membership\nThe Abelian hidden subgroup problem\nSome (but not all) non-Abelian hidden subgroup problems\nSome (but not all) problems phrased as special cases of the hidden shift problem\nSome (but not all) Hidden Nonlinear Structures problems\nExploring some graphs (Welded trees)\nGroup Isomorphism, for Abelian and some non-Abelian groups\nFind some properties of Finite Rings and Ideals\n\nApproximation and Simulation\n\nQuantum simulation. Obviously $BQP$-complete\nComputing some knot-invariants, including HOMFLY polynomial, of which the Jones polynomial is a special case. Some of them are $BQP$-complete\nComputing some Three-manifold Invariants. Some of them are $BQP$-complete.\nEstimating the thermodynamic partition function of some classical systems\nComputing Zeta Functions over finite fields\nA string rewriting problem is  $\\mathit{PromiseBQP}$-complete\napproximating matrix elements of powers of exponentially large sparse matrices.\n\nAlgorithm I don\u2019t really  get.\nThese are mainly algorithms where QAZ claims a superpolynomial increase, but I don\u2019t get why the original problem is supposed to be out of $P$. That said, I\u2019ll bet lots of my money on QAZ being right and myself being wrong on that.\n\nPattern matching for large enough ($>\\log(n)$) patterns\nSome linear system problems, in $P$ but having a $\\mathrm{polylog}$ quantum algorithm if the linear system is given as an oracle.\nComputing the Electrical Resistance of a graph,has a $\\mathrm{polylog}$ quantum algorithm if the electric circuit is given as an oracle\nWeight Enumerators problem. Something related to code and partition functions, but I don\u2019t understand what it is about.\n\n$P$ problems 1st proved to be in $BQP$ and then in $P$\nHere are some problems where an efficient quantum algorithm has been published before a classical one. In other words, they were once conjectured to be in $BQP$ but not in $P$, but this conjecture is now invalidated.\n\nSatisfying more than $(\\tfrac12-\\tfrac{\\text{constant}}{D})N$ (but less than $\\left(\\tfrac12-\\tfrac{1}{22D^{3/4}}\\right)N$) constraints of the  Max E3LIN2 problem. As pointed by Juan Berego Vega in the comments : there is now a classical algorithm for $(\\tfrac12-\\tfrac{\\text{constant}}{\\sqrt{D}})N$, which was motivated by the quantum result. (Blog post on this result, paper 1, paper2)\nRecommendation systems (see Scott Aaronson\u2019s blog post  for a more detailed explanation). Recommendation system \u2014 \u00e0 la Netflix/Amazon/etc.\u2014 can be seen as completing a sparse $m\u00d7n$ matrix of low rank $k$ with very incomplete data. Known classical algorithm where polynomial in $m$, $n$ ad $k$. If the matrix is given as an oracle, Iordanis Kerenidis an Anupam Prakash found a $\\mathrm{poly}(k)\\mathrm{polylog}(mn)$ quantum algorithm finding samples of the unknown elements of the matrix in 2016 (paper). In 2018, while trying to prove this scaling is impossible to reach with a classical machine, Ewin Tang actually found a classical algorithm achieving the same performance under the same conditions (paper available here and here).", "meta": {"post_id": 31139, "input_score": 21, "output_score": 23, "post_title": "Problems in BQP but conjectured to be outside P"}}
{"input": "This question was previously posted to Computer Science Stack Exchange here.\n\nImagine you're a very successful travelling salesman with clients all over the country. To speed up shipping, you've developed a fleet of disposable delivery drones, each with an effective range of 50 kilometers. With this innovation, instead of travelling to each city to deliver your goods, you only need to fly your helicopter within 50km and let the drones finish the job.\nProblem: How should your fly your helicopter to minimize travel distance?\nMore precisely, given a real number $R>0$ and $N$ distinct points $\\{p_1, p_2, \\ldots, p_N\\}$ in the Euclidean plane, which path intersecting a closed disk of radius $R$ about each point minimizes total arc length? The path need not be closed and may intersect the disks in any order.\nClearly this problem reduces to TSP as $R \\to 0$, so I don't expect to find an efficient exact algorithm. I would be satisfied to know what this problem is called in the literature and if efficient approximation algorithms are known.", "output": "This is a special case of the Travelling Salesman with Neighborhoods (TSPN) problem. In the general version, the neighborhoods need not all be the same.\nA paper by Dumitrescu and Mitchell, Approximation algorithms for TSP with neighborhoods in the plane, addresses your question. They give a constant factor approximation algorithm for a slightly more general problem (case 1), and a PTAS when the neighborhoods are disjoint balls of the same size (case 2).\nAs a side comment, I think Mitchell has done a lot of work on geometric TSP variants, so you might want to look at his other papers.", "meta": {"post_id": 31511, "input_score": 15, "output_score": 22, "post_title": "What is known about this TSP variant?"}}
{"input": "Is Martin-L\u00f6f type theory basically the predicative Calculus of inductive Constructions without impredicative $\\mathtt{Prop}$?\nIf they're closely related but with more differences than just $\\mathtt{Prop}$, what are those differences?", "output": "The short answer is yes, MLTT can reasonably be equated with CIC without impredicative Prop.\nThe main technical issue is that there are dozens of variants when one talks about Martin-L\u00f6f Type Theory and, perhaps more surprisingly, when one talks about CIC. For example, taking the version of CIC defined in Benjamin Werner's thesis, it doesn't even make sense to remove Prop, as one doesn't have either Set or universes of Type.\nThe main variations one can consider in either of these theories are:\n\nUniverses: how many, and how are they defined (Palmgren, On Universes in Type Theory, discusses many inequivalent variations), and whether or not universe polymorphism is admitted.\nWhich inductive types/families: Agda admits Inductive-Recursive types, but there are many more mundane variations depending on how \"large\" the types in the constructors and eliminators are allowed, handling parameters vs indices, etc.\nInjectivity of type constructors. This leads to a system inconsistent with EM in Agda. Of course Epigram has a more extreme \"Observational Type Theory\", but this can be considered something different altogether.\nAxiom K: this comes for free with certain versions of dependent pattern matching.\nIntentional vs Extensional: this is a huge difference, where essentially a new conversion rule is added in the extensional systems\n$$ \\frac{\\Gamma\\vdash t:\\mathrm{Id}_{\\mathrm{Type}}\\ A\\ B }{\\Gamma\\vdash A\\ =\\ B} $$\nWhich makes type-checking undecidable (but much more powerful!). Martin-L\u00f6f himself seems to have considered both types of systems.\nThe presence of coinductive types and associated elimination principles.\n\nAll of the above variations (except OTT) have been considered in the literature and associated with the name \"Martin-L\u00f6f Type Theory\" or \"Calculus of Inductive Constructions\", mostly because of their association with the Agda and Coq systems, respectively.\nSo the long answer is that there is no consensus about what the exact definition of either of these systems is.", "meta": {"post_id": 32071, "input_score": 15, "output_score": 23, "post_title": "Is MLTT effectively pCiC without Prop?"}}
{"input": "At http://www.dharwadker.org/tevet/isomorphism/, there is a presentation of an algorithm for determining if two graphs are isomorphic. Given a number of shall we say, \"interesting\" claims by A Dharwadker, I am not inclined to believe it.\nIn my investigation, I find that the algorithm will definitely produce the correct answer and tell you that two graphs are not isomorphic when in fact that is correct. However, it is not clear that the algorithm will consistently tell you if two graphs are isomorphic when they actually are. The \"proof\" of their result leaves something to be desired.\nHowever, I am not aware of a counter-example. Before I start writing software to test out the algorithm, I thought I would see if anyone was already aware of a counter-example.\nSomeone requested a synopsis of the algorithm. I will do what I can here, but to really understand it, you should visit http://www.dharwadker.org/tevet/isomorphism/.\nThere are two phases to the algorithm: A \"signature\" phase and a sorting phase. The first \"signature\" phase (this is my term for their process; they call it generating the \"sign matrix\") effectively sorts vertices into different equivalence classes. The second phase first orders vertices according to their equivalence class, and then applies a sort procedure within equivalence classes to establish an isomorphism between the two graphs. Interestingly, they do not claim to establish a canonical form for the graphs - instead, one graph is used as a kind of template for the second.\nThe signature phase is actually quite interesting, and I would not do it justice here by attempting to paraphrase it. If you want further details, I recommend following the link to examine his signature phase. The generated \"sign matrix\" certainly retains all information about the original graph and then establishes a bit more information. After collecting the signatures, they ignore the original matrix since the signatures contain the entire information about the original matrix. Suffice to say that the signature performs some operation that applies to each edge related to the vertex and then they collects the multiset of elements for a vertex to establish an equivalence class for the vertex.\nThe second phase - the sort phase - is the part that is dubious. In particular, I would expect that if their process worked, then the algorithm developed by Anna Lubiw for providing a \"Doubly Lexical Ordering of Matrices\" (See: http://dl.acm.org/citation.cfm?id=22189) would also work to define a canonical form for a graph.\nTo be fair, I do not entirely understand their sort process, though I think they do a reasonable job of describing it. (I just have not worked through all the details). In other words, I may be missing something. However, it is unclear how this process can do much more than accidentally find an isomorphism. Sure, they will probably find it with high probability, but not with a guarantee. If the two graphs are non-isomorphic, the sort process will never find it, and the process correctly rejects the graphs.", "output": "For graphA.txt:\n25\n 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0\n 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0\n 1 1 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0\n 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1\n 1 0 0 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1\n 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 0\n 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 1\n 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 0\n 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0\n 1 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1\n 0 1 0 1 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1\n 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0\n 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1\n 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1\n 0 1 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0\n 0 1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0\n 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0\n 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1\n 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 1 0\n 0 0 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1\n 0 0 1 0 1 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 1\n 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0\n\nand graphB.txt:\n25\n 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0\n 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1\n 0 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0\n 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0\n 1 1 0 1 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1 0\n 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 1\n 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0\n 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 0 1\n 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 1\n 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 1\n 1 0 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 1 1 1 0\n 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1\n 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 0 0 1\n 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 0\n 0 1 0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 0\n 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 1\n 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0\n 1 0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 1 0\n 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0\n 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1\n 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 1\n 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1\n 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1\n 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 0\n 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 0 0\n\nwhich is obtained from graphA.txt by applying the (random) permutation\n 22 9 24 11 15 8 5 18 13 14 2 10 23 0 3 17 4 16 6 19 7 21 12 1 20\n\nthe C++ program isororphism.cpp from Figure 6.3. A C++ program for the graph isomorphism algorithm in http://www.dharwadker.org/tevet/isomorphism/ delivers the following output:\nThe Graph Isomorphism Algorithm\nby Ashay Dharwadker and John-Tagore Tevet\nhttp://www.dharwadker.org/tevet/isomorphism/\nCopyright (c) 2009\nComputing the Sign Matrix of Graph A...\nComputing the Sign Matrix of Graph B...\nGraph A and Graph B have the same sign frequency vectors in lexicographic order but cannot be isomorphic.\nSee result.txt for details.\n\nSo we may assume that this is a counter-example to the Dharwadker-Tevet Graph Isomorphism algorithm.\nAs suggested by Bill Province, the problem is\n\n4.1. Proposition. If graphs $G_A$ and $G_B$ are isomorphic, then the algorithm finds an isomorphism.\n\nBill Province's objection is that the proof of Proposition 4.1. doesn't use any special property of the sign matrix that wouldn't also apply to the adjacency matrix. More precisely, the following step in the proof is wrong:\n\nFor the induction hypothesis, assume that rows $1, ..., t$ of $A$ and $B$ have been perfectly matched by Procedure 3.4 such that the vertex labels for the rows $1, ..., t$ of $A$ are $v_1, ..., v_t$ and the vertex labels for the rows $1, ..., t$ of $B$ are $\u03c6(v_1) = v'_1, ..., \u03c6(v_t) = v'_t$ respectively.\n\nbecause even if the rows have been perfectly matched, it doesn't follow that the vertex labels match the labels given by any isomorphism $\u03c6$.\nBecause a hole in the correctness proof was identified, the above counter-example should be sufficient for refuting claimed correctness of the proposed algorithm.\n\nAcknowledgments\nThe counter-example is the first of the 8th graph pairs from\n\nhttp://funkybee.narod.ru/graphs.htm\n\nTo manipulate graphs, I used and modified source code from ScrewBoxR1160.tar found at\n\nhttps://people.mpi-inf.mpg.de/~pascal/software/\n\nTo understand the hole in the correctness proof, Andr\u00e1s Salamon comment about Weisfeiler-Lehman was very helpful, as were the explanations from\n\nhttp://users.cecs.anu.edu.au/~pascal/docs/thesis_pascal_schweitzer.pdf\n\nMotivation to use this question as an opportunity to get familiar with nauty/Traces and the practical aspects of graph isomorphism was provided by vzn. The benefit of learning how to use state of the art programs for graph isomorphisms made it worthwhile to sink some time for finding a counter-example (which I strongly believed to exist).", "meta": {"post_id": 32237, "input_score": 13, "output_score": 23, "post_title": "Is anyone aware of a counter-example to the Dharwadker-Tevet Graph Isomorphism algorithm?"}}
{"input": "I have two historical questions:\n\nWho first described nondeterministic computation?\n\nI know that Cook described NP-complete problems, and \nthat Edmonds proposed that P algorithms are \"efficient\" or \"good\" algorithms.  \nI searched this Wikipedia article and \nskimmed \"On the Computational Complexity of Algorithms,\" \nbut couldn't find any reference to when nondeterministic computation was first discussed.\n\nWhat was the first reference to the class NP? Was it Cook's 1971 paper?", "output": "I have always seen the notion of nondeterminism in computation attributed to Michael Rabin and Dana Scott. They defined nondeterministic finite automata in their famous paper Finite Automata and Their Decision Problems, 1959. Rabin's Turing Award citation also suggests that Rabin and Scott introduced nondeterministic machines.", "meta": {"post_id": 32403, "input_score": 20, "output_score": 30, "post_title": "Who introduced nondeterministic computation?"}}
{"input": "I know that it is undecidable to determine if a set of tiles can tile the plane,\na result of Berger using Wang tiles.\nMy question is whether it is also known to be undecidable to determine\nif a single given tile can tile the plane, a monohedral tiling.\nIf this remains unsettled, I would be interested to know what is the minimum\ncardinality of a set of tiles for which there is an undecidability proof.\n(I have not yet accessed Berger's proof.)", "output": "According to the introduction of [1],\n\nThe complexity of determining if a single polyomino tiles the plane remains open [2,3], and\nThere is an undecidability proof for sets of 5 polyominoes [4].\n\n[1] Stefan Langerman, Andrew Winslow. A Quasilinear-Time Algorithm for Tiling the Plane Isohedrally with a Polyomino. ArXiv e-prints, 2015. arXiv:1507.02762 [cs.CG]\n[2] C. Goodman-Strauss. Open questions in tiling. Online, published 2000.\n[3] C. Goodman-Strauss. Can\u2019t decide? undecide! Notices of the American\nMathematical Society, 57(3):343\u2013356, 2010.\n[4] N. Ollinger. Tiling the plane with a fixed number of polyominoes. In\nA. H. Dediu, A. M. Ionescu, and C. Mart\u00b4\u0131n-Vide, editors, LATA 2009,\nvolume 5457 of LNCS, pages 638\u2013647. Springer, 2009.", "meta": {"post_id": 32538, "input_score": 25, "output_score": 23, "post_title": "Is it decidable to determine if a given shape can tile the plane?"}}
{"input": "Is there any natural problem in P for which the best known running time bound is of the form $O(n^\\alpha)$, where $\\alpha$ is an irrational constant?", "output": "While admittedly I haven't done the analysis, and this is not strictly a decision problem, I am willing to wager the best known matrix multiplication algorithms (by Coppersmith, Winograd, Stothers, Williams, et al) have irrational exponent. \nThis can be seen more clearly in the simple case of Strassen's algorithm, which has running time $O(n^{\\log_2 7})$.\nAnd, this is not precisely what you asked, but Ryan Williams has shown that all algorithms that solve SAT in space $n^{o(1)}$ require time $n^{2 \\cos(\\pi/7) - o(1)}$, which is another interesting and unusual appearance of an irrational constant in TCS.", "meta": {"post_id": 32632, "input_score": 19, "output_score": 21, "post_title": "Time complexity with irrational exponent?"}}
{"input": "In the official Clay problem description for P versus NP it's stated that $P \\neq NP$ would follow from showing that \"every language in $E$ [the class of languages recognizable in exponential time with a deterministic Turing machine] can be computed by a Boolean circuit family $<B_n>$ such that for at least one $n$, $B_n$ has fewer gates than the maximum needed to\ncompute any Boolean function $f: \\{0,1\\}^n \\longrightarrow \\{0,1\\}$.\" However, the only reference is that this \"is an intriguing observation by V. Kabanets.\" Could someone please point me to a published version of this implication with the proof?", "output": "I don't think the paper in the other answer contains an answer to your question. Indeed I am not really sure a proof has been published, because the result follows from other well known results. \nThe proof of the statement you want is as follows: \n\n$\\Sigma_3 E$ contains a function of maximum possible circuit complexity on every input length, by simply defining a function which proves itself (using alternation) to be different from all functions with non-maximum circuit complexity. This is standard and the proof idea can be found in sources such as Arora and Barak's textbook.\nIf $P = NP$ then $\\Sigma_3 E = E$, by padding and the collapse of the polynomial time hierarchy to $P $.\nTherefore if $P = NP$ then there is a language in $E$ with maximum circuit complexity. This is the contrapositive of what you want to prove.", "meta": {"post_id": 32829, "input_score": 18, "output_score": 25, "post_title": "Proof that circuit upper bounds for $E$ imply $P \\neq NP$"}}
{"input": "The $k$-cycle problem is as follows:\nInstance: An undirected graph $G$ with $n$ vertices and up to $n \\choose 2$ edges.\nQuestion: Does there exist a (proper) $k$-cycle in $G$?\nBackground: For any fixed $k$, we can solve $2k$-cycle in $O(n^2)$ time.\n\nRaphael Yuster, Uri Zwick: Finding Even Cycles Even Faster. SIAM J.  Discrete Math. 10(2): 209-222 (1997)\n\nHowever, it is not known if we can solve 3-cycle (i.e. 3-clique) in less than matrix multiplication time.\nMy Question: Assuming that $G$ contains no 4-cycles, can we solve the 3-cycle problem in $O(n^2)$ time?\nDavid suggested an approach for solving this variant of the 3-cycle problem in $O(n^{2.111})$ time.", "output": "Yes, this is known. It appears in one of the must-cite references on triangle finding...\nNamely, Itai and Rodeh show in SICOMP 1978 how to find, in $O(n^2)$ time, a cycle in a graph that has at most one more edge than the minimum length cycle. (See the first three sentences of the abstract here: http://www.cs.technion.ac.il/~itai/publications/Algorithms/min-circuit.pdf) It is a simple procedure based on properties of breadth-first search.\nSo, if your graph is 4-cycle free and there is a triangle, their algorithm must output it, because it cannot output a 5-cycle or larger.", "meta": {"post_id": 33005, "input_score": 15, "output_score": 29, "post_title": "Given a 4-cycle free graph $G$, can we determine if it has a 3-cycle in quadratic time?"}}
{"input": "According to this paper, which discusses a nondeterministic extension of the Strong Exponential Time Hypothesis (SETH), \"[\u2026] Williams has recently shown related hypotheses about Merlin-Arthur complexity of k-TAUT are false\". However, that paper only cites a personal communication.\nHow is the MA version of SETH proven to be false?\nI suspect that it involves algebrizing the formula, but do not have any further idea.", "output": "You can find a preprint by following this link http://eccc.hpi-web.de/report/2016/002/\nEDIT (1/24) By request, here is a quick summary, taken from the paper itself, but glossing over many things. Suppose Merlin can prove to Arthur that for a $k$-variable arithmetic circuit $C$, its value on all points in $\\{0,1\\}^k$ is a certain table of $2^k$ field elements, in time about $(s + 2^k) \\cdot d$, where $s$ is the size of $C$ and $d$ is the degree of the polynomial computed by $C$. (We call this a \"short non-interactive proof of batch evaluation\" --- evaluating $C$ on many assignments.)\nThen Merlin can solve $\\#$SAT for Arthur as follows. Given a CNF $F$ on $n$ variables and $m$ clauses, Merlin and Arthur first construct an arithmetic circuit $C$ on $n/2$ variables of degree at most $mn$, size about $mn \\cdot 2^{n/2}$, which takes a sum over all assignments to the first $n/2$ variables of the CNF $F$ (adding a $1$ to the sum when $F$ is true, and $0$ when it's false). Using the batch evaluation protocol, Merlin can then prove that $C$ takes on $2^{n/2}$ particular values on all its $2^{n/2}$ Boolean assignments, in about $2^{n/2} poly(n,m)$ time. Summing up all those values, we get the count of the SAT assignments to $F$.\nNow we say at a high level how to do the batch evaluation protocol. We want the proof to be a succinct representation of the circuit $C$ that is both easy to evaluate on all of the $2^k$ given inputs, and also easy to verify with randomness. We set the proof to be a univariate polynomial $Q(x)$ defined over a sufficiently large extension field of the base field $K$ (of characteristic at least $2^n$ for our application), where $Q(x)$ has degree about $2^k \\cdot d$, and $Q$ ``sketches'' the evaluation of the degree-$d$ arithmetic circuit $C$ over all $2^k$ assignments. The polynomial $Q$ satisfies two conflicting conditions: \n\nThe verifier can use the sketch $Q$ to efficiently produce the truth table of $C$. In particular, for some explicitly known $\\alpha_i$ from the extension of $K$, we want $(Q(\\alpha_0), Q(\\alpha_1),\\ldots,Q(\\alpha_K)) = (C(a_1),\\ldots,C(a_{2^K}))$, where $a_i$ is the $i$th Boolean assignment to the $k$ variables of $C$ (under some ordering on assignments). \nThe verifier can check that $Q$ is a faithful representation of $C$'s behavior on all $2^k$ Boolean assignments, in about $2^k + s$ time, with randomness. This basically becomes a univariate polynomial identity test.\n\nThe construction of $Q$ uses an interpolation trick originating from the holographic proofs, where multivariate expressions can be efficiently ``expressed'' as univariate ones. Both of the two items utilize fast algorithms for manipulating univariate polynomials.", "meta": {"post_id": 33037, "input_score": 14, "output_score": 22, "post_title": "How is the MA version of SETH proven to be false?"}}
{"input": "I'm a fourth year PhD student in theoretical computer science. I'd like to stay in academia, so I'm thinking about how best to advance my career. Obviously the best way to do that is write lots of good papers, but another question is whether I should be trying to have more of those papers be single author.\nSo far I only have one single author paper (out of six). It's neither my best work, nor very recent. Is that a red flag when applying for postdoc or faculty positions? Should I try to have more single author papers?\nThis comes down to my approach to research. I like talking to people. I like telling people what I'm working on and, if they are interested, I'm keen to work with them. In other words, I'm very open to collaboration even when it isn't strictly necessary. Should I change that? That is, should I try to keep projects to myself more so that I end up with some single author papers?\nApologies if this question is off topic. I want to ask this question to people in my area, rather than on a general forum like academia.se. In particular, on all my papers, authors are ordered alphabetically. This makes single author papers a more important signal in TCS than in other areas, where author ordering conveys this information.", "output": "In some fields (like e.g. Economics and Mathematics) single authored papers -are- a good thing to have when you go on the job market. In theoretical computer science, collaboration is much more common, and it is not unusual for even relatively senior researchers to have very few single authored papers. It is not at all suspicious if a student on the market has only papers with co-authors. This is partly because we publish more frequently, so it is ok that each individual paper has less signal about your specific contribution. This is not to say that single authored papers are not impressive, but credit is super-additive across authors, and all things being equal, you should prefer to have a better paper with more coauthors than a worse paper with fewer. This should push you towards collaboration, since collaborators make your research both more fun and generally stronger. \nOf course in hiring decisions, committees will attempt to figure out whether you were a significant contributor to the papers you worked on or not -- but this will be done largely through the letters you obtain. If you have several good papers with the same senior co-author, that coauthor should write a letter for you, since they can explain in detail your contribution. It also helps if you have a clear research agenda of your own. Many papers on -your- topic with a rotating cast of coauthors conveys that you are leading the research direction, in contrast to a series of papers on disparate topics, each in the research agenda of your various coauthors.", "meta": {"post_id": 33074, "input_score": 40, "output_score": 23, "post_title": "Importance of single author papers?"}}
{"input": "The CoC is said to be the culmination of all three dimensions of the Lambda Cube. This isn't apparent to me at all. I think I understand the individual dimensions, and the combination of any two seems to result in a relatively straightforward union (maybe I'm missing something?). But when I look at the CoC, instead of looking like a combination of all three, it looks like a completely different thing. Which dimension do Type, Prop, and small/large types come from? Where did dependent products disappear to? And why is there a focus on propositions and proofs instead of types and programs? Is there something equivalent that does focus on types and programs?\nEdit: In case it isn't clear, I'm asking for an explanation of how the CoC is equivalent to the straightforward union of the Lambda Cube dimensions. And is there an actual union of all three out there somewhere I can study (that is in terms of programs and types, not proofs and propositions)? This is in response to comments on the question, not to any current answers.", "output": "First, to reiterate one of cody's points, the Calculus of Inductive Constructions (which Coq's kernel is\nbased on) is very different from the Calculus of Constructions. It is\nbest thought of as starting at Martin-Lo\u0308f type theory with universes,\nand then adding a sort Prop at the bottom of the type hierarchy.  This \nis a very different beast than the original CoC, which is\nbest thought of as a dependent version of F-omega. (For instance, CiC \nhas set-theoretic models and the CoC doesn't.) \nThat said, the lambda-cube (of which the CoC is a member) is typically presented as a pure type system for reasons of economy in the number of typing rules. By treating sorts, types, and terms as elements of the same syntactic category, you can write down many fewer rules and your proofs get quite a bit less redundant as well. \nHowever, for understanding, it can be helpful to separate out the different categories explicitly. We can introduce three syntactic categories, kinds (ranged over by the metavariable k), types (ranged over by the metavariable A), and terms (ranged over by the metavariable e). Then all eight systems can be understood as variations on what is permitted at each of the three levels.\n\u03bb\u2192 (Simply-typed lambda calculus)\n k ::= \u2217\n A ::= p | A \u2192 B\n e ::= x | \u03bbx:A.e | e e\n\nThis is the basic typed lambda calculus. There is a single kind \u2217, which is the kind of types. The types themselves are atomic types p and function types A \u2192 B. Terms are variables, abstractions or applications.\n\u03bb\u03c9_ (STLC + higher-kinded type operators)\n k ::= \u2217 | k \u2192 k\n A ::= a | p | A \u2192 B | \u03bba:k.A | A B\n e ::= x | \u03bbx:A.e | e e\n\nThe STLC only permits abstraction at the level of terms. If we add it at the level of types, then we add a new kind k \u2192 k which is the type of type-level functions, and abstraction \u03bba:k.A and application A B at the type level as well. So now we don't have polymorphism, but we do have type operators.\nIf memory serves, this system does not have any more computational power than the STLC; it just gives you the ability to abbreviate types.\n\u03bb2 (System F)\n k ::= \u2217\n A ::= a | p | A \u2192 B  | \u2200a:k. A \n e ::= x | \u03bbx:A.e | e e | \u039ba:k. e | e [A]\n\nInstead of adding type operators, we could have added polymorphism. At the type level, we add \u2200a:k. A which is a polymorphic type former, and at the term level, we add abstraction over types \u039ba:k. e and type application e [A].\nThis system is much more powerful than the STLC -- it is as strong as second-order arithmetic.\n\u03bb\u03c9 (System F-omega)\n k ::= \u2217 | k \u2192 k \n A ::= a | p | A \u2192 B  | \u2200a:k. A | \u03bba:k.A | A B\n e ::= x | \u03bbx:A.e | e e | \u039ba:k. e | e [A]\n\nIf we have both type operators and polymorphism, we get F-omega. This system is more or less the kernel type theory of most modern functional languages (like ML and Haskell). It is also vastly more powerful than System F -- it is equivalent in strength to higher order arithmetic.\n\u03bbP (LF)\n k ::= \u2217 | \u03a0x:A. k \n A ::= a | p | \u03a0x:A. B | \u039bx:A.B | A [e]\n e ::= x | \u03bbx:A.e | e e\n\nInstead of polymorphism, we could have gone in the direction of dependency from simply-typed lambda calculus. If you permitted the function type to let its argument be used in the return type (ie, write \u03a0x:A. B(x) instead of A \u2192 B), then you get \u03bbP. To make this really useful, we have to extend the set of kinds with a kind of type operators which take terms as arguments \u03a0x:A. k , and so we have to add a corresponding abstraction \u039bx:A.B and application A [e] at the type level as well. \nThis system is sometimes called LF, or the Edinburgh Logical Framework.\nIt has the same computational strength as the simply-typed lambda calculus.\n\u03bbP2 (no special name)\n k ::= \u2217 | \u03a0x:A. k \n A ::= a | p | \u03a0x:A. B | \u2200a:k.A | \u039bx:A.B | A [e]\n e ::= x | \u03bbx:A.e | e e | \u039ba:k. e | e [A]\n\nWe can also add polymorphism to \u03bbP, to get \u03bbP2. This system is not often used, so it doesn't have a particular name. (The one paper I've read which used it is Herman Geuvers' Induction is Not Derivable in Second Order Dependent Type Theory.)\nThis system has the same strength as System F.\n\u03bbP\u03c9_ (no special name)\n k ::= \u2217 | \u03a0x:A. k | \u03a0a:k. k'\n A ::= a | p | \u03a0x:A. B | \u039bx:A.B | A [e] | \u03bba:k.A | A B \n e ::= x | \u03bbx:A.e | e e \n\nWe could also add type operators to \u03bbP, to get \u03bbP\u03c9_. This involves adding a kind \u03a0a:k. k' for type operators, and corresponding type-level abstraction \u039bx:A.B and application A [e]. \nSince there's again no jump in computational strength over the STLC, this system should also make a fine basis for a logical framework, but no one has done it. \n\u03bbP\u03c9 (the Calculus of Constructions)\n k ::= \u2217 | \u03a0x:A. k | \u03a0a:k. k'\n A ::= a | p | \u03a0x:A. B | \u2200a:k.A | \u039bx:A.B | A [e] | \u03bba:k.A | A B \n e ::= x | \u03bbx:A.e | e e | \u039ba:k. e | e [A]\n\nFinally, we get to \u03bbP\u03c9, the Calculus of Constructions, by taking \u03bbP\u03c9_ and adding a polymorphic type former \u2200a:k.A and term-level abstraction \u039ba:k. e and application e [A] for it. \nThe types of this system are much more expressive than in F-omega, but it has the same computational strength.", "meta": {"post_id": 36054, "input_score": 25, "output_score": 35, "post_title": "How do you get the Calculus of Constructions from the other points in the Lambda Cube?"}}
{"input": "Classical algorithms can solve 3-SAT in $1.3071^n$ time (randomized) or $1.3303^n$ time (deterministic). (Reference: Best Upper Bounds on SAT )\nFor comparison, using Grover's algorithm on a quantum computer would look for and provide a solution in $1.414^n$, randomized. (This may still require some knowledge of how many solutions there may or may not be, I'm not sure how necessary those bounds still are.) This is clearly significantly worse. Are there are any quantum algorithms that do better than the best classical algorithms (or at least -- almost as good?)\nOf course the classical algorithms could be used on a quantum computer assuming sufficient working space; I'm wondering about inherently quantum algorithms.", "output": "Indeed, as wwjohnsmith1 said, you can get a square root speed-up over Sch\u00f6ning's algorithm for 3-SAT, but also more generally for Sch\u00f6ning's algorithm for k-SAT. In fact, many randomized algorithms for k-SAT can be implemented quadratically faster on a quantum computer.\nThe reason for this general phenomenon is the following. Many randomized algorithms for k-SAT that run in time $O(T(n) \\mathrm{poly}(n))$ (where $T(n)$ is some exponentially growing function of $n$) actually do something stronger. At their core, there is a polynomial-time algorithm that outputs a satisfying assignment, if one exists, with probability at least $1/T(n)$. From this it is clear that if you repeat this poly-time algorithm $O(T(n))$ many times and accept if any of the runs returns a solution, you will get a randomized algorithm for k-SAT that runs in time $O(T(n) \\mathrm{poly}(n))$.\nNow instead of running this algorithm $O(T(n))$ times, you can run amplitude amplification on this poly-time algorithm. Amplitude amplification is a general quantum algorithm that can decide if another algorithm accepts with probability 0 or with probability $1/T$ using only $O(\\sqrt{T})$ uses of this algorithm. Applying amplitude amplification to such a k-SAT solver will immediately yield a quantum algorithm for k-SAT with running time $O(\\sqrt{T(n)}\\mathrm{poly}(n))$, which is quadratically faster (ignoring the poly(n) term).", "meta": {"post_id": 36428, "input_score": 42, "output_score": 40, "post_title": "Do any quantum algorithms improve on classical SAT?"}}
{"input": "What's stopping ghc from translating Haskell into a concatenative programming language such as combinatory logic and then simply using stack allocation for everything? According to Wikipedia, the translation from lambda calculus to combinatory logic is trivial, and also, concatenative programming languages can rely solely on a stack for memory allocation. Is it feasible to do this translation and thus eliminate garbage collection for languages such as Haskell and ocaml? Are there downsides to doing this?\nEDIT: moved here https://stackoverflow.com/questions/39440412/why-do-functional-programming-languages-require-garbage-collection", "output": "All of the following comments are premised on the choice of a standard implementation strategy using closures to represent function values and a call-by-value evaluation order:\n\nFor the pure lambda calculus, garbage collection is not necessary. This is because it is not possible to form cycles in the heap: every newly-allocated value can only contain references to previously-allocated values, and so the memory graph forms a DAG -- so reference counting suffices to manage memory.\nMost implementations do not use reference counting for two reasons. \n\nThey support a form of pointer type (eg, the ref type constructor in ML), and so true cycles in the heap can be formed.\nReference counting is much less efficient than garbage collection, since \n\n\nit requires a lot of additional space to keep the reference counts, and \nupdating the counts is usually wasted work, and \nthe updates to the counts create a bunch of write contention which kills parallel performance.\n\n\nLinearly-typed languages can eliminate the reference count (essentially because counts are 0-1: either the value has a single reference to it or it is dead and can be freed). \nHowever, stack allocation still does not suffice. This is because it is possible to form function values which refer to free variables (i.e., we need to implement function closures), if you allocate things on the stack, then live values can be interleaved with dead values, and this will cause incorrect asymptotic space usage. \nYou can get the right asymptotics by replacing a stack with a \"spaghetti stack\" (ie, implement the stack as a linked list in the heap, so that you can cut out dead frames as needed).\nIf you want a real stack discipline, you can use type systems based on \"ordered logic\" (essentially linear types minus exchange).", "meta": {"post_id": 36564, "input_score": 15, "output_score": 21, "post_title": "Why do functional programming languages require garbage collection?"}}
{"input": "Is there a (preferably natural) NP-complete language $L\\subseteq \\{0,1\\}^*$, such that for every $n\\geq 1$\n$$|L\\cap \\{0,1\\}^n|=2^{n-1}$$\nholds? In other words, $L$ contains precisely half of all $n$-bit instances.", "output": "I asked this question a few years ago and Boaz Barak positively answered it.\n\nThe statement is equivalent to the existence of an NP-complete language $L$ where $|L_n|$ is polynomial-time computable.\nConsider Boolean formulas and SAT.\nUsing padding and slightly modifying the encoding of formulas \nwe can make sure that \n$\\varphi$ and $\\lnot \\varphi$ have the same length.\nLet $\\langle\\ \\rangle$ be an encoding that \n\nfor all formulas $\\varphi$ and \nfor all truth assignment $\\tau \\in \\{0,1\\}^{|\\varphi|}$, \n$|\\langle\\varphi\\rangle| = |\\langle\\varphi, \\tau\\rangle|$.\n$|\\langle\\varphi\\rangle| \\mapsto |\\varphi|$ is polynomial-time computable. \nthe number of formulas with encoded length $n$ is polynomial-time computable.\n\nConsider \n$$L := \\{\\langle\\varphi\\rangle \\mid \\varphi \\in \\mathsf{SAT} \\} \\cup\n\\{\\langle \\varphi, \\tau \\rangle \\mid \\tau \\vDash \\varphi \\text{ and } \n\\exists \\sigma<\\tau\\ \\sigma\\vDash\\varphi \\}$$\nIt is easy to see that $L$ is NP-complete.\nIf $\\varphi \\in \\mathsf{SAT}$, \nthe number of truth assignments satisfying\n$$\\tau \\vDash \\varphi \\text{ and } \n\\exists \\sigma<\\tau\\ \\sigma\\vDash\\varphi$$\nis equal to the number of satisfying truth assignments $- 1$.\nAdding $\\varphi$ itself it adds up to \nthe number of satisfying truth assignments for $\\varphi$.\nThere are $2^{|\\varphi|}$ truth assignments.\nEach $\\tau$ either satisfies $\\varphi$ or $\\lnot \\varphi$ (and not both).\nFor every formula $\\varphi$,\nconsider the $2(2^{|\\varphi|}+1)$ strings $\\langle\\varphi\\rangle$, \n$\\langle\\lnot \\varphi\\rangle$, \n$\\langle\\varphi, \\tau\\rangle$, and \n$\\langle \\lnot\\varphi, \\tau\\rangle$\nfor $\\tau \\in \\{0,1\\}^{|\\varphi|}$.\nExactly $2^{|\\varphi|}$ of these $2^{|\\varphi|+1}+2$ strings are in $L$.\nThis means that the number of strings of length $n$ in $L$ is\nthe number of formulas $\\varphi$ of encoded length $n$ multiplied by $2^{|\\varphi|}$ which polynomial-time computable.", "meta": {"post_id": 37035, "input_score": 25, "output_score": 24, "post_title": "Is there an NP-complete language that contains precisely half of the n-bit instances?"}}
{"input": "In a conference paper, in order to prove the $\\mathsf{NP}$-completeness of a problem, I wrote the stupid sentence \"It is clear that the problem is in $\\mathsf{NP}$. So we will prove that it is $\\mathsf{NP}$-hard\". In fact, it was not clear at all. It even seems to be an open problem. For the targeted audience, it's not a big deal because the main result is the $\\mathsf{NP}$-hardness, and thus the impossibility \"difficulty\" to design a polynomial algorithm.\nBut, of course, I want to correct the mistake in the journal version. \n\nMy question is: In a journal paper, how to point a mistake in the conference version and correct it?\n\nShould I write: \"There is a mistake in the conference version: ...\"? Or should I  state the correct result without saying that the conference version was wrong? Any advise is welcome.", "output": "I think it is very helpful to point out if and where previous results are erroneous. I've done this myself (more times than I would have liked to). My style is to state the correct result, and in immediate proximity (above, below, footnote) a remark to the effect that \"In the conference version [citation], Theorem X incorrectly stated that...\".", "meta": {"post_id": 38056, "input_score": 11, "output_score": 23, "post_title": "Correcting a conference paper error in the journal version"}}
{"input": "I'm wondering if there are some known sources of open TCS problems? I'm a junior studying math/CS and would like to know of some accessible problems that I could start thinking about! \nThanks so much!", "output": "Here's a partial list of collections of open problems in TCS, broadly construed. Note that a collection of \"major open problems\" exists already on this site: http://cstheory.stackexchange.com/questions/174/major-unsolved-problems-in-theoretical-computer-science/251#251.\n\nIn Computer Science (Wikipedia): https://en.wikipedia.org/wiki/List_of_unsolved_problems_in_computer_science\nSublinear time algorithms: http://sublinear.info/index.php?title=Main_Page\nAnalysis of Boolean Functions: http://lanl.arxiv.org/abs/1204.6447\nComputational geometry: http://cs.smith.edu/~orourke/TOPP/\nExact algorithms: http://faculty.cs.tamu.edu/chen/courses/cpsc669/2011/notes/ww1.pdf\nFormal languages, etc.: https://www.student.cs.uwaterloo.ca/~cs462/openproblems.html\nParameterized complexity: http://fpt.wikidot.com/open-problems\nTopological graph theory: http://www.cems.uvm.edu/~darchdea/problems/problems.html\nEmbeddings of finite metric spaces: http://kam.mff.cuni.cz/~matousek/metrop.ps\nLambda calculus, proof theory, semantics, and programming languages: http://tlca.di.unito.it/opltlca/\nPerfect graphs: http://www.aimath.org/WWN/perfectgraph/\nReal analysis in computer science: https://simons.berkeley.edu/sites/default/files/openprobsmerged.pdf\nFine-grained complexity: http://duch.mimuw.edu.pl/~malcin/opl.pdf\nCommunication complexity: https://sublinear.info/index.php?title=Workshops:Banff_2017\nErd\u0151s problems: http://www.math.ucsd.edu/~erdosproblems/All.html", "meta": {"post_id": 38560, "input_score": 14, "output_score": 23, "post_title": "Sources of open problems?"}}
{"input": "I have a (hopefully simple, maybe dumb) question on Babai's landmark paper showing that $\\mathsf{GI}$ is quasipolynomial.\nBabai showed how to produce a certificate that two graphs $G_i=(V_i,E_i)$ for $i\\in\\{1,2\\}$ are isomorphic, in time quasipolynomial in $v=|V_i|$.\n\nDid Babai actually show how to find an element $\\pi\\in S_v$ that permutes the vertices of $G_1$ to $G_2$, or is the certificate merely an existence-statement?\n\nIf an oracle tells me that $G_1$ and $G_2$ are isomorphic, do I still need to look through all $v!$ permutations of the vertices?\nI ask because I also think about knot equivalence.  As far as I know, it's not known to be, but say detecting the unknot were in $\\mathsf{P}$.  Actually finding a sequence of Reidemeister moves that untie the knot might still take exponential time...", "output": "These problems are polynomially equivalent.\nIndeed, suppose that you have an algorithm that can decide whether two graphs are isomorphic or not, and it claims that they are.\nAttach a clique of size $n+1$ to an arbitrary vertex of each graph.\nTest whether the resulting graphs are isomorphic or not.\nIf they are, then we can conclude that there's an isomorphism that maps the respective vertices to each other, thus we can delete them.\nBy repeating this test $n$ times, we can find (a possible) image for any vertex.\nAfter this, we attach another clique, this time of size $n+2$ to a (different) arbitrary vertex of each original graph, and proceed as before, etc.\nEventually, we'll end up with two graphs that are isomorphic, with cliques of size $n+1,\\ldots n+n$ hanging from their vertices, which makes the isomorphism unique.", "meta": {"post_id": 39844, "input_score": 13, "output_score": 28, "post_title": "Does Babai's quasipolynomial time $\\mathsf{GI}$ algorithm actually generate the isomorphism?"}}
{"input": "It's been over a year since his January 2017 retraction and correction. \nIs there news?\nIf not is this normal for validation to take this long? I would expect it would get plenty of attention. \nHas anyone of note spoken up to support/doubt the quasi-polynomial result?", "output": "Aggregating comments by  Thomas Klimpel, Sasho Nikolov and  Mohammad Al-Turkistany into a community answer:\nThe correction (and hence the quasi-polynomial result) was immediately supported by Harald Andr\u00e9s Helfgott. His expository paper (https://arxiv.org/abs/1701.04372) and its translation (https://arxiv.org/abs/1710.04574) are all the support that is needed for the quasi-polynomial results. Helfgott\u2019s exposition appeared as Expos\u00e9 1125 in Ast\u00e9risque 407 (2019), S\u00e9minaire Bourbaki 2016/2017, pp. 135\u2013182.\nThere are no current known issues with Babai\u2019s proof, and it has gone through extensive peer review. That said, even published peer-reviewed papers have later been withdrawn as incorrect. \nThe support by Harald Andr\u00e9s Helfgott along with the lack of other issues should be sufficient for us to accept that graph isomorphism is indeed solvable in quasi-polynomial time.", "meta": {"post_id": 40353, "input_score": 29, "output_score": 27, "post_title": "What's the status of Babai's Graph isomorphism result?"}}
{"input": "Let the variables be $x_1 , x_2 , x_3 ... x_n$.  The distance between two variables is defined as $d(x_a , x_b) = |a-b|$.  The distance between two literals is the distance between the corresponding two variables.\nSuppose I have a 3-SAT instance such that for every clause $(x_a , x_b, x_c)$ we have $d(x_a , x_b) \\leq N \\wedge d(x_a , x_c) \\leq N \\wedge d(x_b , x_c) \\leq N$ for some fixed value $N$. \nConceptually you can picture this as all the literals being physically on a line and all the clauses are incapable of reaching beyond a certain length for physical reasons.  \nGiven this constraint are there any hard instances of 3-SAT? How small can I make the neighborhood and still find hard instances? What if I allow a few clauses to violate the constraint? \nBy hard I mean a heuristic solver would fall back on the worst case.", "output": "No.  If the 3-SAT instance has $m$ clauses, then you can test satisfiability in $O(m 2^N)$ time.  Since $N$ is a fixed constant, this is a polynomial-time algorithm that solves all instances of your problem.\nThe algorithm works in $m$ stages.  Let $\\varphi_i$ denote the formula consisting of the clauses that use only variables from $x_1,\\dots,x_i$.  Let $S_i \\subseteq \\{0,1\\}^n$ denote the set of assignments to $x_{i-N},x_{i-N+1},\\dots,x_i$ that can be extended to a satisfying assignment for $\\varphi_i$.  Note that given $S_{i-1}$, we can compute $S_i$ in $O(2^N)$ time: for each $(x_{i-N-1},\\dots,x_{i-1}) \\in S_{i-1}$, we try both possibilities for $x_i$ and check whether it satisfies all clauses from $\\varphi_i$ that contain the variable $x_i$; if so, we add $(x_{i-N},\\dots,x_{i})$ to $S_i$.  In the $i$th stage, we compute $S_i$.  Once we have finished all $m$ stages, the 3-SAT instance is satisfiable if and only if $S_m \\ne \\emptyset$.  Each stage takes $O(2^N)$ time, and there are $m$ stages, so the total running time is $O(m 2^N)$.  This is polynomial in the size of the input, and thus constitutes a polynomial-time algorithm.\nEven if you allow a fixed number of clauses to violate the constraint, the problem can still be solved in polynomial time.  In particular, if $t$ counts the number of clauses that violate the constraint, you can solve the problem in $O(m 2^{(t+1)N})$ time, by first enumerating all possible values for the variables in those clauses, then continuing with the algorithm above.  When $t$ is a fixed constant, this is polynomial time.  There may be more efficient algorithms.", "meta": {"post_id": 41180, "input_score": 23, "output_score": 31, "post_title": "Are there any hard instances of 3-SAT when the clauses can only use literals that are \"nearby\" each other?"}}
{"input": "General Problem\nSuppose we have a multivariate polynomial function $f(\\mathbf{x})$, and several linear functions $\\ell_i(\\mathbf{x})$. What is known about the complexity of solving the following optimization problem?\n\\begin{align*}\n \\text{Maximize} & \\;\\; f(\\mathbf{x}) \\\\\n  \\text{Subject to: } & \\;\\, \\ell_i(\\mathbf{x}) \\le 0\\text{ for all } i \n\\end{align*}\nWe can assume that the region determined by the constraints is bounded.\nRelated, but More Specific, Problem\nSuppose we have a bounded polytope (represented as the intersection of a set of linear inequalities). \nI want to compute the maximum volume of an (axis parallel) hyperrectangle completely contained in the polytope. What is the complexity of solving this problem? \nHelp on either of these problems is greatly appreciated.", "output": "Your problem is NP-hard, even for polynomials of degree 2. \nThe crucial reference is  \n\nTheodore Motzkin and Ernst Strauss  (1965)\n  \"Maxima for graphs and a new proof of a theorem of Turan\"\n  Canadian Journal of Mathematics 17, pp 533-540  \n\nMotzkin and Strauss consider an undirected graph $G=(V,E)$ \nwith vertex set $V=\\{1,2,\\ldots,n\\}$. \nThey show that the optimal objective value of the following optimization problem equals $1-1/\\omega$, where $\\omega$ is the clique number of $G$:\n\\begin{eqnarray*}\n\\max &&\\sum_{ij\\in E} x_ix_j \\\\[2ex]\ns.t. &&\\sum_{i\\in V} x_i=1 \\\\[1ex]\n&& 0\\le x_i\\le 1~~~ \\text{ for all $i\\in V$}\n\\end{eqnarray*}\nSince computing the clique number is NP-hard, this implies the NP-hardness of maximizing a multivariate polynomial function subject to linear constraints.", "meta": {"post_id": 41252, "input_score": 11, "output_score": 25, "post_title": "How \"hard\" is it to maximize a polynomial function subject to linear constraints?"}}
{"input": "What is the complexity of deciding whether an interval of the natural numbers contains a prime? A variant of the Sieve of Eratosthenes gives an $\\tilde O(L)$ algorithm, where $L$ is the length of the interval and $\\sim$ hides poly-logarithmic factors in the starting point of the interval; can we do better (in terms of $L$ alone)?", "output": "Disclaimer: I'm not an expert in number theory.\nShort answer: If you're willing to assume \"reasonable number-theoretic conjectures\", then we can tell whether there is a prime in the interval $[n, n+\\Delta]$ in time $\\mathrm{polylog}(n)$. If you're not willing to make such an assumption, then there is a beautiful algorithm due to Odlyzko that achieves $n^{1/2 + o(1)}$, and I believe that this is the best known.\nVery helpful link with lots of great information about a closely related problem: PolyMath project on deterministic algorithms for finding primes.\nLong answer:\nThis is a difficult problem, an active area of research, and seems to be intimately connected to the difficult question of bounding gaps between the primes. Your problem is morally very similar to the problem of finding a prime between $n$ and $2n$ deterministically, which was recently the subject of a PolyMath project. (If you want to really dive into these questions, that link is a great place to start.) In particular, our best algorithms for both problems are essentially the same.\nIn both cases, the best algorithm depends heavily on the size of gaps between the prime. In particular, if $f(n)$ is such that there is always a prime between $n$ and $n + f(n)$ (and $f(n)$ can be computed efficiently), then we can always find a prime in time $\\mathrm{polylog}(n) \\cdot f(n)$ as follows. To determine whether there is a prime between $n$ and $n + \\Delta$, first check if $\\Delta \\geq f(n)$. If so, output yes. Otherwise, just iterate through the integers between $n$ and $n + \\Delta$ and test each for primality and answer yes if you find a prime and no otherwise. (This can be done deterministically, which is why deterministically finding a prime between $n$ and $2n$ is so closely related to determining whether there is a prime in a certain interval.)\nIf the primes behave like we think they do, then this is the end of the story (up to $\\mathrm{polylog}(n)$ factors). In particular, we expect to be able to take $f(n) = O(\\log^2 n)$. This is known as Cram\u00e9r's conjecture after Harald Cram\u00e9r, and proving it seems very far out of reach at the moment. But, as far as I know, it is widely believed. (One arrives at this conjecture, e.g., from the heuristic that the primes behave like the random set of integers obtained by including each integer $n \\geq 3$ independently at random with probability $1/\\log n$.)\nThere are many conjectures that imply the much much weaker bound $f(n) \\leq O(\\sqrt{n})$, such as Legendre's conjecture. (I'm not aware of any conjectures that are known to imply an intermediate bound, though I imagine that they exist.) And, the Riemann hypothesis is known to imply the similar bound $f(n) \\leq O(\\sqrt{n} \\log n)$. So, if you assume these conjectures, you essentially match Odlyzko's algorithm (up a factor of $n^{o(1)}$) with a much simpler algorithm.\nI believe that the best unconditional bound right now is $\\widetilde{O}(n^{0.525})$ due to Baker, Harman, and Pintz. So, if you assume nothing, then Odlyzko's algorithm beats the obvious algorithm by roughly a factor of $n^{0.025}$.", "meta": {"post_id": 41270, "input_score": 14, "output_score": 27, "post_title": "Deciding whether an interval contains a prime number"}}
{"input": "Denote by $w_n$ the number of words of length $n$ in a (possibly ambiguous) context-free language.\n\nWhat is known about $w_n$?\n\nI'm sure this has been studied a lot, but I couldn't find anything at all on it.", "output": "Every context-free language has either polynomial growth or exponential growth. In the notation of the question poser:\n\nEither there is a polynomial $p$ so that $w_n\\le p(n)$ for all $n$\nOr there exists a $c>1$, so that $w_n\\ge c^n$ for infinitely many $n$.\n\nThis has been shown for instance in:\n\nRoberto Incitti:\n\"The growth function of context-free languages\"\nTheoretical Computer Science 255 (2001), Pages 601-605\nMartin R. Bridson, Robert H. Gilman:\n\"Context-Free Languages of Sub-exponential Growth\"\nJournal of Computer and System Sciences 64 (2002), Pages 308-310\n\nAnd for a given context-free grammar, one can decide in polynomial time whether the generated language has polynomial or exponential growth:\n\nPawel Gawrychowski, Dalia Krieger, Narad Rampersad, Jeffrey Shallit:\n\"Finding the Growth Rate of a Regular or Context-Free Language in Polynomial Time.\nInternational Journal of Foundations of Computer Science 21 (2010), Pages 597-618", "meta": {"post_id": 41878, "input_score": 21, "output_score": 27, "post_title": "Number of words of length n in a context-free language"}}
{"input": "Pierce (2002) introduces the typing relation on page 92 by writing:\n\nThe typing relation for arithmetic expressions, written \"t : T\", is defined by\n  a set of inference rules assigning types to terms\n\nand the footnote says The symbol $\\in$ is often used instead of :. My question is simply why type theorists prefer to use : over $\\in$? If a type $T$ is a set of values then it makes perfect sense to write $t \\in T$, no new notation needed. \nIs this similar to how some cs writers prefer $3n^2 = O(n^2)$ even thought it is abuse of notation and should be written $3n^2 \\in O(n^2)$?", "output": "The main reason to prefer the colon notation $t : T$ to the membership relation $t \\in T$ is that the membership relation can be misleading because types are not (just) collections.\n[Supplemental: I should note that historically type theory was written using $\\in$. Martin-L\u00f6f's conception of type was meant to capture sets constructively, and already Russell and Whitehead used $\\epsilon$ for the class memebrship. It would be interesting to track down the moment when $:$ became more prevalent than $\\in$.]\nA type describes a certain kind of construction, i.e., how to make objects with a certain structure, how to use them, and what equations holds about them.\nFor instance a product type $A \\times B$ has introduction rules that explain how to make ordered pairs, and elimination rules explaining that we can project the first and the second components from any element of $A \\times B$. The definition of $A \\times B$ does not start with the words \"the collection of all ...\" and neither does it say anywhere anything like \"all elements of $A \\times B$ are pairs\" (but it follows from the definition that every element of $A \\times B$ is propositionally equal to a pair). In constrast, the set-theoretic definition of $X \\times Y$ is stated as \"the set of all ordered pairs ...\".\nThe notation $t : T$ signifies the fact that $t$ has the structure described by $T$.\nA type $T$ is not to be confused with its extension, which is the collection of all objects of type $T$.  A type is not determined by its extension, just like a group is not determined by its carrier set. Furthermore, it may happen that two types have the same extension, but are different, for instance:\n\nThe type of all even primes larger than two: $\\Sigma (n : \\mathbb{N}) . \\mathtt{isprime}(n) \\times \\mathtt{iseven}(n) \\times (n > 2)$. \nThe type of all odd primes smaller than two: $\\Sigma (n : \\mathbb{N}) . \\mathtt{isprime}(n) \\times \\mathtt{isodd}(n) \\times (n < 2)$.\n\nThe extension of both is empty, but they are not the same type.\nThere are further differences between the type-theoretic $:$ and the set-theoretic $\\in$. An object $a$ in set theory exists independently of what sets it belongs to, and it may belong to several sets. In contrast, most type theories satisfy uniqueness of typing: if $t : T$ and $t : U$ then $T \\equiv U$. Or to put it differently, a type-theoretic construction $t$ has precisely one type $T$, and in fact there is no way to have just an object $t$ without its (uniquely determined) type.\nAnother difference is that in set theory we can deny the fact that $a \\in A$ by writing $\\lnot (a \\in A)$ or $a \\not\\in A$. This is not possible in type theory, because $t : T$ is a judgement which can be derived using the rules of type theory, but there is nothing in type theory that would allow us to state that something has not been derived. When a child makes something from LEGO blocks they proudly run to their parents to show them the construction, but they never run to their parents to show them what they didn't make.", "meta": {"post_id": 43971, "input_score": 21, "output_score": 39, "post_title": "Why colon to denote that a value belongs to a type?"}}
{"input": "Robin Gandy was a student of Alan Turing. \nGandy did an analysis of Babbage's Analytical Engine (see 'Gandy \n- The Confluence of Ideas in 1936' quoted in 'Herken, Rolf - The Universal Turing Machine\u2014A Half-Century Survey. Springer Verlag') - and said it did (cf. p. 52\u201353):\n\nThe arithmetic functions +, \u2212, \u00d7, where \u2212 indicates \"proper\" subtraction x \u2212 y = 0 if y \u2265 x.\nAny sequence of operations is an operation.\nIteration of an operation (repeating n times an operation P).\nConditional iteration (repeating n times an operation P conditional on the \"success\" of test T).\nConditional transfer (i.e., conditional \"goto\").\n\nThen he states\n\nthe functions which can be calculated by (1), (2), and (4) are precisely those which are Turing computable. \n\n(p. 53).\nThen he states:\n\n\u2026 the emphasis is on programming a fixed iterable sequence of arithmetical operations. The fundamental importance of conditional iteration and conditional transfer for a general theory of calculating machines is not recognized\u2026\n\nGandy p. 55\nI'm assessing the scope of Gandy's claim here. (Whether it is right or wrong). He seems to be stating that although Babbage seems to have stumbled onto a notion of Turing Completeness (can express any program using (1), (2) and (4) - he didn't have a notion of a Computable Function. (Perhaps Gandy was saying that since the work of Babbage was prior to the work of Hilbert and Godel, he didn't have the mathematical tools to tie down the definition of a universal computing machine.)\nMy question is: Did Alan Turing's student Robin Gandy assert that Charles Babbage had no notion of a universal computing machine?", "output": "No, the opposite. This quote of Gandy's is not referring to Babbage, but to some intervening proposals for universal-style computing between Babbage and Turing. Gandy says those proposals did not have Babbage's recognition of the importance of branching and iteration to universal computation.\n\nIn \"The Confluence of Ideas in 1936\" by Gandy, as printed in the book \"The Universal Turing Machine - A Half Century Survey\", Section 2 is \"Babbage and His Followers\".\nHere Gandy emphasizes that Babbage did understand and respect \"conditional iteration\" and \"conditional transfer\", e.g. end of p53 and top of p54\n\nAlthough Babbage mentions conditional transfer (67-68), he, with a natural respect for well-structured programming, uses only conditional iteration[....] He states conditional transfer explicitly (240), allowing that a 'go to' instruction may have to be executed by ringing a bell to summon the attendant; he gives an example of its use (241).\n\n(Here Gandy refers to the article by Menabrea 1842 on Babbage's engine, but seems to attribute the ideas to Babbage himself.)\nGandy then quotes Babbage\n\nThat the whole of the development and operations of analysis are now capable of being executed by machinery.\n\nand writes\n\nBabbage, in his work on general algebra and functional equations, had shown\n  his ability to think in abstract terms. If, then, one had led him to speculate (not\n  difficult!) on what could be done with an abstract machine, free from limitations on\n  its storage, he would surely have assented to a version (based on Sections 2.1.(1)-(5)) of Church's thesis.\n\nThen Gandy goes on to Section 2.3, \"Subsequent developments.\" He writes\n\nOther authors, concerned\n  with more practical machines, referred to Babbage's work. Examples from Ran-\n  dell 1982 are: M. d'Ocagne [1922], L. Couffignal [1933], V. Bush 1936, H.H. Aiken\n  11964] (which is an unpublished memorandum of 1937). But the emphasis is on\n  programming a fixed iterable sequence of arithmetical operations. The fundamental\n  importance of conditional iteration and conditional transfer for a general theory of calculating machines is not recognized, though the principles may be used in very particular contexts [....]\n\nFinally, Gandy writes:\n\nConclusions. Babbage asserted what was, in effect a version of Church's thesis. His work was never entirely forgotten, but its theoretical importance - its importance, so to speak, as software - was little recognized[....]", "meta": {"post_id": 44475, "input_score": 10, "output_score": 22, "post_title": "Did Alan Turing's student Robin Gandy assert that Charles Babbage had no notion of a universal computing machine?"}}
{"input": "It is commonly believed that for all $\\epsilon > 0$, it is possible to multiply two $n \\times n$ matrices in $O(n^{2 + \\epsilon})$ time. Some discussion is here.\nI have asked some people who are more familiar with the research whether they think that there is a $k>0$ independent of $n$ such that there exists an $O(n^2 \\log^k n)$ algorithm for matrix multiplication and they overwhelmingly seemed to have intuition that the answer is \"no\" but could not explain why. That is, they believe that we can do it in $O(n^{2.001})$ time, but not $O(n^2 \\log^{100} n)$ time.\nWhat reasons are there to believe that there is no $O(n^2 \\log^k n)$ algorithm at a fixed $k>0$?", "output": "There's an algorithm for multiplying an $N \\times N^{0.172}$ matrix with an $N^{0.172} \\times N$ matrix in $N^2 \\operatorname{polylog}\\left(N\\right)$ arithmetic operations. The main identity used for it comes from Coppersmith's paper \"Rapid multiplication of rectangular matrices\", but the explanation for why it leads to $N^2 \\operatorname{polylog}\\left(N\\right)$ instead of $N^{2 + \\epsilon}$ is in the appendix of Williams' paper, \"New algorithms and lower bounds for circuits with linear threshold gates\".\nThis only works because Coppersmith's identity has some additional structure you can take advantage of, and the more recent MM algorithms don't seem to have this structure. That said, I'm not sure why one can't hope to extend this approach to $N \\times N \\times N$ matrix multiplication.", "meta": {"post_id": 44509, "input_score": 44, "output_score": 32, "post_title": "Evidence that matrix multiplication is not in $O(n^2\\log^kn)$ time"}}
{"input": "I was wondering if there are individual publications that have led their authors to win the Turing Prize or if the Turing Prize is the result of a lifetime's work and multiple publications and results.", "output": "Yes, it happens that the work that merits the Turing award was pioneered or introduced in a single very influential paper. Sometimes, this is even explicitly the reason for the award. For example, in 1976, Rabin and Scott were given the Turing award\n\nFor their joint paper \"Finite Automata and Their Decision Problem,\" which introduced the idea of nondeterministic machines, which has proved to be an enormously valuable concept. Their (Scott & Rabin) classic paper has been a continuous source of inspiration for subsequent work in this field.\n\nSimilarly, Hartmanis and Stearns won the 1993 Turing award\n\nIn recognition of their seminal paper which established the foundations for the field of computational complexity theory.\n\n(The paper contains the original proof of the Time Hierarchy theorem.) Finally, in the blurb for the 2015 Turing award to Diffie and Hellman, a specific paper is mentioned, but it is not the sole reason for the award. The blurb states:\n\nFor fundamental contributions to modern cryptography. Diffie and Hellman's groundbreaking 1976 paper, \"New Directions in Cryptography,\"[44] introduced the ideas of public-key cryptography and digital signatures, which are the foundation for most regularly-used security protocols on the Internet today.\n\nIn general, the Turing award looks at widespread impact over a long period (20 years or more). It is more common for this to be over a line of several papers which collectively summarize the impact. For example, the 2018 award to Bengio, Hinton, and LeCun cannot be traced back to a single paper or even two or three, because Neural Networks as we know them today were not defined, optimized, specialized, and engineered successfully all in one paper. Similarly, Barbara Liskov's 2008 award for contributions to programming languages and distributed computing mentions several ideas: \"For contributions to practical and theoretical foundations of programming language and system design, especially related to data abstraction, fault tolerance, and distributed computing.\" Each of the phrases mentioned in the blurb can be traced to a different paper or set of papers.", "meta": {"post_id": 45979, "input_score": 21, "output_score": 25, "post_title": "Turing award papers"}}
{"input": "Given: An undirected, unweighted graph\nLooking for: A disjoint vertex cycle cover where every cycle has at least 3 edges\nIs there any algorithm that solves this problem, possibly with some heuristics? Can the bipartite representation of the graph used for finding perfect matching be leveraged here?", "output": "The cycle cover problem (CC) is the problem of finding a spanning set of cycles in a given directed or undirected input graph. \nIf all the cycles in the cover must consist of at least $k$ edges/arcs, the resulting restriction of the problem is denoted $k$-UCC (in undirected graphs) and $k$-DCC (in directed graphs).\nThe complexity of the directed version is fully understood:\n\nMarkus Bl\u00e4ser and Bodo Siebert (\"Computing Cycle Covers without Short Cycles\", in Proceedings of ESA 2001, LNCS 2161, pp 368--379) have proved that $k$-DCC is NP-complete for any fixed $k\\ge3$.\n\nThe complexity landscape of the undirected version is more diverse, and there are some open questions: \n\n$3$-UCC is polynomially solvable. This is a folklore result that follows from a reduction of Tutte (\"A short proof of the factor theorem for finite graphs\", Canadian Journal of Mathematics 6, pp 347\u2013352, 1954) to the classical unrestricted matching problem.\nDavid Hartvigsen (in his PhD thesis \"An Extension of Matching Theory\", Carnegie-Mellon University, 1984) has shown that $4$-UCC is polynomially solvable. \nThe complexity status of $5$-UCC is open. David Hartvigsen has some positive results on special cases of this problem (\"The square-free 2-factor problem in bipartite graphs\", in Proceedings of IPCO 1999, LNCS 1610, pp 234\u2013241). \nPapadimitriou has proved that $k$-UCC is NP-complete for any fixed $k\\ge6$. His proof is sketched in the 1980 paper \"A matching problem with side conditions\" by Gerard Cornuejols and Bill Pulleyblank (Discrete Mathematics 29, pp 135--159).", "meta": {"post_id": 46819, "input_score": 7, "output_score": 22, "post_title": "Algorithm for finding a 3-cycle cover"}}
{"input": "I know that for the vertex cover problem, if we know that the parameter $k$ (which is the number of vertices in the solution) is small, then we can expect to solve it feasibly in practice. So far, this is the only example I've seen on Downey, Rodney G. and Michael R. Fellows. \"Parameterized Complexity\".\nHas considering a problem in a parameterized way led to different algorithms that end up to be feasible in practice? Or is the Parameterized Complexity Theory just a tool for evaluating complexity of problems?", "output": "There are several examples of problems where a parameterized algorithm performs well in practice. Let me mention two such problems.\nIn the $k$-Path problem where we are looking for a simple path of length $k$. Alon, Yuster and Zwick [1] showed that this problem can be solved in $2^{O(k)}\\cdot n$ time on $n$-vertex graphs. A weighted version of $k$-Path has applications in computational biology and the biologically interesting paths have length at most 20. Several of the implemented algorithms successfully use the color coding technique [2].\nThe Clique problem parameterized by the solution size $k$ has presumably no FPT algorithm, but Clique parameterized by the degeneracy $d$ of the input graph has an FPT algorithm. More precisely, all maximal cliques of an $n$-vertex graph can be enumerated in $O(3^{d/3}\\cdot n)$ time [3]. Since many real-world graphs (e.g. social networks) have small degeneracy, this running time bound explains why clique enumeration is feasible on these graphs.\nI would say there is a crucial difference between the two results. In the case of $k$-Path, the color coding technique is an FPT technique that was developed in theory and was later turned into a practical algorithm. In the case of Clique, the central technique of the FPT algorithm, which, roughly speaking, is to enumerate first the cliques containing a minimum-degree vertex $v$ and then enumerating all cliques not containing $v$, was already known, in some form, before the theoretical analysis and probably used in several implementations. Hence, I would say that for $k$-Path, parameterized algorithmics has led to better algorithms, and for Clique, parameterized algorithmics rather explains why algorithms are good.\n[1]: Alon, Yuster and Zwick: Color Coding.  J. ACM 42(4): 844-856 (1995) https://doi.org/10.1145/210332.210337\n[2] Jacob Scott, Trey Ideker, Richard M. Karp, Roded Sharan: Efficient Algorithms for Detecting Signaling Pathways in Protein Interaction Networks. J. Comput. Biol. 13(2): 133-144 (2006)\n[3] David Eppstein, Maarten L\u00f6ffler, Darren Strash:\nListing All Maximal Cliques in Large Sparse Real-World Graphs. ACM J. Exp. Algorithmics 18 (2013)", "meta": {"post_id": 47663, "input_score": 19, "output_score": 26, "post_title": "Has parameterized complexity led to better algorithms?"}}
{"input": "I want to use use Agda to help me write proofs, but I am getting contradictory feedback about the value of proof relevance.\nJacques Carette wrote a Proof-relevant Category Theory in Agda library. But some seem to think (perhaps here, but I was told elsewhere) that proof relevance can be problematic. 1-Category Theory is supposed to be proof irrelevant (and I guess above two categories, this is no longer the case?) I even heard that one may not get the same results if one uses proof relevant category theory.\nAt the same time I believe the Category Theory in the HoTT book and the implementation in Cubical Agda are proof irrelevant (as the HomSets are Sets, i.e., have only one way of being equal).\nWhen should I be happy to have proof relevance? When should I rather choose a proof irrelevant library or proof assistant? What are the advantages of each? Would proof irrelevance be problematic as I move to two categories?", "output": "There are several possible notions of proof relevance. Let us consider three similar situations:\n\nAn element of a sum $\\Sigma (x : A) . P(x)$ is a pair $(a, p)$ where $a : A$ and $p$ is a proof of $P(a)$.\n\nAn element of $\\Sigma (x : A) . \\|P(x)\\|$, where $\\|{-}\\|$ is propositional truncation, is a pair $(a, q)$ where $a : A$ and $q$ is an equivalence class of proofs of $P(a)$ (where any two proofs of $P(a)$ are considered equivalent).\n\nIn set theory, an element of the subset $\\{x \\in A \\mid \\phi(x)\\}$, where $\\phi(x)$ is a logical formula, is just $a \\in A$ such that $\\phi(a)$ holds.\n\n\nThe first situation is proof relevant because we get full access to the proof $p$, and in particular we may analyze $p$.\nThe third situation is proof irrelevant because we get access just to $a \\in A$ but have no further information as to why $\\phi(a)$ holds, just that it does.\nThe second situation looks like proof irrelevance, but is actually a form of restricted proof relevance: we do not delete the proof of $P(a)$ but just control its uses with truncation. That is, from $q$ we may extract a representative proof $p$ of $P(a)$, so long as the choice of $p$ is irrelevant.\nThere is a cruicial difference between the third and the second situation, for having restricted access to $p$ is not at all the same as not having access at all. Here is a concrete example. Given $f : \\mathbb{N} \\to \\mathbb{N}$, define\n$$\nZ(f) = \\Sigma(x : \\mathbb{N}) . \\Pi (y : \\mathbb{N}) . \\mathrm{Id}(f(x + y), 0)\n$$\nAn element of $Z(f)$ is a pair $(m, p)$ witnessing the fact that $f(n)$ is zero for all $n \\geq m$. Given $f$ with this property, we want to define the sum $S(f) = f(0) + f(1) + f(2) + \\cdots$, which of course should be a natural number since eventually the terms are all zero. But proof relevance matters:\n\nWe may define $S : (\\Sigma (f : \\mathbb{N} \\to \\mathbb{N}) . Z(f)) \\to \\mathbb{N}$ by\n$$S(f, (m, p)) = f(0) + \\cdots + f(m)$$\n\nWe may define $S : (\\Sigma (f : \\mathbb{N} \\to \\mathbb{N}) . \\|Z(f)\\|) \\to \\mathbb{N}$ by\n$$S(f, |(m,p)|) = f(0) + \\cdots + f(m),$$\nwhere $|(m,p)|$ is the truncated witness of $Z(f)$. This is a valid definition because using a different representative $(m',p')$ leads to the same value (as we just end up adding fewer or more zeroes).\n\nImagining that in type theory we had proof irrelevant subset types\n$$\\frac{\\vdash a : A \\qquad \\vdash p : P(a)}{\\vdash a : \\{x : A \\mid P(x)\\}}$$\nwe cannot define $S : \\{f : \\mathbb{N} \\to \\mathbb{N} \\mid Z(f)\\} \\to \\mathbb{N}$ because we have no information that would allow us to limit the number of terms $f(0), f(1), f(2), \\ldots$ that need to be added. (There are other things we can do, but that is beside the point here.)\n\n\nAs long as one works in type theory, the only truly proof irrelevant judgements are judgemental equalities. We never define subset types, such as the one above, because that ruins many good properties of type theory (although it would be interesting to investigate this direction).\nIn the old days type theory did not have propositional truncation or any other form of quotienting, and so one was forced to work in a completely proof relevant way all the time. This is unsatisfactory because it fails to capture properly a great deal of mathematical reasoning. People invented setoids to deal with the problem, and later on introduced propositional truncation (and other forms of quotienting).\nYou ask wheter 1-categories are \"proof relevant\". Well, everything in type theory is proof relevant, the only question is how do we deal with having too much proof relevance. Concretely, in a 1-category $\\mathcal{C}$, equality of morphisms $f, g : A \\to B$ should be \"irrelevant\" in the sense that it never matter how $f$ and $g$ are equal, only that they are. In HoTT this is expressed by requiring that $\\mathrm{Id}(f,g)$ have at most one element, which amounts to\n$\\mathrm{Hom}_\\mathcal{C}(A,B)$ being an h-set.\nIn setoid-based formulations of category theory, one needs to account for this phenomenon in some other way, or else one is secretly doing something other than 1-category theory. But I never liked the setoid approach (or Bishop's notion of sets, for that matter), so I will let someone else explain why and how it all makes sense.", "meta": {"post_id": 48112, "input_score": 17, "output_score": 21, "post_title": "Proof relevance vs. proof irrelevance"}}
{"input": "Recently, I came across the problem of figuring out whether a given binary function $f(x)$ is constant (0 for all values of $x$ or 1 for all values of $x$) or balanced (0 for half of values and 1 for the other half), for $x \\leq N$.\nClearly, the complexity of a bounded error probabilistic algorithm is $O(1)$, because the probability of the function being constant if you get k random elements with the same value is less than $\\frac{1}{2^k}$.\nHowever, the deterministic algorithm is to check $f(x)$ for the possible values of $x$ until you find different values or $\\frac{N}{2} + 1$ equal values. The time complexity for the worst case is $O(2^n)$, with $n$ being the number of bits of $N$, which is exponential.\nTo me it seems trivial that there is no better solution than this one, because you cannot be sure that two values inside a black box are different until you find them or get the maximum amount of equal numbers, so this problem is in $BPP$, but not in $P$.\nWhat is wrong in my line of thought? Also, is this a \"clue\" that P is probably different from BPP?", "output": "It is true that if the function $f$ is given by an oracle, then a randomized algorithm is exponentially faster than any deterministic algorithm. With an oracle function, however, this is not a $BPP$ problem! It becomes a $BPP$ problem only if the function $f$ is given by a polynomial time algorithm, so that the whole task can be defined via a polynomial time Turing machine.\nIn that case, however, it is not clear that you indeed have to check exponentially many values in the deterministic case. You might be able to bypass it via capitalizing on knowing the special algorithm that computes $f$. (Note that  knowing the algorithm is essential to make it a $BPP$ problem.)\nOnce you are in this setting, it might be possible  to use the knowledge of the algorithm   to devise a deterministic polynomial time solution. For example, by an appropriate pseudo random number generator you might be able to  simulate the randomness well enough for the specific function $f$, so that the same solution is obtained as by the randomized algorithm. Whether this is indeed possible in every case is a major open question, it is the $P=?BPP$ problem.\nYour line of thought can used, however, to prove that there is no universal deterministic pseudo random number generator, which works for every function $f$  in this setting.", "meta": {"post_id": 52885, "input_score": 10, "output_score": 22, "post_title": "Why is the \"balanced vs constant function\" problem not a proof that P \u2260 BPP?"}}
