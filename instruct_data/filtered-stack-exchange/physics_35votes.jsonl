{"input": "I searched and couldn't find it on the site, so here it is (quoted to the letter):\n\nOn this infinite grid of ideal one-ohm resistors, what's the equivalent resistance between the two marked nodes?\n\n\nWith a link to the source.\nI'm not really sure if there is an answer for this question. However, given my lack of expertise with basic electronics, it could even be an easy one.", "output": "This is the XKCD Nerd Sniping problem. It forced me to abandon everything else I was doing to research and write up this answer. Then, years later, it compelled me to return and edit it for clarity.\nThe following full solution is based on the links posted in the other answer. But in addition to presenting this information in a convenient form, I've also made some significant simplifications of my own. Now, nothing more than high school integration is needed!\nThe strategy in a nutshell is to\n\nWrite down an expression for the resistance between any two points as an integral.\n\nUse integration tricks to evaluate the integral found in Step 1 for two diagonally separated points.\n\nUse a recurrence relation to determine all other resistances from the ones found in Step 2.\n\n\nThe result is an expression for all resistances, of which the knight's move is just one. The answer for it turns out to be\n$$ \\frac{4}{\\pi} - \\frac{1}{2} $$\nSetting up the problem\nWhile we're ultimately interested in a two-dimensional grid, to start with nothing will depend on the dimension. Therefore we will begin by working in $N$ dimensions, and specialise to $N = 2$ only when necessary.\nLabel the grid points by $\\vec{n}$, an $N$-component vector with integer components.\nSuppose the voltage at each point is $V_\\vec{n}$. Then the current flowing into $\\vec{n}$ from its $2N$ neighbours is\n$$ \\sum_{i, \\pm} ( V_{\\vec{n} \\pm \\vec{e}_i} - V_\\vec{n} ) $$\n($\\vec{e}_i$ is the unit vector along the $i$-direction.)\nInsist that an external source is pumping one amp into $\\vec{0}$ and out of $\\vec{a}$. Current conservation at $\\vec{n}$ gives\n$$ \\sum_{i, \\pm} ( V_{\\vec{n} \\pm \\vec{e}_i} - V_\\vec{n} ) = -\\delta_\\vec{n} + \\delta_{\\vec{n} - \\vec{a}} \\tag{1}\\label{eqv} $$\n($\\delta_\\vec{n}$ equals $1$ if $\\vec{n} = \\vec{0}$ and $0$ otherwise.)\nSolving this equation for $V_\\vec{n}$ will give us our answer. Indeed, the resistance between $\\vec{0}$ and $\\vec{a}$ will simply be\n$$ R_\\vec{a} = V_\\vec{0} - V_\\vec{a} $$\nUnfortunately, there are infinitely many solutions for $V_\\vec{n}$, and their results for $R_\\vec{a}$ do not agree! This is because the question does not specify any boundary conditions at infinity. Depending on how we choose them, we can get any value of $R_\\vec{a}$ we like! It will turn out that there's a unique reasonable choice, but for now, let's forget about this problem completely and just find any solution.\nSolution by Fourier transform\nTo solve our equation for $V_\\vec{n}$, we will look for a Green's function $G_\\vec{n}$ satisfying a similar equation:\n$$ \\sum_{i, \\pm} ( G_{\\vec{n} \\pm \\vec{e}_i} - G_\\vec{n} ) = \\delta_\\vec{n} \\tag{2}\\label{eqg} $$\nA solution to $\\eqref{eqv}$ will then be\n$$ V_n = -G_\\vec{n} + G_{\\vec{n} - \\vec{a}} $$\nTo find $G_\\vec{n}$, assume (out of the blue) that it can be represented as\n$$ G_\\vec{n} = \\int_0^{2\\pi} \\frac{d^N \\vec{k}}{(2\\pi)^N} (e^{i \\vec{k} \\cdot \\vec{n}} - 1) g(\\vec{k}) $$\nfor some unknown function $g(\\vec{k})$. Then noting that the two sides of $\\eqref{eqg}$ can be written as\n\\begin{align}\n\\sum_{i, \\pm} ( G_{\\vec{n} \\pm \\vec{e}_i} - G_\\vec{n} )\n&=\n\\int_0^{2\\pi} \\frac{d^N \\vec{k}}{(2\\pi)^N} e^{i \\vec{k} \\cdot \\vec{n}} \\left( \\sum_{i, \\pm} e^{\\pm i k_i} - 2N \\right) g(\\vec{k})\n\\\\\n\\delta_\\vec{n}\n&=\n\\int_0^{2\\pi} \\frac{d^N \\vec{k}}{(2\\pi)^N} e^{i \\vec{k} \\cdot \\vec{n}}\n\\end{align}\nwe see $\\eqref{eqg}$ can be solved by choosing\n$$ g(\\vec{k}) = \\frac{1}{\\sum_{i, \\pm} e^{\\pm k_i} - 2N} $$\nwhich leads to the Green's function\n$$ G_\\vec{n} = \\frac{1}{2} \\int_0^{2\\pi} \\frac{d^N \\vec{k}}{(2\\pi)^N} \\frac{\\cos(\\vec{k} \\cdot \\vec{n}) - 1}{\\sum_i \\cos(k_i) - N} $$\nBy the way, the funny $-1$ in the numerator doesn't seem to be doing much other than shifting $G_\\vec{n}$ by the addition of an overall constant, so you might wonder what it's doing there. The answer is that it's technically needed to make the integral finite, but other than that it doesn't matter as it will cancel out of the answer.\nSo the final answer for the resistance is\n$$ R_\\vec{a} = V_\\vec{0} - V_\\vec{a} = 2(G_\\vec{a} - G_\\vec{0}) = \\int_0^{2\\pi} \\frac{d^N \\vec{k}}{(2\\pi)^N} \\frac{1 - \\cos(\\vec{k} \\cdot \\vec{a})}{N - \\sum_i \\cos(k_i)} $$\nWhy is this the right answer?\n(From this point on, $N = 2$.)\nI said earlier that there were infinitely many solutions for $V_\\vec{n}$. But the one above is special, because at large distances $r$ from the origin, the voltages and currents behave like\n$$ V = \\mathcal{O}(1/r) \\qquad I = \\mathcal{O}(1/r^2) $$\nA standard theorem (Uniqueness of solutions to Laplace's equation) says there can be only one solution satisfying this condition. So our solution is the unique one with the least possible current flowing at infinity and with $V_\\infty = 0$. And even if the question didn't ask for that, it's obviously the only reasonable thing to ask.\nOr is it? Maybe you'd prefer to define the problem by working on a finite grid, finding the unique solution for $V_\\vec{n}$ there, then trying to take some sort of limit as the grid size goes to infinity. However, one can argue that the $V_\\vec{n}$ obtained from a size-$L$ grid should converge to our $V_\\vec{n}$ with an error of order $1/L$. So the end result is the same.\nThe diagonal case\nIt turns out the integral for $R_{n,m}$ is tricky to do when $n \\neq m$, but much easier to do when $n = m$. Therefore, we'll deal with that case first. We want to calculate\n\\begin{align}\nR_{n,n}\n&= \\frac{1}{(2\\pi)^2} \\int_A dx \\, dy \\, \\frac{1 - \\cos(n(x + y))}{2 - \\cos(x) - \\cos(y)} \\\\\n&= \\frac{1}{2(2\\pi)^2} \\int_A dx \\, dy \\, \\frac{1 - \\cos(n(x + y))}{1 - \\cos(\\frac{x+y}{2}) \\cos(\\frac{x-y}{2})}\n\\end{align}\nwhere $A$ is the square $0 \\leq x,y \\leq 2 \\pi$.\nBecause the integrand is periodic, the domain can be changed from $A$ to $A'$ like so:\n\nThen changing variables to\n$$ a = \\frac{x+y}{2} \\qquad b = \\frac{x-y}{2} \\qquad dx \\, dy = 2 \\, da \\, db $$\nthe integral becomes\n$$ R_{n,n} = \\frac{1}{(2\\pi)^2} \\int_0^\\pi da \\int_{-\\pi}^\\pi db \\, \\frac{1 - \\cos(2na)}{1 - \\cos(a) \\cos(b)} $$\nThe $b$ integral can be done with the half-tan substitution\n$$ t = \\tan(b/2) \\qquad \\cos(b) = \\frac{1-t^2}{1+t^2} \\qquad db = \\frac{2}{1+t^2} dt $$\ngiving\n$$ R_{n,n} = \\frac{1}{2\\pi} \\int_0^\\pi da \\, \\frac{1 - \\cos(2na)}{\\sin(a)} $$\nThe trig identity\n$$ 1 - \\cos(2na) = 2 \\sin(a) \\big( \\sin(a) + \\sin(3a) + \\dots + \\sin((2n-1)a) \\big) $$\nreduces the remaining $a$ integral to\n\\begin{align}\nR_{n,n}\n&=\n\\frac{2}{\\pi} \\left( 1 + \\frac{1}{3} + \\dots + \\frac{1}{2n-1} \\right)\n\\end{align}\nA recurrence relation\nThe remaining resistances can in fact be determined without doing any more integrals! All we need is rotational/reflectional symmetry,\n$$ R_{n,m} = R_{\\pm n, \\pm m} = R_{\\pm m, \\pm n} $$\ntogether with the recurrence relation\n$$ R_{n+1,m} + R_{n-1,m} + R_{n,m+1} + R_{n,m-1} - 4 R_{n,m} = 2 \\delta_{(n,m)} $$\nwhich follows from $R_\\vec{n} = 2 G_\\vec{n}$ and $\\eqref{eqg}$. It says that if we know all resistances but one in a \"plus\" shape, then we can determine the missing one.\nStart off with the trivial statement that\n$$ R_{0,0} = 0 $$\nApplying the recurrence relation at $(n,m) = (0,0)$ and using symmetry gives\n$$ R_{1,0} = R_{0,1} = 1/2 $$\nThe next diagonal is done like so:\n\nHere the turquoise square means that we fill in $R_{1,1}$ using the formula for $R_{n,n}$. The yellow squares indicate an appliation of the recurrence relation to determine $R_{2,0}$ and $R_{0,2}$. The dotted squares also indicate resistances we had to determine by symmetry during the previous step.\nThe diagonal after that is done similarly, but without the need to invoke the formula for $R_{n,n}$:\n\nRepeatedly alternating the two steps above yields an algorithm for determining every $R_{m,n}$. Clearly, all are of the form\n$$ a + b/\\pi $$\nwhere $a$ and $b$ are rational numbers. Now this algorithm can easily be performed by hand, but one might as well code it up in Python:\nimport numpy as np\nimport fractions as fr\n\nN = 4\narr = np.empty((N * 2 + 1, N * 2 + 1, 2), dtype='object')\n\ndef plus(i, j):\n    arr[i + 1, j] = 4 * arr[i, j] - arr[i - 1, j] - arr[i, j + 1] - arr[i, abs(j - 1)]\n\ndef even(i):\n    arr[i, i] = arr[i - 1, i - 1] + [0, fr.Fraction(2, 2 * i - 1)]\n    for k in range(1, i + 1): plus(i + k - 1, i - k)\n\ndef odd(i):\n    arr[i + 1, i] = 2 * arr[i, i] - arr[i, i - 1]\n    for k in range(1, i + 1): plus(i + k, i - k)\n\narr[0, 0] = 0\narr[1, 0] = [fr.Fraction(1, 2), 0]\n\nfor i in range(1, N):\n    even(i)\n    odd(i)\n\neven(N)\n\nfor i in range(0, N + 1):\n    for j in range(0, N + 1):\n        a, b = arr[max(i, j), min(i, j)]\n        print('(', a, ')+(', b, ')/\u03c0', sep='', end='\\t')\n    print()\n\nThis produces the output\n$$\n\\Large\n\\begin{array}{|c:c:c:c:c}\n40 - \\frac{368}{3\\pi} & \\frac{80}{\\pi} - \\frac{49}{2} & 6 - \\frac{236}{15\\pi} & \\frac{24}{5\\pi} - \\frac{1}{2} & \\frac{352}{105\\pi} \\\\\n\\hdashline\n\\frac{17}{2} - \\frac{24}{\\pi} & \\frac{46}{3\\pi} - 4 & \\frac{1}{2} + \\frac{4}{3\\pi} & \\frac{46}{15\\pi} & \\frac{24}{5\\pi} - \\frac{1}{2} \\\\\n\\hdashline\n2 - \\frac{4}{\\pi} & \\frac{4}{\\pi} - \\frac{1}{2} & \\frac{8}{3\\pi} & \\frac{1}{2} + \\frac{4}{3\\pi} & 6 - \\frac{236}{15\\pi} \\\\\n\\hdashline\n\\frac{1}{2} & \\frac{2}{\\pi} & \\frac{4}{\\pi} - \\frac{1}{2} & \\frac{46}{3\\pi} - 4 & \\frac{80}{\\pi} - \\frac{49}{2} \\\\\n\\hdashline\n0 & \\frac{1}{2} & 2 - \\frac{4}{\\pi} & \\frac{17}{2} - \\frac{24}{\\pi} & 40 - \\frac{368}{3\\pi} \\\\\n\\hline\n\\end{array}\n$$\nfrom which we can read off the final answer,\n$$ R_{2,1} = \\frac{4}{\\pi} - \\frac{1}{2} $$", "meta": {"post_id": 2072, "input_score": 127, "output_score": 61, "post_title": "On this infinite grid of resistors, what's the equivalent resistance?"}}
{"input": "W and Z bosons are observed/discovered. But as force carrying bosons they should be virtual particles, unobservable? And also they require to have mass, but if they are virtual they may be off-shell, so are they virtual or not.", "output": "[Edit June 2, 2016:\nA significantly updated version of the material below can be found in\nthe two articles \nhttps://www.physicsforums.com/insights/misconceptions-virtual-particles/\nand\nhttps://www.physicsforums.com/insights/physics-virtual-particles/\n]\nLet me give a second, more technical answer.\nObservable particles.\nIn QFT, observable (hence real) particles of mass $m$ are conventionally\ndefined as being associated with poles of the S-matrix at energy \n$E=mc^2$ in the rest frame of the system \n(Peskin/Schroeder, An introduction to QFT, p.236). If the pole is at a \nreal energy, the mass is real and the particle is stable; if the pole \nis at a complex energy (in the analytic continuation of the S-matrix \nto the second sheet), the mass is complex and the particle is unstable. \nAt energies larger than the real part of the mass, the imaginary part \ndetermines its decay rate and hence its lifetime \n(Peskin/Schroeder, p.237); at smaller energies, the unstable particle \ncannot form for lack of energy, but the existence of the pole is \nrevealed by a Breit-Wigner resonance in certain cross sections.\nFrom its position and width, one can estimate the mass and the lifetime \nof such a particle before it has ever been observed. \nIndeed, many particles listed in the tables \nhttp://pdg.lbl.gov/2011/reviews/contents_sports.html by the Particle \nData Group (PDG) are only resonances.\n\nStable and unstable particles.\nA stable particle can be created and annihilated, as there are \nassociated creation and annihilation operators that add or remove \nparticles to the state. According to the QFT formalism, these \nparticles must be on-shell. This means that their momentum $p$ is \nrelated to the real rest mass $m$ by the relation $p^2=m^2$.\nMore precisely, it means that the 4-dimensional Fourier transform of the time-dependent single-particle wave function associated with it has a support that satisfies the on-shell relation $p^2=m^2$. There is no need for this wave function to be a plane wave, though these are taken as the basis functions between the scattering matrix elements are taken.\nAn unstable particle is represented quantitatively by a so-called \nGamov state (see, e.g., http://arxiv.org/pdf/quant-ph/0201091.pdf), \nalso called a Siegert state \n(see, e.g., http://www.cchem.berkeley.edu/millergrp/pdf/235.pdf) \nin a complex deformation of the Hilbert space of a QFT, obtained by \nanalytic continuation of the formulas for stable particles.\nIn this case, as $m$ is complex, the mass shell consists of all complex \nmomentum vectors $p$ with $p^2=m^2$ and $v=p/m$ real, and states are \ncomposed exclusively of such momentum vectors. This is the \nrepresentation in which one can take the limit of zero decay, in which \nthe particle becomes stable (such as the neutron in the limit of \nnegligible electromagnetic interaction), and hence the representation \nappropriate in the regime where the unstable particle can be observed \n(i.e., resolved in time).\nA second representation in terms of normalizable states of real mass \nis given by a superposition of scattering states of their decay \nproducts, involving all energies in the range of the Breit-Wigner \nresonance. In this standard Hilbert space representation, the unstable \nparticle is never formed; so this is the representation appropriate in \nthe regime where the unstable particle reveals itself only as a \nresonance.\nThe 2010 PDG description of the Z boson, \nhttp://pdg.lbl.gov/2011/reviews/rpp2011-rev-z-boson.pdf\ndiscusses both descriptions in quantitative detail (p.2: Breit-Wigner \napproach; p.4: S-matrix approach).\n(added March 18, 2012): \nAll observable particles are on-shell, though the mass shell is real \nonly for stable particles.\n\nVirtual (or off-shell) particles.\nOn the other hand, virtual particles are defined as internal lines in \na Feynman diagram (Peskin/Schroeder, p.5, or \nZeidler, QFT I Basics in mathematics and physiics, p.844).\nand this is their only mode of being. In diagram-free approaches \nto QFT such as lattice gauge theory, it is even impossible to make \nsense of the notion of a virtual particle. Even in orthodox QFT one \ncan dispense completely with the notion of a virtual particle, as \nVol. 1 of the QFT book of Weinberg demonstrates. He represents the \nfull empirical content of QFT, carefully avoiding mentioning the \nnotion of virtual particles.\nAs virtual particles have real mass but off-shell momenta, and \nmultiparticle states are always composed of on-shell particles only, \nit is impossible to represent a virtual particle by means of states. \nStates involving virtual particles cannot be created for lack of \ncorresponding creation operators in the theory.\nA description of decay requires an associated S-matrix, but the in- \nand out- states of the S-matrix formalism are composed of on-shell \nstates only, not involving any virtual particle. (Indeed, this is the \nreason for the name ''virtual''.)\nFor lack of a state, virtual particles cannot have any of the usual \nphysical characteristics such as dynamics, detection probabilities, \nor decay channels. How then can one talk about their probability of \ndecay, their life-time, their creation, or their decay? One cannot, \nexcept figuratively!\n\nVirtual states.\n(added on March 19, 2012):\nIn nonrelativistic scattering theory, one also meets the concept \nof virtual states, denoting states of real particles on the second \nsheet of the analytic continuation, having a well-defined but purely \ninmaginary energy, defined as a pole of the S-matrix. See, e.g., Thirring, \nA course in Mathematical Physics, Vol 3, (3.6.11). \nThe term virtual state is used with a different meaning in virtual \nstate spectroscopy (see, e.g., \nhttp://people.bu.edu/teich/pdfs/PRL-80-3483-1998.pdf), and denotes \nthere an unstable energy level above the dissociation threshold. \nThis is equivalent with the concept of a resonance. \nVirtual states have nothing to do with virtual particles, which have \nreal energies but no associated states, though sometimes the name \n''virtual state'' is associated to them. See, e.g., \nhttps://researchspace.auckland.ac.nz/bitstream/handle/2292/433/02whole.pdf; \nthe author of this thesis explains on p.20 why this is a misleading \nterminology, but still occasionally uses this terminology in his work.\n\nWhy are virtual particles often confused with unstable particles?\nAs we have seen, unstable particles and resonances are observable and \ncan be characterized quantitatively in terms of states.\nOn the other hand, virtual particles lack a state and hence have no \nmeaningful physical properties.\nThis raises the question why virtual particles are often confused with \nunstable particles, or even identified. \nThe reason, I believe, is that in many cases, the dominant contribution \nto a scattering cross section exhibiting a resonance comes from the \nexchange of a corresponding virtual particle in a Feynman diagram \nsuggestive of a collection of world lines describing particle creation \nand annihilation. (Examples can be seen on the Wikipedia page for W and \nZ bosons, http://en.wikipedia.org/wiki/Z-boson.)\nThis space-time interpretation of Feynman diagrams is very tempting \ngraphically, and contributes to the popularity of Feynman diagrams \nboth among researchers and especially laypeople, though some authors \n- notably Weinberg in his QFT book - deliberately resist this \ntemptation.\nHowever, this interpretation has no physical basis. Indeed, a single \nFeynman diagram usually gives an infinite (and hence physically \nmeaningless) contribution to the scattering cross section. The finite, \nrenormalized values of the cross section are obtained only by summing \ninfinitely many such diagrams. This shows that a Feynman diagram \nrepresents just some term in a perturbation calculation, and not a \nprocess happening in space-time. Therefore one cannot assign physical \nmeaning to a single diagram but at best to a collection of infinitely \nmany diagrams. \n\nThe true meaning of virtual particles.\nFor anyone still tempted to associate a physical meaning to virtual \nparticles as a specific quantum phenomenon, let me note that \nFeynman-type diagrams arise in any perturbative treatment of \nstatistical multiparticle properties, even classically, as any textbook \nof statistical mechanics witnesses. \nMore specifically, the paper \nhttp://homepages.physik.uni-muenchen.de/~helling/classical_fields.pdf\nshows that the perturbation theory for any classical field theory \nleads to an expansion into Feynman diagrams very similar to those for quantum field theories, except that only tree diagrams occur. If the picture of virtual particles derived from Feynman diagrams had any intrinsic validity, one should conclude that associated to every classical field there are classical virtual particles behaving just like their quantum analogues, except that (due to the lack of loop diagrams) there are no virtual creation/annihilation patterns.\nBut in the literature, one can find not the slightest trace of a suggestion that classical field theory is sensibly interpreted in terms of virtual particles. \nThe reaon for this similarity in the classical and the quantum case is that  Feynman diagrams are nothing else than a graphical notation \nfor writing down products of tensors with many indices summed via the \nEinstein summation convention. The indices of the results are the \nexternal lines aka ''real particles'', while the indices summed over \nare the internal lines aka ''virtual particles''. As such sums of \nproducts occur in any multiparticle expansion of expectations, \nthey arise irrespective of the classical or quantum nature of the \nsystem.\n\n(added September 29, 2012)\nInterpreting Feynman diagrams.\nInformally, especially in the popular literature, virtual paricles are \nviewed as transmitting the fundamental forces in quantum field theory.\nThe weak force is transmitted by virtual Zs and Ws. The strong force \nis transmitted by virtual gluons. The electromagnetic force is \ntransmitted by virtual photons. This ''proves'' the existence of \nvirtual particles in the eyes of their aficionados.\nThe physics underlying this figurative speech are Feynman diagrams,\nprimarily the simplest tree diagrams that encode the low order \nperturbative contributions of interactions to the classical limit of \nscattering experiments. (Thus they are really a manifestation of \nclassical perturbative field theory, not of quantum fields.\nQuantum corrections involve at least one loop.)\nFeynman diagrams describe how the terms in a series expansion of the \nS-matrix elements arise in a perturbative treatment of the interactions \nas linear combinations of multiple integrals. Each such multiple \nintegral is a product of vertex contributions and propagators, and each \npropagator depends on a 4-momentum vector that is integrated over.\nIn additon, there is a dependence on the momenta of the ingoing \n(prepared) and outgoing (in principle detectable) particles.\nThe structure of each such integral can be represented by a Feynman \ndiagram. This is done by associating with each vertex a node of the \ndiagram and with each momentum a line; for ingoing momenta an external \nline ending in a node, for outgoing momenta an external line starting \nin a node, and for propagator momenta an internal line between two \nnodes. \nThe resulting diagrams can be given a very vivid but superficial \ninterpretation as the worldlines of particles that undergo a \nmetamorphosis (creation, deflection, or decay) at the vertices.\nIn this interpretation, the in- and outgoing lines are the worldlines \nof the prepared and detected particles, respectively, and the others \nare dubbed virtual particles, not being real but required by this\ninterpretation. This interpretation is related to - and indeed \nhistorically originated with - Feynman's 1945 intuition that all \nparticles take all possible paths with a probability amplitute given \nby the path integral density. Unfortunately, such a view is naturally \nrelated only to the formal, unrenormalized path integral. But there all \ncontributions of diagrams containing loops are infinite, defying a \nprobability interpretation.\nAccording to the definition in terms of Feynman diagrams, a virtual \nparticle has specific values of 4-momentum, spin, and charges, \ncharacterizing the form and variables in its defining propagator.\nAs the 4-momentum is integrated over all of $R^4$, there is no mass \nshell constraint, hence virtual particles are off-shell.\nBeyond this, formal quantum field theory is unable to assign any \nproperty or probability to a virtual particle. This would require to \nassign to them states, for which there is no place in the QFT formalism.\nHowever, the interpretation requires them to exist in space and time, \nhence they are attributed by inmagination with all sorts of miraculous \nproperties that complete the picture to something plausible. (See, for \nexample, the \nWikipedia article on virtual particles.)\nBeing dressed with a fuzzy notion of quantum fluctuations, where the \nHeisenberg uncertainty relation allegedly allows one to borrow for a \nvery short time energy from the quantum bank, these properties have a \nsuperficial appearance of being scientific.\nBut they are completely unphysical as there is neither a way to test \nthem experimentally nor one to derive them from formal properties of \nvirtual particles. \nThe long list of manifestations of virtual particles mentioned in the \nWikipedia article cited are in fact manifestations of computed \nscattering matrix elements.\nThey manifest the correctness of the formulas for the multiple \nintegrals associated with Feynman diagrams, but not the validity of \nthe claims about virtual particles.\nThough QFT computations generally use the momentum representation, \nthere is also a (physically useless) Fourier-transformed complementary \npicture of Feynman diagrams using space-time positions in place of \n4-momentaa. In this version, the integration is over all of space-time, \nso virtual particles now have space-time positions but no dynamics, \nhence no world lines. (In physics, dynamics is always tied to states \nand an equation of motion. No such thing exists for virtual particles.) \n\nCan one distinguish real and virtual photons?\nThere is a widespread view that external legs of Feynman diagrams are \nin reality just internal legs of larger diagrams. This would blur the \ndistinction between real and virtual particles, as in reality, every \nleg is internal. \nThe basic argument behind this view is the fact that the photons that \nhit an eye (and this give evidence of something real) were produced by \nexcitation form some distant object. This view is consistent with \nregarding the creation or destruction of photons as what happens at a \nvertex containing a photon line. In this view, it follows that the \nuniverse is a gigantic Feynman diagram with many loops of which we and \nour experiments are just a tiny part.\nBut single Feynman diagrams don't have a technical meaning. Only the \nsum of all Feynman diagrams has predictive value, and the small ones \ncontribute most - otherwise we couldn't do any perturbative \ncalculations. \nMoreover, this view contradicts the way QFT computations are actually \nused. Scattering matrix elements are always considered between on-shell \nparticles. Without exception, comparisons of QFT results with \nscattering experiments are based on these on-shell results. \nIt must necessarily be so, as off-shell matrix elements don't make \nformal sense:\nMatrix elements are taken between states, and all physical states are \non-shell by the basic structure of QFT. Thus thestructure of QFT itself \nenforces a fundamental distinction between real particles representable \nby states and virtual particles representable by propagators only.\nThe basic problem invalidating the above argument is the assumption \nthat creation and desctruction of particles in space and time can be \nidentified with vertices in Feynman diagrams. They cannot. For Feynman \ndiagrams lack any dynamical properties, and their interpretation in \nspace and time is sterile. \nThus the view that in reality there are no external lines is based on\na superficial, tempting but invalid identification of theoretical \nconcepts with very different properties.\nThe conclusion is that, indeed, real particles (represented by external legs) \nand virtual particles (represented by internal legs) are completely separate conceptual entities, clearly distinguished by their meaning. In particular, never turns one into the other or affects one the other.", "meta": {"post_id": 4349, "input_score": 52, "output_score": 69, "post_title": "Are W & Z bosons virtual or not?"}}
{"input": "I've read some papers recently that talk about gapped Hamiltonians or gapless systems, but what does it mean?\nEdit: Is an XX spin chain in a magnetic field gapped? Why or why not?", "output": "This is actually a very tricky question, mathematically. Physicists  may think this question to be trivial. But it takes me one hour in a math summer school to explain the notion of gapped Hamiltonian.\nTo see why it is tricky, let us consider the following statements. Any physical\nsystem have a finite number of degrees of freedom (assuming the universe is finite). Such physical\nsystem is described by a Hamiltonian matrix with a finite dimension.\nAny Hamiltonian matrix with a finite dimension has a discrete spectrum.\nSo all the physical systems (or all the Hamiltonian) are gapped.\nCertainly, the above is not what we mean by \"gapped Hamiltonian\" in physics.\nBut what does it mean for a Hamiltonian to be gapped?\nSince a gapped system may have gapless excitations at boundary, so\nto define  gapped Hamiltonian, we need to put the Hamiltonian on a space with no boundary. Also, system with certain sizes may contain non-trivial excitations\n(such as spin liquid state of spin-1/2 spins on a lattice with an ODD number of sites), so we have to specify that the system have a certain sequence of sizes as we take the thermodynamic limit.\nSo here is a definition of \"gapped Hamiltonian\" in physics:\nConsider a system on a closed space, if there is a sequence of sizes\nof the system $L_i$, $L_i\\to\\infty$ as $i \\to \\infty$,\nsuch that the size-$L_i$ system on closed space has the following \"gap property\", then the system is said to be gapped. \nNote that the notion of  \"gapped Hamiltonian\" cannot be even defined for a single Hamiltonian. It is a properties of a sequence of Hamiltonian\nin the large size limit.\nHere is the definition of the \"gap property\":\nThere is a fixed $\\Delta$ (ie independent of $L_i$) such that the \nsize-$L_i$ Hamiltonian has no eigenvalue in an energy window of size $\\Delta$.\nThe number of eigenstates below the energy window does not depend on\n$L_i$, the energy splitting of those eigenstates below the energy window\napproaches zero as $L_i\\to \\infty$.\nThe number eigenstates below the energy window becomes the ground state degeneracy of the gapped system.\nThis is how the ground state degeneracy of a topological ordered state\nis defined.\nI wonder, if some one had consider the definition of gapped many-body system very carefully, he/she might discovered the notion on topological order mathematically.", "meta": {"post_id": 4930, "input_score": 61, "output_score": 101, "post_title": "What does it mean for a Hamiltonian or system to be gapped or gapless?"}}
{"input": "In all the discussions about how the heavy elements in the universe are forged in the guts of stars and especially during a star's death, I usually hear that once the star begins fusing lighter atoms to produce iron (Fe) that's the end of the star's life and the whole system collapses onto itself; and based on how massive the star was initially, it has different outcome - like a white dwarf, a neutron star or a black hole.\nI have rarely heard a detailed explanation of how the elements heavier than iron are produced. I would appreciate a convincing explanation of this process.", "output": "Elements heavier than iron are produced mainly by neutron-capture inside stars, or during neutron star mergers (see below, although there are other more minor contributors cosmic ray spallation, radioactive decay). The reason for this is that fusion producing elements beyond iron is strongly disfavoured by (i) the large Coulomb barrier and (ii) that if temperatures get high enough to circumvent the Coulomb barrier, then photons in the gas will have enough energy to disintegrate nuclei. Neutron capture faces no Coulomb barrier.\nThe elements beyond iron are not only produced in stars that explode as supernovae. This has now been established fact since the detection of short-lived Technetium in the atmospheres of red giant and AGB stars in the 1950s (e.g. Merrill 1952), and it requires continual correction of this pop-sci claim more than 60 years later (e.g. here).\nThe r-process\nNeutron capture can occur rapidly (the r-process). Rapid here, means the neutron capture timescale is short compared with the decay timescale of the products. This process occurs could inside and during supernova explosions but perhaps more readily during the merger of neutron stars. The free neutrons in a supernova are created by electron capture in the final moments of core collapse. At the same time this can lead to the build up of neutron-rich nuclei and the decay products of these lead to many of the chemical elements heavier than iron once they are ejected into the interstellar medium during the supernova explosion.\nIn neutron star mergers, the sources of free neutrons is rather obvious, but the seed nuclei are also present in abundance in the neutron star crust and in fact the release of this material into a low-density environment means that much of this neutron-rich material will in any case decay into more familiar heavy elements.\nThe r-process is almost exclusively responsible for elements heavier than lead and contributes to the abundances of many elements between iron and lead. Rapid neutron capture will \"stall\" once nuclei are produced with magic numbers of neutrons (50, 82, 126) in closed shells. These nuclei will however be far from the valley of stability and they beta-decay back to a position in this valley such that there are three peaks in abundance for stable elements with atomic mass about $\\sim 5-10$ below nuclei with magic numbers of neutrons on the stability line (produced in the s-process, see below).\nThere is still ongoing debate about the site of the primary r-process. My judgement from a scan of recent literature is that whilst core-collapse supernovae proponents were in the majority, there is a growing case to be made that neutron star mergers may become more dominant, particularly for the r-process elements with $A>110$ (e.g. Berger et al. 2013; Tsujimoto & Shigeyama 2014). In fact some of the latest research I have found suggests that the pattern of r-process elemental abundances in the solar system could be entirely produced by neutron star mergers (e.g. Wanajo et al. 2004), though models of core-collapse supernovae that incorporate magneto-rotational instabilities or from rapidly-rotating \"collapsar\" models, also claim to be able to reproduce the solar-system abundance pattern (Nishimura et al. 2017). Since, the merger of neutron stars takes some time (perhaps $\\geq 100$ million years) then sone supernova contribution may be necessary to explain the enhanced r-process abundances (particularly Europium) found in some very old halo stars (see for example Brauer et al. 2020).\nSignificant new information on this debate comes from observations of kilonovae and in particular, the spectacular confirmation, in the form of GW170817, that kilonovae can be produced by the merger of two neutron stars. Observations of the presumably neutron-rich ejecta, have confirmed the opacity signature (rapid optical decay, longer IR decay and the appearance of very broad absorption features) that suggest the production of lanthanides and other heavy r-process elements (e.g. Pian et al. 2017; Chornock et al. 2017). Whether neutron star mergers are the dominant source of r-process elements awaits an accurate assessment of how frequently they occur and how much r-process material is produced in each event - both of which are uncertain by factors of a few at least.\nA paper by Siegel (2019) reviews the merits of neutron star merger vs production of r-process elements in rare types of core collapse supernovae (aka \"collapsars\"). Their conclusion is that collapsars are responsible for the majority of the r-process elements in the Milky Way and that neutron star mergers, whilst probably common enough, do not explain the r-process enhancements seen in some very old halo stars and dwarf galaxies and the falling level of europium (an r-process element) to Iron with increased iron abundance - (i.e. the Eu behaves like the \"alpha\" elements - oxygen and neon that are produced in supernovae).\nThe debate continues...\nThe s-process\nHowever, many of the chemical elements heavier than iron are also produced by slow neutron capture - where the neutron capture rate timescale is on general longer (hundreds or even thousands of years) than product decay timescales; the so-called s-process. The free neutrons for these low-flux, neutron-capture events come from alpha particle reactions with carbon 13 (inside asymptotic giant branch [AGB] stars with masses of 1-8 solar masses) or neon 22 in giant stars above 10 solar masses. After a neutron capture, a neutron in the new nucleus may then beta decay, thus creating a nucleus with a higher mass number and proton number. A chain of such events can produce a range of heavy nuclei, starting with iron-peak nuclei as seeds. Examples of elements produced mainly in this way include Sr, Y, Rb, Ba, Pb and many others. Proof that this mechanism is effective is seen in the massive overabundances of such elements that are seen in the photospheres of AGB stars. A clincher is the presence of Technetium in the photospheres of some AGB stars, which has a short half life and therefore must have been produced in situ.\nNuclei with magic numbers of neutrons prove particularly stable, so there is a \"pile-up\" in the abundances of s-process elements in the valley of stability associated with the three magic numbers, e.g.,  Sr-88 (N=50), Ba-138 (N=82), Pb-208, Bi-209 (N=126).\nAccording to Pignatari et al. (2010), models suggests that the s-process in high mass stars (that will become supernovae) dominates the s-process production of elements with $A<90$, but for everything else up to and including Lead the s-process elements are mainly produced in modest sized AGB stars that never become supernovae. The processed material is simply expelled into the interstellar medium by mass loss during thermal pulsations during the AGB phase.\nThe overall picture\nAs a further addition, just to drive home the point that not all heavy elements are produced by supernovae, here is a plot from the epic review by Wallerstein et al. (1997), which shows the fraction of the heavy elements in the solar system that are produced in the r-process (i.e. an upper limit to what is produced in supernovae explosions). Note that this fraction is very small for some elements (where the s-process dominates), but that the r-process produces everything beyond lead.\n\nA more up-to-date visualisation of what goes on (produced by Jennifer Johnson) and which attempts to identify the sites (as a percentage) for each chemical element is shown below. It should be stressed that the details are still subject to a lot of model-dependent uncertainty.\n\nAn even more recent version of this diagram is provided by Arcones & Thielemann (2022). If you look carefully there are some minor differences between these two diagrams (e.g. Bi).", "meta": {"post_id": 7131, "input_score": 45, "output_score": 68, "post_title": "What is the origin of elements heavier than iron?"}}
{"input": "I have been studying scattering theory in Sakurai's quantum mechanics.  The phase shift in scattering theory has been a major conceptual and computational stumbling block for me.\nHow (if at all) does the phase shift relate to the scattering amplitude?\nWhat does it help you calculate?\nAlso, any literature or book references that might be more accessible than Sakurai would be greatly appreciated.", "output": "Suppose you treat scattering of a particle in a central potential. This means that the Hamiltonian $H$ commutes with the angular momentum operators $L^2$ and $L_z$. Hence, you can find simultaneous eigenfunctions $\\psi_{k,l,m}$. \nYou might know, for example from the solution of the hydrogen atom, that these functions can be expressed in terms of the spherical harmonics:\n$$\\psi_{k,l,m}(x) = R_{k,l}(r) \\Psi_m^l(\\theta, \\varphi)$$\nwhere the radial part satisfies\n$$\\frac{1}{r^2} \\frac{d}{dr} \\left( r^2 \\frac{dR_{k,l}}{dr}\\right)\n+\\left(n^2 - U(r) - \\frac{l(l+1)}{r^2}\\right) R_{k,l} = 0$$\nwith $U(r) = 2m/\\hbar^2 V(r)$, your central potential, and $k$ is the particle's wavenumber, i.e., $E = \\frac{\\hbar^2 k^2}{2m}.$\nThe first step is to look for a special case with simple solutions. This would be the free particle, with $U(r) = 0$. Then, the radial equation is a special case of Bessel's equation. The solutions are the spherical Bessel functions $j_l(kr)$ and $n_l(kr)$, where the $j_l$ are regular at the origin whereas the $n_l$ are singular at the origin. Hence, for a free particle, the solutions are superpositions of the $j_l$:\n$$\\psi(x) = \\sum_{l,m} a_{l,m} j_l(kr) Y^l_m(\\theta, \\varphi)$$\nIf we also have axial symmetry, only $m = 0$ is relevant. Then we can rewrite the spherical harmonics using Legendre polynomials. This will lead to\n$$\\psi(x) = \\sum_{l,m} A_{l} j_l(kr) P_l(\\cos \\theta)$$\nOne important special case of such an expansion is the Rayleigh plane wave expansion\n$$e^{ikz} = \\sum_l (2l+1) i^l j_l(kr) P_l(\\cos\\theta)$$\nwhich we will need in the next step.\nWe move away from free particles and consider scattering from a potential with a finite range (this excludes Coulomb scattering!). So, $U(r) = 0$ for $r > a$ where $a$ is the range of the potential. For simplicity, we assume axial symmetry. Then, outside the range, the solution must be again that of a free particle. But this time, the origin is not included in the range, so we can (and, in fact, must) include the $n_l(kr)$ solutions to the Bessel equations:\n$$\\psi(r) = \\sum_l (a_l j_l(kr) + b_l n_l(kr)) P_l(\\cos \\theta)$$\nNote how the solution for a given $l$ has two parameters $a_l$ and $b_l$. We can think of another parametrization: $a_l = A_l \\cos\\delta_l$ and $b_l = -A_l \\sin \\delta_l$. The reason for doing this becomes apparent in the next step:\nThe spherical Bessel functions have long range approximations:\n$$j_l(kr) \\sim \\frac{\\sin(kr - l\\pi/2)}{kr}$$\n$$n_l(kr) \\sim \\frac{\\cos(kr - l\\pi/2)}{kr}$$\nwhich we can insert into the wavefunction to get a long range approximation. After some trigonometry, we get\n$$\\psi(r) \\sim \\sum_l \\frac{A_l}{kr} \\sin(kr - l\\pi/2 + \\delta_l) P_l(\\cos \\theta)'$$\nSo, this is what our wavefunction looks like for large $r$. But we already know how it should look: if the incoming scattered particle is described as a plane wave in $z$-direction, it is related to the scattering amplitude $f$ via\n$$\\psi(\\vec{x}) \\sim e^{ikz} + f(\\theta) \\frac{e^{ikr}}{r}.$$\nObviously, both forms for writing down a long-range approximation for $\\psi$ should give the same, so we use the Rayleigh plane wave expansion to rewrite the latter form. We also rewrite the $\\sin$ function using complex exponentials. The ensuing calculations are a bit tedious, but not complicated in itself. You just insert the expansions. What we can do afterwards is comparing the coefficients in both expressions for the same terms, e.g. equation the coefficients for $e^{-ikr}P_l(\\cos\\theta)$ will give you\n$$A_l = (2l+1)i^l e^{i\\delta_l}$$\nwhereas equating coefficients for $e^{ikr}$ gives you\n$$f(\\theta) = \\frac{1}{2ik} \\sum_l (2l+1) \\left( e^{2i\\delta_l} - 1 \\right) P_l(\\cos \\theta).$$\nInterpretation of the Phase Shift: Remember the long range limit of the wavefunction. It led to an expression for the $l$-th radial wavefunction in the long-range of\n$$u_l(r) = kr\\psi_l(r) \\sim A_l \\sin(kr - l\\pi/2 +\\delta_l).$$\nFor a free particle, the phase shift $\\delta_l$ would be $0$. One could therefore say that the phase shift measures how far the asymptotic solution of your scattering problem is displaced at the origin from the asymptotic free solution.\nInterpretation of the Partial Wave Expansion: In the literature, you will often come across terms such as $s$-wave scattering. The partial wave expansion decomposes the scattering process into the scattering of incoming waves with definite angular momentum quantum number. It explains in which way $s$-, $p$-, $d$-waves etc. are affected by the potential. For low energy scattering, only the first few $l$-quantum numbers are affected. If all but the first term are discarded, only the $s$-waves take part in the scattering process. This is an approximation that is, for example, made in the scattering of the atoms in a Bose-Einstein condensate.", "meta": {"post_id": 8132, "input_score": 39, "output_score": 53, "post_title": "Phase shifts in scattering theory"}}
{"input": "Is it energy?\nIs it energy per unit volume?\nIs it energy per unit time i.e power?\nWhat is it?", "output": "I'll try to give an answer in purely classical thermodynamics.\nSummary\nHeat is a way of accounting for energy transfer between thermodynamic systems.  Whatever energy is not transferred as work is transferred as heat.  If you observe a thermodynamic process and calculate that system A lost $Q$ calories of heat, this means that if the environment around system A were replaced with $Q$ grams of water at $14\\sideset{^{\\circ}}{}{\\mathrm{C}}$ and the process were repeated, the temperature of that water would rise to $15\\sideset{^{\\circ}}{}{\\mathrm{C}}$.\nEnergy\nEnergy is a number associated with the state of a system.  It can be calculated if you give the state variables - things like mass, temperature, chemical composition, pressure, and volume.  (These state variables are not all independent, so you only need to give some combination of them.)\nSometimes the energy can be accounted very simply.  For an ideal gas, the energy is simply proportional to the temperature, number of molecules, and number of dimensions.  For a system with interesting chemistry, internal stresses and deformation, gravitational potential, etc. the energy may be more complicated.  Essentially, we get to invent the formulas for energy that are most useful to us.\nThere's a nice overview of energy in The Feynman Lectures, here.  For a more theoretical point of view on where these energy formulas come free, see Lubos Motl's answer here.\nEnergy Conservation\nAs long as we make the right definitions of energy, it turns out that energy is conserved.\nSuppose we have an isolated system.  If it is not in equilibrium, its state may change.  Energy conservation means that at the end of the change, the new state will have the same energy.  (For this reason, energy is often treated as a constraint.  For example, an isolated system will maximize its entropy subject to the constraint that energy is conserved.)\nThis leaves the question of what an isolated system is.  If we take another system (the environment) and keep it around the isolated system, we find no observable changes in the environment as the state of the isolated system changes.  For example, changes in an isolated system cannot change the temperature, pressure, or volume of the environment.  Practically, an isolated system should have no physical mechanisms for interacting with the rest of the universe.  Matter and radiation cannot leave or enter, and there can be no heat conduction (I'm jumping the gun on that last one, of course, but take \"heat conduction\" as a rough term for now).  A perfectly isolated system is an idealization only.\nNext we observe systems A and B interacting.  Before the interaction, A has 100 joules of energy.  After interacting, A has 90 joules of energy, so it has lost 10 joules.  Energy conservation says that if we measure the energy in system B before and after the interaction, we will always find that system B has gained 10 joules of energy.  In general, system B will always gain exactly however much system A loses, so the total amount is constant.\nThere are nuances and caveats to energy conservation.  See this question, for example.\nWork\nWork is defined by\n$$\\textrm{d}W = P\\textrm{d}V$$\n$P$ is pressure; $V$ is volume, and it is fairly easy to give operational definitions of both.\nUsing this equation, we must ensure that $P$ is the pressure the environment exerts on the system.  For example, if we took a balloon into outer space, it would begin expanding.  However, it would do no work because the pressure on the balloon is zero.  However, if the balloon expands on Earth, it does work given by the product of its volume change and the atmospheric pressure.\nThat example treats the entire balloon as the system.  Instead, we might think of only the air inside the balloon as a system.  Its environment is the rubber of the balloon.  Then, as the balloon expands in outer space, the air inside does work against the pressure from the elastic balloon.\nI wrote more about work in this answer.\nAdiabatic Processes\nWork and energy, as described so far, are independent ideas.  It turns out that in certain circumstances, they are intimately related.\nFor some systems, we find that the decrease in energy of the system is exactly the same as the work it does.  For example, if we took that balloon in space and watched it expand, the air in the balloon would wind up losing energy as it expanded.  We'd know because we measure the temperature, pressure, and volume of the air before and after the expansion and calculate the energy change from a formula.\nMeanwhile, the air would have done work on the balloon.  We can calculate this work by measuring the pressure the balloon exerts on the air and multiplying by the volume change (or integrating if the pressure isn't constant).\nRemarkably, we could find that these two numbers, the work and the energy change, always turned out to be exactly the same except for a minus sign.  Such a process is called adiabatic.\nIn reality, adiabatic processes are approximations.  They work best with systems that are almost isolated, but have a limited way of interacting with the environment, or else occur too quickly for interactions beside pressure-volume ones to be important.\nIn our balloon, the expansion might fail to be adiabatic due to radiation or conduction between the balloon and the air.  If the balloon were a perfect insulator and perfectly white, we'd expect the process to be adiabatic.\nSound waves propagate essentially adiabatically, not because there are no mechanisms for one little mass of air to interact with nearby ones, but because those mechanisms (diffusion, convection, etc.) are too slow to operate on the time scale of the period of a sound wave (about a thousandth of a second).\nThis leads us to thinking of work in a new way.  In adiabatic processes, work is the exchange of energy from one system to another.  Work is still calculated from $P\\textrm{d}V$, but once we calculate the work, we know the energy change.\nHeat\nReal processes are not adiabatic.  Some are close, but others are not close at all.  For example, if I put a pot of water on the stove and turn on the burner, the water's volume hardly changes at all, so the work done as the water heats is nearly zero, and what work is done by the water is positive, meaning the water should lose energy.\nThe water actually gains a great deal of energy, though, which we can discover by observing the temperature change and using a formula for energy that involves temperature.  Energy got into  the pot, but not by work.\nThis means that work is not a sufficient concept for describing energy transfer.  We invent a new, blanket term for energy transfer that is not done by work.  That term is \"heat\".\nHeat is simply any energy transferred between two systems by means aside from work.  The energy entering the boiling pot is entering by heat.  This leads to the thermodynamic equation\n$$\\textrm{d}E = -\\textrm{d}W + \\textrm{d}Q$$\n$E$ is energy, $W$ work, and $Q$ heat.  The minus sign is a convention.  It says the if a system does work, it loses energy, but if it receives heat, it gains energy.\nInterpreting Heat\nI used to be very confused about heat because it felt like something of a deus ex machina to say, \"all the leftover energy must be heat\".  What does it mean to say something has \"lost 30 calories through heat\"?  How can you look at it and tell?  Pressure, temperature, volume are all defined in terms of very definite, concrete things, and work is defined in terms of pressure and volume.  Heat seems too abstract by comparison.\nOne way to get a handle on heat, as well as review everything so far, is to look at the experiments of James Joule.  Joule put a paddle wheel in a tub of water, connected the wheel to a weight so that the weight would drive the wheel around, and let the weight fall.  Here's the Wikipedia picture of the set up:$\\hspace{100px}$.\nAs the weight fell, it did work on the water; at any given moment, there was some pressure on the paddles, and they were sweeping out a volume proportional to their area and speed.  Joule assumed that all the energy transferred to the water was transferred by work.\nThe weights lost energy as they fell because their gravitational potential energy went down.  Assuming energy is conserved, Joule could then find how much energy went into the water.  He also measured the temperature of the water.  This allowed him to find how the energy of water changes as its temperature changes.\nNext suppose Joule starting heating the water with a fire.  This time the energy is transferred as heat, but if he raises the temperature of the water over exactly the same range as in the work experiment, then the heat transfer in this trial must be the same as the work done in the previous one.  So we now have an idea of what heat does in terms of work.  Joule found that it takes 4.2 joules of work to raise the temperature of one gram of water from $14\\sideset{^{\\circ}}{}{\\mathrm{C}}$ to $15\\sideset{^{\\circ}}{}{\\mathrm{C}}$.  If you have more water than that, it takes more work proportionally.  4.2 joules is called one calorie.\nAt last we can give a physical interpretation to heat.  Think of some generic thermodynamic process.  Imagine it happening in a piston so that we can easily track the pressure and volume.  We measure the energy change and the work during the process.  Then we attribute any missing energy transfer to heat, and say \"the system gave up 1000 joules (or 239 calories) of heat\".  This means that if we took the piston and surrounded it with 239 grams of water at $14\\sideset{^{\\circ}}{}{\\mathrm{C}}$, then did exactly the same process, the water temperature would rise to $15\\sideset{^{\\circ}}{}{\\mathrm{C}}$.\nMisconceptions\nWhat I discussed in this post is the first law of thermodynamics - energy conservation.  Students frequently get confused about what heat is because they mix up its definition with the role it plays in the second law of thermodynamics, which I didn't discuss here.  This section is intended to point out that some commonly-said things about heat are either loose use of language (which is okay as long as everyone understands what's being said), or correct use of heat, but not directly a discussion of what heat is.\nThings do not have a certain amount of heat sitting inside them.  Imagine a house with a front door and a back door.  People can come and go through either door.  If you're watching the house, you might say \"the house lost 3 back-door people today\".  Of course, the people in the house are just people.  The door only describes how they left.  Similarly, energy is just energy.  \"Work\" and \"heat\" describe what mechanism it used to leave or enter the system.  (Note that energy itself is not a thing like people, only a number calculated from the state, so the analogy only stretches so far.)\nWe frequently say that energy is \"lost to heat\".  For example, if you hit the brakes on your car, all the kinetic energy seems to disappear.  We notice that the brake pads, the rubber in the tires, and the road all get a little hotter, and we say \"the kinetic energy of the car was turned into heat.\"  This is imprecise.  It's a colloquialism for saying, \"the kinetic energy of the car was transferred as heat into the brake pads, rubber, and road, where it now exists as thermal energy.\"\nHeat is not the same as temperature.  Temperature is what you measure with a thermometer.  When heat is transferred into a system, its temperature will increase, but its temperature can also increase because you do work on it.\nThe relationship between heat and temperature involves a new state variable, entropy, and is described by the second law of thermodynamics.  Statements such as \"heat flows spontaneously from hot bodies to cold bodies\" are describing this second law of thermodynamics, and are really statements about how to use heat along with certain state variables to decide whether or not a given process is spontaneous; they aren't directly statements about what heat is.\nHeat is not \"low quality energy\" because it is not energy.  Such statements are, again, discussion of the second law of thermodynamics.\nReference\nThis post is based on what I remember from the first couple of chapters in Enrico Fermi's Thermodynamics.", "meta": {"post_id": 8522, "input_score": 44, "output_score": 70, "post_title": "What exactly is heat?"}}
{"input": "What is the difference between implicit, explicit, and total time dependence, e.g. $\\frac{\\partial \\rho}{\\partial t}$ and $\\frac{d \\rho} {dt}$?\nI know one is a partial derivative and the other is a total derivative. But physically I cannot distinguish between them. I have a clue that my doubt really might be understanding the difference between implicit, explicit and  total time dependence.", "output": "I usually explain it this way:\n$$\\rho = \\rho(t,x(t),p(t))$$\n$$\\frac{\\partial\\rho}{\\partial t} = \\lim_{\\Delta t \\to 0} \\frac{\\rho(t+\\Delta t,x(t),p(t))-\\rho(t,x(t),p(t))}{\\Delta t}$$\n$$\\frac{d\\rho}{d t} = \\lim_{\\Delta t \\to 0} \\frac{\\rho(t+\\Delta t,x(t+\\Delta t),p(t+\\Delta t))-\\rho(t,x(t),p(t))}{\\Delta t}$$", "meta": {"post_id": 9122, "input_score": 60, "output_score": 66, "post_title": "What is the difference between implicit, explicit, and total time dependence, e.g. $\\frac{\\partial \\rho}{\\partial t}$ and $\\frac{d \\rho} {dt}$?"}}
{"input": "In classical mechanics with 3 space dimensions the orbital angular momentum is defined as\n$$\\mathbf{L} = \\mathbf{r} \\times \\mathbf{p}.$$\nIn relativistic mechanics we have the 4-vectors $x^{\\mu}$ and $p^{\\mu}$, but the cross product in only defined for 3 dimensions. So how to define orbital angular momentum e.g. in special relativity in terms of 4-vectors? Or more generally in $d$ dimensions?", "output": "Dear asmaier, you shouldn't view $\\vec L = \\vec x \\times \\vec p$ as a primary \"definition\" of the quantity but rather as a nontrivial result of a calculation.\nThe angular momentum is defined as the quantity that is conserved because of the rotational symmetry - and this definition is completely general, whether the physical laws are quantum, relativistic, both, or nothing, and whether or not they're mechanics or field theory.\nTo derive a conserved charge, one may follow the Noether's procedure that holds for any pairs of a symmetry and a conservation law:\n\nhttp://en.wikipedia.org/wiki/Noether_charge\n\nIn particular, the angular momentum has no problem to be evaluated in relativity - when the background is rotationally symmetric. The fact that you write $\\vec L$ as a vector is just a bookkeeping device to remember the three components. More naturally, even outside relativity, you should imagine\n$$ L_{ij} = x_i p_j - x_j p_i $$\ni.e. $L_{ij}$ is an antisymmetric tensor with two indices. Such a tensor, or 2-form, may be mapped to a 3-vector via $L_{ij} = \\epsilon_{ijk} L_k$ but it doesn't have to be. And in relativity, it shouldn't. So in relativity, one may derive the angular momentum $L_{\\mu\\nu}$ which contains the 3 usual components $yz,zx,xy$ (known as $x,y,z$ components of $\\vec L$) as well as 3 extra components $tx,ty,tz$ associated with the Lorentz boosts that know something about the conservation of the velocity of the center-of-mass.\nIncidentally, the general $x\\times p$ Ansatz doesn't get any additional \"gamma\" or other corrections at high velocities. It's because you may imagine that it's the generator of rotations, and rotations are translations (generated by $\\vec p$) that linearly depend on the position $x$. So the formula remains essentially unchanged. In typical curved backgrounds which still preserve the angular momentum, the other non-spatial components of the relativistic angular momentum tensor are usually not preserved because the background can't be Lorentz-boost-symmetric at the same moment.", "meta": {"post_id": 9864, "input_score": 35, "output_score": 47, "post_title": "How to define orbital angular momentum in other than three dimensions?"}}
{"input": "I've read on NASA's page on neutron star that one teaspoonful of that star would weigh over 20 billion tonnes on Earth. If it was somehow possible to bring it to earth would it:\n\nBurn and disappear during Earth atmosphere entry?\nAssuming we have 20 billion tonnes of mass occupying the volume of a teaspoon here on Earth, would it fall through the ground under its own weight?", "output": "If we take neutron star material at say a density of $\\sim 10^{17}$ kg/m$^{3}$ the neutrons have an internal kinetic energy density of $3 \\times 10^{32}$ J/m$^{3}$. This is calculated by multiplying the number density of the neutrons $n_n$ by, $3p_{f}^2/(10m_n)$, the average KE per fermion in a non-relativistically degenerate gas and where $p_f =(3h^3n_n/8\\pi)^{1/3}$ is the Fermi momentum.\nSo even in a teaspoonful (say 5 ml), there is $1.5\\times10^{27}$ J of kinetic energy (more than the Sun emits in a second, or a billion or so atom bombs) and this will be released instantaneously.\nThe energy is in the form of around $10^{38}$ neutrons travelling at around 0.1-0.2$c$. So roughly speaking it is like half the neutrons (about 250 million tonnes) travelling at 0.1$c$ ploughing into the Earth. If I have done my Maths right, that is roughly equivalent to a 40km radius near-earth asteroid hitting the Earth at 30 km/s.\nSo, falling through the Earth is not the issue - vapourising a significant chunk of it is.\nNote that the beta decay of the free neutrons that dominate the neutron material is also energetic, but a slow process. On these 10 minute timescales, the neutrons could have exploded to a radius of a tenth of an au.", "meta": {"post_id": 10052, "input_score": 31, "output_score": 41, "post_title": "What would happen to a teaspoon of neutron star material if released on Earth?"}}
{"input": "A similar question was asked here, but the answer didn't address the following, at least not in a way that I could understand.\nElectric charge is simple - it's just a real scalar quantity. Ignoring units and possible quantization, you could write $q \\in \\mathbb{R}$. Combination of electric charges is just arithmetic addition: $ q_{net} = q_1 + q_2 $.\nNow to color charge. Because there are three \"components\", I am tempted to conclude that color charges are members of $\\mathbb{R}^3$. However, I've read that \"red plus green plus blue equals colorless\", which seems to rule out this idea. I can only think that either:\n\nred, green and blue are not orthogonal, or\n\"colorless\" doesn't mean zero color charge (unlikely), or\ncolor charges don't combine in a simple way like vector addition\n\nIn formulating an answer, please consider that I know some mathematics (vectors, matrices, complex numbers, calculus) but almost nothing about symmetry groups or Lie algebras.", "output": "Color charge is the representation of the SU(3) gauge group. The representation theory of SU(3) is described below:\nThe basic representation is called the \"3\" or the fundamental, or defining, representation. It is a triplet of complex numbers $V^i$, which transform under a 3 by 3 SU(3) matrix by getting multiplied by the matrix. The value of \"i\" is sometimes called \"red\",\"green\",\"blue\", so that a quark which is all in the $V^1$ direction is red, etc. This is reasonable, because every fundamental representation vector is a linear combination with complex coefficient of red-green-blue.\nHermann Weyl proved that every other representation occurs somewhere among the tensors: $V^{i_1,i_2 .. i_n}_{j_1,j_2,...,j_m}$ where the upper indices transform by multiplying the index by the SU(3) matrix, and lower indices by multiplying by the conjugate matrix, which is also the inverse. Addition of representations is just like addition of angular momentum in quantum mechanics, by taking tensor products.\nWarm-up: Quick Representations SU(2)\nFor SU(2), the invariant tensors are $\\delta^i_j$, $\\epsilon_{ij}$, and $\\epsilon^{ij}$, which are trace and two-dimensional volume. You can raise and lower indices using $\\epsilon$ tensors, so every tensor representation is equivalent to one with all the indices down. Any three antisymmetric indices are necessarily zero, and any two antisymmetric indices can be deleted by contracting them with the appropriate epsilon tensor. So there are only clumps of symmetric indices in a representation.\nThe irreducible representations are exhausted by the fully symmetric tensors with all indices down:\n$$ T_{i_1, i_2 , .... i_n}$$\nBecause when you multiply two of these, you get a tensor\n$$ T_{i_1, i_2,....,i_n;j_1, j_2, ... j_n'}$$\nwith symmetry on permuting the first n indices and the last n' indices. I will write this as (n,n'). By contracting the $\\epsilon$ tensor on one of the i's and one of the j's (they all give the same result because they are symmetric), you extract an (n-1,n'-1) representation from this. The remainder is fully symmetric on n+n' indices, because you have removed the antisymmetric part. The result is the decomposition\n$$(n,n') = (n+n') + (n-1,n'-1)$$\nSo that, recursively, the tensor product of (n) and (n') decomposes into\n$$(n+n'), (n+n'-2), (n+n'-4), ... (1) or (0)$$\nwhere the last term is 1 if n+n' is odd, or 1 if n+n' is even. If you recognize that the n-index totally symmetric tensor with two possible values for each index has exactly n+1 different components, you realize that the (n) representation is just the spin (n/2) representation, and the decomposition above is the familiar Clebsch-Gordon series for addition of quantum angular momentum.\nThe tensorial method is never taught for some reason, but it is the quickest way to do Clebsch-Gordon decompositions in real life.\nBack to SU(3)\nSU(3) transformations preserve inner products, and 3-dimensional complex volumes, so there are three basic invariant tensors, $\\delta^i_j$, $\\epsilon_{ijk}$, and $\\epsilon^{ijk}$. The $\\epsilon$ tensors allow you to take the antisymmetric part on any two upper indices and turn it into a lower index, or the anyisymmetric part of two lower indices and turn it into an upper index.\nThe irreducible representations of SU(3) are all tensors\n$$ T^{i_1,i_2,....,i_n}_{j_1,j_2,...,j_m}$$\nwhich are fully symmetric on the upper indices, and fully symmetric on the lower indices. To see this, call this representation (n;m), and tensor two such representations to produce\n$$(n,n';m,m')$$\nWhich means n totally symmetric upper indices followed by n' totally symmetric upper indices, and m totally symmetric lower indices followed by m' totally symmetric lower indices.\nThen, acting the epsilon tensor between the n and n' clump produces\n$$(n,n'; 1,m,m')$$\nleaving behind $(n+n';m,m')$, since it takes away the antisymmetric part. The recursive rule is as ollows\n$$(n_1,...,n_k; m_1,,...,m_k) \\rightarrow $$\n$$ (n_1+n_2,n_3,...,n_k;m_1,...,m_k) \r\n \\oplus (n_1-1,n_2-1,n_3,...n_k; 1, m_1, ...,m_k)$$\n$$(n_1,...,n_k; m_1,....,m_k) \\rightarrow$$\n$$ (n1,...,n_k; m_1+m_2,m_3,...,m_k)\r\n\\oplus (1,n_1,...,n_k;m_1-1,m_2-1,...,m_k)$$\nThese rules correspond to acting with the two epsilon tensors, and they terminate on terms of the form (n;m) in a finite number of steps, because either thing on the right hand side either has a smaller number of clumps, or a smaller sum of indices. Decomposing the traces out of (n;m) gives all the irreducible representations.\nRemoving the traces\nAfter you reduce the tensors to (n;m), you get rid of all the trace parts, by subtracting $\\delta^i_j$ times an (n;m) tensor. This turns every (n,m) of the previous section into a series of trace-reduced (n-k;m-k) parts which go from k=0 to k=min(m,n). These tensors are the true irreducible representations.\nThe color charge is defined as the representation of SU(3) of the colored object. The representation is indexed by (n,m). The color-charge of an instance of the actual object is an n-list of rgb-rgb-..rgb values, where the order doesn't matter, and an m-list of cmy-cmy...-cmy colors, where the order doesn't matter. These are the basic colors, and you superpose them with arbitrary complex numbers, but imposing the trace condition, which is a little hard to state in RGB language--- it says that the sum of (r,LIST;c,LIST) + (g,LIST;m,LIST') + (b,LIST;y,LIST') is zero for any colors in LIST and LIST'.\nTo add two color charges, you use the procedure above for tensor products. The sum of two color charges is a complicated mixture of color-charges, given by decomposing the tensor representation.\nThese rules are relatively complicated, so be thankful that the only fundamental color representations in the world are quark fundamental triplets, and gluon one-up-index, one-down-index traceless tensors, and that all hadrons are singlets.", "meta": {"post_id": 10403, "input_score": 29, "output_score": 39, "post_title": "Mathematically, what is color charge?"}}
{"input": "The media are reporting the commercially sold 128-bit quantum computer from D-Wave\n\nhttp://news.google.com/news?ned=us&hl=us&q=d-wave+quantum&cf=all&scoring=n\n\nwhich of course sounds amazing. The gadget is described as something capable of doing quantum annealing\n\nhttp://en.wikipedia.org/wiki/Quantum_annealing\n\nwhich looks less convincing. I want to ask you what classes of problems the D-Wave computer can actually solve or perform. It can't run Shor's algorithm on 128 qubits, can it?", "output": "The DWave machine stirred up quite an amount on controversy in the community when it was first announces. The machine basically attempts to solve an NP-complete optimization problem (MAX-2SAT) by encoding it as a ground state of a Hamiltonian, and tries to reach this ground state by moving adiabatically to it from the ground state of an efficiently coolable Hamiltonian.\nIn general, the adiabatic algorithm is not known to be able to find ground states efficiently as the proximity of low lying levels to the ground state means that the transition between Hamiltonians has to be performed slowly, and the speed at which this can occur is governed by the gap between the ground state and the lowest excited levels. It is commonly believed within the community, but not proved, that no quantum algorithm can efficiently solve NP-complete problems.\nIn general the ground state of a Hamiltonian can be used to encode a wider variety of problems than NP (know QMA-complete problems), and so decision to focus on NP optimization problems has led to restrictions which prevent the device from being used for general purpose quantum computing (even if noise was not an issue). Thus you can't run Shor's algorithm on the device. Further, you -can- factor any number that you could fit on a 128 qubit device by classical means. The general number field sieve puts 128 bits within reach of modern personal computers.\nNoise is a real issue with DWave's device, and although there have been a number of technical papers from them playing down the issue and trying to demonstrate quantum effects, the coherence times for the individual qubits are much shorter than the time scale for the algorithm. Thus the common view within the community seems to be that this is basically an expensive classical special purpose computer.\nThere is an interesting subtlety as regards noise: If you add noise to the adiabatic algorithm, it degrades gracefully into one of the best classical algorithms for the same problem. Thus you can obtain the same result either way, and the only difference is in the assymptotics for large systems (which are obviously not observables). Thus even if they produce a valid answer for every problem you throw at such a device, this is not enough information to determine if you are actually performing quantum computation.\nLet me add that the adiabatic model can encode universal quantum computation, however the limitations of DWave's implementation means that specific machine cannot.", "meta": {"post_id": 10496, "input_score": 60, "output_score": 40, "post_title": "What can the D-Wave quantum computer do?"}}
{"input": "I am following the first volume of the course of theoretical physics by Landau. So, whatever I say below mainly talks regarding the first 2 chapters of Landau and the approach of deriving Newton's laws from Lagrangian principle supposing Hamilton's principle of extremum action. Please keep this view in mind while reading and answering my queries and kindly neglect the systems to which Action Principle is not applicable:\nIf we use homogeneity of space in Euler-Lagrange equations, we obtain a remarkable result i.e. the conservation of momentum for a closed system.\nNow, this result, using the form of Lagrange for a closed system of particles, transforms into $ \\Sigma F = 0 $ . Now, how from this can we conclude that the internal forces that particles exert come in equal and opposite pairs?\nIs it because for 2 particles this comes out as $ F_{1} + F_{2} = 0 $ and we take the forces exerted by particles on one other to be independent of other particles (i.e. Superposition Principle) as an experimental fact?\nI doubt it as whole of Newtonian Mechanics is derivable from Lagrangian Mechanics and supposed Symmetries. So, according to me, a fact like Newton's Third Law should be derivable from it without using an additional experimental fact.\nI have an idea to prove it rigorously. Consider two particles $i$ and $j$. Let the force on $i$ by $j$ be $F_{ij}$ and on $j$ by $i$ be $k_{ij}F_{ij}$. Now the condition becomes $\\Sigma (1+k_{ij})F_{ij}=0$ where the terms to be included and rejected in summation understood. As this must be true for any value of $F_{ij}$, we get $k_{ij}=-1$. I don't know if this argument or refinement of such an argument holds or not. I can see many questions arising in this argument and it's not very convincing to me.\nI would like to hear from you people as to if it is an experimental result used or not? If not, then is the method given above right or wrong? If wrong, how can we prove it?\nAddendum\nMy method of proof uses the fact of superposition of forces itself, so it is flawed. I have assumed that the coefficients $k_{ij}$ are constants and don't change in the influence of all other particles which is exactly what superposition principle says.\nAs the superposition of Forces can be derived by superposition of potential energies at a point in space and potential energy being more fundamental in Lagrangian Mechanics, I restate my question as follows:\nIs the principle of superposition of potential energies by different sources at a point in space derivable from the inside of Lagrangian Mechanics or is it an experimental fact used in Lagrangian Mechanics?\nI, now, doubt this to be derivable as the fundamental assumption about potential energy is only that it is a function of coordinates of particles and this function may or may not respect superposition.", "output": "The derivation in Landau and Lifschitz is making some additional implicit assumptions. They assume that all forces come from pair-interactions, and that the pair forces are rotationally invariant. With these two assumptions, the potential function in the Lagrangian is\n$$V(x_1,\\ldots,x_n) = \\sum_{\\langle i,j\\rangle} V(|x_i - x_j|)$$\nAnd then it is easy to prove Newton's third law, because the derivative of the distance function is equal and opposite for each pair of particles.\nThis type of derivation is reasonable from a physical point of view for macroscopic objects, but it is not mathematically ok, because it omits important examples.\nNo rotational invariance, no third law\nDropping the assumption of rotational invariance, but keeping the assumption of pair-wise interaction, one gets the following counterexample in 2 dimensions, with two particles (A,B) with position vectors $(A_x,A_y)$ $(B_x,B_y)$ respectively:\n$$V(A_x,A_y,B_x,B_y) = f(A_x-B_x) + f(A_y - B_y) $$\nwhere $f$ is any function other than $f(x)=x^2$. This pair potential leads to equal and opposite forces, but not collinear ones. Linear momentum and energy are conserved, but angular momentum is not, except when both particles are on the lines $y=\\pm x$ relative to each other. The potential is un-physical of course, in the absence of a medium like a lattice that breaks rotational invariance.\nMany-body direct interactions, no reflection symmetry, no third law\nThere is another class of counterexamples which is much more interesting, because they do not break angular momentum or center of mass conservation laws, and so they are physically possible interactions in vacuum, but they do break Newton's third law. This is the chiral three-body interaction.\nConsider 3 particles A,B,C in two dimensions whose potential function is equal to the signed area of the triangle formed by the points A,B,C.\n$$V(A,B,C) = B_x C_y - A_x C_y -B_x A_y - C_x B_y + C_x A_y + A_x B_y$$\nIf all 3 particles are collinear, the forces for this 3-body potential are perpendicular to the common line they lie on. The derivative of the area is maximum by moving the points away from the common line. So you obviously cannot write the force as any sum of pairwise interactions along the line of separation, equal and opposite or not. The forces and torques still add up to zero, since this potential is translationally and rotationally invariant.\nMany body direct interaction, spatial reflection symmetry, crappy third law\nIf the force on k particles is reflection invariant, it never gets out of the subspace spanned by their mutual separation. This is because if they lie in a lower dimensional subspace, the system is invariant with respect to reflections perpendicular to that subspace, so the forces must be as well.\nThis means that you can always cook up equal and opposite forces between the particles that add up to the total force, and pretend that these forces are physically meaningful. This allows you to salvage Newton's third law, in a way. But it gives nonsense forces.\nTo see that this is nonsense, consider the three-particle triangle area potential from before, but this time take the absolute value. The result is reflection invariant, but contains a discontinuity in the derivative when the particles become collinear. Near collinearity, the forces perpendicular have a finite limit. But in order to write these finite forces as a sum of equal and opposite contributions from the three-particles, you need the forces between the particles to diverge at collinearity.\nThree body interactions are natural\nThere is natural physics that gives such a three-body interaction. You can imagine the three bodies are connected by rigid frictionless struts that are free to expand and contract like collapsible antennas, and a very high-quality massless soap bubble is stretched between the struts. The soap bubble prefers to have less area according to its nonzero surface tension. If the dynamics of the soap bubble and the struts are fast compared to the particles, you can integrate out the soap bubble degrees of freedom and you will get just such a three-body interaction.\nThen the reason the bodies snap together near collinearity with a finite transverse force is clear--- the soap bubble wants to collapse to zero area, so it pulls them in. It is then obvious that there is no sense in which they have any diverging pairwise forces, or any pairwise forces at all.\nOther cases where you get three body interactions directly is when you have a non-linear field between the three objects, and the field dynamics are fast. Consider a cubically self-interacting massive scalar field (with cubic coupling $\\lambda$) sourced by classical stationary delta-function sources of strength g. The leading non-linear contribution to the classical potential is a tree-level, classical, three-body interaction of the form\n$$V(x,y,z) \\propto g^3 \\lambda \\int \\,\\mathrm d^3k_1\\mathrm  d^3k_2 { e^{i(k_1\\cdot (x-z) + k_2\\cdot(y-z))} \\over (k_1^2 + m^2) (k_2^2 + m^2)((k_1+k_2)^2 + m^2)}$$\nwhich heuristically goes something like ${e^{-mr_{123}}r_{123}\\over r_{12}r_{23}r_{13}}$ where the r's are the side lengths of the triangle and $r_{123}$ is the perimeter (this is just a scaling estimate). For nucleons, many body potentials are significant.\nThe forces from the crappy third law are not integrable\nIf you still insist on a Newton's third law description of three-body interactions like the soap bubble particles, and you give a pairwise force for each pair of particles which adds up to the full many-body interaction, these pairwise forces cannot be thought of as coming from a potential function. They are not integrable.\nThe example of the soap-bubble force makes it clear--- if A,B,C are nearly collinear with B between A and C, closer to A, you can slide B away from A towards C very very close to collinearity, and bring it back less close to collinear. The A-B force is along the line of separation, and it diverges at collinearity, so the integral of the force along this loop cannot be zero.\nThe force is still conservative of course, it comes from a three-body potential after all. This means that the two-body A-B force plus the two-body B-C force is integrable. It's just that the A-C two body force is not. So the separation is completely silly.\nAbsence of multi-body interactions for macroscopic objects in empty space\nThe interactions of macroscopic objects are through contact forces, which are necessarily pairwise since all other contacts are far away, and electromagnetic and gravitational fields, which are very close to linear at these scales. The electromagnetic and gravitational forces end up being linearly additive between pairs, and the result is a potential of the form Landau and Lifschitz consider--- pairwise interactions which are individually rotationally invariant.\nBut for close packed atoms in a crystal, there is no reason to ignore 3-body potentials. It is certainly true that in the nucleus three-body and four-body potentials are necessary, but in both cases you are dealing with quantum systems.\nSo I don't think the third law is particularly fundamental. As a philosophical thing, that nothing can act without being acted upon, it's as valid as any other general principle. But as a mathematical statement of the nature of interactions between particles, it is completely dated. The fundamental things are the conservation of linear momentum, angular momentum, and center of mass, which are independent laws, derived from translation invariance, rotational invariance, and Galilean invariance respectively. The pair-wise forces acting along the separation direction are just an accident.", "meta": {"post_id": 12122, "input_score": 25, "output_score": 41, "post_title": "Deriving Newton's Third Law from homogeneity of Space"}}
{"input": "Every once in a while, we get a question asking for a book or other educational reference on a particular topic at a particular level. This is a meta-question that collects all those links together. If you're looking for book recommendations, this is probably the place to start.\nAll the questions linked below, as well as others which deal with more specialized books, can be found under the tag resource-recommendations (formerly books).\nIf you have a question to add, please edit it in. However, make sure of a few things first:\n\nThe question should be tagged resource-recommendations\nIt should be of the form \"What are good books to learn/study [subject] at [level]?\"\nIt shouldn't duplicate a topic and level that's already on the list\n\nRelated Meta: Do we need/want an overarching books question?", "output": "Broad Interest\n\nPlease recommend a good book about physics for young child (elementary school aged)\nBooks that develop interest & critical thinking among high school students\nBooks that every layman should read\nBooks that every physicist should read\nA good highschool level physics book\nAre there modern 1st year university physics textbooks using old-schoool layout, i.e. no sidebars and smaller format?\n\nMathematics\n\nGeneral: Best books for mathematical background?\nBasic methods: Book recommendations for Fourier Series, Dirac Delta Function and Differential Equations?\nTensors: Learn about tensors for physics\nComplex analysis: Complex Variable Book Suggestion\nGroup theory: Comprehensive book on group theory for physicists?\nSpectral theory: Books for linear operator and spectral theory\nVariational calculus: Introductory texts for functionals and calculus of variation\nGeometry and topology: Book covering differential geometry and topology for physics\nAlgebraic geometry: Crash course on algebraic geometry with view to applications in physics\nDynamical systems/chaos: Self-study book for dynamical systems theory?\nFractals: Physics-oriented books on fractals\nDistribution theory: Resources for theory of distributions (generalized functions) for physicists\nStatistics: Rigorous error analysis theory\n\nMechanics\n\nIntroductory: Recommendations for good Newtonian mechanics and kinematics books\nIntroductory (for mathematicians): Which Mechanics book is the best for beginner in math major?\nFoundations: Book suggestions for foundation of Newtonian Mechanics\nLagrangian and Hamiltonian: Any good resources for Lagrangian and Hamiltonian Dynamics?\nAdvanced/geometrical: Book about classical mechanics\nFully geometrical: Classical mechanics without coordinates book\n\nClassical Field Theories\n\nElectromagnetism (advanced undergraduate): Recommended books for advanced undergraduate electrodynamics\nElectromagnetism (graduate): Graduate level book in classical electrodynamics\nElectromagnetism (with applications): Electrodynamics textbooks that emphasize applications\nWaves: What's a good textbook to learn about waves and oscillations?\nGeneral: Need for a side book for E. Soper's Classical Theory Of Fields\nElasticity: Modern references for continuum mechanics\nFluid dynamics: Book recommendations for fluid dynamics self-study\nBoundary layer theory: Boundary layer theory in fluids learning resources\n\nSpecial Relativity\n\nIntroductory: What are good books for special relativity?\nVisual: Textbook for special relativity: modern version of Bondi's Relativity and Common Sense?\nGeometric: Textbook on the Geometry of Special Relativity\nMath-free: Recommended books for a \"relativity for poets\" class?\nRelativistic imaging: Reference request for relativistic imaging\n\nThermodynamics and Statistical Mechanics\n\nShort: Crash course in classical thermodynamics\nUndergraduate statistical mechanics: Good undergraduate statistical mechanics textbook\nAdvanced: Recommendations for statistical mechanics book\nCareful: References about rigorous thermodynamics\nFoundational: Are there any modern textbooks on statistical mechanics which don't ignore Gibbs' analysis of the microcanonical ensemble?\nDifferential forms: Introduction to differential forms in thermodynamics\nStochastic processes: Suggestion on good stochastic processes book for self-teaching\nQuantum statistical mechanics: Resources for introductory quantum statistical mechanics\nComplex systems: What are some of the best books on complex systems and emergence?\nInformation Theoretic Point of View: Reference for statistical mechanics from information theoretic view\n\nAstrophysics and Cosmology\n\nPopular: Recommend good book(s) about the \"scientific method\" as it relates to astronomy/astrophysics?\nAstronomy: What is a good introductory text to astronomy\nAstrophysics: What are good books for graduates/undergraduates in Astrophysics?\nCosmology (introductory): Books on cosmology\nDark matter/dark energy: Dark matter and dark energy references\nInflation: Good resources for understanding inflationary cosmology\nNeutrinos: Book suggestion about Neutrino effect on Cosmic Structure\n\nQuantum Mechanics\n\nPopular: Looking for a good casual book on quantum physics\nHistorical: Good book on the history of Quantum Mechanics?\nIntroductory: What is a good introductory book on quantum mechanics?\nAdvanced: Learn QM algebraic formulations and interpretations\nMathematical: A book on quantum mechanics supported by the high-level mathematics\nPath integral: Path integral formulation of quantum mechanics\nDecoherence: Decoherence and quantum to classical limit: good resources?\nBerry phase: Book on Berry phase and its relation to topology\nInterpretations: Books about alternative interpretations of quantum mechanics\n\nAtomic, Molecular, Optical Physics\n\nHigh school optics: Where is a good place to learn classical optics for high school competitions?\nAtomic and molecular: Book recommendation for Atomic & Molecular physics\nOpen systems: Book recommendations for learning about open quantum systems\nQuantum information: Quantum information references\nQuantum cryptography: A good book for Quantum Cryptography\nQuantum optics: Book Recommendation: Quantum optics\n\nCondensed Matter\n\nIntroductory/solid state: Intro to Solid State Physics\nAdvanced: Books for Condensed Matter after Ashcroft/Mermin\nSecond quantization: Book recommendations for second quantization\nMathematically rigorous: Mathematical rigorous introduction to solid state physics\nAnyons: References on the physics of anyons\nFractional statistics: Resource recommendation for fractional statistics\nTopological insulators: Book recommendations - Topological Insulators for dummies\nIron-based superconductors: Reference needed for Iron-based superconductors\nSoft matter: Soft Condensed Matter book for self-study\nIntermolecular forces: Resource for intermolecular forces in soft condensed matter\nMaterials science: Best Materials Science Introduction Book?\nQuantum chemistry: Is there any quantum physics book that treats covalent bonding systematically?\n\nParticle Physics\n\nPopular: Good book about elementary particles for high school students?\nGeneral: Books for particle physics and the Standard Model\nExperimental: Enlightening experimental physics books/resources\nDetectors: Reference for solid state particle detector\nData analysis: Textbook about the handiwork of a HEP analysis?\nHeavy ion collisions: Reference on stages of heavy ion collisions in particle physics\nTheories of everything: What is a good non-technical introduction to theories of everything?\n\nQuantum Field Theory\n\nBackground: Textbook on group theory to be able to start QFT\nBasics: A No-Nonsense Introduction to Quantum Field Theory\nRelativistic QM: Any suggestion for a book that includes quantum mechanics principles and smoothly introduces you to QED (quantum electrodynamics)?\nIntroductory: What is a complete book for introductory quantum field theory?\nLectures: Online QFT video lectures\nS-matrix theory: Materials about S-matrix and S-matrix theory\nRenormalization: Are there books on Regularization and Renormalization in QFT at an Introductory level?\nRenormalization (in general): Suggested reading for renormalization (not only in QFT)\nFor mathematicians: Quantum Field Theory from a mathematical point of view\nRigorous/axiomatic: Rigorous approaches to quantum field theory\nAlgebraic QFT: Which are some best sources to learn Algebraic Quantum Field Theory (AQFT)?\nTopological field theory: Reading list in topological QFT\nNonperturbative: Books on non-perturbative phenomena in quantum field theory\nCurved spacetime: Suggested reading for quantum field theory in curved spacetime\nCurved spacetime (advanced): Modern treatment of effective QFT in curved spacetime\n\nGeneral Relativity\n\nIntroductory: Books for general relativity\nMathematical: Mathematically-oriented Treatment of General Relativity\nExercises: Recommendation on books with problems for general relativity?\nExact solutions: A book containing a large subset of known exact solutions to the EFEs\n\nHigh Energy Theory\n\nString theory (introductory): Introduction to string theory\nString theory (advanced): Advanced topics in string theory\nString theory (matrix): Good introductory text for matrix string theory\nSupersymmetry (with exercises): Problems book recommendation on supersymmetry, supergravity and superstring theory\nKahler manifolds: K\u00e4hler and complex manifolds\nConformal field theory: Reading list and book recommendation on Conformal Field Theory\nConformal bootstrap: Looking for intro to Conformal Bootstrap\nAdS/CFT: Introduction to AdS/CFT\nIntegrability: What is a good introduction to integrable models in physics?\nEntanglement entropy: Quantum field theory text on entanglement entropy\nTwistors: Gentle introduction to twistors\nLoop quantum gravity: LQG Demystified Book?\nQuantum Gravity in general: Obligated Bibliography for Quantum Gravity\n\nMiscellaneous\n\nFree: List of freely available physics books\nLecture notes: Best Sets of Physics Lecture Notes and Articles\nHistorical: Physics history book with some math\nAcoustics: Books about musical acoustics\nChemistry: Where should a physicist go to learn chemistry?\nBiophysics: What are good references for learning about Biophysics at graduate level?\nComputational: Textbook recommendation for computational physics\nExperimental: What's a good book on experimental methods for physics?\nPlasma physics: Book suggestion for introductory plasma physics\n\nProblems\n\nOlympiad: Best physics olympiad resources\nGraduate exams: Graduate Physics Problems Books\nPuzzles site: Is there a physics Puzzles site like Project Euler?", "meta": {"post_id": 12175, "input_score": 305, "output_score": 294, "post_title": "Resource recommendations"}}
{"input": "I have very little background in physics, so I apologize if this question is painfully naive.\nConsider the following thought experiment: an observer is in a closed room whose walls, floor, and ceiling are made entirely of mirrors, with a single light source in the middle of the room. When the light is on, the observer can see many copies of his reflection all over the place.\nSuddenly, the light source turns itself off. Intuitively, I would expect the observer to \"instantly\" see darkness. However, I can't figure out why that is the case under the \"particle\" interpretation of light. There are obviously lots of photons already in the room from before. Furthermore, we know that they don't get \"consumed\" when they hit a wall, because otherwise the observer wouldn't see so many reflections of himself. Basically, when the light goes off, what happens to the photons already in the room?\nI suspect the answer goes something like this: the photons in the room lose a little bit of energy every time they bounce off a mirror, but it's so minuscule that we can still see more reflections than our eye can resolve anyway. When the light goes off, however, it takes them a very small fraction of a second to bounce around the room enough times to diffuse completely, which our eye cannot detect.\nIs that about right? If we had a theoretical \"perfect reflector\", would the light remain trapped in the room forever? If we had instruments that could measure such things very finely, would it take (slightly) longer for the light to go out in a room made of mirrors as opposed to a room made of, say, black cloth?", "output": "When being reflected by a mirror, the photons do not lose \"a tiny bit\" of energy. Either they are reflected unchanged, or they are completely absorbed. A good mirror will reflect most of the photons, but will absorb a small fraction of them as well, say $0.1\\%$ of them. \nThat is: Your photons don't lose energy over time; what happens is that the room loses photons over time: For each time a photon hits a wall, there is some probability $p$ that it will get absorbed (\"consumed\"). The chance that it doesn't get consumed after $N$ hits is $(1-p)^N$. Since the photons are very fast, they'll bounce off the walls very often in a short amount of time, so $N$ becomes really large really quick, and then $(1-p)^N$ becomes really small pretty fast, so after a short amount of time, all photons have been consumed with very high probability. \nAn important property of photons, that might not be entirely intuitive when coming from a \"wave\" background: The energy of an individual photon is determined entirely by the frequency of the light. Blue photons have higher energy than red photons. The intensity of light is determined not by the energy of your photons, but by their number. \nIf the photons would lose energy each time they bounce off a mirror, the reflections would change their color gradually, so that eventually blue light becomes red, then infrared etc. That doesn't happen: The mirrors don't change the color of the light. They only swallow some of the photons, i.e. they reduce the intensity.\nWith perfect mirrors, you could indeed expect to never lose any photons. But since anyone looking at the photons also absorbs then, the room would still get dark eventually. Unless there's nobody in there. \nTo be overly pedantic: Unless you keep the walls at zero temperature, you will always have some photons in the room as blackbody radiation. At \"normal\" temperatures, these photons are mostly in the infrared range, but if you make it really hot, the walls will start glowing.", "meta": {"post_id": 13500, "input_score": 29, "output_score": 42, "post_title": "How are photons \"consumed\"?"}}
{"input": "The great russian physicist Lev Landau developed a famous entry exam to test his students. This \"Theoretical Minimum\" contained everything he considered elementary for a young theoretical physicist. Despite its name, it was notoriously hard and comprehensive, and in Landau's time, only 43 students passed it.\nI wonder if anyone can provide the list of topics, or even a copy of the exam?\n(I'm sure I'd have no chance to pass, but I'd like to see it out of a sense of sportmanship ;-). Also, I think it would make quite a good curriculum of theoretical physics (at least pre 1960).)", "output": "The list of topics can be found here (in Russian, of course). Nowadays students are examined by collaborators of Landau Institute for Theoretical Physics. Each exam, as it was before, consists of problems solving. For every exam there is one or several examiners with whom you are supposed to contact with to inform that you're willing to pass this particular exam (they will make an appointment). Everyone can pass any exam in any order. Today Landau's theoretical minimum (not all 11 exams, but at least 6 of them) is included in the program for students of Department of General and Applied Physics (Moscow Institute of Physics and Technology).\nThe program for each exam, as you can see from the link above, corresponds to the contents of volumes in the Course of Theoretical Physics by L&L (usually you have to master almost all paragraphs in the volume to pass the exam).\n\nMathematics I. Integration, ordinary differential equations, vector algebra and tensor analysis. \nMechanics. Mechanics, Vol. 1, except \u00a7\u00a7 27, 29, 30, 37, 51 (1988 russian edition) \nField theory The Classical Theory of Fields, Vol. 2, except \u00a7\u00a7 50, 54-57, 59-61, 68, 70, 74, 77, 97, 98, 102, 106, 108, 109, 115-119 (1973 russian edition)\nMathematics II. The theory of functions of a complex variable, residues, solving equations by means of contour integrals (Laplace's method), the computation of the asymptotics of integrals, special functions (Legendre, Bessel, elliptic, hypergeometric, gamma function) \nQuantum Mechanics. Quantum Mechanics: Non-Relativistic Theory, Vol. 3,  except \u00a7\u00a7 29, 49, 51, 57, 77, 80, 84, 85, 87, 88, 90, 101, 104, 105, 106-110, 114, 138, 152 (1989 russian edition) \nQuantum electrodynamics. Relativistic Quantum Theory, Vol. 4, except \u00a7\u00a7 9, 14-16, 31, 35, 38-41, 46-48, 51, 52, 55, 57, 66-70, 82, 84, 85, 87, 89 - 91, 95-97, 100, 101, 106-109, 112, 115-144 (1980 russian edition)\nStatistical Physics I. Statistical Physics, Vol. 5, except \u00a7\u00a7 22, 30, 50, 60, 68, 70, 72, 79, 80, 84, 95, 99, 100, 125-127, 134-141, 150-153 , 155-160 (1976 russian edition)\nMechanics of continua. Fluid Mechanics, Vol. 6, except \u00a7\u00a7 11, 13, 14, 21, 23, 25-28, 30-32, 34-48, 53-59, 63, 67-78, 80, 83, 86-88, 90 , 91, 94-141 (1986 russian edition); Theory of Elasticity, Vol. 7, except \u00a7\u00a7 8, 9, 11-21, 25, 27-30, 32-47 (1987 russian edition)\nElectrodynamics of Continuous Media. Electrodynamics of Continuous Media, Vol. 8, except \u00a7\u00a7 1-5, 9, 15, 16, 18, \u200b\u200b25, 28, 34, 35, 42-44, 56, 57, 61-64, 69, 74, 79-81 , 84, 91-112, 123, 126 (1982 russian edition)\nStatistical Physics II. Statistical Physics, Part 2. Vol. 9, only \u00a7\u00a7 1-5, 7-18, 22-27, 29, 36-40, 43-48, 50, 55-61, 63-65, 69 (1978 russian edition)\nPhysical Kinetics. Physical Kinetics. Vol. 10, only \u00a7\u00a7 1-8, 11, 12, 14, 21, 22, 24, 27-30, 32-34, 41-44, 66-69, 75, 78-82, 86, 101.\n\n\nSome real problems (Quantum Mechanics exam):\n\nThe electron enters a straight pipe of circular cross section (radius $r$). The tube is bent at a radius $R \\gg r$ by the angle $\\alpha$ and then is aligned back again. Find the probability that the electron will jump out.\nA hemisphere lies on an infinite two-dimensional plane. The electron falls on the hemisphere, determine the scattering cross section in the Born approximation.\nThe electron \"sits\" in the ground state in the cone-shaped \"bag\" under the influence of gravity. The lower end of the plastic bag is cut with scissors. Find the time for the electron to fall out (in the semi-classical approximation).", "meta": {"post_id": 13861, "input_score": 79, "output_score": 58, "post_title": "Lev Landau's \"Theoretical Minimum\""}}
{"input": "I was quite surprised to read this all over the news today:\n\nElusive, nearly massive subatomic particles called neutrinos appear to travel just faster than light, a team of physicists in Europe reports. If so, the observation would wreck Einstein's theory of special relativity, which demands that nothing can travel faster than light.\n\n\u2014source\nApparently a CERN/Gran Sasso team measured a faster-than-light speed for neutrinos.\n\nIs this even remotely possible?\nIf so, would it be a real violation of Lorentz invariance or an \"almost, but not quite\" effect?\n\nThe paper is on arXiv; a webcast is/was planned here.\nNews conference video here", "output": "You have a few longer answers which were already updated, but here is a concise statement of the situation in mid-2014:\n\nAn independent measurement by the ICARUS collaboration, also using neutrinos traveling from CERN to Gran Sasso but using independent detector and timing hardware, found detection times \"compatible with the simultaneous arrival of all events with equal speed, the one of light.\"\nIn an edited press release (and probably in the peer-reviewed literature as well), all four of the neutrino experiments at Gran Sasso report results consistent with relativity.\nThe mumblings that begin a few months after the initial report, that a loose cable caused a timing chain error, have been accepted by the experimenters.  Fr\u00e9d\u00e9ric Grosshans links to a nice discussion by Matt Strassler\nwhich includes this image:\n\nYou can clearly see that the timing offset was introduced in mid-2008 and not corrected until the end of 2011.\n\nIt's important to remember the scale of the problem here.  In vacuum, the speed of light is one foot per nanosecond.  In copper/poly coaxial cable it's slower, about six inches per nanosecond, and in optical  fiber it's comparable.  A bad cable connector can take a beautiful digital logic signal and reflect part of it back to the emitter, in a time-dependent way, turning the received signal into an analog mess with a complicated shape.  And a cable can go bad if somebody hits it the wrong way with their butt while they are working in the electronics room.\n(I actually had something similar happen to me on an experiment: I had an analog signal splitter \"upstairs\" that sent a signal echo back to my detectors \"downstairs\", and a runty little echoed pulse came back upstairs after about a microsecond and got processed like another event.  I wound up spending several thousand dollars on signal terminators to swallow the echo downstairs.  It was an unusual configuration and needed unusual termination hardware and I must have answered the question \"but couldn't you just\" a hundred times.)\nGran Sasso is an underground facility for low-background experiments \u2014 the detectors can't see GPS satellites directly, because there's a mountain in the way, and their access to the surface is via a tunnel whose main purpose is to carry traffic for a major Italian motorway.  I'm quite impressed that they had ~100\u00a0ns timing resolution between the two laboratories; the \"discovery\" came about because they were trying to do ten times better than that.\nAs an experimentalist I don't begrudge the OPERA guys their error at all.  I'm sure they spent an entire year shitting pineapples because they couldn't identify the problem.  When they finally did release their result, they had the courage to report it at face value.  The community was properly incredulous and the wide interest prompted a large number of other checks they could make.  Independent measurements were performed.  An explanation was found.  Science at its best.", "meta": {"post_id": 14968, "input_score": 91, "output_score": 40, "post_title": "Superluminal neutrinos"}}
{"input": "I've read many times, including here on this very site that the commonly known explanation of flight is wrong, and that airplanes can fly because the shape of their wings deflects air down. This makes sense, but as far as I can tell it doesn't explain upside down flight or symmetric wings.\nThe images I've seen show an inclined wing, which forces the air to go downwards. But how can planes fly upside down then?", "output": "Upside-down or right side up, flight works the same way. As you stated, the wing deflects air downward. When inverted, the pilot simply controls the the pitch of the aircraft to keep the nose up, thus giving the wings sufficient angle of attack to deflect air downwards.\nMost airplanes are designed with some positive angle of attack \"built-in,\" meaning that there is some angle between the wings and the fuselage so that the wings have a small positive angle of attack while the fuselage is level. This is why the floor isn't tilted tailwards when you're in an airliner in level flight. So when upside down the nose has to be held a bit higher than usual, and the other flight systems (including the pilot!) must be designed to handle it, but there is nothing really special about upside-down flight.", "meta": {"post_id": 15981, "input_score": 47, "output_score": 42, "post_title": "How can airplanes fly upside down?"}}
{"input": "Would the effect of gravity on me change if I were to dig a very deep hole and stand in it? If so, how would it change? Am I more likely to be pulled downwards, or pulled towards the edges of the hole? If there would be no change, why not?", "output": "The other answers provide a first-order approximation, assuming uniform density (though Adam Zalcman's does allude to deviations from linearity).  (Summary: All the mass farther away from the center cancels out, and gravity decreases linearly with depth from 1 g at the surface to zero at the center.)\nBut in fact, the Earth's core is substantially more dense than the outer layers (mantle and crust), and gravity actually increases a bit as you descend, reaching a maximum at the boundary between the outer core and the lower mantle.  Within the core, it rapidly drops to zero as you approach the center, where the planet's entire mass is exerting a gravitational pull from all directions.\nThe Wikipedia article on \"gravity of Earth\" goes into the details, including this graph:\n\n\"PREM\" in the figure refers to the Preliminary Reference Earth Model.\nLarger versions of the graph can be seen here\nAnd there are other, smaller, effects as well.  The Earth's rotation results in a smaller effective gravity near the equator, the equatorial bulge that results from that rotation also has a small effect, and mass concentrations have local effects.", "meta": {"post_id": 18446, "input_score": 57, "output_score": 83, "post_title": "How does gravity work underground?"}}
{"input": "If we ignore 5GHz WiFi, then both microwaves and WiFi create photons at ~2.4GHz but one of them will boil water in a few seconds but the other doesn't have any effect. So what's the difference?\nIs it simply the number of photons created? Is that what the wattage of a microwave measures? If so, what would be the wattage of a wireless router?\nDoes the enclosed space have anything to do with it?\n\nIf it all has to do with power output could I put enough WiFi routers together in a room to cook a turkey (from microwaves and not waste heat)?", "output": "Power - your wifi router puts out about 0.1 - 1.0 W, your microwave oven puts out 1000W.\nIt would take a lot of wifi routers to cook a turkey - more than you think because the antennea on the router is designed to spread the power evenly around the room rather than concentrate it on the center of the oven.\nThere is a danger of being 'cooked' from being close to very high power transmitters such as some warship's radar while they are operating.\nps. It's the same reason your laser pointer can't be used to cut steel plates (or James Bond) in half!", "meta": {"post_id": 19285, "input_score": 30, "output_score": 49, "post_title": "If microwave ovens and WiFi both operate on the same frequency, why doesn't WiFi cook things?"}}
{"input": "In day, when you look in the room through the window out, you can clearly see what happens outside. At night when it's dark outside but there's light inside you can look in the window but it becomes a mirror.\nWhy?", "output": "Any translucent surface both reflects and refracts light. By refraction, I mean that it bends the light a bit, but lets it through to the other side. Now, reflection for such surfaces is much less than refraction (unless there's total internal reflection, but thats irrelevant for glass+air). Edit: According to @JohnRennie (see comments), only 5% of the light is reflected\nDuring the day, you have light from your room being largely refracted out, and reflected back inwards a tiny bit. The outside light does someing similar. It is largely refracted into your room, and reflected back outside a tiny bit. So, the majority of the light you see coming from the window is due to the outside light. You will see a reflection if you look carefully (exacly how carefully depends upon the lighting of your room)\nNow, during the night, there is little or no light coming from the outside. So the majority/all of the light you see is due to reflection. So you see the reflected image.\nNow an interesting question is, if the reflected image has the same intensity in both cases, why do you see it in one case and not see it in another? The answer lies in the working of the eye. The eye does not have a constant sensitivity to light. Whenever there is a lot of light, your irises contract, admitting less light into your eyes. This means that you can perceive bright light but dim light becomes invisible.  When it is darker, they expand, and the reverse effect happens. That's why you feel blinded by bright light when you leave a dark room, and also why it takes time to adjust to a dark room. (You can actually see your irises contracting; go to a well lit room with a mirror, stare at your eyes, close them for a few seconds, then reopen.. Takes a few tries, but you can see them contracting). Edit: (Credit @BenjaminFranz for pointing this out) The regulatory mechanism does not consist of only the iris/pupil. The retina also does a lot of regulation, which is why it takes half a minute or more to get used to a dark room, whereas our irises can dilate within a few seconds.\nSo, during the day, the profusion of light refracted from the outside makes your irises contract, thus making the reflected light nearly invisible. During the night, your pupil is dilated, so you can clearly see a reflection.", "meta": {"post_id": 21075, "input_score": 74, "output_score": 74, "post_title": "Why does a window become a mirror at night?"}}
{"input": "Is Fire a Plasma?\nIf not, what is it then?\nIf yes why, don't we teach kids this basic example?\n\nUPDATE: I probably meant a regular commonplace fire of the usual temperature. That should simplify the answer.", "output": "Firstly, 'Fire', according to numerous comments and answers [here][1] is a 'process', in which case, the answer to the question will be 'no', since plasma is a state of matter.\nIt would be unfair to leave it there by blaming the semantics, and given the abundant references to 'flame' region, I am going to assume that that is what the question meant to ask. I am also assuming that proving a candle flame constitutes plasma is enough to sufficiently answer the question.\nFrom some papers (a quick google search gave me [2,3]) that flames have ionised content and that they are electrically conductive.\nMy suspicion was that not all flames are conductive, but [3] includes the statement:\n\nIt has been known for a long time that flames possess a high electrical conductivity and can be distorted by an electric field.\n\nSources [4] and [5], and numerous other sources, including a video on YouTube [6] claim that a candle flame is ionised and that's what causes the flame to be affected by electric field.\nNow is it plasma?\nThe 'Plasma Coalition', which is a coalition of many reputed institutes around the world [7], says that ionisation alone is not enough, but enough atoms have to be ionized to significantly affect the electrical characteristics of the gas, in order for it to be called plasma. In one of its documents [8], it expands on this description in great detail.\nIt actually has a paper dedicated to this question, [8], which says that some flames contain plasma, whilst others don't. It expand further in sufficient detail, claiming that the answer depends on the region, what's being burned, the temperature, etc. \nIt also acknowledges that the current knowledge about flames is quite limited to conclusively ascertain the charged particle densities at a particle location in the flame, as of 2008.\nA wide variety of sources that claim that a flame (like a candle flame) is plasma is referring to the fact that it is ionised. \nFrancis F Chen's book [10] includes an exercise on page 12 that connotes a typical flame being plasma. This claim is repeated in [4] and [5] (refers to candle flame).\nMy Conclusion\nI understand that the Plasma coalition paper [8] says that the temperature of a candle is too low for much ionisation to occur, but technically, the experiments cited above [2,4,6], demonstrating the significant effect of flames in an electric field, coupled with the theoretical predictions [3,10] seem to imply that the flame is indeed a plasma. Even by the condition stated by the Plasma Coalition [11] itself!\nI found it interesting that an old paper [3] proposes to explain the excessive amounts of ions formed in hydrocarbon flames by suggesting that it is in part due cumulative excitation or chemi-ionisation. I do not know if it is still relevant today. \n$\\ \\ $  [1] Is fire matter or energy?, Physics Stack Exchange.\n$\\ \\ $  [2] Electrical Properties of Flames: Burner Flames in Longitudinal Electric Fields. Hartwell F. Calcot and Robert N. Pease. Ind. Eng. Chem. 43 no. 12, pp 2726\u20132731 (1951).\n$\\ \\ $  [3] Mechanisms for the formation of ions in flames. H.F. Calcote. Combust. Flame. 1 no. 4, pp. 385\u2013403 (1957).\n$\\ \\ $  [4] Waves in Dusty Space Plasmas. Frank Verheest (Kluwer Academic, 2000, The Netherlands).\n$\\ \\ $  [5] Sun, Earth and Sky. Kenneth R. Lang (Springer, 2006, Berlin).\n$\\ \\ $  [6] What's in a candle flame, Veritasium YouTube Channel.\n$\\ \\ $  [7] About the Coalition for Plasma Science.\n$\\ \\ $  [8] About Plasmas. Coalition of Plasma Science, 2008.\n$\\ \\ $  [9] Plasma State of Matter. Lecture notes for PX384 Electrodynamics at Warwick University, chapter IV. Erwin Verwichte, 2013.\n$\\ $  [10] Introduction to Plasma Physics and Controlled Fusion. Francis Chen. Available here for the moment.\n$\\ $  [11] What is Plasma?. Coalition for Plasma Science, 2000.", "meta": {"post_id": 23469, "input_score": 75, "output_score": 46, "post_title": "Is fire plasma?"}}
{"input": "If you've ever been annoyingly poked by a geek, you might be familiar with the semi-nerdy obnoxious response of \n\n\"I'm not actually touching you! The electrons in the atoms of my\n  skin are just getting really close to yours!\"\n\nExpanding on this a little bit, it seems the obnoxious geek is right. After all, consider Zeno's paradox. Every time you try to touch two objects together, you have to get them halfway there, then quarter-way, etc. In other words, there's always a infinitesimal distance in between the two objects. \nAtoms don't \"touch\" each other; even the protons and neutrons in the nucleus of an atom aren't \"touching\" each other.\nSo what does it mean for two objects to touch each other?\n\nAre atoms that join to form a molecule \"touching\"? I suppose the atoms are touching, because their is some overlap, but the subatomic particles are just whizzing around avoiding each other. If this is the case, should \"touching\" just be defined relative to some context? I.e, if I touch your hand, our hands are touching, but unless you pick up some of my DNA, the molecules in our hands aren't touching? And since the molecules aren't changing, the atoms aren't touching either? \nIs there really no such thing as \"touching\"?", "output": "Wow, this one has been over-answered already, I know... but it is such a fun question! So, here's an answer that hasn't been, um, \"touched\" on yet... :)\nYou, sir, whatever your age may be (anyone with kids will know what I mean), have asked for an answer to one of the deepest questions of quantum mechanics. In the quantum physics dialect of High Nerdese, your question boils down to this: Why do half-integer spin particles exhibit Pauli exclusion - that is, why do they refuse to the be in the same state, including the same location in space, at the same time?\nYou are quite correct that matter as a whole is mostly space. However, the specific example of bound atoms is arguably not so much an example of touching as it is of bonding. It would be the equivalent of a 10-year-old son not just poking his 12-year-old sister, but of poking her with superglue on his hand, which is a considerably more drastic offense that I don't think anyone would be much amused by.\nTouching, in contrast, means that you have to push - that is, exert some real energy - into making the two objects contact each other. And characteristically, after that push, the two object remain separate (in most cases) and even bound back a bit after the contact is made.\nSo, I think one can argue that the real question behind \"what is touching?\" is \"why do solid objects not want to be compressed when you try to push them together?\" If that were not the case, the whole concept of touching sort of falls apart. We would all become at best ghostly entities who cannot make contact with each other, a bit like Chihiro as she tries to push Haku away during their second meeting in Spirited Away.\nNow with that as the sharpened version of the query, why do objects such a people not just zip right through each other when they meet, especially since they are (as noted) almost entirely made of empty space?\nNow the reflex answer - and it's not a bad one - is likely to be electrical charge. That's because we all know that atoms are positive nuclei surrounded by negatively charged electrons, and that negative charges repel. So, stated that way, it's perhaps not too surprising that, when the outer \"edges\" of these rather fuzzy atoms get too close, their respective sets of electrons would get close enough to repel each other. So by this answer, \"touching\" would simply be a matter of atoms getting so close to each other that their negatively charged clouds of electrons start bumping into each other. This repulsion requires force to overcome, so the the two objects \"touch\" - reversibly compress each other without merging - through the electric fields that surround the electrons of their atoms.\nThis sounds awfully right, and it even is right... to a limited degree.\nHere's one way to think of the issue: If charge was the only issue involved, then why do some atoms have exactly the opposite reaction when their electron clouds are pushed close to each other? For example, if you push sodium atoms close to chlorine atoms, what you get is the two atoms leaping to embrace each other more closely, with a resulting release of energy that at larger scales is often described by words such as \"BOOM!\" So clearly something more than just charge repulsion is going on here, since at least some combinations of electrons around atoms like to nuzzle up much closer to each other instead of farther away.\nWhat, then, guarantees that two molecules will come up to each other and instead say \"Howdy, nice day... but, er, could you please back off a bit, it's getting stuffy?\"\nThat general resistance to getting too close turns out to result not so much from electrical charge (which does still play a role), but rather from the Pauli exclusion effect I mentioned earlier. Pauli exclusion is often skipped over in starting texts on chemistry, which may be why issues such as what touching means are also often left dangling a bit. Without Pauli exclusion, touching - the ability of two large objects to make contact without merging or joining - will always remain a bit mysterious.\nSo what is Pauli exclusion? It's just this: Very small, very simple particles that spin (rotate) in a very peculiar way always, always insist on being different in some way, sort of like kids in large families where everyone wants their unique role or ability or distinction. But particles, unlike people, are very simple things, so they only have a very limited set of options to choose from. When they run out of those simple options, they have only one option left: they need their own bit of space, apart from any other particle. They will then defend that bit of space very fiercely indeed. It is that defense of their own space that leads large collections of electrons to insist on taking up more and more overall space, as each tiny electron carves out its own unique and fiercely defended bit of turf.\nParticles that have this peculiar type of spin are called fermions, and ordinary matter is made of three main types of fermions: Protons, neutrons, and electrons. For the electrons, there is only one identifying feature that distinguishes them from each other, and that is how they spin: counterclockwise (called \"up\") or clockwise (called \"down\"). You'd think they'd have other options, but that, too, is a deep mystery of physics: Very small objects are so limited in the information they carry that they can't even have more than two directions from which to choose when spinning around.\nHowever, that one option is very important for understanding that issue of bonding that must be dealt with before atoms can engage in touching. Two electrons with opposite spins, or with spins that can be made opposite of each other by turning atoms around the right way, do not repel each other: They attract. In fact, they attract so much that they are an important part of that \"BOOM!\" I mentioned earlier for sodium and chlorine, both of which have lonely electrons without spin partners, waiting. There are other factors on how energetic the boom is, but the point is that, until electrons have formed such nice, neat pairs, they don't have as much need to occupy space.\nOnce the bonding has happened, however - once the atoms are in arrangements that don't leave unhappy electrons sitting around wanting to engage in close bonds - then the territorial aspect of electrons comes to the forefront: They begin defending their turf fiercely.\nThis defense of turf first shows itself in the ways electrons orbit around atoms, since even there the electrons insist on carving out their own unique and physically separate orbits, after that first pairing of two electrons is resolved. As you can imagine, trying to orbit around an atom while at the same time trying very hard to stay away from other electron pairs can lead to some pretty complicated geometries. And that, too, is a very good thing, because those complicated geometries lead to something called chemistry, where different numbers of electrons can exhibit very different properties due to new electrons being squeezed out into all sorts of curious and often highly exposed outside orbits.\nIn metals, it gets so bad that the outermost electrons essentially become community children that zip around the entire metal crystal instead of sticking to single atoms. That's why metals carry heat and electricity so well. In fact, when you look at a shiny metallic mirror, you are looking directly at the fastest-moving of these community-wide electrons. It's also why, in outer space, you have to be very careful about touching two pieces of clean metal to each other, because with all those electrons zipping around, the two pieces may very well decide to bond into a single new piece of metal instead of just touching. This effect is called vacuum welding, and it's an example of why you need to be careful about assuming that solids that make contact will always remain separate.\nBut many materials, such a you and your skin, don't have many of these community electrons, and are instead full of pairs of electrons that are very happy with the situations they already have, thank you. And when these kinds of materials and these kinds of electrons approach, the Pauli exclusion effect takes hold, and the electrons become very defensive of their turf.\nThe result at out large-scale level is what we call touching: the ability to make contact without easily pushing through or merging, a large-scale sum of all of those individual highly content electrons defending their small bits of turf.\nSo to end, why do electrons and other fermions want so desperately to have their own bits of unique state and space all to themselves? And why, in every experiment ever done, is this resistance to merger always associated with that peculiar kind of spin I mentioned, a form of spin that is so minimal and so odd that it can't quite be described within ordinary three-dimensional space?\nWe have fantastically effective mathematical models of this effect. It has to do with antisymmetric wave functions. These amazing models are instrumental to things such as the semiconductor industry behind all of our modern electronic devices, as well as chemistry in general, and of course research into fundamental physics.\nBut if you ask the \"why\" question, that becomes a lot harder. The most honest answer is, I think, \"because that is what we see: half-spin particles have antisymmetric wave functions, and that means they defend their spaces.\"\nBut linking the two together tightly - something called the spin-statistics problem - has never really been answered in a way that Richard Feynman would have called satisfactory. In fact, he flatly declared more than once that this (and several other items in quantum physics) were still basically mysteries for which we lacked really deep insights into why the universe we know works that way.\nAnd that, sir, is why your question of \"what is touching?\" touches more deeply on profound mysteries of physics than you may have realized. It's a good question.\n\n2012-07-01 Addendum\nHere is a related answer I did for S.E. Chemistry. It touches on many of the same issues, but with more emphasis on why \"spin pairing\" of electrons allows atoms to share and steal electrons from each other -- that is, it lets them form bonds. It is not a classic textbook explanation of bonding, and I use a lot of informal English words that are not mathematically accurate. But the physics concepts are accurate. My hope is that it can provide a better intuitive feel for the rather remarkable mystery of how an uncharged atom (e.g. chlorine) can overcome the tremendous electrostatic attraction of a neutral atom (e.g. sodium) to steal one or more of its electrons.", "meta": {"post_id": 23797, "input_score": 138, "output_score": 137, "post_title": "What does it mean for two objects to \"touch\"?"}}
{"input": "I always see pictures of the solar system where our sun is in the middle and the planets surround the sun. All these planets move on orbits on the same layer. Why?", "output": "We haven't ironed out all the details about how planets form, but they almost certainly form from a disk of material around a young star. Because the disk lies in a single plane, the planets are broadly in that plane too.\nBut I'm just deferring the question. Why should a disk form around a young star? While the star is forming, there's a lot of gas and dust falling onto it. This material has angular momentum, so it swirls around the central object (i.e. the star) and the flow collides with itself. The collisions cancel out the angular momentum in what becomes the vertical direction and smear the material out in the horizontal direction, leading to a disk. Eventually, this disk fragments and forms planets. Like I said, the details aren't well understood, but we're pretty sure about the disk part, and that's why the planets are co-planar.", "meta": {"post_id": 26083, "input_score": 49, "output_score": 45, "post_title": "Why are our planets in the solar system all on the same disc/plane/layer?"}}
{"input": "The sun is made of fire but fire needs oxygen right? So.. \n\nWhy can there be flames in space, while there's no oxygen? \nSame idea as with the rocket engines of the spaceship, which also produce fire while there's no oxygen?", "output": "The Sun isn't \"made of fire\".  It's made mostly of hydrogen and helium.  Its heat and light come from nuclear fusion, a very different process that doesn't require oxygen.  Ordinary fire is a chemical reaction; fusion merges hydrogen nuclei into helium, and produces much more energy.  (Other nuclear reactions are possible.)\nAs for rockets, they carry both fuel and oxygen (or another oxidizer) with them (at least chemical rockets do; there are other kinds).  That's the difference between a rocket engine and a jet engine; jets carry fuel, but get oxygen from the air.", "meta": {"post_id": 26628, "input_score": 17, "output_score": 39, "post_title": "Why can there be fire in space while there is no oxygen?"}}
{"input": "Inspired by physics.SE: Does the dimensionality of phase space go up as the universe expands?\nIt made me wonder about symplectic structures in GR, specifically, is there something like a Louiville form? In my dilettante understanding, the existence of the ADM formulation essentially answers that for generic cases, but it is unclear to me how boundaries change this. Specifically, I know that if one has an interior boundary, then generally the evolution is not hamiltonian; on the other hand, if the interior boundary is an isolated horizon, then the it is hamiltonian iff the first law of blackhole thermodynamics is obeyed (see http://arxiv.org/abs/gr-qc/0407042). \nThe sharper form of the question is thus what happens cosmologically? \n(And as usual for a research level (?) question: what are the Google-able search terms to find out more about this?)", "output": "Notice first that the phase space of any theory is nothing but the space of all its classical solutions. The traditional presentation of phase spaces by fields and their canonical momenta on a Cauchy surface is just a way of parameterizing all solutions by initial value data -- if possible. This is often possible, but comes with all the disadvantages that a choice of coordinates always comes with. The phase space itself exists independently of these choices and whether they exist in the first place. In order to emphasize this point one sometimes speaks of covariant phase space .\nThis is well known, even if it remains a bit hidden in many textbooks. For more details and an extensive and commented list of references on this see the $n$Lab entry phase space .\nThen notice that the phase space of every field theory that comes from a local action functional (meaning that it is the integral of a Lagrangian which depends only on finitely many derivatives of the fields) comes canonically equipped with a canonical Liouville form and a canonical presymplectic form. The way this works is also discuss in detail at phase space . A good classical reference is Zuckerman, a more leisurely discussion is in Crncovic-Witten .\nThis canonical presymplectic form that exists on the phase space of every local theory becomes symplectic on the reduced phase space, which is the space obtained by quotienting out the gauge symmetries. This quotient is often very ill-behaved, but it always exists nicely as a \"derived\" quotient, and as such is modeled by the BV-BRST complex (as discussed there). The whole (Lagrangian) BV-BRST machinery is there to produce the canonical symplectic form existing on the reduced phase space of any local action functional.\nSince the Einstein-Hilbert action and all of its usual variants with matter couplings etc. is a local action functional, all this applies to gravity. Recently Fredenhagen et al. have given careful discussions of the covariant phase space of gravity (and its Liouville form), see the references listed here .\nIt follows that the \"dimension\" of the covariant phase space of gravity does not depend on the \"size of the universe\", nor does it make much sense to ask this, in the first place. A given cosmology is one single point in this phase space (or rather it is so in the reduced phase space, after quotienting out symmetries).\nHowever, you might be after some truncations or effective approximations or coarse graining to full covariant gravity. For these the story might be different.", "meta": {"post_id": 26883, "input_score": 31, "output_score": 43, "post_title": "Sympletic structure of General Relativity"}}
{"input": "A symmetry is anomalous when the path-integral measure does not respect it.  One way this manifests itself is in the inability to regularize certain diagrams containing fermion loops in a way compatible with the symmetry.  Specifically, it seems that the effect is completely determined by studying 1-loop diagrams.  Can someone give a heuristic explanation as to why this is the case?  And is there a more rigorous derivation that \"I just can't find any good way to regularize this thing.\"?\nAn alternative approach, due to to Fujikawa, is to study the path integral of the fermions in an instanton background.  Then one sees that the zero modes are not balanced with respect to their transformation under the symmetries, leading to an anomalous transformation of the measure under this symmetry.  Specifically, the violation is proportional to the instanton number, and thus one finds the non-conservation of the current is proportional to the instanton density.  This is also found by the perturbative method above.\nMy question, which is a little heuristic, is how is it that the effect seems perturbative (and exact at 1-loop) on the one hand, and yet related to instantons, which are non-perturbative, on the other?", "output": "These are all good questions. Perhaps I can answer a few of them at once. The equation describing the violation of current conservation is \n$$\\partial^\\mu j_\\mu=f(g)\\epsilon^{\\mu\\nu\\rho\\sigma}F_{\\mu\\nu}F_{\\rho\\sigma}$$ \nwhere $f(g)$ is some function of the coupling constant $g$. It is not possible to write any other candidate answer by dimensional analysis and by parity (assuming the current is the ordinary axial current...)\nNow we integrate both sides over $\\int d^4x$, and we find on the left hand side $\\Delta Q$, meaning, now that the current is violated, the charge can change while the system evolves, while the right hand side is \n$$f(g)\\int d^4x \\epsilon^{\\mu\\nu\\rho\\sigma}F_{\\mu\\nu}F_{\\rho\\sigma}$$\nThe object on the right hand side is a known topological invariant of the gauge bundle, and it is an integer (if all the charges are appropriately quantized). So on the left hand side we get $\\Delta Q$, which must be an integer (if all fundamental particles carry integer charge) and the right hand side is an integer too, up to the function $f(g)$.\nThis means that the function $f(g)$ cannot, in fact, depend on $g$. (More precisely, there is a scheme where it does not.) Hence, it is exact at one loop. This is the modern proof (without any computation) of the ABJ theorem about one-loop exactness of the anomaly. \nSo you see the deep connection between one loop and instantons... The violation of the conservation equation is at one loop, but to lead to interesting consequences we need to have a nontrivial gauge bundle.\nAbout some of the other comments you made: ANY regularization scheme that respects Bose symmetry will lead to the anomaly, it is totally unavoidable. This is proven in http://inspirehep.net/record/154341?ln=en. \nAnother comment: anomalies can also arise from boson loops, for example, the trace anomaly. (It is not one-loop exact in any sense I am aware of.)", "meta": {"post_id": 27002, "input_score": 37, "output_score": 39, "post_title": "Instantons, anomalies, and 1-loop effects"}}
{"input": "What is a good summary of the results about the correspondence between matrix product states (MPS) or projected entangled pair states (PEPS) and the ground states of local Hamiltonians? Specifically, what \"if and only if\" type of equality/approximation hold?\nI know about this review-like paper by Verstraete, Cirac, and Murg but I feel some of its results are superseded by new ones...", "output": "A short summary of the relation between MPS/PEPS and ground states local Hamiltonians:\nFirst the direction from MPS/PEPS to Hamiltonians:\n\nEvery MPS/PEPS naturally appears as the exact ground state of a frustration free local Hamiltonian. (\"parent Hamiltonian\")\nFor generic MPS/PEPS, this ground state will be unique.\nThere is a number of cases beyond the generic one where one can make statements about the ground state degeneracy.  In particular, for translational invariant MPS the ground state degeneracy is always constant.\nFor translational invariant MPS, there is always a spectral gap above the ground state manifold; for PEPS, this holds only in certain cases.\n\nConversely, from Hamiltonians to MPS/PEPS:\n\nGiven a gapped local 1D Hamiltonian, its ground state is well approximated by an MPS. (cf. [Hastings '07] for the scaling)\nGiven a local 2D Hamiltonian where the density of states does not grow too quickly, its ground state (as well as thermal states) is well described by a PEPS (cf. [Hastings '05],[Hastings '07] for the scaling)\n\nThis concerns only the analytical relations between MPS/PEPS and Hamiltonians. In practice, better bounds concerning approximability etc. will typically hold.\nConcerning \"if and only if\" relations, I think all these results only hold rigorously in one direction (though typically they might be \"if and only if\", e.g., I would think that typical gapless Hamiltonians will not have MPS ground states).\nIf you are looking for something more concrete, please let us know.", "meta": {"post_id": 27043, "input_score": 37, "output_score": 38, "post_title": "State of Matrix Product States"}}
{"input": "The purpose of this question is to ask about the role of mathematical rigor in physics. In order to formulate a question that can be answered, and not just discussed, I divided this large issue into five specific questions.\nUpdate February, 12, 2018: Since the question was put yesterday on hold as too board, I ask future to refer only to questions one and two listed below. I will ask a separate questions on item 3 and 4. Any information on question 5 can be added as a remark. \n\n\nWhat are the most important and the oldest insights (notions, results) from physics that are still lacking rigorous mathematical\n  formulation/proofs.\nThe endeavor of rigorous mathematical explanations, formulations, and proofs for notions and results from physics is mainly taken by\n  mathematicians. What are examples that this endeavor was beneficial to\n  physics itself.\n\n\n\nWhat are examples that insisting on rigour delayed progress in physics.\nWhat are examples that solid mathematical understanding of certain issues from physics came from further developments in physics itself. (In particular, I am interested in cases where mathematical rigorous understanding of issues from classical mechanics required quantum mechanics, and also in cases where progress in physics was crucial to rigorous mathematical solutions of questions in mathematics not originated in physics.)\nThe role of rigor is intensely discussed in popular books and blogs. Please supply references (or better annotated references) to academic studies of the role of mathematical rigour in modern physics.\n\n(Of course, I will be also thankful to answers which elaborate on a single item related to a single question out of these five questions. See update)\nRelated Math Overflow questions: \n\nExamples-of-non-rigorous-but-efficient-mathematical-methods-in-physics (related to question 1); \nExamples-of-using-physical-intuition-to-solve-math-problems; \nDemonstrating-that-rigour-is-important.", "output": "Rigorous arguments are very similar to computer programming--- you need to write a proof which can (in principle) ultimately be carried out in a formal system. This is not easy, and requires defining many data-structures (definitions), and writing many subroutines (lemmas), which you use again and again. Then you prove many results along the way, only some of which are of general usefulness.\nThis activity is extremely illuminating, but it is time consuming, and tedious, and requires a great deal of time and care. Rigorous arguments also introduce a lot of pedantic distinctions which are extremely important for the mathematics, but not so important in the cases one deals with in physics.\nIn physics, you never have enough time, and we must always have a only just precise enough understanding of the mathematics that can be transmitted maximally quickly to the next generation. Often this means that you forsake full rigor, and introduce notational short-cuts and imprecise terminology that makes turning the argument rigorous difficult.\nSome of the arguments in physics though are pure magic. For me, the replica trick is the best example. If this ever gets a rigorous version, I will be flabbergasted.\n\n1) What are the most important and the oldest insights (notions, results) from physics that are still lacking rigorous mathematical formulation/proofs.\n\nHere are old problems which could benefit from rigorous analysis:\n\nMandelstam's double-dispersion relations: The scattering amplitude for 2 particle to 2 particle scattering can be analytically expanded as an integral over the imaginary discontinuity $\\rho(s)$ in the s parameter, and then this discontinuity $\\rho(s)$ can be written as an integral over the t parameter, giving a double-discontinuity $\\rho(s,t)$ If you go the other way, expand the discontinuity in t first then in s, you get the same function. Why is that? It was argued from perturbation theory by Mandelstam, and there was some work in the 1960s and early 1970s, but it was never solved as far as I know.\nThe oldest, dating back centuries: Is the (Newtonian, comet and asteroid free) solar system stable for all time? This is a famous one. Rigorous bounds on where integrability fails will help. The KAM theorem might be the best answer possible, but it doesn't answer the question really, since you don't know whether the planetary perturbations are big enough to lead to instability for 8 planets some big moons, plus sun.\ncontinuum statistical mechanics: What is a thermodynamic ensemble for a continum field? What is the continuum limit of a statistical distribution? What are the continuous statistical field theories here?\nWhat are the generic topological solitonic solutions to classical nonlinear field equations? Given a classical equation, how do you find the possible topological solitons? Can they all be generated continuously from given initial data? For a specific example, consider the solar-plasma--- are there localized magneto-hydrodynamic solitons?\n\nThere are a bazillion problems here, but my imagination fails.\n\n2) The endeavor of rigorous mathematical explanations, formulations, and proofs for notions and results from physics is mainly taken by mathematicians. What are examples that this endeavor was beneficial to physics itself.\n\nThere are a few examples, but I think they are rare:\n\nPenrose's rigorous proof of the existence of singularities in a closed trapped surface is the canonical example: it was a rigorous argument, derived from Riemannian geometry ideas, and it was extremely important for clarifying what's going on in black holes.\nQuasi-periodic tilings, also associated with Penrose, first arose in Hao and Wang's work in pure logic, where they were able to demonstrate that an appropriate tiling with complicated matching edges could do full computation. The number of tiles were reduced until Penrose gave only 2, and finally physicists discovered quasicrystals. This is spectacular, because here you start in the most esoteric non-physics part of pure mathematics, and you end up at the most hands-on of experimental systems.\nKac-Moody algebras: These came up in half-mathematics, half early string theory. The results became physical in the 1980s when people started getting interested in group manifold models.\nThe ADE classificiation from Lie group theory (and all of Lie group theory) in mathematics is essential in modern physics. Looking back further, Gell-Mann got SU(3) quark symmetry by generalizing isospin in pure mathematics.\nObstruction theory was essential in understanding how to formulate 3d topological field theories (this was the subject of a recent very interesting question), which have application in the fractional quantum hall effect. This is very abstract mathematics connected to laboratory physics, but only certain simpler parts of the general mathematical machinery are used.\n\n\n3) What are examples that insisting on rigour delayed progress in physics.\n\nThis has happened several times, unfortunately.\n\nStatistical mechanics: The lack of rigorous proof of Boltzmann ergodicity delayed the acceptance of the idea of statistical equilibrium. The rigorous arguments were faulty--- for example, it is easy to prove that there are no phase transitions in finite volume (since the Boltzmann distribution is analytic), so this was considered a strike against Boltzmann theory, since we see phase transitions. You could also prove all sorts of nonsense about mixing entropy (which was fixed by correctly dealing with classical indistinguishability). Since there was no proof that fields would come to thermal equilibrium, some people believed that blackbody light was not thermal. This delayed acceptance of Planck's theory, and Einstein's. Statistical mechanics was not fully accepted until Onsager's Ising model solution in 1941.\nPath integrals: This is the most notorious example. These were accepted by some physicists immediately in the 1950s, although =the formalism wasn't at all close to complete until Candlin formulated Grassman variables in 1956. Past this point, they could have become standard, but they didn't. The formalism had a bad reputation for giving wrong results, mostly because people were uncomfortable with the lack of rigor, so that they couldn't trust the method. I heard a notable physicist complain in the 1990s that the phase-space path integral (with p and q) couldn't possibly be correct because p and q don't commute, and in the path integral they do because they are classical numbers (no, actually, they don't--- their value in an insertion depends discontinuously on their time order in the proper way). It wasn't until the early 1970s that physicists became completely comfortable with the method, and it took a lot of selling to overcome the resistance.\nQuantum field theory construction: The rigorous methods of the 1960s built up a toolbox of complicated distributional methods and perturbation series resummation which turns out to be the least useful way of looking at the thing. It's now C* algebras and operator valued distributions. The correct path is through the path integral the Wilsonian way, and this is closer to the original point of view of Feynman and Schwinger. But a school of rigorous physicists in the 1960s erected large barriers to entry in field theory work, and progress in field theory was halted for a decade, until rigor was thrown out again in the 1970s. But a proper rigorous formulation of quantum fields is still missing.\n\nIn addition to this, there are countless no-go theorems that delayed the discovery of interesting things:\n\nTime cannot be an operator (Pauli): this delayed the emergence of the path integral particle formulation due to Feynman and Schwinger. Here, the time variable on the particle-path is path-integrated just like anything else.\nVon-Neumann's proof of no-hidden variables: This has a modern descendent in the Kochen Sprecher theorem about entangled sets of qubits. This delayed the Bohm theory, which faced massive resistance at first.\nNo charges which transform nontrivially under the Lorentz group(Coleman-Mandula): This theorem had both positive and negative implications. It killed SU(6) theories (good), but it made people miss supersymmetry (bad).\nQuasicrystal order is impossible: This \"no go\" theorem is the standard proof that periodic order (the general definition of crystals) is restricted to the standard space-groups. This made quasicrystals bunk. The assumption that is violated is the assumption of strict periodicity.\nNo supergravity compactifications with chiral fermions (Witten): this theorem assumed manifold compactification, and missed orbifolds of 11d SUGRA, which give rise to the heterotic strings (also Witten, with Horava, so Witten solved the problem).\n\n\n4) What are examples that solid mathematical understanding of certain issues from physics came from further developements in physics itself. (In particular, I am interested in cases where mathematical rigorous understanding of issues from classical mechanics required quantum mechenics, and also in cases where progress in physics was crucial to rigorous mathematical solutions of questions in mathematics not originated in physics.)\n\nThere are several examples here:\n\nUnderstanding the adiabatic theorem in classical mechanics (that the action is an adiabatic invariant) came from quantum mechanics, since it was clear that it was the action that needed to be quantized, and this wouldn't make sense without it being adiabatic invariant. I am not sure who proved the adiabatic theorem, but this is exactly what you were asking for--- an insightful classical theorem that came from quantum mechanics (although some decades before modern quantum mechanics)\nThe understanding of quantum anomalies came directly from a physical observation (the high rate of neutral pion decay to two photons). Clarifying how this happens through Feynman diagrams, even though a naive argument says it is forbidden led to complete understanding of all anomalous terms in terms of topology. This in turn led to the development of Chern-Simons theory, and the connection with Knot polynomials, discovered by Witten, and earning him a Fields medal.\nDistribution theory originated in Dirac's work to try to give a good foundation for quantum mechanics. The distributional nature of quantum fields was understood by Bohr and Rosenfeld in the 1930s, and the mathematics theory was essentially taken from physics into mathematics. Dirac already defined distributions using test functions, although I don't think he was pedantic about the test-function space properties.\n\n\n5) The role of rigor is intensly discussed in popular books and blogs. Please supply references (or better annotated references) to academic studies of the role of mathematical rigour in modern physics.\n\nI can't do this, because I don't know any. But for what it's worth, I think it's a bad idea to try to do too much rigor in physics (or even in some parts of mathematics). The basic reason is that rigorous formulations have to be completely standardized in order for the proofs of different authors to fit-together without seams, and this is only possible in very long hindsight, when the best definitions become apparent. In the present, we're always muddling through fog. So there is always a period where different people have slightly different definitions of what they mean, and the proofs don't quite work, and mistakes can happen. This isn't so terrible, so long as the methods are insightful.\nThe real problem is the massive barrier to entry presented by rigorous definitions. The actual arguments are always much less daunting than the superficial impression you get from reading the proof, because most of the proof is setting up machinery to make the main idea go through. Emphasizing the rigor can put undue emphasis on the machinery rather than the idea.\nIn physics, you are trying to describe what a natural system is doing, and there is no time to waste in studying sociology. So you can't learn all the machinery the mathematicians standardize on at any one time, you just learn the ideas. The ideas are sufficient for getting on, but they aren't sufficient to convince mathematicians you know what you're talking about (since you have a hard time following the conventions). This is improved by the internet, since the barriers to entry have fallen down dramatically, and there might be a way to merge rigorous and nonrigorous thinking today in ways that were not possible in earlier times.", "meta": {"post_id": 27665, "input_score": 122, "output_score": 86, "post_title": "The Role of Rigor"}}
{"input": "I don't understand why when first launched Space X's Dragon capsule had to orbit the Earth many times in order to match up with the ISS? Was this purely to match it's speed, or to get closer (as in altitude) to the ISS?\nIn the stages when it gets to about 200m, it seemed like it was able to go directly up to the ISS, how come it couldn't do that the entire way.\n(Additionally, in Scifi movies you see smaller shuttles able to go directly to space stations in orbit, is that type if travel not possible?)", "output": "In space you don't just \"go somewhere\".\nYou have to match orbits, while not wasting too much fuel.\nIf you're in a low circular orbit, and you want to get to a high circular orbit, it takes two tangential burns, one to elongate your orbit into an ellipse, and another at the high point of the ellipse to make it circular again.\nThis is called a Hohman transfer.\nYou may have to do this multiple times, depending on how much thrust you have.\nIf your orbit is in a different plane from the orbit of the space station, you have to wait until you reach the plane of the other orbit, then do a lateral burn. You may have to do this several times to change your orbit's angle sufficiently, each time having to wait another half-orbit.\nEDIT: to give some perspective on this, if your orbit crosses the plane of the other orbit at an angle of 10 degrees, that means you are crossing that plane at about one mile per second.\n(Orbit velocity times sin(10 degrees).)\nIf your rocket motor generates 1G of thrust, you need to run it around 2.5 minutes to get aligned with that plane. (5280/32/60)\nREVISED:\nIf you're in the same orbit as your destination, but some distance behind it (say), the way you catch up is by getting into a lower orbit by a Hohman transfer, with greater angular velocity, and then another such transfer to get back to the original orbit.\nThis is called orbit phasing.\nIf you just accelerate toward the object, that would put you in an orbit that rises above the target, and then eventually falls further behind because it is a higher orbit.", "meta": {"post_id": 28975, "input_score": 31, "output_score": 54, "post_title": "Why does it take so long to get to the ISS?"}}
{"input": "The Feynman lectures are universally admired, it seems, but also a half-century old.\nTaking them as a source for self-study, what compensation for their age, if any, should today's reader undertake?  I'm interested both in pointers to particular topics where the physics itself is out-of-date, or topics where the pedagogical approach now admits attestable improvements.", "output": "The Feynman Lectures need only a little amending, but it's a relatively small amount compared to any other textbook. The great advantage of the Feynman Lectures is that everything is worked out from scratch Feynman's way, so that it is taught with the maximum insight, something that you can only do after you sit down and redo the old calculations from scratch. This makes them very interesting, because you learn from Feynman how the discovering gets done, the type of reasoning, the physical intuition, and so on.\nThe original presentation also makes it that Feynman says all sorts of things in a slightly different way than other books. This is good to test your understanding, because if you only know something in a half-assed way, Feynman sounds wrong. I remember that when I first read it a million years ago, a large fraction of the things he said sounded completely wrong. This original presentation is a very important component: it teaches you what originality sounds like, and knowing how to be original is the most important thing.\nI think Vol. I is pretty much OK as an intro, although it should be supplemented at least with this stuff:\n\nComputational integration: Feynman does something marvellous at the start of Volume I (something unheard of in 1964), he describes how to Euler time-step a differential equation forward in time. Nowadays, it is a simple thing to numerically integrate any mechanical problem, and experience with numerical integration is essential for students. The integration removes the student's paralysis: when you are staring at an equation and don't know what to do. If you have a computer, you know exactly what to do! Integrating reveals many interesting qualitative things, and shows you just how soon the analytical knowledge painstakingly acquired over 4 centuries craps out. For example, even if you didn't know it, you can see the KAM stability appears spontaneously in self-gravitating clusters at a surprisingly large number of particles. You might expect chaotic motion until you reach 2 particles, which then orbit in an ellipse. But clusters with random masses and velocities of some hundreds of particles eject out particles like crazy, until they get to one or two dozen particles, and then they settle down into a mess of orbits, but this mess must be integrable, because nothing else is ejected out anymore! You discover many things like this from piddling around with particle simulations, and this is something which is missing from Volume I, since computers were not available at the time it was written. It's not completely missing, however, and it's much worse elsewhere.\nThe Kepler problem: Feynman has an interesting point of view regarding this which is published in the \"Lost Lecture\" book and audio-book. But I think the standard methods are better here, because the 17th century things Feynman redoes are too specific to this one problem. This can be supplemented in any book on analytical mechanics.\nThermodynamics: The section on thermodynamics does everything through statistical mechanics and intuition. This begins with the density of the atmosphere, which motivates the Boltzmann distribution, which is then used to derive all sorts of things, culminating in the Clausius-Clayperon equation. This is a great boon when thinking about atoms, but it doesn't teach you the classical thermodynamics, which is really simple starting from modern stat-mech. The position is that the Boltzmann distribution is all you need to know, and that's a little backwards from my perspective. The maximum entropy arguments are better--- they motivate the Boltzmann distribution. The heat-engine he uses is based on rubber-bands too, and yet there is no discussion of why rubber bands are entropic, or of free-energies in the rubber band, or the dependence of stiffness on temperature.\nMonte-Carlo simulation: This is essential, but it obviously requires computers. With Monte-Carlo you can make snapshots of classical statistical systems quickly on a computer and build up intuition. You can make simulations of liquids, and see how the atoms knock around classically. You can simulate rubber-band polymers, and see the stiffness dependence on temperature. All these things are clearly there in Feynman's head, but without a computer, it's hard to transmit it into any of the students' heads.\n\nFor Volume II, the most serious problem is that the foundations are off. Feynman said he wanted to redo the classical textbook point of view on E&M, but he wasn't sure how to do it. The Feynman Lectures were written at a time just before modern gauge theory took off, and while they emphasize the vector potential a lot compared to other treatments of the time, they don't make the vector potential the main object. Feynman wanted to redo Volume II to make it completely vector-potential-centered, but he didn't get to do it. Somebody else did a vector-potential based discussion of E&M based on this recommendation, but the results were not so great.\nThe major things I don't like in Vol. II:\n\nThe derivation of the index of refraction is done by a complicated rescattering calculation which is based on plum-pudding-style electron oscillators. This is essentially just the forward-phase index-of-refraction argument Feynman gives to motivate unitarity in the 1963 ghost paper in Acta Physica Polonika. It is not so interesting or useful in my opinion in Vol. II, but it is the most involved calculation in the series.\nNo special functionology: While the subject is covered with a layer of 19th-century mildew, it is useful to know some special functions, especially Bessel functions and spherical harmonics. Feynman always chooses ultra special forms which give elementary functions, and he knows all the cases which are elementary, so he gets a lot of mileage out of this, but it's not general enough.\nThe fluid section is a little thin--- you will learn how the basic equations work, but no major results. The treatment of fluid flow could have been supplemented with He4 flows, where the potential flow description is correct (it is clear that this is Feynman's motivation for the strange treatment of the subject, but this isn't explicit).\nNumerical methods in field simulation: Here if one wants to write an introductory textbook, one needs to be completely original, because the numerical methods people use today are not so good for field equations of any sort.\n\nVol. III is extremely good because it is so brief. The introduction to quantum mechanics there gets you to a good intuitive understanding quickly, and this is the goal. It probably could use the following:\n\nA discussion of diffusion, and the relation between Schr\u00f6dinger operators and diffusion operators: This is obvious from the path integral, but it was also clear to Schr\u00f6dinger. It also allows you to quickly motivate the exact solutions to Schrodinger's equation, like the $1/r$ potential, something which Feynman just gives you without motivation. A proper motivation can be given by using SUSY QM (without calling it that, just a continued stochastic equation) and trying out different ground state ansatzes.\nGalilean invariance of the Schr\u00f6dinger equation: This part is not done in any book, I think only because Dirac omitted it from his. It is essential to know how to boost wavefunctions. Since Feynman derives the Schr\u00f6dinger equation from a tight-binding model (a lattice approximation), the galilean invariance is not obvious at all.\n\nSince the lectures are introductory, everything in there just becomes second nature, so it doesn't matter that they are old. The old books should just be easier, because the old stuff is already floating in the air. If you find something in the Feynman Lectures which isn't completely obvious, you should study it until it is obvious--- there's no barrier, the things are self-contained.", "meta": {"post_id": 29355, "input_score": 136, "output_score": 137, "post_title": "Reading the Feynman lectures in 2012"}}
{"input": "This is an ultra-soft question about relatively recent history. While reading some of Mandelstam's papers, I noticed that he cites David John Candlin consistenly whenever he does anything with Grassman path-integral. Everyone else cites Berezin.\nSo I read Candlin's 1956 paper, and I was stunned to find a complete and correct description of anticommuting variables, presented more lucidly than anywhere else, with a clear definition of Grassman integration, and a proof that it reproduces the Fermionic quantum field. This is clearly the original source of all the Grassman methods. I was stunned that the inventor of this method is quietly buried away.\nI wrote the Wikipedia page on the guy, but I couldn't find out anything beyond the sketchy stuff I found on an old Princeton staff listing. The fellow doesn't google very well at all.\nHere are the questions:\n\nIs he still alive? (Hello? Are you there?)\nDid he become the experimental physicist David John Candlin in the late 1970s/early 1980s? Or is this someone else with the same name?\nDid he get any credit for his discovery?\n\nI mean, this is one of the central tools of modern physics, it is used every day by every theorist, and the inventor is never mentioned. It's 50% of the path integral. Why the silence?", "output": "I googled a little bit a while ago, and found him. I didn't get any insights into the history of this discovery, he didn't respond to my email. The person I contacted in order to reach him was eventually so offended by my rude email questions that he told me to buzz off. I am only posting this because the guy obviously wants his privacy, and one should respect this. I saw the bounty, and thought people are going to pester this guy in retirement.", "meta": {"post_id": 29475, "input_score": 86, "output_score": 36, "post_title": "What happened to David John Candlin?"}}
{"input": "When correlation function has branch cut in momentum space,\nhow to find correlation in coordinate space? \nFor example\n$$ \\tilde {G}(\\omega) = \\frac{2i}{\\omega+(\\omega^2-\\nu^2)^{1/2}}$$\nHow to get the $G(t)$ usng Fourier transformation ?\nt>0 HERE.\nThis problem is from matrix model of Iizuka and Polchinski. They discuss the propagator in the model and find that the propagator $G(t)$ has power law decay behavior if there is branch cut in $\\tilde{G}(\\omega)$. If there is a pole in the lower half plane for  $\\tilde{G}(\\omega)$, there is an exponential decay in $G(t)$.", "output": "Cutology\nThe math books aren't good for this, you need seat-of-the-pants intuition. The quick and dirty physicist answer is that a branch cut is best thought of as a continuum of poles densely spread over a line. You reproduce branch cuts by integrating poles spread over an interval, for example with a constant \"residue density\" (this is not the standard term for it, see below)\n$$ \\log\\left({x-a\\over x-b}\\right) = \\int_a^b {1\\over x-u} du$$\nAnd this is a continuous density of poles with unit residue between a and b, just as you can see from the right hand side, and a function with a cut between a and b on the left hand side. If you make the residue density between a and b some function $\\rho(u)$\n$$ f(x) = \\int_a^b {\\rho(u)\\over x-u} du $$\nyou get different functions, but always with a cut inside [a,b] wherever $\\rho(u)$ is nonzero. The residue density is not usually called the residue density--- it's called the \"cut discontinuity\", because if you consider the value of the function f defined by integral just above and just below the real axis somewhere in the interval [a,b], and take the difference between the two values, you get 2\\pi i times $\\rho$ as the difference. This is because you can deform the two integrals in opposite sense into a small circle, or, if you like, because of the Cauchy-distribution representation of the delta function as:\n$$\\delta(x) = {1\\over 2\\pi i} \\left({1\\over x-i\\epsilon} - {1\\over x+i\\epsilon}\\right)$$\nWhich you can work out explicitly.\nTo show you how it works in detail, say you want reproduce the square-root function's branch cut, running along the negative real axis, you look for the jump-discontinuity in $\\sqrt{x}$ along the negative axis. It goes from $i\\sqrt{|x|}$ to $-i\\sqrt{x}$, the jump discontinuity is the square root of the distance from the origin. So you write \n$$ f(x) = {1\\over \\pi} \\int_{-\\infty}^0 {\\sqrt{|u|}\\over x-u} du $$\nAnd this should reproduce the square-root function. Except this is nonsense, since the integral is divergent! This is still morally true, however, by doing the following manipulation: change u to -u, and split the integral as follows:\n$$ {2\\over \\pi} \\int_0^\\infty {1\\over2\\sqrt{u}} {u\\over x+u} du $$\nThen split ${u\\over x+u}$ into $1 - {x\\over x+u}$. Discard the 1, because this is an (infinite) x independent constant, and change variables to $\\alpha=\\sqrt{u}$, and you get\n$$ {2\\over \\pi} \\int_0^\\infty {x\\over x+\\alpha^2} d\\alpha $$\nNow you can see that this evaluates to $\\sqrt{x}$ by rescaling by x. So it works, but you have to watch out for divergences.\nPolology\nWhen there is a single pole on the negative imaginary axis at position $-ai$, when you integrate with $e^{-i\\omega t}$, for t positive, the integration contour can be moved down to the $\\mathrm{Im}(\\omega)=-ia$ line, just by sliding it down (there are no singularities along the way) and the integral along the new contour is a sum of contributions each with an exponential decay $e^{-at}$. So the dominant exponential decay at infinity is the pole closest to the real axis.\nIf the pole is the only singularity and with appropriate stuff at negative imaginary infinity, you can do the integral explicitly, but the contour moving is simple and doesn't depend on anything, and shows the exponential decay immediately. Usually you have many singularities, and you only want the leading behavior at infinity.\nIf there is a pole very close to the real axis with position $a-i\\epsilon$, the fourier transform isn't exponentially decaying (or rather it is decaying with a rate $\\epsilon$), but oscillating. There can't be any singularities in the positive imaginary $\\omega$ halfplane, as this would lead to a blow up in the future. This means that you should imagine all singularities shifted infinitesimally to the negative imaginary half-plane, just like this.\nWhen there is a continuous density of poles, you get a continuous density of decay rates, and if they accumulate arbitrarily close to the real axis, you get a continuous superposition of different decay rates that can reproduces a power law, if the pole-density near the real axis is the appropriate power.\nYour thing\nIn you case, you have a cut starting at $\\omega=\\nu$ on the real axis, and the cut runs off to infinity somehow along the negative imaginary axis. The discontinuity in the imaginary part along the cut can be found by writing the thing as\n$$ {\\omega - \\sqrt{\\omega^2 - \\nu^2}}\\over \\nu^2 $$\nand you can see there is a square-root pole-density near $\\omega=\\nu$. Each pole gives a decy of $e^{-at}$ in real time, so you superpose the decays:\n$$ \\int_0^\\infty \\sqrt{a} e^{-at} da \\approx t^{-\\frac{3}{2}} $$\nThis is all on top of a general oscillation of $e^{-i\\nu t}$ which you get from the fact that this stuff is happening near $\\omega=\\nu$. This sort of stuff is very useful, and is secret lore for some reason.", "meta": {"post_id": 29532, "input_score": 15, "output_score": 37, "post_title": "Correlation function which has branch cut in momentum space"}}
{"input": "When I smear oil onto a scrap of paper and rub it in, the paper becomes quite translucent; but when I attempt the same with water it doesn't as much. Why?", "output": "The thing is that paper fibers are really transparent (unless the paper has been painted some color, of course). The only reason paper blocks light is that its fibers are all \"immersed\" in air. \nTry to imagine what you would see with a very potent microscope: various clear tubes going in all directions. What happens to a ray of light entering this maze of \"transparent tubes\"? It gets refracted each time it enters and each time it leaves each tube. The final result is that light might scatter in any direction, but it's more probable to leave by the same surface it entered, that means: back to you. That makes paper white.\nNow, if you fill all this space with a fluid (by soaking paper in said fluid) and this fluid has a refractive index similar to the fibers, the light will not \"feel\" so much when it passes from fluid to fiber. The end result is that light will not scatter that much, and the paper becomes more transparent. The better the matching between the refractive indexes the more transparent the paper will be.\nWhat you are noticing is that oil has a refractive index that is more similar to that of the fibers than water has. Still, water is closer to target than air, so paper gets a bit transparent with water too.\nP.S. This is also related to your other question (\"wet is dark\"). If the object is thick (imagine a pile of paper, or sand). Wetting it will enable light to penetrate more. Less of it will be reflected back to you, making the object look darker.", "meta": {"post_id": 30365, "input_score": 52, "output_score": 74, "post_title": "Why does paper become translucent when smeared with oil but not (so much) with water?"}}
{"input": "I have this childrens rubber ball which glows in the dark after it's exposed to light. I \"charge\" it with a flash light then play with my dogs at night. I thought to try a very intense green laser, and see how the ball reacted.\nThe laser light had no effect on the balls ability to glow. So I'm left wondering, why does laser light not allow luminescence (maybe not the right word) materials to glow?\nEDIT In Response to Answer.\nSo I tried a little modification. I tried exciting the ball with three different light sources; a \"super bright\" Red LED, a very very \"super bright\" white LED and a blue LED of unknown specs (no package, bottom of my kit). I held the ball to each light source (driven with the same current) for the same approximate amount of time and compared the results. The red LED had no effect. The white had a bit of an effect, enough to see dimly in normal room lighting. The blue led had a significant effect, causing a bright glow. This was interesting as the blue LED was the least bright visually. Yay science!", "output": "The ball is probably glowing because it has strontium aluminate in, which produces light by phosphoresence. It's a characteristic of phosphorescence that the light emission is quite long lived. This happens because when you shine light onto a phosphor the light promotes it into an excited state that subsequently decays by interactions with the solid lattice into a long lived metastable state. It's this metastable state that decays slowly and emits light as it does so.\nBecause of this mechanism the light emitted is always a longer wavelength/lower energy than the light you need to excite the phosphor. You don't say what colour light the ball emits, but if it uses strontium aluminate it will be a slightly bluey green colour. The light needed to excite is has to be bluer than the light it emits, and that's why your green laser won't make the ball glow. It has too long a wavelength.\nWhite light from a torch won't contain that much blue light (unless it has a xenon bulb) but the green laser won't have any blue light at all because obviously lasers are monochromatic.\nIt's also possible that the ball contains zinc sulphide. This isn't as good a phosphor as strontium aluminate, but it's a lot cheaper. If the ball does contain zinc sulphide then the situation is a little more confused because the colour of the phosphorescence is determined by metal additives such as silver and copper. However, the basic principle still applies, that the light needed to excite the phosphor has to be nearer the blue end of the spectrum than the light emitted.\nAnyhow, thanks (and +1 :-) for a facinating question and I wish I could give you another +1 for actually doing the experiment with the laser. If you have some time on your hands see if you can find some coloured gels and try shining your torch onto the ball through the gels. You should find that the red gel won't cause any glow while the blue gel will, and at some point in the spectrum there will be a colour where the glow starts.", "meta": {"post_id": 32402, "input_score": 40, "output_score": 36, "post_title": "Why does laser light not affect glowing materials?"}}
{"input": "I have read about anomalies in different contexts and ways. I would like to read an explanation that unified all these statements or points of view:\n\nAnomalies are due to the fact that quantum field theories (and maybe quantum mechanical theories with singular potential) must be regularized and it can be possible that none regularization procedure may respect all the symmetries of the classical theory. For instance, according to Fujikawa's viewpoint, one cannot find a regularized functional measure in the path-integral which preserves the symmetries of the classical action.\nAnomalies are due to the fact that quantum theory requires an ordering prescription for operators and it may happen that none ordering prescription respects the symmetries of the classical theory. Here in principle one could have anomalies in quantum mechanics with non-singular potentials.\nAnomalies are due to the fact that generators of the symmetry do not leave invariant the domain of definition of the Hamiltonian and thus, although the formal commutator of those generators with the Hamiltonian vanishes, the charges are not conserved due to the extra surface term that appears in the exact Heisenberg equation. It is not clear to me if in this case the anomaly is already present in the classical theory.\nAnomalies are due to the emergence of central charges in the algebra of conserved quantities. In this case one can have classical anomalies if it is in the algebra of Poisson brackets, or quantum anomalies if it happens at the level of quantum commutators.\n\nI would like you to share examples and relations between the previous perspectives, and discussions about their equivalence. The only I see is the following relation:\nOrdering of operators ----> different definition of path integral measure.\nOrdering of operators ----> delta functions ---> regularization.\nOrdering of operators ----> different algebra of conserved charges.", "output": "Nowadays there exists a more fundamental geometrical interpretation of anomalies which I think can resolve some of your questions. The basic source of anomalies is that classically and quantum-mechanically we are working with realizations and representations of the symmetry group, i.e., given a group of symmetries through a standard realization on some space  we need to lift the action to the adequate geometrical objects we work with in classical and quantum theory and sometimes, this action cannot be lifted. Mathematically, this is called an obstruction to the action lifting, which is the origin of anomalies. The obstructions often lead to the possibility to the realization not of the group of symmetries itself but some extension of it by another group acting naturally on the geometrical objects defining the theory.\nThere are three levels of realization of a group of symmetries:\nThe abstract level: for example the action of the Lorentz (Galilean) group on a Minkowski (Eucledian) space. This representation, for example is not unitary, and it is not the representation we work with in quantum mechanics.\nThe classical level:  When the group action is realized in terms of functions belonging to the Poisson algebra of some phase space. For example, the realization of the Galilean or the Lorentz groups on the phase space of a classical free particle.\nThe quantum level when the group action realized in terms of a linear representations of operators on some Hilbert space (or just operators belonging to some $C^*$ algebra. For example, the realization of the Galilean or the Lorentz groups on a quantum Hilbert space of a free particle. \nNow, passing from the abstract level to either the classical or the\nquantum level may be accompanied with an obstruction. These obstructions exist in already quantum and classical mechanics with finite number of degrees of freedom, and not only in quantum field theories. Two very known examples are the Galilean group which cannot be realized on the Poisson algebra of the phase space of the free particle, rather, a central extension of which with a modified commutation relation:\n$$[K_i, P_j] =-i \\delta_{ij}m$$\n, is realized. ($K_i$ are boosts and $P_i$ are translations $m$ is the mass). This extension was discovered by Bargmann, and sometimes it is called the Bargmann group. A second example, is the realization of spin systems in terms of sections of homogeneous line bundles over the two sphere $S^2$. Now, the action of the isometry group $SO(3)$ cannot be lifted to line bundles corresponding to half integer spins, rather a $\\mathbb{Z}_2$ extension of which, namely $SU(2)$ can be lifted. In this case the extended group is semisimple and the issue that $SU(2)$ being a group extension of $SO(3)$ and not just a universal cover is not usually emphasized in physics texts.\nThe group extensions realized as a consequence of these obstructions may require:\n1) Ray representations of the original group which are true representations of the extended group. This is the case of $SO(3)$, where the half integer spins can be realized through ray epresentations of SO(3), which are true representations of $SU(2)$. In this\nthe Lie algebras of both groups are isomorphic.\n2) Group extensions corresponding Lie algebra extensions. This is the more general case corresponding for example to the Galilean case.\nNow, in the quantum level, one can easier understand, why the\nobstructions lead to group extensions. This is because, we are looking\nfor representations satisfying two additional conditions:\n1) Unitarity\n2) Positive energy\nSometimes (up to $1+1$ dimensions), we can satisfy these conditions merely by normal ordering, which results central extensions of the symmetry groups. This method apply to the case of the Virasoro and the Kac-Moody algebras which are central extensions to the Witt and loop algebras respectively, and can be obtained in the quantum level after normal ordering.\nThe relation between normal ordering and anomalies can be explained in\nthat the quantization operators are needed to be Toeplitz operators. A very known example is the realization of the harmonic oscillator on the Bargmann space of analytic functions, then the Toeplitz operators are exactly those operators where all derivatives are moved to the right. This is called the Wick quantization and it exactly corresponds to normal ordering in the algebraic representation. The main property of Toeplitz operators is that their composition is performed through star products, and star products of Toeplitz operators are are also Toeplitz operators thus the algebra of quantum operators is closed, but it is not closed to the original group but rather to a central extension of which. This important interpretation hasn't been extended to field theories yet.\nIt is worthwhile to mention that central extensions are not the most\ngeneral extensions one can obtain when a symmetry is realized in terms of operators in quantum theory, there are Abelian and even non-Abelian\nextensions. One of the more known extensions of this type is the\nMickelsson-Faddeev extension of the algebra of chiral fermion non-Abelian charge densities when coupled to an external Yang-Mills field in $3+1$ dimensions:\n$$[T_{a}(x), T_{b}(y)] = if_{ab}^c T_c(x) \\delta^{(3)}x-y) +id_{ab}^c\\epsilon_{ijk} \\partial_i\\delta^{(3)}(x-y) \\partial_j A_{ck}$$\nThis extension is an Abelian noncentral extension.\nThe explanation of the existence \"anomalies\" in the classical case, i.e., on the Poisson algebra can be understood already in the case of the simplest symplectic manifold $\\mathbb{R}^2$, the Poisson algebra is not isomorphic the translations algebra. A deeper analysis for example given in: Marsden and Ratiu page 408 for the case of the Galilean group. They showed that on the free particle Hilbert space, the Galilean group lifts to a central extension (the Bargmann group) which acts unitarily on the free particle Hilbert space: $\\mathcal{H} = L^2(\\mathbb{R}^3)$. Now, the projective Hilbert space $\\mathcal{PH}$ is a symplectic manifold (as any complex projective space) in which the particle's phase space is embedded. The restriction of the representation to the projective Hilbert space and then to the particle's phase space retains the central extension i.e., is isomorphic to the extended group, thus the extended group acts on the Poisson algebra.\nAs a matter of fact one should expect always that the anomaly should be realized classically on the phase space. The case of fermionic chiral anomalies seems singular, because it is customary to say that the anomaly is existent only at the quantum level. The reason is that the space of Grassmann variables is not really a phase space, and even in the case of fermions, the anomaly exists in the classical level when one represents them in terms of \"Bosonic coordinates\". These anomalies are given as Wess-Zumino-Witten terms. (Of course these representations are not useful in Perturbation theory).\nAnother reasoning why anomalies exist always on the classical (phase space) level is that in geometric quantization, anomalies can be obtained on the level of prequantization. Now, prequantization does not require any more data than the phase space (not like the quantization itself which requires a polarization).\nNow, trying to respond on your specific questions. It is true that chiral anomalies were discovered in quantum field theories when no ultraviolet regulators respecting the chiral symmetry could be found. But anomaly is actually an infrared property of the theory. The signs for that is the Adler-Bardeen theorem that no higher loop (than one) correction to the axial anomaly is present and more importantly only massless particles contribute to the anomaly. In the operator approach that I tried to adopt in this answer the anomaly is a consequence of a deformation that should be performed on the symmetry generators in order to be well defined on the physical Hilbert space and not a direct consequence of regularization.\nSecondly, the anomaly exists in equally on both levels quantum and classical (on the phase space). The case of fermions and regularization was addressed separately. \nUpdate - Elaboration of the spin case:\nHere is the elaboration of the $SO(3)$, $SU(2)$ case which contains all the\ningredients regarding the obstruction to lifting and group extensions,\nexcept that it does not have a corresponding Lie algebra extension.\nWe work on $S^2$ using the stereographic projection coordinate given in terms of the polar coordinates by:\n$$z = \\tan \\frac{\\theta}{2} e^{i \\phi}$$\nAn element of the group $SU(2)$ \n$$g=\\begin{pmatrix}\n  \\alpha& \\beta\\\\\n  -\\bar{\\beta} & \\bar{\\alpha }  \n\\end{pmatrix}$$\nacts on $S^2$ according to the M\u00f6bius transformation:\n$$ z \\rightarrow z^g = \\frac{\\alpha z + \\beta}{-\\bar{\\beta} z +  \\bar{\\alpha }  }$$\nHowever, one observes that the action of the special element: \n$$g_0=\\begin{pmatrix}\n  -1& 0\\\\\n  0 & -1  \n\\end{pmatrix}$$\nis identical to the action of the identity.  This element is an SU(2)\nelement that projects to the unity of SO(3) (This can be seen from its\nthree dimensional representation which is the unit matrix). Thus the\ngroup which acts nontrivially on $S^2$ is $SO(3)$\nNow quantum mechanically spin systems can be realized on the sphere in\nHilbert spaces of  analytic functions:\n$$ (\\psi, \\xi) = \\int_{S^2} \\overline{\\xi(z)} \\psi(z) \\frac{dzd\\bar{z}}{(1+\\bar{z}z)^2}$$\nTransforming under $SU(2)$ according to:\n$$ \\psi(z) \\rightarrow \\psi^g(z) = (-\\bar{\\beta} z +  \\bar{\\alpha })^{2j} \\psi(z^{g^{-1}})$$\nThis is a ray representation of $SO(3)$ as  $SO(3)$ does not have half integer representations.\nNow, the first observation (the quantum level) is that the special element does not act\non the wave functions as the unit operator, for half integer spins it\nadds a phase of $\\pi$. This is what is meant that the $SO(3)$ action\ncannot be lifted to the quantum Hilbert space.\nNow turning to the the classical level. The symplectic form on $S^2$ is proportional to its area\nelement. The proportionality constant has to be an integer in a prequantizable theory (Dirac quantization condition)\n$$\\omega = 2j \\frac{dz \\wedge d\\bar{z}}{(1+\\bar{z}z)^2}$$\nThe corresponding Poisson bracket between two functions on the sphere:\n$$\\{f, h\\} =\\frac{1}{2j} (1+\\bar{z}z)(\\partial_z f \\partial_{\\bar{z}} h - \\partial_z h \\partial_{\\bar{z}} f)$$\nThe function generating the group action in the Poisson algebra is given\nby:\n$$f_g=  \\left(\\frac{\\alpha \\bar{z}z + \\beta  \\bar{z} - \\bar{\\beta}z + \\bar{\\alpha}}{1+\\bar{z}z}\\right)^{2j}$$\nNow, the function representing the unity of SU(2) in the function $f=1$,\nwhile the function representing the special element is  $f=-1$ for half integer spins, which is\na different function (It has to be a constant because it belongs to the\ncenter of $SU(2)$, thus it has to Poisson commute with all functions.\nThus even at the classical level, the action of $SO(3)$ does not lift to\nthe Poisson algebra.\nNow, regarding the question of classically distinguishing $SU(2)$ of $SO(3)$. If you compute the classical partition function of a spin\n$\\frac{1}{2}$ gas interacting with a magnetic field, it will be different than say spin $1$, but spin  $\\frac{1}{2}$ exists in the first place only if $SU(2)$ acts because $SO(3)$ allows only integer spins.", "meta": {"post_id": 33195, "input_score": 96, "output_score": 66, "post_title": "Classical and quantum anomalies"}}
{"input": "Deterministic models. Clarification of the question:\nThe problem with these blogs is that people are inclined to start yelling at each other. (I admit, I got infected and it's difficult not to raise one's electronic voice.) I want to ask my question without an entourage of polemics.\nMy recent papers were greeted with scepticism. I've no problem with that. What disturbes me is the general reaction that they are \"wrong\". My question is summarised as follows: \nDid any of these people actually read the work and can anyone tell me where a mistake was made?\nNow the details. I can't help being disgusted by the \"many world\" interpretation, or the Bohm-de Broglie \"pilot waves\", and even the idea that the quantum world must be non-local is difficult to buy. I want to know what is really going on, and in order to try to get some ideas, I construct some models with various degrees of sophistication. These models are of course \"wrong\" in the sense that they do not describe the real world, they do not generate the Standard Model, but one can imagine starting from such simple models and adding more and more complicated details to make them look more realistic, in various stages.\nOf course I know what the difficulties are when one tries to underpin QM with determinism. Simple probabilistic theories fail in an essential way. One or several of the usual assumptions made in such a deterministic theory will probably have to be abandoned; I am fully aware of that. On the other hand, our world seems to be extremely logical and natural. \nTherefore, I decided to start my investigation at the other end. Make assumptions that later surely will have to be amended; make some simple models, compare these with what we know about the real world, and then modify the assumptions any way we like.\nThe no-go theorems tell us that a simple cellular automaton model is not likely to work. One way I tried to \"amend\" them, was to introduce information loss. At first sight this would carry me even further away from QM, but if you look a little more closely, you find that one still can introduce a Hilbert space, but it becomes much smaller and it may become holographic, which is something we may actually want. If you then realize that information loss makes any mapping from the deterministic model to QM states fundamentally non-local\u2014while the physics itself stays local\u2014then maybe the idea becomes more attractive.\nNow the problem with this is that again one makes too big assumptions, and the math is quite complicated and unattractive.\nSo I went back to a reversible, local, deterministic automaton and asked: To what extent does this resemble QM, and where does it go wrong? With the idea in mind that we will alter the assumptions, maybe add information loss, put in an expanding universe, but all that comes later; first I want to know what goes wrong.\nAnd here is the surprise: In a sense, nothing goes wrong. All you have to assume is that we use quantum states, even if the evolution laws themselves are deterministic. So the probability distributions are given by quantum amplitudes. The point is that, when describing the mapping between the deterministic system and the quantum system, there is a lot of freedom. If you look at any one periodic mode of the deterministic system, you can define a common contribution to the energy for all states in this mode, and this introduces a large number of arbitrary constants, so we are given much freedom.\nUsing this freedom I end up with quite a few models that I happen to find interesting. Starting with deterministic systems I end up with quantum systems. I mean real quantum systems, not any of those ugly concoctions. On the other hand, they are still a long way off from the Standard Model, or even anything else that shows decent, interacting particles.\nExcept string theory. Is the model I constructed a counterexample, showing that what everyone tells me about fundamental QM being incompatible with determinism, is wrong? No, I don't believe that. The idea was that, somewhere, I will have to modify my assumptions, but maybe the usual assumptions made in the no-go theorems will have to be looked at as well. \nI personally think people are too quick in rejecting \"superdeterminism\". I do reject \"conspiracy\", but that might not be the same thing. Superdeterminism simply states that you can't \"change your mind\" (about which component of a spin to measure), by \"free will\", without also having a modification of the deterministic modes of your world in the distant past. It's obviously true in a deterministic world, and maybe this is an essential fact that has to be taken into account. It does not imply \"conspiracy\".\nDoes someone have a good, or better, idea about this approach, without name-calling? Why are some of you so strongly opinionated that it is \"wrong\"? Am I stepping on someone's religeous feelings? I hope not.\nReferences: \n\"Relating the quantum mechanics of discrete systems to standard canonical quantum mechanics\",  arXiv:1204.4926 [quant-ph];\n\"Duality between a deterministic cellular automaton and a bosonic quantum field theory in $1+1$ dimensions\", arXiv:1205.4107 [quant-ph];\n\"Discreteness and Determinism in Superstrings\", arXiv:1207.3612 [hep-th].\n\nFurther reactions on the answers given. (Writing this as \"comment\" failed, then writing this as \"answer\" generated objections. I'll try to erase the \"answer\" that I should not have put there...)\nFirst: thank you for the elaborate answers.\nI realise that my question raises philosophical issues; these are interesting and important, but not my main concern. I want to know why I find no technical problem while constructing my model. I am flattered by the impression that my theories were so \"easy\" to construct. Indeed, I made my presentation as transparent as possible, but it wasn't easy. There are many dead alleys, and not all models work equally well. For instance, the harmonic oscillator can be mapped onto a simple periodic automaton, but then one does hit upon technicalities: The hamiltonian of a periodic system seems to be unbounded above and below, while the harmonic oscillator has a ground state. The time-reversible cellular automaton (CA) that consists of two steps $A$ and $B$, where both $A$ and $B$ can be written as the exponent of physically reasonable Hamiltonians, itself is much more difficult to express as a Hamiltonian theory, because the BCH series does not converge. Also, explicit $3+1$ dimensional QFT models resisted my attempts to rewrite them as cellular automata. This is why I was surprised that the superstring works so nicely, it seems, but even here, to achieve this, quite a few tricks had to be invented.\n@RonMaimon. I here repeat what I said in a comment, just because there the 600 character limit distorted my text too much. You gave a good exposition of the problem in earlier contributions: in a CA the \"ontic\" wave function of the universe can only be in specific modes of the CA. This means that the universe can only be in states $\\psi_1,\\ \\psi_2,\\ ...$ that have the property $\\langle\\psi_i\\,|\\,\\psi_j\\rangle=\\delta_{ij}$, whereas the quantum world that we would like to describe, allows for many more states that are not at all orthonormal to each other. How could these states ever arise? I summarise, with apologies for the repetition:\n\nWe usually think that Hilbert space is separable, that is, inside every infinitesimal volume element of this world there is a Hilbert space, and the entire Hilbert space is the product of all these.\nNormally, we assume that any of the states in this joint Hilbert space may represent an \"ontic\" state of the Universe.\nI think this might not be true. The ontic states of the universe may form a much smaller class of states $\\psi_i$; in terms of CA states, they must form an orthonormal set. In terms of \"Standard Model\" (SM) states, this orthonormal set is not separable, and this is why, locally, we think we have not only the basis elements but also all superpositions. \nThe orthonormal set is then easy to map back onto the CA states. \n\nI don't think we have to talk about a non-denumerable number of states, but the number of CA states is extremely large. In short: the mathematical system allows us to choose: take all CA states, then the orthonormal set is large enough to describe all possible universes, or choose the much smaller set of SM states, then you also need many superimposed states to describe the universe. The transition from one description to the other is natural and smooth in the mathematical sense. \nI suspect that, this way, one can see how a description that is not quantum mechanical at the CA level (admitting only \"classical\" probabilities), can \"gradually\" force us into accepting quantum amplitudes when turning to larger distance scales, and limiting ourselves to much lower energy levels only. You see, in words, all of this might sound crooky and vague, but in my models I think I am forced to think this way, simply by looking at the expressions: In terms of the SM states, I could easily decide to accept all quantum amplitudes, but when turning to the CA basis, I discover that superpositions are superfluous; they can be replaced by classical probabilities without changing any of the physics, because in the CA, the phase factors in the superpositions will never become observable.\n@Ron I understand that what you are trying to do is something else. It is not clear to me whether you want to interpret $\\delta\\rho$ as a wave function. (I am not worried about the absence of $\\mathrm{i}$, as long as the minus sign is allowed.) My theory is much more direct; I use the original \"quantum\" description with only conventional wave functions and conventional probabilities.\n\n(New since Sunday Aug. 20, 2012)\nThere is a problem with my argument. (I correct some statements I had put here earlier). I have to work with two kinds of states: 1: the template states, used whever you do quantum mechanics, these allow for any kinds of superposition; and 2: the ontic states, the set of states that form the basis of the CA. The ontic states $|n\\rangle$ are all orthonormal: $\\langle n|m\\rangle=\\delta_{nm}$, so no superpositions are allowed for them (unless you want to construct a template state of course). One can then ask the question: How can it be that we (think we) see superimposed states in experiments? Aren't experiments only seeing ontic states?\nMy answer has always been: Who cares about that problem? Just use the rules of QM. Use the templates to do any calculation you like, compute your state $|\\psi\\rangle$, and then note that the CA probabilities, $\\rho_n=|\\langle n|\\psi\\rangle|^2$, evolve exactly as probabilities are supposed to do.\nThat works, but it leaves the question unanswered, and for some reason, my friends on this discussion page get upset by that.\nSo I started thinking about it. I concluded that the template states can be used to describe the ontic states, but this means that, somewhere along the line, they have to be reduced to an orthonormal set. How does this happen? In particular, how can it be that experiments strongly suggest that superpositions play extremely important roles, while according to my theory, somehow, these are plutoed by saying that they aren't ontic? \nLooking at the math expressions, I now tend to think that orthonormality is restored by \"superdeterminism\", combined with vacuum fluctuations. The thing we call vacuum state, $|\\emptyset\\rangle$, is not an ontological state, but a superposition of many, perhaps all, CA states. The phases can be chosen to be anything, but it makes sense to choose them to be $+1$ for the vacuum. This is actually a nice way to define phases: all other phases you might introduce for non-vacuum states now have a definite meaning.\nThe states we normally consider in an experiment are usually orthogonal to the vacuum. If we say that we can do experiments with two states, $A$ and $B$, that are not orthonormal to each other, this means that these are template states; it is easy to construct such states and to calculate how they evolve. However, it is safe to assume that, actually, the ontological states $|n\\rangle$ with non-vanishing inner product with $A$, must be different from the states $|m\\rangle$ that occur in $B$, so that, in spite of the template, $\\langle A|B\\rangle=0$. This is because the universe never repeats itself exactly. My physical interpretation of this is \"superdeterminism\": If, in an EPR or Bell experiment, Alice (or Bob) changes her (his) mind about what to measure, she (he) works with states $m$ which all differ from all states $n$ used previously. In the template states, all one has to do is assume at least one change in one of the physical states somewhere else in the universe. The contradiction then disappears.  \nThe role of vacuum fluctuations is also unavoidable when considering the decay of an unstable particle.\nI think there's no problem with the above arguments, but some people find it difficult to accept that the working of their minds may have any effect at all on vacuum fluctuations, or the converse, that vacuum fluctuations might affect their minds. The \"free will\" of an observer is at risk; people won't like that.\nBut most disturbingly, this argument would imply that what my friends have been teaching at Harvard and other places, for many decades as we are told, is actually incorrect. I want to stay modest; I find this disturbing.\nA revised version of my latest paper was now sent to the arXiv (will probably be available from Monday or Tuesday). Thanks to you all. My conclusion did not change, but I now have more precise arguments concerning Bell's inequalities and what vacuum fluctuations can do to them.", "output": "This could have been a comment, but as it actually anwers the question asked in the title, I'll post it as such:\nAs far as I can tell there's no rational reason to dismiss these models out of hand - it's just that quantum mechanics (QM) has set the bar awfully high: So far, there's no experimental evidence that QM is wrong, and no one has come up with a viable alternative.\nUltimately, your theory needs to reproduce all experimentally verified predictions of QM (or rather, your theory may only deviate within the experimental precision). However, there is of course no need to reproduce arbitrary predictions - in fact, if you did, you'd end up with a re-formulation - i.e. a new interpretation - of ordinary QM. If your model tells us large-scale quantum computation is impossible, then it's up to the experimentalists to prove you wrong.\nAny objections beyond that are just psychology at work: It takes quite some effort for most people to convince themselves that QM is a valid description of the world we live in, and once such a belief is ingrained, it easily becomes dogma.", "meta": {"post_id": 34217, "input_score": 140, "output_score": 39, "post_title": "Why do people categorically dismiss some simple quantum models?"}}
{"input": "If so, how much? Is it possible to detect it, or is it beyond any measurement?\nI'd say there are two possible scenarios (depending on the battery type) and both seem interesting:\n\nThe battery reacts chemically with its environment.\nThe battery doesn't exchange any matter with its environment except electrons. I suppose there should be some difference at least due to the principle of energy-matter equivalence, but the difference is most likely immeasurable.", "output": "Yes, the total mass of a battery increases when the battery is charged and decreases when it is discharged.\nThe difference boils to Einstein's $E=mc^2$ that follows from his special theory of relativity. Energy is equivalent to mass and $c^2$, the squared speed of light, is the conversion factor.\nI would omit the scenario I. If the lithium is leaking from a battery, or if any atoms (and it's the nuclei that I am talking about) are moving in or out, the mass of the battery is obviously changing by the mass of these nuclei (or whole atoms). That probably doesn't need an extra explanation. So we will continue with the scenario II in which the atoms inside the battery are only rearranged into different configurations or different molecules but the identity and the number of the nuclei inside the battery is constant.\nLet me just emphasize that the energy can't be calculated from masses of the electrons. Electrons are not lost when a battery is discharged. If a battery is losing electric energy, it doesn't mean that it's losing the electric charge! They're just moved from one electrode closer to the other and it's just the motion through the wire stretched between the electrodes (and the electric field inside the wires) that powers the electric devices. But the whole battery is always electrically neutral; because it contains a fixed number of protons, it must contain a fixed (the same) number of electrons, too.\nInstead, the energy difference really boils down to different electrostatic potential energies of the electrons relatively to the nuclei. One could say that when a battery is being discharged, its electrons are moving to places that are closer to the nuclei, perhaps other nuclei, in average and the modified interaction energy affects the amount of energy=mass stored in the electromagnetic field. \n(There are also interaction energies of electron pairs and kinetic energies of electrons \u2013 $m_e c^2 (1/\\sqrt{1-v^2/c^2} - 1)$ \u2013 but let me simplify it by the potential energies of protons-electrons which are dominant and have the right sign. Well, it could actually be pedagogical to borrow the electrons' kinetic energies as the source of the mass difference because for them, we immediately see that the relativistic mass is $m_e/\\sqrt{1-v^2/c^2}$ which depends on the velocity and the average squared velocity of the electrons depends on how we arrange the molecules i.e. on whether or not the battery is charged.)\nYes, the change of the mass is pretty much negligible and can't be measured by current scales.\nFor example, Chevrolet Volt has batteries that may store 16 kWh. Multiply it by 1,000 and 3,600 to get the value in Joules; divide it by $10^{17}$ which is (approximately) the squared speed of light and you get the mass difference in kilograms. It's about\n$$ 16 \\times 1,000 \\times 3,600 / 10^{17} = 0.6 \\times 10^{-9} $$\nThat's half a microgram \u2013 for this huge Chevrolet Volt battery. One can't really measure it this precisely because pieces of the battery evaporate, the battery may absorb some dust, humidity etc. The mass difference above is comparable to the mass of a water droplet of diameter 0.1 mm or so. Even the national prototype kilograms\n\nhttp://en.wikipedia.org/wiki/International_Prototype_Kilogram#Stability_of_the_international_prototype_kilogram\n\nhave masses that differ from the mass of the international prototype kilogram by dozens of micrograms. From 1900, each of them has changed by a dozen of micrograms. So the unit of \"kilogram\" isn't even defined \"internationally\" with the accuracy needed to distinguish the masses of the battery before and after. However, it's plausible that a fancy device could measure the mass difference more directly; the difference of the mass isn't infinitesimal, after all. But when you're touching the electrodes, you must be careful not to scratch them, not even a little bit, and not to allow the paint to evaporate when the battery gets warmer, not even a little bit, and so on.\nThe measurement problem would become much more manageable with a nuclear battery, of course. ;-) If you let some uranium decay by fission, it creates lots of energy (e.g. in Temel\u00edn) and the mass $m=E/c^2$ decreases by 0.1 percent or so. If you had a thermonuclear power plant running on hydrogen, the products of the fusion would be about 1% lighter than the hydrogen at the beginning. That would of course be measurable in principle. Nuclear energy is much more concentrated (about 1 million times higher densities in Joules per kilogram: 1 MeV per nucleus i.e. per atom) than the chemical energy (and batteries run on chemical energies: about 1 eV per atom) so the relative change of the mass would be 1 million times more significant, too.\nA hypothetical (science-fiction) matter-antimatter fuel producing energy from complete annihilation of matter against antimatter (note that both of them have a positive $m$) to electromagnetic waves (quickly converted to heat etc.) would lower the original mass of the solid material $m=E/c^2$ down to zero i.e. by 100%; the objects that would absorb the heat (or the energy partly converted to more useful forms) would get heavier by the same amount.", "meta": {"post_id": 34421, "input_score": 45, "output_score": 55, "post_title": "Does the mass of a battery change when charged/discharged?"}}
{"input": "In a perfectly symmetrical spherical hollow shell, there is a null net gravitational force according to Newton, since in his theory the force is exactly inversely proportional to the square of the distance.\nWhat is the result of general theory of relativity? Is the spacetime flat inside (given the fact that orbit of Mercury rotates I don't think so)? How is signal from the cavity redshifted to an observer at infinity?", "output": "Here we will only answer OP's two first question(v1).  Yes, Newton's Shell Theorem generalizes to General Relativity as follows. The Birkhoff's Theorem states that a spherically symmetric solution is static, and a (not necessarily thin) vacuum shell (i.e. a region with no mass/matter) corresponds to a radial branch of the Schwarzschild solution \n$$\\tag{1} ds^2~=~-\\left(1-\\frac{R}{r}\\right)c^2dt^2 \n+ \\left(1-\\frac{R}{r}\\right)^{-1}dr^2 +r^2 d\\Omega^2$$\nin some radial interval $r \\in I:=[r_1, r_2]$. Here the constant $R$ is the Schwarzschild radius, and $d\\Omega^2$ denotes the metric of the angular $2$-sphere.\nSince there is no mass $M$ at the center of OP's internal hollow region $r \\in I:=[0, r_2]$, the Schwarzschild radius $R=\\frac{2GM}{c^2}=0$ is zero. Hence the metric (1) in the hollow region is just flat Minkowski space in spherical coordinates.", "meta": {"post_id": 43626, "input_score": 64, "output_score": 126, "post_title": "Is spacetime flat inside a spherical shell?"}}
{"input": "I have been told that $$[\\hat x^2,\\hat p^2]=2i\\hbar (\\hat x\\hat p+\\hat p\\hat x)$$ illustrates operator ordering ambiguity.\nWhat does that mean?\nI tried googling but to no avail.", "output": "The ordering ambiguity is the statement \u2013 or the \"problem\" \u2013 that for a classical function $f(x,p)$, or a function of analogous phase space variables, there may exist multiple operators $\\hat f(\\hat x,\\hat p)$ that represent it. In particular, the quantum Hamiltonian isn't uniquely determined by the classical limit.\nThis ambiguity appears even if we require the quantum operator corresponding to a real function to be Hermitian and $x^2 p^2$ is the simplest demonstration of this \"more serious\" problem. On one hand, the Hermitian part of $\\hat x^2 \\hat p^2$ is \n$$ \\hat x^2 \\hat p^2 - [\\hat x^2,\\hat p^2]/2 = \\hat x^2\\hat p^2 -i\\hbar (\\hat x\\hat p+\\hat p\\hat x)$$\nwhere I used your commutator.\nOn the other hand, we may also classically write the product and add the hats as $\\hat x \\hat p^2\\hat x$ which is already Hermitian. But\n$$ \\hat x \\hat p^2\\hat x = \\hat x^2 \\hat p^2+\\hat x[\\hat p^2,\\hat x] = \\hat x^2\\hat p^2-2i\\hbar\\hat x\\hat p $$\nwhere you see that the correction is different because $\\hat x\\hat p+\\hat p\\hat x$ isn't quite equal to $2\\hat x\\hat p$ (there's another, $c$-valued commutator by which they differ). So even when you consider the Hermitian parts of the operators \"corresponding\" to classical functions, there will be several possible operators that may be the answer. The $x^2p^2$ is the simplest example and the two answers we got differed by a $c$-number. For higher powers or more general functions, the possible quantum operators may differ by $q$-numbers, nontrivial operators, too.\nThis is viewed as a deep problem (perhaps too excessive a description) by the physicists who study various effective quantum mechanical models such as those with a position-dependent mass \u2013 where we need $p^2/2m(x)$ in the kinetic energy and by an expansion of $m(x)$ around a minimum or a maximum, we may get the $x^2p^2$ problem suggested above.\nBut the ambiguity shouldn't really be surprising because it's the quantum mechanics, and not the classical physics, that is fundamental. The quantum Hamiltonian contains all the information, including all the behavior in the classical limit. On the other hand, one can't \"reconstruct\" the full quantum answer out of its classical limit. If you know the limit $\\lim_{\\hbar\\to 0} g(\\hbar)$ of one variable $g(\\hbar)$, it clearly doesn't mean that you know the whole function $g(\\hbar)$ for any $\\hbar$.\nMany people don't get this fundamental point because they think of classical physics as the fundamental theory and they consider quantum mechanics just a confusing cherry on a pie that may nevertheless obtained by quantization, a procedure they consider canonical and unique (just hat addition). It's the other way around, quantum mechanics is fundamental, classical physics is just a derivable approximation valid in a limit, and the process of quantization isn't producing unique results for a sufficiently general classical limit.\nThe ordering ambiguity also arises in field theory. In that case, all the ambiguous corrections are actually divergent, due to short-distance singularities, and the proper definition of the quantum theory requires one to understand renormalization. At the end, what we should really be interested in is the space of relevant/consistent quantum theories, not \"the right quantum counterpart\" of a classical theory (the latter isn't fundamental so it shouldn't stand at the beginning or base of our derivations).\nIn the path-integral approach, one effectively deals with classical fields and their classical functions so the ordering ambiguities seem to be absent; in reality, all the consequences of these ambiguities reappear anyway due to the UV divergences that must be regularized and renormalized. The process of regularization and renormalization depends on the subtraction of various divergent counterterms, to get the finite answer, which isn't quite unique, either (the finite leftover coupling may be anything).\nThat's why the renormalization ambiguities are just the ordering ambiguities in a different language. Whether we study those things as ordering ambiguities or renormalization ambiguities, the lesson is clear: the space of possible classical theories isn't the same thing as the space of possible quantum theories and we shouldn't think about the classical answers when we actually want to do something else \u2013 to solve the problems in quantum mechanics.", "meta": {"post_id": 46988, "input_score": 28, "output_score": 42, "post_title": "Operator Ordering Ambiguities"}}
{"input": "The gravitational force on your body, called your weight, pushes you down onto the floor.\n$$W=mg$$\nSo, what is the weight equation through general relativity?", "output": "Start with the Schwarzschild metric $$ds^2 = (1-\\frac{r_S}{r})c^2dt^2-(1-\\frac{r_S}{r})^{-1}dr^2-r^2d\\Omega^2 $$  where $$r_S=\\frac{2GM}{c^2} $$  A particle at rest at radius $r$ and angular parameters zero from the centre of mass has worldline $$ x^{\\mu}=(t, r, 0, 0)$$  Its four velocity is thus $$ u^{\\mu}=\\frac{dx^{\\mu}}{d\\tau}=((1-\\frac{r_S}{r})^{-\\frac{1}{2}}, 0, 0, 0)$$  Its four-acceleration is $$a^{\\mu}= \\frac{du^{\\mu}}{d\\tau}+\\Gamma^{\\mu}_{\\alpha \\beta}u^{\\alpha}u^{\\beta} $$  After looking up the Christoffel symbols, because I'm lazy, I get $$ a^{\\mu} = (0, \\frac{c^2r_S}{2r^2}, 0, 0)$$  So the Lorentz norm squared of the four-acceleration is $$g_{\\mu \\nu}a^{\\mu}a^{\\nu}= \\frac{c^4r_S^2}{4r^4(1-\\frac{r_S}{r})}=\\frac{G^2M^2}{r^4(1-\\frac{2GM}{c^2r})}$$        Now the proper acceleration of an object at time t is the acceleration relative to an observer in free fall, who is momentarily at rest w.r.to the object at time t.  The free fall guy is the one who is not accelerating - the object held at rest at radius r is the one who is accelerating.  As we've shown, his acceleration is $$\\frac{GM}{r^2}\\frac{1}{\\sqrt{1-\\frac{2GM}{c^2r}}} $$  So if you want to define a force, it would be $$F=ma=\\frac{GMm}{r^2}\\frac{1}{\\sqrt{1-\\frac{2GM}{c^2r}}} $$ As $c\\rightarrow \\infty$ we recover the Newtonian definition, but nobody bothers phrasing it in these terms.", "meta": {"post_id": 47379, "input_score": 48, "output_score": 64, "post_title": "What is the weight equation through general relativity?"}}
{"input": "In Griffiths' Intro to QM [1] he gives the eigenfunctions of the Hermitian operator $\\hat{x}=x$ as being \n$$g_{\\lambda}\\left(x\\right)~=~B_{\\lambda}\\delta\\left(x-\\lambda\\right)$$\n(cf. last formula on p. 101). He then says that these eigenfunctions are not square integrable because \n$$\\int_{-\\infty}^{\\infty}g_{\\lambda}\\left(x\\right)^{*}g_{\\lambda}\\left(x\\right)dx\n~=~\\left|B_{\\lambda}\\right|^{2}\\int_{-\\infty}^{\\infty}\\delta\\left(x-\\lambda\\right)\\delta\\left(x-\\lambda\\right)dx\n~=~\\left|B_{\\lambda}\\right|^{2}\\delta\\left(\\lambda-\\lambda\\right)\n~\\rightarrow~\\infty$$\n(cf. second formula on p. 102). My question is, how does he arrive at the final term, more specifically, where does the $\\delta\\left(\\lambda-\\lambda\\right)$ bit come from? \nMy total knowledge of the Dirac delta function was gleaned earlier on in Griffiths and extends to just about understanding \n$$\\tag{2.95}\\int_{-\\infty}^{\\infty}f\\left(x\\right)\\delta\\left(x-a\\right)dx~=~f\\left(a\\right)$$\n(cf. second formula on p. 53).\nReferences:\n\nD.J. Griffiths, Introduction to Quantum Mechanics, (1995) p. 101-102.", "output": "You need nothing more than your understanding of \n$$\n\\int_{-\\infty}^\\infty f(x)\\delta(x-a)dx=f(a)\n$$\nJust treat one of the delta functions as $f(x)\\equiv\\delta(x-\\lambda)$ in your problem. So it would be something like this:\n$$\n\\int\\delta(x-\\lambda)\\delta(x-\\lambda)dx=\\int f(x)\\delta(x-\\lambda)dx=f(\\lambda)=\\delta(\\lambda-\\lambda)\n$$\nSo there you go.", "meta": {"post_id": 47934, "input_score": 40, "output_score": 42, "post_title": "Don't understand the integral over the square of the Dirac delta function"}}
{"input": "It is often quoted that the number of atoms in the universe is 10$^{70}$ or 10$^{80}$.\nHow do scientists determine this number? \nAnd how accurate is it (how strong is the supporting evidences for it)?\nIs it more likely (logically >50% chance) that the numbers are right, or is it more likely that the numbers are wrong?", "output": "The cosmological estimation of the number of atoms in the observable universe works as follows: one of the Friedmann equations can be written as\n$$\n\\dot{a}^2 -\\frac{8\\pi G}{3}\\rho a^2= -kc^2, \n$$\nwhere the scale factor $a(t)$ describes the expansion of the universe, $\\rho$ is the total mass density (radiation, baryonic matter, dark matter, and dark energy) and the integer $k$ is the intrinsic curvature of the universe ($k$ can be 1, 0 or -1). Observations of the Cosmic Microwave Background (CMB) indicate that the spacial curvature $k/a^2$ of the universe is practically zero, so we can set $k=0$. In this case the total density is equal to the so-called critical density\n$$\n\\rho_\\text{c}(t) = \\frac{3H^2(t)}{8\\pi G},\n$$\nwhere \n$$\nH(t) = \\frac{\\dot{a}}{a}\n$$\nis the Hubble parameter. The present-day density is then\n$$\n\\rho_\\text{c,0} = \\rho_\\text{c}(t_0) = \\frac{3H_0^2}{8\\pi G},\n$$\nwith $H_0=H(t_0)$ the Hubble constant. We can write $H_0$ in the following form\n$$\nH_0 = 100\\,h\\;\\text{km}\\,\\text{s}^{-1}\\,\\text{Mpc}^{-1},\n$$\nwith $h$ a dimensionless parameter and $1\\;\\text{Mpc}=3.0857\\times 10^{19}\\;\\text{km}$ (called a megaparsec). So\n$$\n\\rho_\\text{c,0} = 1.8785\\,h^2\\times 10^{-26}\\;\\text{kg}\\,\\text{m}^{-3}.\n$$\nA detailed analysis of the Cosmic Microwave Background reveals what the density of ordinary matter (baryons) is: according to the latest CMB data, the present-day baryon fraction is\n$$\n\\Omega_\\text{b,0}h^2 = \\frac{\\rho_\\text{b,0}}{\\rho_\\text{c,0}}h^2 =\n0.02205 \\pm 0.00028.\n$$\nNotice how accurately this quantity is known. The same data also yield a value of the Hubble constant:\n$$\nH_0 = 67.3 \\pm 1.2\\;\\text{km}\\,\\text{s}^{-1}\\,\\text{Mpc}^{-1},\n$$\nin other words, $h = 0.673\\pm0.012$ so that\n$$\n\\Omega_\\text{b,0} = 0.0487,\n$$\nwhich means that ordinary matter makes up 4.87% of the content of the universe. We don't actually need the value of $h$ to calculate the baryon density $\\rho_\\text{b,0}$, because the factor $h^2$ cancels out: we get\n$$\n\\rho_\\text{b,0} = \\Omega_\\text{b,0}\\rho_\\text{c,0} = 0.4142\\times 10^{-27}\\;\\text{kg}\\,\\text{m}^{-3}.\n$$\nAbout 75% of the baryon density is in the form of hydrogen, and nearly 25% is helium; all other elements make up about 1%, so I'll ignore those. The masses of hydrogen and helium atoms are\n$$\n\\begin{align}\nm_\\text{H} &= 1.674\\times 10^{-27}\\;\\text{kg},\\\\\nm_\\text{He} &= 6.646\\times 10^{-27}\\;\\text{kg},\n\\end{align}\n$$\nso the number density of hydrogen and helium atoms is\n$$\n\\begin{align}\nn_\\text{H} &= 0.75\\rho_\\text{b,0}/m_\\text{H} = 0.1856\\;\\text{m}^{-3},\\\\\nn_\\text{He} &= 0.25\\rho_\\text{b,0}/m_\\text{He} = 0.0156\\;\\text{m}^{-3},\n\\end{align}\n$$\nand the total number density of atoms is\n$$\nn_\\text{A} = n_\\text{H}+n_\\text{He} = 0.2012\\;\\text{m}^{-3}.\n$$\nNow, the radius of the observable universe is calculated to be $D_\\text{ph} = 46.2$ billion lightyears, which is $4.37\\times 10^{26}\\,\\text{m}$ (the subscript 'ph' stands for particle horizon; see this post for a detailed explanation). This is a derived value, which depends on all cosmological parameters; nonetheless, it is accurate to about 1%. The volume of the observable universe is thus\n$$\nV = \\frac{4\\pi}{3}\\!D_\\text{ph}^3 = 3.50\\times 10^{80}\\;\\text{m}^3.\n$$\nSo finally, there are about\n$$\nN_\\text{A} = n_\\text{A}V = 7.1\\times 10^{79}\n$$\natoms in the observable universe.", "meta": {"post_id": 47941, "input_score": 47, "output_score": 37, "post_title": "Dumbed-down explanation how scientists know the number of atoms in the universe?"}}
{"input": "Assume a certain action $S$ with certain symmetries, from which according to the Lagrangian formalism, the equations of motion (EOM) of the system are the corresponding Euler-Lagrange equations.\nCan it happen that the equations of motion derived by this procedure have different kinds and/or numbers of symmetries than the action one has started with? And if yes, are there underlying principles that state why which kind of symmetries the action does not have can emerge in corresponding EOMs or which kind of symmetries of the action can potentially disappear in the EOMs derived from the Euler-Lagrange equations?", "output": "Setting. We are considering a transformation$^1$ that acts on the field variables $\\phi^{\\alpha}(x)$ and possibly the space-time point $x^{\\mu}$. The transformation in turn apply to\n\nThe action $S_V[\\phi]=\\int_V \\! d^nx~{\\cal L} $.\n\nThe Euler-Lagrange equations = the equations of motion (EOM).\n\nA solution $\\phi$ of EOM.\n\n\nDefinition. If any of the items 1-3 are invariant under the transformation, we speak of a symmetry of the corresponding item 1-3 .\nDefinition.  If a solution (3) doesn't have a symmetry that the EOM (2) have, we speak of a spontaneously broken symmetry.\nDefinition.  Next let us recall the definition of an (off-shell$^2$) quasi-symmetry of the action. It means that the action changes by a boundary integral\n$$ S_{V^{\\prime}}[\\phi^{\\prime}]\n+\\int_{\\partial V^{\\prime}} \\!d^{n-1}x~(\\ldots)\n~=~S_V[\\phi]+ \\int_{\\partial V} \\!d^{n-1}x~(\\ldots) \\tag{0.1}$$\nunder the transformation.\nProposition.  In general, if an action (1) has a quasi-symmetry, then the EOM (2) must have a symmetry (wrt. the same transformation), cf. e.g. this Phys.SE post.\nExamples:\n\nOne example is the Maxwell Lagrangian density (in vacuum without the $J^{\\mu}A_{\\mu}$ source term)\n$${\\cal L} ~=~ -\\frac{1}{4}F_{\\mu\\nu}F^{\\mu\\nu}~=~\\frac{1}{2}(\\vec{E}^2-\\vec{B}^2), \\tag{1.1}$$\nwhich doesn't have electromagnetic $SO(2,\\mathbb{R})$ duality symmetry\n$$(\\vec{E}, \\vec{B})\\quad \\longrightarrow \\quad(\\vec{E}\\cos\\theta - \\vec{B}\\sin\\theta, \\vec{B}\\cos\\theta + \\vec{E}\\sin\\theta),\\tag{1.2}$$\nwhile the Euler-Lagrange equations (the Maxwell's equations in vacuum) are symmetric under electromagnetic duality.\n\nAnother example is a non-relativistic free point particle where the Lagrangian\n$$L~=~\\frac{1}{2}m\\dot{q}^2\\tag{2.1}$$\nis not invariant\nunder the Galilean symmetry\n$$\\dot{q}\\quad \\longrightarrow \\quad\\dot{q}+v,\\tag{2.2}$$\nnor the dilation/scale symmetry\n$$ q \\quad \\longrightarrow \\quad \\lambda q,\\tag{2.3}$$\nbut the EOM\n$$\\ddot{q}~=~0\\tag{2.4}$$\nis invariant. In the case of the Galilean symmetry (2.2), the Lagrangian changes by a total\ntime derivative\n$$ L \\quad \\longrightarrow \\quad L +mv\\frac{d}{dt}\\left( q +\\frac{vt}{2}\\right).\\tag{2.5}$$\nSee also this Phys.SE post. Thus (2.2) is actually an example of a quasi-symmetry of the action. [It is an instructive exercise to derive the corresponding Noether charge $Q$. At the infinitesimal level, the Galilean transformation (2.2) reads\n$$\\begin{align} \\delta \\dot{q}~=~&\\delta v~=~\\varepsilon, \\qquad \\delta q~=~\\varepsilon t,\\cr \\delta L ~=~& \\varepsilon\\frac{df}{dt}, \\qquad f ~:=~mq. \\end{align}\\tag{2.6}$$\nThe bare Noether charge is\n$$ Q^0~=~t \\frac{\\partial L}{\\partial \\dot{q}}~=~t m\\dot{q},  \\tag{2.7}$$\nwhile the full Noether charge is\n$$ Q~=~Q^0-f~=~m(\\dot{q}t-q),\\tag{2.8}$$\nwhich is conserved on-shell, cf. Noether's Theorem. The (non-relativistic) Galilean boosts generator (2.8) should be compared to the (relativistic) Lorentz boosts generators $tP-xE$ in relativistic theories, cf. e.g. this Phys.SE post.]\n\nThe dilation/scale transformation\n$$ q \\quad \\longrightarrow \\quad \\lambda q,\\tag{3.1} $$\nis not a quasi-symmetry of the Lagrangian action\n$$  S[q]~= ~\\int\\! dt ~L, \\qquad L ~=~\\frac{m}{2}\\dot{q}^2- \\frac{k}{2}q^2, \\tag{3.2}$$\nfor the simple harmonic oscillator (SHO), but it is a symmetry of the EOM\n$$ m\\ddot{q}~=~-kq. \\tag{3.3}$$\n\nThe dilation/scale transformation\n$$ q \\quad \\longrightarrow \\quad \\lambda q, \\qquad  p \\quad \\longrightarrow \\quad \\lambda p, \\tag{4.1}$$\nis not a quasi-symmetry of the Hamiltonian action\n$$\\begin{align}  S_H[q,p]~= ~&\\int\\! dt ~L_H, \\qquad L_H ~=~p\\dot{q}-H, \\cr H ~=~&\\frac{p^2}{2m}+ \\frac{k}{2}q^2,\\end{align} \\tag{4.2}$$\nfor the SHO, but it is a symmetry of Hamilton's EOM\n$$ p~=~m\\dot{q} , \\qquad \\dot{p}~=~-kq. \\tag{4.3}$$\n\nThe EOM of the SHO\n$$  m\\ddot{q}~=~-kq \\tag{5.1}$$\nis not invariant under the temporal symmetry\n$$ t \\quad \\longrightarrow \\quad \\lambda t,\\qquad \\lambda~\\neq~\\pm 1,\\tag{5.2}$$\nbut the trivial solution $q=0$ is.\n\n\n--\n$^1$ Note that in the main part of this answer the transformation acts only on the field variables $\\phi^{\\alpha}(x)$ and possibly the space-time point $x^{\\mu}$, which is the type of transformation relevant for Noether's theorem. We are not considering a transformation of other objects (such as parameters) per se.\nExample of the latter: A transformation of the Lagrangian density $${\\cal L} \\longrightarrow \\lambda {\\cal L},\\qquad  \\lambda~\\neq~ 1,\\tag{6.1}$$\nis not a quasi-symmetry of the Lagrangian density, but it is a symmetry of the EL equations.\n$^2$ Here the word off-shell indicates that the EOM are not assumed to hold under the specific transformation. In case of continuous transformations, if we assume the EOM to hold, then any infinitesimal variation of the action is trivially a boundary integral.", "meta": {"post_id": 51327, "input_score": 44, "output_score": 46, "post_title": "Do an action and its Euler-Lagrange equations have the same symmetries?"}}
{"input": "I have seen the term topological charge defined in an abstract mathematical way as a essentially a labeling scheme for particles which follows certain rules. However I am left guessing when trying to explain what physical properties of a system lead to the need to introduce this new type of \"charge.\" \nIf it makes any difference, I'm interested in studying the statistical properties of Quantum Hall systems (and in particular anyonic interferometry), where the different topological charges contribute to the total number of quantum states.", "output": "Local quasiparticle excitations and topological quasiparticle\nexcitations\nTo understand and classify anyonic quasiparticles in topologically ordered states, such as FQH states, it is important to\nunderstand the notions of local quasiparticle excitations and topological\nquasiparticle excitations.  First let us define the notion of ``particle-like''\nexcitations.  \nLet us consider a system with translation symmetry.  The ground\nstate has a uniform energy density.  If we have a state with an excitation, we\ncan observe the energy distribution of the state over the space.  If for some\nlocal area the energy density is higher than ground state, while for the rest\narea the energy density is the same as ground state, one may say there is a\n``particle-like'' excitation, or a quasiparticle, in this area.  Quasiparticles\ndefined like this can be further divided into two types.  The first type can be\ncreated or annihilated by local operators, such as a spin flip.  Hence they are\nnot robust under perturbations.  The second type are robust states. The higher\nlocal energy density cannot be created or removed by any local operators\nin that area.  We will refer the first type of quasiparticles as local\nquasiparticles, and the second type of quasiparticles as topological\nquasiparticles.\nAs an simple example, consider the 1D Ising model with open boundary condition.\nThere are two ground states, spins all up or all down.\nSimply flipping one spin of the ground state leads to the second excited state, and creates a local quasiparticle. \nOn the other hand, the first excited state looks like a domain wall.\nFor example the spins on the left are all up while those on the right all down,\nand the domain wall between the up domain and the down domain is a topological quasiparticle.\nFlipping the spins next to the domain wall moves the quasiparticle but cannot remove it.\nSuch quasiparticles is protected by the boundary condition.\nAs long as as the two edge spins are opposite, there will be at least one domain wall, or one topological quasiparticle in the bulk.\nMoreover a spin flip can be viewed as two domain walls.\nFrom the notions of local quasiparticles and topological quasiparticles, we can\nalso introduce a notion topological quasiparticle types (ie topological charges), or simply,\nquasiparticle types.  We say that local quasiparticles are of the trivial type,\nwhile topological quasiparticles are of non-trivial types.  Also two\ntopological quasiparticles are of the same type if and only if they differ by\nlocal quasiparticles.  In other words, we can turn one topological\nquasiparticle into the other one by applying some local operators.  The total\nnumber of the  topological quasiparticle types (including the trivial type) is\nalso a topological property. It turns out\nthat this  topological property is directly related to another topological\nproperty for 2+1D topological states: The number of the  topological\nquasiparticle types equal to the ground state degeneracy on torus. This is one\nof many amazing and deep relations in topological order.\nSee also Why is fractional statistics and non-Abelian common for fractional charges?, A physical understanding of fractionalization, and Whis is the difference between charge fractionalization in 1D and 2D?", "meta": {"post_id": 55204, "input_score": 31, "output_score": 38, "post_title": "Topological Charge. What is it Physically?"}}
{"input": "My knowledge on this particular field of physics is very sketchy, but I frequently hear of a theoretical \"graviton\", the quantum of the gravitational field.  So I guess most physicists' assumption is that gravity can be described by a QFT?\nBut I find this weird, because gravity seems so incredibly different from the other forces (yes, I know \"weirdness\" isn't any sort of scientific deduction principle).\nFor relative strengths:\n\nStrong force: $10^{38}$\nElectromagnetic force: $10^{36}$\nWeak force: $10^{25}$\nGravity: $1$\n\nNot only does gravity have a vastly weaker magnitude, it also has a very strange interaction with everything else.  Consider the Standard Model interactions:\n\nNo particle (or field) interacts directly with all other fields.  Heck, gluons only barely interact with the rest of them.  So why is it then that anything that has energy (e.g. everything that exists) also has a gravitational interaction?  Gravity seems unique in that all particles interact through it.\nThen there's the whole issue of affecting spacetime.  As far as I'm aware, properties such as charge, spin, color, etc. don't affect spacetime (only the energy related to these properties).", "output": "The short answer for why gravity is unique is that it is the theory of a massless, spin-2 field.  To contrast with the other forces, the strong, weak and electromagnetic forces are all theories of spin-1 particles.  \nAlthough it's not immediately obvious, this property alone basically fixes all of the essential features of gravity.  To begin with, the fact that gravity is mediated by massless particles means that it can give rise to long-range forces.  \"Long-range\" here means that gravitational potential between distant masses goes like $\\dfrac{1}{r}$, whereas local interactions most commonly fall of exponentially, something like $\\dfrac{e^{-mr}}{r}$, where $m$ is the mass of the force particle (this is known as a Yukawa potential).  \nAnother important feature of massless particles is they must have a gauge symmetry associated with them.  Gauge symmetry is important because it leads to conserved quantities.  In the case of electromagnetism (a theory of a massless, spin-1 particle), there is also gauge symmetry, and it is known that the conservation of electric charge is a consequence of this symmetry.  \nFor gravity, the gauge symmetry puts even stronger constraints on the way gravity interacts: not only does it lead to a conserved \"charge\" (the stress energy tensor of matter), it actually requires that the gravitational field couple in the same way to all types of matter.  So, as you correctly noted, gravity is very unique in that it is required to couple to all other particles and fields.  Not only that, but gravity also doesn't care about the electric charge, color charge, spin, or any other property of the things it is interacting with, it only couples to the stress-energy of the field.  For people who are familiar with general relativity, this universal coupling of gravity to the stress energy of matter, independent of internal structure, is known as the equivalence principle.  A more technical discussion of the fact that massless, spin-2 implies the equivalence principle (which was first derived by Weinberg) is given in the lecture notes found at the bottom of this page.\nAnother consequence of this universal coupling of gravity is that there can only by one type of graviton, i.e. only one massless, spin-2 field that interacts with matter.  This is much different from the spin-1 particles, for example the strong force has eight different types of gluons.  So since gravity is described by massless, spin-2 particles, it is necessarily the unique force containing massless spin-2 particles.  \nIn regards to the geometric viewpoint of gravity, i.e. how gravity can be seen as causing curvature in spacetime, that property also follows directly (although not obviously) from the massless spin-2 nature of the gravitons.  One of the standard books treating this idea is Feynman's Lectures on Gravitation (I think at least the first couple of chapters are available on google books).  The viewpoint that Feynman takes is that gravity must couple universally to the stress tensor of all matter, including the stress tensor of the gravitons themselves. This sort of self-interaction basically gives rise to the nonlinearities that one finds in general relativity.  Also, the gauge symmetry that was mentioned before gets modified by the self-interactions, and turns into diffeomorphism symmetry found in general relativity (also known as general covariance).  \nAll of this analysis comes from assuming that there is a quantum field theoretic description of gravity.  It may be concerning that people generally say we don't have a consistent quantum theory of gravity.  This is true, however, it can more accurately be stated that we don't have an ultraviolet complete theory of quantum gravity (string theory, loop quantum gravity, asymptotically safe gravity are all proposed candidates for a full theory, among many others).  That means that we don't believe that this theory of massless spin-2 particles is valid at very high energies.  The cutoff where we think it should break down is around the Planck mass, $M_p \\approx 10^{19}$ GeV.  These energies would be reached, for example, at the singularity of a black hole, or near the big bang.  But in most regions of the universe where such high energies are not present, perturbative quantum general relativity, described in terms of gravitons, is perfectly valid as a low energy effective field theory.  \nFinally, you noted that the extremely weak coupling of gravity compared to the other forces also sets it apart.  This is known as the hierarchy problem, and to the best of my knowledge it is a major open problem in physics.  \nRegardless, I hope this shows that even hierarchy problem aside, gravity plays a very special role among the forces of nature.", "meta": {"post_id": 57228, "input_score": 62, "output_score": 55, "post_title": "Why is gravity such a unique force?"}}
{"input": "What is the definition of a timelike and spacelike singularity?\nTrying to find, but haven't yet, what the definitions are.", "output": "A singularity is a condition in which geodesics are incomplete. For example, if you drop yourself into a black hole, your world-line terminates at the singularity. It's not just that you're destroyed. You (and the subatomic particles you're made of) have no future world-lines. A careful definition of geodesic incompleteness is a little tricky, because we want to talk about geodesics that can't be extended past a certain length, but length is measured by the metric, and the metric goes crazy at a singularity so that length becomes undefined. The way to get around this is to use an affine parameter, which can be defined without a metric. Geodesic incompleteness means that there exists a geodesic that can't be extended past a certain affine parameter. (This also covers lightlike geodesics, which have zero metric length.)\nThere are two types of singularities, curvature singularities and conical singularities.\nA black hole singularity is an example of a curvature singularity; as you approach the singularity, the curvature of spacetime diverges to infinity, as measured by a curvature invariant such as the Ricci scalar. Another example of a curvature singularity is the Big Bang singularity.\nA conical singularity is like the one at the tip of a cone. Geodesics are incomplete there basically because there's no way to say which way the geodesic should go once it hits the tip. In 2+1-dimensional GR, curvature vanishes identically, and the only kind of gravity that exists is conical singularities. I don't think conical singularities are expected to be important in our universe, e.g., I don't think they can form by gravitational collapse.\nActual singularities involving geodesic incompleteness are to be distinguished from coordinate singularities, which are not really singularities at all. In the Schwarzschild spacetime, as described in Schwarzschild's original coordinates, some components of the metric blow up at the event horizon, but this is not an actual singularity. This coordinate system can be replaced with a different one in which the metric is well behaved.\nThe reason curvature scalars are useful as tests for an actual curvature singularity is that since they're scalars, they can't diverge in one coordinate system but stay finite in another. However, they are not definitive tests, for several reasons: (1) a curvature scalar can diverge at a point that is at an infinite affine distance, so it doesn't cause geodesic incompleteness; (2) curvature scalars won't detect conical singularities; (3) there are infinitely many curvature scalars that can be constructed, and some could blow up while others don't. A good treatment of singularities is given in the online book by Winitzki, section 4.1.1.\nThe definition of a singularity is covered in WP and in all standard GR textbooks. I assume the real issue you were struggling with was the definition of timelike versus spacelike.\nIn GR, a singularity is not a point in a spacetime; it's like a hole in the topology of the manifold. For example, the Big Bang didn't occur at a point.  Because a singularity isn't a point or a point-set, you can't define its timelike or spacelike character in quite the way you would with, say, a curve. A timelike singularity is one that is in the future light cone of some point A but in the past light cone of some other point B, such that a timelike world-line can connect A to B. Black hole and big bang singularities are not timelike, they're spacelike, and that's how they're shown on a Penrose diagram. (Note that in the Schwarzschild metric, the Schwarzschild r and t coordinates swap their timelike and spacelike characters inside the event horizon.)\nThere is some variety in the definitions, but a timelike singularity is essentially what people mean by a naked singularity. It's a singularity that you can have sitting on your desk, where you can look at it and poke it with a stick. For more detail, see Penrose 1973. In addition to the local definition I gave, there is also a global notion, Rudnicki, 2006, which is essentially that it isn't hidden behind an event horizon (hence the term \"naked\"). What's being formalized is the notion of a singularity that can form by gravitational collapse from nonsingular initial conditions (unlike a Big Bang singularity), and from which signals can escape to infinity (unlike a black hole singularity).\nPenrose, Gravitational radiation and gravitational collapse; Proceedings of the Symposium, Warsaw, 1973. Dordrecht, D. Reidel Publishing Co. pp. 82-91, free online at http://adsabs.harvard.edu/full/1974IAUS...64...82P\nRudnicki, Generalized strong curvature singularities and weak cosmic censorship in cosmological space-times, http://arxiv.org/abs/gr-qc/0606007\nWinitzki, Topics in general relativity, https://sites.google.com/site/winitzki/index/topics-in-general-relativity", "meta": {"post_id": 60869, "input_score": 35, "output_score": 36, "post_title": "What is the definition of a timelike and spacelike singularity?"}}
{"input": "As we know, in condensed matter theory, especially in dealing with strongly correlated systems, physicists have constructed various \"peculiar\" slave-fermion and slave-boson theories. For example,\nFor Heisenberg model, we have Schwinger-fermion $\\vec{S_i}=\\frac{1}{2}f^\\dagger_i\\vec{\\sigma }f_i $ and Shwinger-boson $\\vec{S_i}=\\frac{1}{2}b^\\dagger_i\\vec{\\sigma }b_i $ approaches, with constraints $f^\\dagger_{1i}f_{1i}+f^\\dagger_{2i}f_{2i}=1$ and $b^\\dagger_{1i}b_{1i}+b^\\dagger_{2i}b_{2i}=2S$, repectively.\nFor $t-j$ model, there are slave-fermion $C^\\dagger_{i\\sigma}=b^\\dagger_{i\\sigma}f_i$ and slave-boson $C^\\dagger_{i\\sigma}=f^\\dagger_{i\\sigma}b_i$ methods, with constraints $f^\\dagger_{i}f_{i}+\\sum b^\\dagger_{i\\sigma}b_{i\\sigma}=1$ and $b^\\dagger_{i}b_{i}+\\sum f^\\dagger_{i\\sigma}f_{i\\sigma}=1$, repectively. \nFor Hubbard model, we have slave-fermion $C^\\dagger_{i\\sigma}=b^\\dagger_{i\\sigma}f_{1i}+\\sigma f^\\dagger_{2i}b_{i\\sigma}$ and slave-boson $C^\\dagger_{i\\sigma}=f^\\dagger_{i\\sigma}b_{1i}+\\sigma b^\\dagger_{2i}f_{i\\sigma}$ methods, with constraints $\\sum f^\\dagger_{\\alpha i}f_{\\alpha i}+\\sum b^\\dagger_{i\\sigma}b_{i\\sigma}=1$ and $\\sum b^\\dagger_{\\alpha i}b_{\\alpha i}+\\sum f^\\dagger_{i\\sigma}f_{i\\sigma}=1$, repectively. \nAnd my questions are:\n(1) Whatever it's spin or electron system, the slave-fermion and slave-boson constructions have very similar forms, simply interchanging bosonic and fermionic operators in one we would get the other one. So is there any deep connection between these two formalism? Does this similarity have something to do with supersymmetry?\n(2) From the mathematical point of view, both the slave-fermion and slave-boson constructions are correct. But physically, when should we use slave-fermion methods and when should we use slave-boson methods? What are the differences between these two approaches when we deal with a particular physical model?", "output": "The slave particle approach is based on the assumption of spin-charge separation in the strongly correlated electron systems (typically Mott insulators). It was proposed that the electrons can decay into spinons and chargons (holons/doublons). But to preserve the fermion statistics of the electrons, the spinon-chargon bound state must be fermionic, so the simplest way is to ascribe the fermion statistics to one of them: if the spinon is fermionic then the chargon should be bosonic (slave-boson), or if the chargon is fermionic then the spinon should be bosonic (slave-fermion). The differences are just a matter of which degrees of freedom (spin or charge) should the fermion statistics be ascribed to.\nWithin one kind of slave particle formalism, the supersymmetry is possible but not necessary. Whether or not the spinon and chargon are suppersymmetric to each other depends on their spectrums (which are the details). If the spinon and chargon have different spectrums (which is always the case), then the effective theory has no supersymmetry.\nIt seems that there is a certain kind of duality between the slave-boson and slave-fermion approaches, one may conjecture if the two approaches can be unified into a single theory. And it was indeed the case. Now we know that the two approaches are just two low-energy effective theories of the complete-fractionalization theory, which has two equivalent versions: the Chern-Simons version by Kou, Qi and Weng Phys. Rev. B 71, 235102 (2005), or the Majorana version by Xu and Sachdev Phys. Rev. Lett. 105, 057201 (2010).\nIn the complete-fractionalization theory, electron is fully fractionalized into bosonic spinon, bosonic chargon, and a mutual Chern-Simons gauge field (or Majorana fermion) to take care of the fermion statistics. Spinons and chargons are treated equally in this theory, both are bosonic degrees of freedom. In the mutual Chern-Simons theory, the spinons and chargons are coupled to a Chern-Simons theory of the K matrix\n$$K=\\left(\\begin{matrix}0&2\\\\2&0\\end{matrix}\\right),$$\nmeaning that the spinon and the chargon will mutually see each other as a $\\pi$-vortex. This mutual $\\pi$-vortex binding renders the spinon-chargon bound state a fermion, corresponding to the electron. If both the spinons and chargons are gapped, the remaining low-energy effective theory will be a $\\mathbb{Z}_2$ gauge theory, which supports 3 kinds of topological excitations: electric charges, magnetic fluxes (visons) and fermions; corresponding to chargons, spinons and electrons respectively. Thus in this phase, the relation between the chargon and the spinon is just like that between the charge and the flux, i.e. the spin and charge degrees of freedom are electromagnetically dual to each other, and the duality is supported by the underlying $\\mathbb{Z}_2$ topological order. This exotic topological phase was proposed to be the basic physics behind the pseudo-gap phase of the cuprates superconductors Phys. Rev. Lett. 106, 147002 (2011) (although more complexity should be added to fully explain the phenomena).\nBy tuning the relative density of spinons and chargons (presumably achievable by doping in real materials), the system can be driven into the ordered phase by condensing one of the fractionalized degrees of freedom (note that now both spinons and chargons are bosons and can condense). Condensing spinon results in a spin ordered state (i.e. the Neel antiferromagnet), while condensing chargon results in a charge superfluid state (i.e. d-wave superconductivity). But the mutual Chern-Simons theory forbidden both spinon and chargon to condense at the same time, which is consistent with the fact that we can never Bose-condense the electrons.\nThe Majorana theory is similar, but more comprehensive. In SU(2) operator matrix form, the decomposition reads\n$$C=B\\Xi Z,$$\nwhere $C$, $B$, $Z$ collect electron, chargon and spinon operators in matrices\n$$C=\\left(\\begin{matrix}c_\\uparrow & c_\\downarrow\\\\-c_\\downarrow^\\dagger & c_\\uparrow^\\dagger\\end{matrix}\\right),B=\\left(\\begin{matrix}b_d & b_h^*\\\\-b_h & b_d^*\\end{matrix}\\right),Z=\\left(\\begin{matrix}z_\\uparrow & z_\\downarrow\\\\-z_\\downarrow^* & z_\\uparrow^*\\end{matrix}\\right),$$\nand $\\Xi=\\xi_0\\sigma_0+i\\xi_1\\sigma_1+i\\xi_2\\sigma_2+i\\xi_3\\sigma_3$ contains the Majorana operators. Both $b$ and $z$ are bosonic, and the fermion statistics is carried by the Majorana fermions $\\xi$. This is the most general scheme of spin-charge separation for electrons. The emergent gauge structure of this theory is $O(4)$ (representing the rotation among 4 Majorana fermions), which can be factorized into two $SU(2)$ gauge structures, as $O(4)\\simeq SU(2)_B\\times SU(2)_Z$, coupling to the chargons and spinons respectively. Because the $SU(2)$ fluctuation is confining in (2+1)D spacetime, without any topological order, the fractionalized particles will all be confined into electrons. But if we condense one of the bosonic degrees of freedom, say the chargons $B$, then $SU(2)_B$ can be Higgs out, and the remaining $SU(2)_Z$ gauge fluctuation would confine the Majorna fermion $\\Xi$ with the spinon $Z$ into a composite particle $\\Xi Z$, rendering the bosonic spinon to fermionic and reducing the Majorana theory to the slave-boson theory (which is exactly the same as Wen's $SU(2)$ theory Quantum Orders and Symmetric Spin Liquids). If we condense the spinon first, then the story will be reversed, ending up with the slave-fermion theory. Therefore the choice of which slave-particle approach depends entirely on the phase we wish to study (the degrees of freedom that we wish to condense). Different orders in the ground state would support different low-energy effective theories, which appear to us as different slave-particle approaches.", "meta": {"post_id": 63073, "input_score": 28, "output_score": 37, "post_title": "What're the relations and differences between slave-fermion and slave-boson formalism?"}}
{"input": "I've found many definitions of Lorentz generators that satisfy the Lorentz algebra: $$[L_{\\mu\\nu},L_{\\rho\\sigma}]=i(\\eta_{\\mu\\sigma}L_{\\nu\\rho}-\\eta_{\\mu\\rho}L_{\\nu\\sigma}-\\eta_{\\nu\\sigma}L_{\\mu\\rho}+\\eta_{\\nu\\rho}L_{\\mu\\sigma}),$$ but I don't know the difference between them.\nFirstly, there is the straightforward deduction evaluating the derivate of the Lorentz transformation at zero and multiplying it by $-i$. It's a very physical approach.\nAnother possibility is to define:\n$$\\left(J_{\\mu\\nu}\\right)_{ab}=-i(\\eta_{\\mu a}\\eta_{\\nu b}-\\eta_{\\nu a}\\eta_{\\mu b})$$\nThis will hold for any dimension. I find it a bit confusing because we mix matrix indices with component indices.\nWe could also define:\n$$M_{\\mu\\nu}=i(x_\\mu\\partial_\\nu-x_\\nu\\partial_\\mu)+S_{\\mu\\nu}$$\nWhere $S_{\\mu\\nu}$ is Hermitian, conmutes with $M_{\\mu\\nu}$ and satisfies the Lorentz algebra. I think this way is more geometrical because we can see a Lorentz transformation as a rotation mixing space and time.\nThe two last options look quite similar to me.\nLastly, we could start with the gamma matrices $\\gamma^\\mu$, that obey the Clifford algebra: $$\\{\\gamma^{\\mu},\\gamma^{\\nu}\\}=2\\eta^{\\mu\\nu}\\mathbb{I}$$ (this is easy to prove in QFT using Dirac's and KG's equations). And define:\n$$S^{\\mu\\nu}=\\frac{i}{4}[\\gamma^{\\mu},\\gamma^{\\nu}]$$\nIt seems that this is the most abstract definition. By the way, how are Clifford algebras used in QFT, besides gamma matrices (I know they are related to quaternions and octonions, but I never saw these applied to Physics)?\nAre there any more possible definitions? \nWhich are the advantages and disadvantages of each?\nAre some of them more fundamental and general than the others?", "output": "UPDATE - Answer edited to be consistent with the latest version of the question.\nThe different definitions you mentioned are NOT definitions. In fact, what you are describing are different representations of the Lorentz Algebra. Representation theory plays a very important role in physics.\nAs far as the Lie algebra are concerned, the generators $L_{\\mu\\nu}$ are simply some operators with some defined commutation properties.\nThe choices $L_{\\mu\\nu} = J_{\\mu\\nu}, S_{\\mu\\nu}$ and $M_{\\mu\\nu}$ are different realizations or representations of the same algebra. Here, I am defining\n\\begin{align}\n\\left( J_{\\mu\\nu} \\right)_{ab} &= - i \\left( \\eta_{\\mu a} \\eta_{\\nu b} - \\eta_{\\mu b} \\eta_{\\nu a} \\right) \\\\\n\\left( S_{\\mu\\nu}\\right)_{ab} &= \\frac{i}{4} [ \\gamma_\\mu , \\gamma_\\nu ]_{ab} \\\\\nM_{\\mu\\nu} &= i \\left( x_\\mu \\partial_\\nu + x_\\nu \\partial_\\mu \\right) \n\\end{align}\nAnother possible representation is the trivial one, where $L_{\\mu\\nu}=0$.\nWhy is it important to have these different representations?\nIn physics, one has several different fields (denoting particles). We know that these fields must transform in some way under the Lorentz group (among other things). The question then is, How do fields transform under the Lorentz group? The answer is simple. We pick different representations of the Lorentz algebra, and then define the fields to transform under that representation! For example\n\nObjects transforming under the trivial representation are called scalars.\nObjects transforming under $S_{\\mu\\nu}$ are called spinors.\nObjects transforming under $J_{\\mu\\nu}$ are called vectors.\n\nOne can come up with other representations as well, but these ones are the most common.\nWhat about $M_{\\mu\\nu}$ you ask? The objects I described above are actually how NON-fields transform (for lack of a better term. I am simply referring to objects with no space-time dependence). On the other hand, in physics, we care about FIELDS. In order to describe these guys, one needs to define not only the transformation of their components but also the space time dependences. This is done by including the $M_{\\mu\\nu}$ representation to all the definitions described above. We then have\n\nFields transforming under the trivial representation $L_{\\mu\\nu}= 0 + M_{\\mu\\nu}$ are called scalar fields.\nFields transforming under $S_{\\mu\\nu} + M_{\\mu\\nu} $ are called spinor fields. \nFields transforming under $J_{\\mu\\nu} + M_{\\mu\\nu}$ are called vector fields. \n\nMathematically, nothing makes these representations any more fundamental than the others. However, most of the particles in nature can be grouped into scalars (Higgs, pion), spinors (quarks, leptons) and vectors (photon, W-boson, Z-boson). Thus, the above representations are often all that one talks about. \nAs far as I know, Clifford Algebras are used only in constructing spinor representations of the Lorentz algebra. There maybe some obscure context in some other part of physics where this pops up, but I haven't seen it. Of course, I am no expert in all of physics, so don't take my word for it. Others might have a different perspective of this.\n\nFinally, just to be explicit about how fields transform (as requested) I mention it here. A general field $\\Phi_a(x)$ transforms under a Lorentz transformation as\n$$\n\\Phi_a(x) \\to \\sum_b \\left[  \\exp \\left( \\frac{i}{2} \\omega^{\\mu\\nu} L_{\\mu\\nu} \\right) \\right]_{ab} \\Phi_b(x)\n$$\nwhere $L_{\\mu\\nu}$ is the representation corresponding to the type of field $\\Phi_a(x)$ and $\\omega^{\\mu\\nu}$ is the parameter of the Lorentz transformation. For example, if $\\Phi_a(x)$ is a spinor, then\n$$\n\\Phi_a(x) \\to \\sum_b \\left[  \\exp \\left( \\frac{i}{2} \\omega^{\\mu\\nu} \\left( S_{\\mu\\nu}  + M_{\\mu\\nu} \\right) \\right) \\right]_{ab} \\Phi_b(x)\n$$", "meta": {"post_id": 63174, "input_score": 21, "output_score": 42, "post_title": "Different representations of the Lorentz algebra"}}
{"input": "I have read the thread regarding 'the difference between the operators $\\delta$ and $d$', but it does not answer my question.\nI am confused about the notation for change in Physics. In Mathematics, $\\delta$ and $\\Delta$ essentially refer to the same thing, i.e., change. This means that $\\Delta x = x_1 - x_2 = \\delta x$. The difference between $\\delta$ and $d$ is also clear and distinct in differential calculus. We know that $\\frac{dy}{dx}$ is always an operator and not a fraction, whereas $\\frac{\\delta y}{\\delta x}$ is an infinitesimal change. \nIn Physics, however, the distinction is not as clear. Can anyone offer a clearer picture?", "output": "The symbol $\\Delta$ refers to a finite variation or change of a quantity \u2013 by finite, I mean one that is not infinitely small.\nThe symbols $d,\\delta$ refer to infinitesimal variations or numerators and denominators of derivatives.\nThe difference between $d$ and $\\delta$ is that $dX$ is only used if $X$ without the $d$ is an actual quantity that may be measured (i.e. as a function of time) without any ambiguity about the \"additive shift\" (i.e. about the question which level is declared to be $X=0$). On the other hand, we sometimes talk about small contributions to laws that can't be extracted from a well-defined quantity that depends on time.\nAn example, the first law of thermodynamics.\n$$dU = \\delta Q - \\delta W$$\nThe left hand side has $dU$, the change of the total energy $U$ of the system that is actually a well-defined function of time. The law says that it is equal to the infinitesimal heat $\\delta Q$ supplied to the system during the change minus the infinitesimal work $\\delta W$ done by the system. All three terms are equally infinitesimal but there is nothing such as \"overall heat\" $Q$ or \"overall work\" $W$ that could be traced \u2013 we only determine the changes (flows, doing work) of these things.\nAlso, one must understand the symbol $\\partial$ for partial derivatives \u2013 derivatives of functions of many variables for which the remaining variables are kept fixed, e.g. $\\partial f(x,y)/\\partial x$ and similarly $y$ in the denominator.\nIndependently of that, $\\delta$ is sometimes used in the functional calculus for functionals \u2013 functions that depend on whole functions (i.e. infinitely many variables). In this context, $\\delta$ generalizes $d$ and has a different meaning, closer to $d$, than $\\delta$ in the example of $\\delta W$ and $\\delta Q$ above. Just like we have $dy=f'(x)dx$ for ordinary derivatives in the case of one variable, we may have $\\delta S = \\int_a^b dt\\,C(t)\\delta x(t)$ where the integral is there because $S$ depends on uncountably many variables $x(t)$, one variable for each value of $t$.\nIn physics, one must be ready that $d,\\delta,\\Delta$ may be used for many other things. For example, there is a $\\delta$-function (a distribution that is only non-vanishing for $x=0$) and its infinite-dimensional, functional generalization is called $\\Delta[f(x)]$. That's a functional that is only nonzero for $f(x)=0$ for every $x$ and the integral $\\int {\\mathcal D}f(x) \\,\\Delta[f(x)]=1$. Note that for functional integrals (over the infinite-dimensional spaces of functions), the integration measure is denoted ${\\mathcal D}$ and not $d$.", "meta": {"post_id": 65724, "input_score": 60, "output_score": 53, "post_title": "Difference between $\\Delta$, $d$ and $\\delta$"}}
{"input": "A bucket is filled with water and a handful of sand. The water is then spun. Why and what forces are in play which cause the sand particles to congregate in the centre of the bucket?", "output": "The problem was solved by a certain Albert Einstein, who is probably not unknown to users of this web site. Actually he also calculated the viscosity of particle dispersions (Einstein (1906). A. Ann. Phys. 19: 289, or section 2 in this PD). Presumably he only did special relativity after getting bored with fluid dynamics.\nAnyhow, it's because the motion of the liquid around the cup causes a flow along the bottom of the cup towards the centre and then upwards. The sand is carried by this current so it collects at the centre. If you swirl the container rapidly you should be able to see the sand being carried upwards a short distance before its weight pulls it back down.\n\nIn the body of the fluid there is a pressure gradient along the line from the centre to the edge of the cup. This gradient is maintained by the variation is speed of the fluid flow from the centre to the edge i.e. high flow rate at the edge and low in the centre. However at the bottom of the cup the friction with the base of the cup slows the film of water close to the base. Because the flow rate is reduced by the friction it cannot balance the pressure gradient, and the result is a flow towards the centre at the base of the cup. As the flowing fluid reaches the centre it flows upwards then out towards the edge of the cup again. This is what causes the circulation shown in the picture.", "meta": {"post_id": 69122, "input_score": 32, "output_score": 43, "post_title": "What forces are at work causing sand to migrate to the centre of a spinning bucket of water?"}}
{"input": "I am referring to this question, and especially this answer. \n\nIn addition, QCD has - like all field theories - only an asymptotic\n  perturbation series, which means that the series itself will also\n  diverge if all terms are summed.\n\nWhat does it mean? From what I know, if the sum over a series diverge, that means that the summation doesn't work, which means that the quantity you are trying to calculate, you can't get answer for that, for any quantity that comes back from your calculation must be of finite value.\nBut in QCD and QED things seem a lot more complicated, since some divergences are allowed:\n\nThis doesn't mean that QCD perturbation theory doesn't have\n  ultraviolet divergences, it has those like any other unitary\n  interacting field theory in 4d. These ultraviolet divergences though\n  are not a sign of a problem with the theory, since the lattice\n  definition works fine. This is in contrast to, say, QED, where the\n  short lattice spacing limit requires the bare coupling to blow up, and\n  it is likely that the theory blows up to infinite coupling at some\n  small but finite distance. This is certainly what happens in the\n  simplest interacting field theory, the quartically self-interacting\n  scalar\n\nMy questions:\n\nHow many kinds of divergence there are in QCD and QED?\nAnd how do we know what kind of divergence is acceptable ( in the sense that we can still extract values out for prediction after some renormalization process)?\nIf the sum diverge, then we won't be able to calculate the series's sum. Isn't that is defeating the purpose of the series? For any series, if the sum diverge after summing all the terms, then we know that the formula must be wrong or the series have no physical meaning. But why is it that for QCD series, the formula is still correct ( because it is used to extract coupling constants) and has physical meaning ( QCD series must correspond to something in reality)?\nThe fact that QCD has non-convergent series means that it cannot be the fundamental theory of nature, right?", "output": "Let me begin with QED. I will subsequently connect with QCD. There are 4 kinds of divergence in QED: \n\nUltraviolet divergences. Naive calculations depend on the cut-off in such a way that they go to infinity as the cut-off do. However, QED is a perturbatively renormalizable theory so that non-naive, well-done computations (see regularization and renormalization) give sensible results.\nLandau pole. The coupling constant $\\alpha={e^2\\over \\hbar \\, c}$, which is the expansion parameter in the perturbative series, grows with energy and goes to infinity for a finite value of the energy. It turns out that this finite value of energy is larger than the electroweak scale, where QED merges with the weak interaction and QED is not a good theory of nature anymore. Therefore, it isn't a real (phenomenological) problem.\nInfrared divergences. These are due to the fact that photons are massless. They however cancel out once one takes into account all the effects that contribute to a measurable observable.\nNon-convergent series. The $n$-th term of the perturbative expansion is of the form   $\\left({\\alpha\\over 2\\pi}\\right)^{n}\\, (2n-1)!!$, so that the series is not convergent but asymptotic because the factor $(2n-1)!!$ grows very fast for large values of $n$. This means that we cannot give a non-perturbative definition of QFT by summing up all the terms of the series. However, the first terms are meaningful and actually give predictions that accurately agree with observations. The 'first terms' are approximately $n\\sim {\\pi\\over \\alpha}\\sim 430$. And for this value of $n$, $\\left({\\alpha\\over 2\\pi}\\right)^{n}\\, (2n-1)!!\\sim 10^{-187}$. Therefore, as long as we are not interested in a precision of one part in $10^{187}$ , this is not a real problem either. Note that QED is the theory of nature that has been confirmed with greatest precision \u2014 one part in $10^{9}$ in electron's anomalous magnetic dipole, for which $n=4$.\n\nFor QCD points 1, 3, and 4 are more o less the same. However, point 2 doesn't apply since in QCD the coupling constant $\\alpha_s$ gets lower with the increasing of energy, and in fact it goes to zero as energy goes to infinity. See asymptotic freedom.\nTo summarize, infrared divergences are due to not taking into account effects that contribute to the observable magnitude. The asymptotic nature of QFT perturbative expansions prevents a non-perturvative (exact) definition of the theory (through its series), but doesn't entail a practical problem when comparing predictions with measurements. The lack of perturbative divergences and Landau-like poles are a necessary condition for a theory to be well-defined at arbitrarily high energies. However, theories that contain these divergences (ultraviolet or Landau-like poles) can still be very useful at energies above some scale. On the other hand, theories without these divergencies (ultraviolet or Landau-like poles), such as QCD, don't have to be valid to all energies as theories of nature.\nAs M. Brown points out in the comments, there is a relation between instantons and renormalons and the asymptotic nature of series. Please, see these notes snd the questions Instantons and Non Perturbative Amplitudes in Gravity and Asymptoticity of Pertubative Expansion of QFT\nReply to Graviton's comment: In my opinion, a fundamental theory of nature (whatever it means) should have a non-perturbative definition. If the perturbative expansion is not convergent, it cannot provide this non-perturbative definition. However, in principle, this doesn't necessarily mean that theory cannot have a non-perturbative definition or an exact solution, but this must be given by other means.", "meta": {"post_id": 70411, "input_score": 26, "output_score": 38, "post_title": "The divergence in QCD Series-- How many are they, and what do they mean?"}}
{"input": "Why does a cork ball float to the side of a glass as illustrated in the following GIF? What is the physical phenomenon behind this observation and why does it happen?", "output": "It's a combination of two effects: buoyancy and adhesion.\nBuoyancy lifts the cork up as much as possible, until it displaces its own weight of water (Archimedes' principle). For this reason, the cork will seek the highest point of the water level.\nBecause of adhesion between the water molecules and the glass, the water level is highest at the edges (the water level is concave). As a result, the cork moves to the sides.\nIf you'd fill up the glass to the brim, the water level becomes convex (due to surface tension), and the cork will stay in the middle.\nSee also this site and this youtube video.\n\nExtra Info\nBy coincidence, a very similar question came up yesterday on a Dutch science program, and I learned there's actually a name for this phenomenon: the Cheerios effect. The name is derived from the fact that small floating objects on a liquid, like bubbles on water or cheerios on milk, tend to clump together, or stick to the walls.\nThe reason is the same as my answer above: there are two forces acting on a floating object: the buoyancy (which tries to push the object out of the liquid) and the surface tension (which tries to keep the object in the liquid). The result is a compromise, where the object is pushed partially out of the liquid, causing the surface to deform: it forms a small hill.\nNearby floating objects are affected by this deformation: a floating object seeks the highest point in a liquid (the buoyancy causes it to rise and move\nupward along the surface), so it will move towards the 'hill' formed by the other object. Therefore, bubbles (or cheerios) will cluster together.\nA similar effect happens with objects that are denser than the liquid, but are not too heavy, so that they don't sink thanks to the surface tension. Paper clips are an example. These objects actually push down the liquid, creating a small 'valley' in the surface around them. But such object will also seek the lowest point on the surface, which means that nearby dense objects will again be attracted to each other. So paper clips also cluster together.\nWhat happens when an object less dense than the liquid (e.g. a cheerio) is next to an object denser than the liquid (e.g. a paper clip)? The first creates a hill and seeks the highest point, the second creates a valley and seeks the lowest point. So the result is that they will repel each other!\nThere's a very nice paper that explains these effects in more detail:\nThe 'Cheerios effect' (Vella & Mahadevan, 2004).", "meta": {"post_id": 71292, "input_score": 33, "output_score": 40, "post_title": "Why does a cork float to the side of a glass?"}}
{"input": "Final edit: I think I pretty much understand now (touch wood)! But there's one thing I don't get. What's the physical reason for expecting the correlation functions to be independent of the cutoff? I.e. why couldn't we just plump for one \"master Lagrangian\" at the Planck scale and only do our integration up to that point? \n\nPerhaps it has something to do with low energy experiments not being influenced by Planck scale physics.\nMaybe it's because there isn't any fundamental scale, i.e. that $\\Lambda$ must be arbitrary in a QFT approximation, for some reason.\n\nI'll award the bounty to anyone who can explain this final conundrum! Cheers!\n$$***$$\nApologies if this question is too philosophical and vague! I've been thinking about QFTs and continuum mechanics, and reading about their interpretation as effective theories. In these theories we have natural cutoffs at high momentum (small scales). We make the assumption ($\\star$) that the large scale physics is decoupled from the small-scale. Therefore we hope that our predictions are independent of the cutoff (after some renormalization if necessary).\nWhy is the assumption ($\\star$) so reasonable? I guess it seems observationally correct, which is powerful empirical evidence. But could it not be the case that the small scale physics had ramifications for larger scale observations? In other words, would it be reasonable to expect that the predictions of a TOE might depend on some (Planck scale) cutoff?\nThis question may be completely trivial, or simply ridiculous. Sorry if so! I'm just trying to get a real feel for the landscape.\nEdit: I'd like to understand this physically from the purely QFT perspective, without resorting to analogy with statistical physics. It might help if I rephrase my question as follows.\nIn the Wilsonian treatment of renormalization we get a flow of Lagrangians as the energy scale $\\Lambda$ changes. For a renormalizable theory we assume that there's a bare Lagrangian independent of $\\Lambda$ in the limit $\\Lambda \\to \\infty$. We calculate with this quantity, by splitting it into physical terms and counterterms. I think these counterterms come from moving down the group flow, but I'm not quite sure...\nBut why do we care about (and calculate with) the bare Lagrangian, rather than one at some prescribed (high) energy scale (say the Planck scale)? I don't really understand the point of there existing a $\\Lambda\\to \\infty$ limit.", "output": "This is a very interesting question which is usually overlooked. First of all, saying that \"large scale physics is decoupled from the small-scale\" is somewhat misleading, as indeed the renormalization group (RG) [in the Wilsonian sense, the only one I will use] tells us how to relate the small scale to the large scale !\nBut usually what people mean by that is that if there exists a fixed-point in the RG flow, then some infrared (IR) [large scale] physics is independent of the details at small scale [ultraviolet (UV)], that is it is universal. For instance, the behavior of the correlation functions at long distance is independent of the bare parameters (to fix the setting, say a scalar field with bare parameters $r_\\Lambda, g_\\Lambda$ for the quadratic and quartic interaction and $\\Lambda$ is the (for now) finite UV cut-off).\nBut one should not forget that a lot of physical quantities are non-universal. For example, the critical value of $r_\\Lambda$ (at fixed $g_\\Lambda$ and $\\Lambda$) to be at the critical point is not universal. And this is a physical quantity in condensed-matter/stat-phys, the same way that $\\Lambda$ also has a physical meaning.\nThe point of view of the old-school RG (with conterterms and all that) is useful for practical calculations (beyond one-loop), but make everything much less clear.\nIn the spirit of high-energy physics with a QFT of everything (i.e. not an effective theory), one does not want a cut-off, because it has no meaning, the theory is supposed to work at arbitrary high-energy. This mean that we should send $\\Lambda$ to infinity. And here comes another non-trivial question : what do we mean by $\\Lambda\\to\\infty$ ?\nThe perturbative answer to that is : being able to send $\\Lambda\\to\\infty$ order by order in perturbation in $g$. But is it the whole answer to the question ? Not really. When we say that we want $\\Lambda\\to\\infty$, it means that we want to define a QFT, at a non-perturbative level, which is valid at all distance, and we want this QFT to be well-defined, that is defined by a finite number of parameters (say two or three). And in fact, this non-perturbative infinite cut-off limit (that I will call the continuum limit) is much more difficult to take. Indeed, having a theory described in the limit $\\Lambda\\to\\infty$ by a finite number of parameter means that the RG flows in the UV to a fixed point. In the same way, the RG has to flow in the IR to another fixed point in order to be well controlled. This implies that very few QFTs in fact exist in the continuum limit, and that some QFTs which are perturbatively renormalizable ($\\Lambda\\to\\infty$ order by order in perturbation in $g$) are not necessarily well defined in the continuum limit !\nFor instance, some well known QFTs in dimension four (such as scalar theories or QED) do not exist in the continuum limit ! The reason is that even if these theories are controlled by a fixed point in the IR (at \"criticality\", which for QED means at least electrons with zero masses), it is not the case in the UV, as the interaction grows with the cut-off. Therefore one has to specify the value an infinite number of coupling constants (even \"non-renormalizable\") to precisely select one RG trajectory.\nOne of the QFTs which exists in the continuum limit is the scalar theory in dimension less that four (say three). In that case, at criticality, there exists one trajectory which is controlled by a fixed point in the UV (the gaussian fixed point) and in the IR (the Wilson-Fisher fixed point). All (!) the other trajectories are either not well defined in the UV (critical theories but with otherwise arbitrary coupling constants) or in the IR (not a critical theory). One then sees why this $\\Lambda\\to\\infty$ limit is less and less seen as important in the modern approach to (effective) QFTs. Unless one wants to describe the physics at all scale by a QFT, without using a fancy up-to-now-unknown theory at energies above $\\Lambda$. Nevertheless, this idea of controlling a QFT both in the IR and the UV is important if you want to prove that General relativity is (non-perturbatively) renormalizable (i.e. can be described at all scales by few parameters) in the asymptotic safety scenario : if there is a non trivial UV fixed point, then there exists a trajectory from this fixed point to the gaussian fixed point (which is, I think, Einstein gravity), and you can take the continuum limit, even though the perturbative $\\Lambda\\to\\infty$ does not exists.\nReference : Most of this is inspired by my reading of the very nice introduction to the non-perturbative RG given in arXiv 0702.365, and especially by the section 2.6 \"Perturbative renormalizability, RG \ufb02ows, continuum limit, asymptotic freedom and all that\".", "meta": {"post_id": 73403, "input_score": 60, "output_score": 48, "post_title": "Why do we expect our theories to be independent of cutoffs?"}}
{"input": "I've read several websites about equipment covered with gold foil and astronaut helmet visors are coated with gold. However, their explanations are devoid of almost all physics content. Can someone explain the basic concept of why gold foil is so popular with NASA as a coating on visors?", "output": "In space, the sun transfers heat via radiation to equipment and astronauts. Although the sun\u2019s peak emission is in the visible region (about 500 nm), you can see that there is also a fair amount of IR (infrared) and UV (ultraviolet) emitted as well at the top of the atmosphere.\n\nTo control the surface temperature of an object that is exposed to IR (heat waves), NASA wraps its equipment with a metallic reflector that reflects IR to keep it from getting \u201chot.\u201d The common reflectors are aluminum, silver, copper, and gold. Below, the plot of reflectance vs. wavelength shows that all four metals are good IR-reflectors since the reflectance is close to 100% for wavelengths greater than 700 nm (\u03bb \u2265  700 nm).\n\nSo why use gold? It\u2019s most likely the same reason why they use gold extensively in circuit boards. (i) Gold does not corrode or rust while silver and copper do, which would reduce reflectance (by the way this happens before takeoff) and (ii) it\u2019s a lot easier to work with gold than aluminum. \nThe outer sun visor is made from polycarbonate plastic and coated with a thin layer of gold. This combination gives complete protection to the astronaut. Why? Your eyes can focus both visible and near IR light onto your retina equally well. Your eye has visible receptors but not IR ones. When intense visible light hits these receptors, the receptors transmit information letting you know that this is painful and will cause damage if you don\u2019t either close them or look away. On the other hand, without IR receptors,  you wouldn\u2019t realize that your eye was being \u201cburned\u201d with an intense IR source. Therefore, astronauts need IR protection from intense sunlight above the earth atmosphere. From the plot above, using a gold-coated visor reflects almost all IR, but gold will also transmit about 60% of visible as well as UV light for about \u03bb \u2264 500 nm. According to the plot above, with the visor down you would see a blue-green hue to objects. On the other hand, about 60% of UV is transmitted through the gold, but a polycarbonate plastic visor has excellent visible transmittance but absorbs/reflects almost all UV as shown below. \n\nPMMA (Polymethylmetacrylate, Lexan, Plexiglass..) and PC (Polycarbonate, the DVD material)", "meta": {"post_id": 74412, "input_score": 177, "output_score": 222, "post_title": "Why does NASA use gold foil on equipment and gold-coated visors?"}}
{"input": "While walking around I noticed something very peculiar. Many chimneys had spiral \"wings\", while others didn't. I came up with two possibilities:\n\nThe wind circles around the chimney upwards which pushes whatever gases being released even higher into the sky.\nThe wind circles around the chimney downwards which prevent the chimney from going left or right and rather \"push\" it downwards to make it more steady.\n\nI feel that both of those possibilities are silly. So, why do some chimneys have those spiral \"wings\"? And why other taller chimneys don't?", "output": "The spirals are used to prevent the formation of K\u00e1rm\u00e1n vortex sheets downwind of the chimney.  They work by diverting the wind upwards on one side of the chimney and downwards on the other, creating a three-dimensional airflow pattern that disrupts the vortex sheet.  Without them, the vortex shedding could cause vortex-induced vibration in the chimney, which in strong winds might be enough to damage the (relatively thin-walled and flexible) chimney.\nHere's a very nice animation of K\u00e1rm\u00e1n vortex shedding from Wikipedia, courtesy of Cesareo de La Rosa Siqueira:\n\nThe circle on the left represents the (smooth) chimney, viewed from above, with wind coming from the left; the cyan and purple dots are tracer particles showing how air passing the chimney on either side joins the vortex train generated behind the chimney.  The K\u00e1rm\u00e1n vorticity is an essentially two-dimensional phenomenon; in three dimensions, each vortex would basically be a tall rotating column of air, with one end on the ground and the other end joining together with the adjacent vortices in a complex turbulent region at the altitude of the top of the chimney.\nAs the vortices are shed on alternate sides of the chimney, each one imparts a counter-force on the chimney itself.  Under suitable conditions, these oscillating forces could drive the chimney itself to vibrate from side to side.  The helical projections on the chimney prevent this by disrupting the vortices as they form, or at least causing them to form out of phase at different altitudes.", "meta": {"post_id": 75459, "input_score": 83, "output_score": 84, "post_title": "Why do chimneys have these spiral \"wings\"?"}}
{"input": "We are always told that there are the four fundamental forces or interactions of nature: gravitation, electromagnetism, and the weak and strong forces. We know that gravitation is attractive, that electromagnetism can be attractive or repulsive depending on the electric charge of the interacting particles, and that the strong force is attractive between quarks.\nBut when the weak force is mentioned, the description is always something such as 'responsible for radioactive decay', but there is no mention of whether this force is attractive or repulsive. So my question is: is the weak force/interaction attractive or repulsive?", "output": "Since the electroweak interaction is mediated by spin 1 bosons, it is the case that \"like (charge) repels like and opposites attract\".\nIn the electroweak case, the charges in question are weak isospin and weak hypercharge.\nFor weak isospin, there are two isospin charges (or flavors),  up and down, and their associated anti-charges, anti-up and anti-down.\nSo:\n\nup repels up  (anti-up repels anti-up)\ndown repels down  (anti-down repels anti-down)\nup attracts down  (anti-up attracts anti-down)\nup attracts anti-up  (down attracts anti-down)\nup repels anti-down  (down repels anti-up)\n\nFor weak hypercharge, there is just one type of charge and its associated anti-charge.\nSo:\n\nhypercharge repels hypercharge  (anti-hypercharge repels\nanti-hypercharge)\nhypercharge attracts anti-hypercharge\n\nNote that electric charge is a certain mixture of weak isospin and weak hypercharge.\nSince (left-handed) particles carry both weak isospin and weak hypercharge, both must be taken into account to determine which particles attract or repel under the electroweak interaction.", "meta": {"post_id": 77196, "input_score": 48, "output_score": 43, "post_title": "Weak force: attractive or repulsive?"}}
{"input": "What constitutes protons? When I see pictures, I can't understand. Protons are made of quarks, but some say that they are made of 99% empty space. Also, in this illustration from Wikipedia, what's between the quarks?", "output": "Ah, I know this one!\nWhat's in a proton?\nA proton is really made of excitations in quantum fields (kind of like localized waves). Remember that. Any time you hear any other description of the composition of a proton, it's just some approximation of the behavior of quantum fields in terms of something people are likely to be more familiar with. We need to do this because quantum fields behave in very nonintuitive ways, so if you're not working with the full mathematical machinery of QCD (which is hard), you have to make some kind of simplified model to use as an analogy.\nOne of the more confusing things about quantum field excitations is that they react differently depending on how they are observed. More specifically, the only way to measure the properties of an excitation in a quantum field is to make it interact with another excitation and see how the excitations affect each other. Or in particle language, you have to hit the particle with another particle (the \"probe\") and see what comes out. Depending on the charge, energy, momentum and other properties of the probe, you can get various results.\nPeople have been doing this for decades, and they've compiled the results into a few general conclusions. For example, in a slow collision, with very little energy involved, a proton acts like a single point particle. If we give the particles slightly more energy, the proton looks more like a blob with three points in it --- this is part of why it's often said that the proton consists of three quarks. (Incidentally, the reason you see images like the one you found on Wikipedia is that for a long time, people were colliding protons at the intermediate energies where they appear to behave as a group of three quarks.) If we give the colliding particles even more and more energy, the proton will appear to be an ever-more-dense amalgamation of all sorts of particles: quarks, antiquarks, gluons, photons, electrons, and everything else. We call these particle partons (because they're part of the proton).\nThe following diagram shows representative examples of the effective composition of the proton in different kinds of collisions. The vertical axis basically corresponds to collision energy, and the horizontal axis corresponds to the \"resolving power\" of the incident (\"probe\") particle. (Resolving power is basically transverse momentum, but I can't explain how that connection works without getting into more detail of quantum mechanics than I think is necessary.) The contents of each circle represents, roughly, a sample \"snapshot\" of how the proton behaves in a collision at the corresponding energy and resolving power. The exact numbers, locations, and colors of the dots aren't significant (except sort of in the bottom left), just note how they get larger or smaller and more or less numerous as you move around the plot.\n\nSo for example, if you hit a proton with a beam of high-energy probes (top) that have weak resolving power (left), it behaves like a dense cluster of partons (quarks and gluons etc.), each of which is fairly large. Or if you hit the proton with a beam of low-energy probes (bottom) with high resolving power (right), it behaves like a sparse cluster of partons, each of which is small. If you hit it with a beam of low-energy (bottom), low-resolving-power (left) probes, it behaves like a collection of three particles.\nPhysicists describe this apparently-changing composition using parton distribution functions (PDFs), often denoted $f(x, Q^2)$. Under certain not-too-crazy assumptions, $f(x, Q^2)$ can be interpreted as the probability density of the probe interacting with a particular type of parton with a particular amount of momentum. Visually, $f(x, Q^2)$ is related to the number of particles in the circle at the corresponding $(x,Q)$ point on the plot (though again, the exact numbers are not chosen to exactly reflect reality). For more information on parton distributions, I would refer you to this answer of mine and the resources named therein, as well as this one.\nWhat's the gray region?\nIn the preceding image, I displayed each snapshot of the proton as a set of partons (quarks and gluons etc.) uniformly distributed within a circle, as if the proton has a definite edge and there is nothing outside that edge. But in reality, that's not the case. The quantum fields that make up a proton gradually fade away to zero as you move further away from the center, giving the proton a fuzzy edge. So a (somewhat) more accurate sample snapshot would look something like this:\n\nNotice that there are more dots near the center of the proton, and progressively fewer as you move toward the edge; this represents the fact that a probe which hits a proton dead-center is more likely to interact than a probe which hits it near the edge.\nThe ordinary parton distributions that I mentioned above, $f(x, Q^2)$, are part of a simplified model in which we ignore this fact and pretend that partons are distributed uniformly throughout space. But we can make a more complicated model that does take into account the fact that partons are clumped up toward the center of the proton. In such a model, instead of regular parton distributions, you get more complicated functions, called impact parameter-dependent parton distributions, and denoted $f(x, Q^2, b)$, where $b$ is the radial distance from the center at which the probe hits - the impact parameter.\nThere have been some theoretical studies showing that these impact parameter-dependent parton distributions trail off gradually as you go to large radii. For example, see figure 5 of this paper (arXiv) or figure 7 in this one (arXiv):\n\nHere $N(y)$ is a quantity related to the parton distributions (specifically, it's the color dipole scattering amplitude), which kind of \"condenses\" the many different parton distributions into one quantity. (Huge oversimplification, but it's good enough for this.) You can then define the spatial extent of the proton as the region in which $N(y)$ is above, say, 5% of its maximum value. Or 10%. Or 50%. The exact number is somewhat arbitrary, but the point is, whatever number you pick, you'll wind up with a circle that encompasses the region in which the parton distribution function is large, kind of like this:\n\nThis is roughly what the gray circle in the image from Wikipedia represents. It's a region with a size on the order of $1\\text{ fm}$ (that's about $5\\text{ GeV}^{-1}$ in natural units), where the chance of an incident particle (a probe) scattering off the proton is relatively significant. Equivalently, it's the region in which the parton distributions are large, and also the region in which the quantum fields that constitute the proton are much different from zero.\nAs you can guess, all this is pretty imprecise. You can make a more rigorous definition of the size of a proton by using the scattering cross section. You can also get a definition without using scattering, using the charge radius, which can be measured or calculated using various other methods. I won't go into those, as the details would be material for a whole separate question, but the results of all these methods come out to a radius a little less than $1\\text{ fm}$.\n\nIncidentally, this claim of a proton being 99% empty space is probably false using any reasonable definition. You might be thinking of atoms, where the volume in which the electron's quantum field has an appreciable value is much larger than the size of the electron itself, whatever it may be. People sometimes simplify that to say that the atom consists of a large fraction of empty space. But you can't really do the same with a proton, given the large number of particles in it and the strength of their interactions.", "meta": {"post_id": 81190, "input_score": 116, "output_score": 220, "post_title": "What's inside a proton?"}}
{"input": "Article in question: http://humansarefree.com/2013/01/science-strange-computer-code.html\nProblem: no credible looking or sounding site has anything on it. Only bunch of youtube videos. And some sites. \nHere is the relevant paper on ArXiv", "output": "The work being described is by Prof S. James Gates and it has a serious basis. He has noted that the supersymmetric equations of string theory contain some binary codes built in. These are the same as codes sometimes used in computing for error correcting. This is the Hamming [Block] Code in particular. He constructs mysterious looking diagrams from mathematical equations and the use of Adinkra symbols (which are used by the Dogon people of West Africa), as a way to show how these error correction codes create our universe / physical reality.\nGates has hyped this quite a bit suggesting that it is a sign that we are living in a computer simulation as in the film \"The Matrix\". The video linked to is hyping this even further.\nIn fact these codes are ubiquitous in several areas of mathematics. They are associated with sphere packings, lattices, reflection groups, octonions and exceptional Lie algebras (especially E8) It is not particularly remarkable to see these coming up in string theory. There are other string theorists looking at these structures in a less hyped way to understand the role of algebraic concepts such as octonions and E8. See e.g. papers by Mike Duff and collaborators.\nPeople working on quantum computing are also looking at these codes which are examples of stabilizer codes that can be generated as eigenvectors of Pauli matrices. They hope that the codes can be used to prevent decoherence and that this would make multi-qubit quantum computation feasible.\nIt is always possible that these codes could play some kind of error correcting role in string theory preventing uncontolled decoherence of spacetime, but this is pure speculation and it is not clear if such a mechanism is even needed. In any case these are natural mathematical structures and there is certainly no indication that they have been programmed in to the laws of physics as implied in the video. It is not as if they have discovered sequences of coded instructions that the laws of physics are following.\nIt is an interesting intellectual exercise to think about the way the universe might run like a computer or quantum computer. but suggesting that we are living in a matrix-like simulation is unjustified.", "meta": {"post_id": 83117, "input_score": 18, "output_score": 52, "post_title": "Is this pseudo science or real: code found in superstring"}}
{"input": "Gauge symmetries do not give rise to conservation laws via Noether's theorem, and they represent redundancies in our description of the system. So why do we want to keep them after quantization? For example:\n\nBut gauge symmetries are not symmetries at all. They are redundancies in our\n  description of the system. As such, we can't afford to lose them and it is imperative that they don't suffer an anomaly in the quantum theory.\n\n(From David Tong's lecture notes on string theory, Chapter 5, Page 108).\nIf they are redundancies, then why do we want to formulate a theory with them in it? They give rise to all sorts of inconveniences, e.g. having to define a new functional integral that only integrates over physically distinct configurations.\nI have seen how, by assuming a symmetry, e.g. U(1) symmetry, one can derive some beautiful results, such as the Maxwell Lagrangian, as done by Peskin and Schroeder. But why demand that there be gauge symmetries in the first place?", "output": "Gauge symmetries, as the note says, are redundancies in our description of nature. For example, a photon has two physical degrees of freedom (the two polarizations). However, we choose to describe a photon using a 1-form field $A_\\mu$ which has 4 degrees of freedom. The two extra degrees of freedom here are related to gauge symmetries. From here on, there are two important questions to be answered:\n\nWhy must gauge symmetries be preserved in the quantum theory?\n\nOne of the things that should be preserved in going from the classical to a quantum theory is the degrees of freedom of the theory. (The way the degrees of freedom behave can change, but not their number). Taking the example of the photon, the total unphysical degrees of freedom remains unchanged upon quantization (the quantum and classical photon is described by the same $A_\\mu$). Thus, in order to maintain the right number of physical degrees of freedom (2 for the photon) gauge invariance must be preserved upon quantization. \n\nIf gauge symmetries are redundancies, why introduce them in the first place?\n\nThe important point here is the requirement that our theory be Lorentz invariant. Now, there are two ways to be certain that our theory (or more precisely, the $S$-matrix) is Lorentz invariant\n\nMake the action manifestly Lorentz invariant. This implies describing the theory in terms of Lorentz covariant objects such as scalars $\\phi$, 1-forms $A_\\mu$ or spinors $\\psi$ (and other representations of the Lorentz group.)\nDon't make the action manifestly Lorentz invariant, i.e. formulate it in terms of fields that are not representations of the Lorentz group, but maintain overall Lorentz invariance by carefully putting together the fields in a Lorentz invariant way.\n\nYou may immediately see the advantages of the first technique. Lorentz invariance is manifest, and as long as the indices match up nicely, we never have to worry about getting funny Lorentz non-invariant answers. With the second technique, one has to check for Lorentz invariance at every step of the calculation.\nThe disadvantage of the first method is the following: Every physical object must be embedded in representations of the Lorentz group. Thus, if we want to describe a spin-1 photon, it must be embedded in the spin-1 representation of the Lorentz group, $A_\\mu$. This leads us to a necessary introduction of gauge invariance. (since the 4 dof of $A_\\mu$ has to be reduced to the 2 of the photon)\nSo as a summary, while gauge invariance does create some inconveniences, it allows to circumvent the even more inconvenient formulation of the theory in a Lorentz non-manifest way.\nPS - In recent developments, people have tried embedding the dof of the photon into the spinor, which continues to allow for manifest Lorentz invariance, but also circumvents the problem of gauge invariances. This is called the spinor-helicity formalism.", "meta": {"post_id": 83735, "input_score": 26, "output_score": 38, "post_title": "Why do we seek to preserve gauge symmetries after quantization?"}}
{"input": "The operator-state correspondence in CFT gives a 1-1 mapping between operators $\\phi(z,\\bar{z})$ and states $|\\phi\\rangle$,\n$$\n|\\phi\\rangle=\\lim_{z,\\bar{z}\\mapsto 0} \\phi(z,\\bar{z}) |0\\rangle\n$$\nwhere $|0\\rangle$ is the $SL(2,\\mathbb{Z})$ invariant vacuum. \nWhy can't we have a similar operator-state correspondence in non-CFT QFTs? Can't we just map operators to states by acting with the operator on the vacuum state?", "output": "The operator-state correspondence says that all states in the theory can be created by operators which act locally in a small neighborhood of the origin. That is to say that the entire Hilbert space of a CFT can be thought of as living at a single point. The key here is that for CFTs we have radial quantization, and states evolve radially outwards unitarily from the origin. This corresponds to the limit $z, \\bar z \\rightarrow 0$. \nIf you wanted to do the same for an ordinary QFT, the analagous thing would be associating a Heisenberg picture operator $\\Phi$ with the state $\\displaystyle \\lim_{t \\rightarrow -\\infty} \\Phi(t) | 0 \\rangle$. The biggest problem here is that now one can't think of these as local operators acting at a single point if you want to get the full Hilbert space of the theory. Obviously one always has a map from operators to states just by acting the operators on the vacuum as above, but only for CFTs does the map go the other way that every state corresponds uniquely to a single local operator.", "meta": {"post_id": 88773, "input_score": 43, "output_score": 45, "post_title": "Operator-state correspondence in QFT"}}
{"input": "The hamiltonian for the hydrogen atom,\n$$\nH = \\frac{\\mathbf{p}^2}{2m} - \\frac{k}{r}\n$$\nis spherically symmetric and it therefore commutes with the angular momentum $\\mathbf{L}$; this causes all its eigenfunctions with equal angular momentum number $l$ but arbitrary magnetic quantum number $m$ to be degenerate in energy. \nThe hydrogen atom also has a further degeneracy, in that given any angular momentum there are usually other $l$s with the same energy. This degeneracy is due to the existence of a second constant of motion, usually called the Laplace-Runge-Lenz vector,\n$$\n\\mathbf{A} = \\frac{1}{2m} ( \\mathbf{p} \\times \\mathbf{L} - \\mathbf{L} \\times \\mathbf{p}) - k \\frac{\\mathbf{r}}{r},\n$$\nwhich is the generator of an even bigger symmetry, which is isomorphic for bound states to the group $\\rm{SO}(4)$ of rotations in four dimensions, of the Kepler problem.\nThe Runge-Lenz vector also has a rich geometrical interpretation. For a classical elliptical orbit, it points from the focus to the periapsis and its magnitude is proportional to the orbit's eccentricity. For circular orbits, it vanishes.\n\nImage source: Wikipedia\nThe hydrogen atom is usually described in the common eigenbasis of the hamiltonian and the angular momentum, with the well-known and well-loved quantum numbers $|nlm\\rangle$. However, the Runge-Lenz vector $\\mathbf{A}$ is also a constant of the motion.\nWhat do its eigenfunctions look like?\nMore concretely, I'm looking for the spatial structure of the common eigenfunctions of $H$ and at least one component of $\\mathbf A$, and possibly also of $A^2$ (which, in analogy with the common eigenfunctions of $H$, $L^2$ and $L_z$, is the most one could expect), and if that's not possible then an explanation of why, and a description of suitable third quantum numbers to complete a CSCO. I would like to know what their corresponding eigenvalues are, and what the uncertainty of the other components is, whether one can assign a classical eccentricity to the orbital, and more generally in the relation to the corresponding classical geometry.", "output": "1. Definitions\nLet's consider the nondimensionalized Hamiltonian\n$$\\hat H=\\frac{\\hat{p}^2}2-\\frac1r.\\tag1$$\nIts standard eigenfunctions diagonalize operators $\\hat H$, $\\hat L_z$ and $\\hat L^2$. Laplace-Runge-Lenz operator can be defined as\n$$\\hat{\\vec A}=\\frac{\\vec r}r-\\frac12\\left(\\hat{\\vec p}\\times\\hat{\\vec L}-\\hat{\\vec L}\\times\\hat{\\vec p}\\right).\\tag2$$\nIts $z$-component $\\hat A_z$ commutes with $\\hat H$, $\\hat L_z$, but doesn't commute with $\\hat L^2$ nor with $\\hat A^2$, although $\\hat A^2$ does commute with $\\hat H$, $\\hat L_z$ and $\\hat L^2$.\n2. Eigenfunctions\nSince $\\hat A^2$ commutes with the operators giving quantum numbers $n,l,m$ to the standard hydrogenic eigenstates, these standard eigenstates are also eigenstates of $\\hat A^2$. So no new functions here. For these, we should look at $\\hat A_z$.\n2.1. Semi-numerical approach to finding exact eigenstates of $\\hat A_z$\nSince operators for $H$ and $L_z$ commute with $\\hat A_z$, any eigenstate of $\\hat A_z$ is a superposition of states with fixed $n$ and $m$ and different $l$ quantum numbers. This lets us find eigenstates of $\\hat A_z$ for given $n,m$ without actually solving the eigenfunction PDE. We can e.g. numerically minimize variance of a sample of values of the expression for the eigenvalue\n$$A_z=\\frac{\\hat A_z\\sum\\limits_l\\alpha_l\\psi_{n,l,m}}{\\sum\\limits_l\\alpha_l\\psi_{n,l,m}},\\tag3$$\nwhere $\\psi_{n,l,m}$ are the standard simultaneous eigenfunctions of $\\hat H$, $\\hat L^2$ and $\\hat L_z$, getting a set of weights $\\alpha_l$. Then we can use the approximations we got to guess the exact values of these weights (and substitute into $(3)$, simplifying, to confirm the guess).\nSo, for $n=1$ we have the only eigenfunction, and it's obviously an eigenfunction of $\\hat A_z$. For $n>1$ we have more basis functions, which lets us actually form more \"interesting\" eigenstates of $\\hat A_z$. Here're some tables for $n=2,3,4$ (I calculated them using the above mentioned minimization procedure):\n$$n=2\\\\\n\\begin{array}{|c|c|c|}\n\\hline\n\\text{Eigenfunction of }\\hat A_z&A_z&m\\\\\n\\hline\n\\psi_{2,1,1}   &0  &1  \\\\\n\\psi_{2,1,-1}  &0  &-1 \\\\\n\\frac1{\\sqrt2}(\\psi_{2,0,0}+\\psi_{2,1,0}) &-\\frac12 & 0\\\\\n\\frac1{\\sqrt2}(\\psi_{2,0,0}-\\psi_{2,1,0}) &\\frac12 & 0\\\\\n\\hline\n\\end{array}$$\n$$n=3\\\\\n\\begin{array}{|c|c|c|}\n\\hline\n\\text{Eigenfunction of }\\hat A_z&A_z&m\\\\\n\\hline\n\\psi_{3,2,-2}   & 0 & -2\\\\\n\\psi_{3,2,2}    & 0 & 2\\\\\n\\frac1{\\sqrt2}(\\psi_{3,1,1}+\\psi_{3,2,1}) & -\\frac13 & 1\\\\\n\\frac1{\\sqrt2}(\\psi_{3,1,1}-\\psi_{3,2,1}) & \\frac13 & 1\\\\\n\\frac1{\\sqrt2}(\\psi_{3,1,-1}+\\psi_{3,2,-1}) & -\\frac13 & -1\\\\\n\\frac1{\\sqrt2}(\\psi_{3,1,-1}-\\psi_{3,2,-1}) & \\frac13 & -1\\\\\n\\sqrt{\\frac13}\\psi_{3,0,0}-\\sqrt{\\frac23}\\psi_{3,2,0} & 0 & 0\\\\\n\\frac1{\\sqrt3}\\psi_{3,0,0}+\\frac1{\\sqrt2}\\psi_{3,1,0}+\\frac1{\\sqrt6}\\psi_{3,2,0} & -\\frac23 & 0\\\\\n\\frac1{\\sqrt3}\\psi_{3,0,0}-\\frac1{\\sqrt2}\\psi_{3,1,0}+\\frac1{\\sqrt6}\\psi_{3,2,0} & \\frac23 & 0\\\\\n\\hline\n\\end{array}$$\n$$n=4\\\\\n\\begin{array}{|c|c|c|}\n\\hline\n\\text{Eigenfunction of }\\hat A_z&A_z&m\\\\\n\\hline\n\\psi_{4,3,3}  & 0 & 3\\\\\n\\psi_{4,3,-3} & 0 & -3\\\\\n\\frac1{\\sqrt2}(\\psi_{4,2,2}+\\psi_{4,3,2}) & -\\frac14 & 2\\\\\n\\frac1{\\sqrt2}(\\psi_{4,2,2}-\\psi_{4,3,2}) & \\frac14 & 2\\\\\n\\frac1{\\sqrt2}(\\psi_{4,2,-2}+\\psi_{4,3,-2}) & -\\frac14 & -2\\\\\n\\frac1{\\sqrt2}(\\psi_{4,2,-2}-\\psi_{4,3,-2}) & \\frac14 & -2\\\\\n%\n\\sqrt{\\frac3{10}}\\psi_{4,1,1}-\\sqrt{\\frac12}\\psi_{4,2,1}+\\sqrt{\\frac15}\\psi_{4,3,1} & \\frac12 & 1\\\\\n%\n\\sqrt{\\frac3{10}}\\psi_{4,1,1}+\\sqrt{\\frac12}\\psi_{4,2,1}+\\sqrt{\\frac15}\\psi_{4,3,1} & -\\frac12 & 1\\\\\n%\n\\sqrt{\\frac3{10}}\\psi_{4,1,-1}-\\sqrt{\\frac12}\\psi_{4,2,-1}+\\sqrt{\\frac15}\\psi_{4,3,-1} & \\frac12 & -1\\\\\n%\n\\sqrt{\\frac3{10}}\\psi_{4,1,-1}+\\sqrt{\\frac12}\\psi_{4,2,-1}+\\sqrt{\\frac15}\\psi_{4,3,-1} & -\\frac12 & -1\\\\\n%\n\\sqrt{\\frac25}\\psi_{4,1,1}-\\sqrt{\\frac35}\\psi_{4,3,1} & 0 & 1\\\\\n%\n\\sqrt{\\frac25}\\psi_{4,1,-1}-\\sqrt{\\frac35}\\psi_{4,3,-1} & 0 & -1\\\\\n%\n\\frac12\\psi_{4,0,0}-\\sqrt{\\frac1{20}}\\psi_{4,1,0}-\\frac12\\psi_{4,2,0}+\\sqrt{\\frac9{20}}\\psi_{4,3,0} & \\frac14 & 0\\\\\n%\n\\frac12\\psi_{4,0,0}+\\sqrt{\\frac1{20}}\\psi_{4,1,0}-\\frac12\\psi_{4,2,0}-\\sqrt{\\frac9{20}}\\psi_{4,3,0} & -\\frac14 & 0\\\\\n%\n\\frac12\\psi_{4,0,0}+\\sqrt{\\frac9{20}}\\psi_{4,1,0}+\\frac12\\psi_{4,2,0}+\\sqrt{\\frac1{20}}\\psi_{4,3,0} & -\\frac34 & 0\\\\\n%\n\\frac12\\psi_{4,0,0}-\\sqrt{\\frac9{20}}\\psi_{4,1,0}+\\frac12\\psi_{4,2,0}-\\sqrt{\\frac1{20}}\\psi_{4,3,0} & \\frac34 & 0\\\\\n\\hline\n\\end{array}$$\nThe values of $m$ have been added to the table to make it more obvious that they, together with the eigenvalues $A_z$ and $n$, actually complete the CSCO. We can even plot configurations of the possible states using these quantum numbers, and see a pattern:\n\nLooking at these plots, we can guess what the eigenvalues of $\\hat A_z$ will be for the higher $n$. And then we won't even need the procedure of minimization of variance of the sample of $(3)$ to find the weights $\\alpha_l$: we can simply solve this equation with a random sample of points in the domain, setting one of the weights to $1$, and those corresponding to the $m$ we're not interested in, to $0$ (number of points should be chosen to make number of equations equal to number of weights remaining unknown).\nNow, $k$th value for $A_z$ appears to follow this formula:\n$$A_z(n,m,k)=\\frac{|m|-n-1+2k}n,\\tag4$$\nwhere\n$$k=1,2,\\dots,n-|m|.\\tag5$$\n2.2. Analytical approach to general solution\nThe general solution to eigenproblem of $\\hat A_z$ can be found, if the Schr\u00f6dinger's equation is expressed in the parabolic coordinates. Then the natural eigenfunctions there will be characterized by a different set of quantum numbers than usual: parabolic ones $n_1$ and $n_2$, and the usual magnetic quantum number $m$. The complete expression in terms of confluent hypergeometric function ${}_1F_1$ for the eigenfunctions and its derivation can be found e.g. in Landau and Lifshitz, \"Quantum Mechanics. Non-relativistic theory\" $\\S37$ \"Motion in a Coulomb field (parabolic coordinates)\". The eigenvalues of $\\hat A_z$ can be expressed in terms of the parabolic and magnetic quantum numbers as\n$$A_z=\\frac{n_1-n_2}n,\\tag6$$\nwhere\n$$n=n_1+n_2+|m|+1\\tag7$$\nis the principal quantum number, and parabolic quantum numbers can have the values\n$$n_{1,2}=0,1,...,n-|m|-1.\\tag8$$\nIn terms of $n$, $m$ and $n_1$, $(6)$ can be rewritten as\n$$A_z=\\frac{|m|-n+2n_1+1}n,\\tag9$$\nwhich is consistent with $(4)$-$(5)$.\n3. What the eigenfunctions of $\\hat A_z$ look like\nEigenfunctions of $\\hat A_z$ with high absolute values of eigenvalues look like bells in shape, with probability density symmetric along the $z$ axis. As $L_z$ is conserved, real and imaginary parts of the eigenfunctions oscillate when we go around the $z$ axis with $m\\ne0$.\nHere're plots of some of the eigenfunctions, with 3D density plot on the LHS and cross-sections in $y=0$ plane on the RHS:\n$n=4,\\,A_z=\\frac34,\\,m=0:$\n\n$n=4,\\,A_z=-\\frac14,\\,m=0:$\n\n$n=4,\\,A_z=-\\frac14,\\,m=2$, real part:\n\n$n=3,\\,A_z=\\frac13,\\,m=1$, real part:\n\n4. Relation to classical orbits and their eccentricity\n4.1. Eigenfunctions of $\\hat A_z$\nUnfortunately, the eigenstates of $\\hat A_z$ don't appear to be nicely related to classical eccentric orbits. In classical orbits, $\\vec A$ is always in the plane of rotation. Classical orbital motion corresponds in quantum regime to the case of high expected values of $L_z$. But $\\hat A_z$ commutes with $\\hat L_z$, not with e.g. $\\hat L_x$, so the \"rotating\" (in the sense of $e^{im\\phi}$) eigenstates rotate roughly perpendicularly to direction of the orbital eccentricity. We can interpret these as eccentric standing waves in the $\\theta$ direction, which is of course far from classical regime.\nIt's interesting to note that although with the high values of $A_z$ the $z$ component of $\\vec A$ indeed dominates, giving the cross-section of the orbital somewhat elliptic shape, it's much less so for lower values. This is because of uncertainty in $A_x$ and $A_z$. See e.g. the following eigenfunctions. Ellipses show the supposed classical orbits with semi-major axis $a=n^2$ and LRL vectors $\\vec A=A_z \\vec e_z+s \\sqrt{\\langle A_x^2\\rangle}\\vec e_x$, where $s=-2,-1,0,1,2$.\n$n=20,\\, A_z=\\frac{19}{20},\\, m=0,\\,\\langle A_x^2\\rangle=\\frac{19}{800}\\colon$\n\n$n=20,\\, A_z=\\frac{9}{20},\\, m=0,\\,\\langle A_x^2\\rangle=\\frac{159}{800}\\colon$\n\n$n=20,\\, A_z=\\frac{1}{20},\\, m=0,\\,\\langle A_x^2\\rangle=\\frac{199}{800}\\colon$\n\n4.2. Eigenfunctions of $\\hat A^2$\nWe may have better luck if we consider instead eigenstates of $\\hat A^2$ (which, as mentioned above, doesn't commute with $\\hat A_z$). These are also eigenstates of $\\hat L^2$ and $\\hat L_z$, so they are the familiar functions. Eigenvalues of $\\hat A^2$ are\n$$A_{n,l}^2=1-\\frac{l(l+1)+1}{n^2}.$$\nAs we can see, consistently with classical intuition, eccentricity $e=\\sqrt{A^2}$ decreases with increasing angular momentum. One might hope to see that at least these states will allow assignment of classical eccentricity. But, despite they do, there's a problem: the eigenstates of $\\hat A^2$ are all almost symmetric with respect to rotations around $z$ axis \u2014 modulo the $\\exp(im\\phi)$ oscillations. So we never get anything resembling eccentric ellipses even in eigenstates of $\\hat A^2$. Instead we get the following cross-sections in $xy$ plane of the real parts of wavefunctions (here $n=21$, $m=l$, $l$ changes from $0$ to $20$ with the step of $4$):\n\nSince these states don't actually have any orientation of the LRL vector (aside from avoiding $z$ direction in case of high $m$ values), a better interpretation and drawing of classical eccentricity for them would be like this:\n\nwhere the ellipses show some of the possible orbits one may get if e.g. one were to form a localized wave packet from similar states with this state being dominant.\n5. A note on the method of semi-numerical calculations\nTo make the numerical procedure more understandable, I'll show an example of how one can get an eigenfunction of $\\hat A_z$ and associated eigenvalue with $n=4$, $m=1$. The code in this section is in Wolfram Language. I did all the calculations in Mathematica 11.2, but the code is compatible with versions as old as Mathematica 9.\nFirst, some definitions for the operators and functions we'll use here.\n(* Components of momentum operator *)\npx = -I D[#,x] &;\npy = -I D[#,y] &;\npz = -I D[#,z] &;\n\n(* z component of LRL vector operator *)\nAz = Simplify[\n    z/Sqrt[x^2+y^2+z^2] # -\n     1/2 (z px@px@# + px[z px@#] - px[x pz@#] + z py@py@# + \n        py[z py@#] - py[y pz@#] - x pz@px@# - y pz@py@#)] &;\n\n(* Hydrogenic wavefunction in spherical coordinates *)\n\u03c8[n_,l_,m_,r_,\u03b8_,\u03d5_] = Sqrt[(n-l-1)!/(n+l)!] E^(-r/n) (2 r/n)^l 2/n^2 *\n                          LaguerreL[n-l-1, 2 l+1, (2 r)/n] *\n                          SphericalHarmonicY[l,m,\u03b8,\u03d5];\n(* The same wavefunction converted to Cartesian coordinates *)\n\u03a8[n_,l_,m_,x_,y_,z_] = \u03c8[n, l, m, Sqrt[x^2+y^2+z^2],\n                         ArcCos[z/Sqrt[x^2+y^2+z^2]],\n                         ArcTan[x,y]];\n\nNow the example test function for $n=4$, $m=1$.\n(* Test function with parameters \u03b1, \u03b2 and \u03b3. Restricting arguments to\nnumeric to avoid attempts at symbolic evaluation, which can seriously slow\nthings down. Simplifying it to speedup calculations and reduce roundoff\nerrors. *)\ntest[x_Real,y_Real,z_Real,\u03b1_?NumericQ,\u03b2_?NumericQ,\u03b3_?NumericQ] =\n        FullSimplify[Az@#/# &[\u03b1 \u03a8[4,1,1,x,y,z] +\n                              \u03b2 \u03a8[4,2,1,x,y,z] +\n                              \u03b3 \u03a8[4,3,1,x,y,z]],\n                     (x|y|z) \u2208 Reals];\n\nAnd finally minimization of its variance. Note that we don't need to actually calculate an integral as in variational methods: we only need a \"close enough\" approximation of the parameters, the rest can be left to Rationalize. So we use a coarse mesh of points to evaluate the function on. Note also that here we let Mathematica go to complex domain, although the parameters should be real-valued. This lets it avoid singularities in the function by simply going around them, and thus gives much faster convergence.\n(* Table is generated not on integers to avoid problems like\n   division by zero on evaluation *)\nWith[{\n    var = Total[Abs[#-Mean@#]^2]& @ Flatten @\n             Table[test[x,y,z,\u03b1,\u03b2R + I \u03b2I,\u03b3R + I \u03b3I],\n                   {x,-10.123,10,4},\n                   {y,-10.541,10,5},\n                   {z,-10.07,10,5}\n                  ]\n },\n{minVal,minim} = NMinimize[{var,Total[#^2] == 1 &[{\u03b1,\u03b2R,\u03b2I,\u03b3R,\u03b3I}] && \u03b1>0.1},\n                           {\u03b1,\u03b2R,\u03b2I,\u03b3R,\u03b3I}]\n]\n\n\n{1.29281973036898*10^-9, {\u03b1 -> 0.547724712837901, \u03b2R -> -0.707106153522197, \u03b2I -> 1.84829862406368*10^-7, \u03b3R -> 0.447211968838118, \u03b3I -> -1.8807768960726*10^-7}}\n\nOK, so we see that indeed the imaginary parts are close to zero, so let's guess the form of actual parameters assuming that what we got are square roots of some rationals.\n(* Tolerance of rationalization is chosen so at to\n    1) ignore numerical errors of minimization,\n    2) still give a good enough room to guess the correct number *)\nSqrt[Rationalize[#^2, 10^-4]]Sign[#]&[{\u03b1,\u03b2R,\u03b3R} /. minim]\n\n\n{Sqrt[3/10], -(1/Sqrt[2]), 1/Sqrt[5]}\n\nThis is what we got. Let's check whether this is a correct guess.\nFullSimplify[Az@#/# &[Sqrt[3/10] \u03a8[4,1,1,x,y,z] - \n                       Sqrt[1/2] \u03a8[4,2,1,x,y,z] + \n                       Sqrt[1/5] \u03a8[4,3,1,x,y,z]],\n             (x|y|z) \u2208 Reals]\n\n\n1/2\n\nNow we not only confirmed that our test function with the guessed values of parameters is an eigenfunction (since we got constant here), but also obtained the associated eigenvalue, $A_z=1/2$. This is entry #7 in the table above for $n=4$.\nTo find another set of parameters we can go the following way. First, we can guess that changing some signs in $\\alpha$, $\\beta$ and $\\gamma$ might give us some more eigenfunctions. Indeed, it does, so using $+\\sqrt{1/2}$ instead of $-\\sqrt{1/2}$ for $\\beta$ does result in an eigenfunction (entry #8 in the table, with eigenvalue $A_z=-1/2$).\nAnother approach at finding other eigenfunctions (useful when there are more parameters, e.g. for $n=4$, $m=0$ there are $4$) is using Orthogonalize to find a basis in the orthogonal subspace of parameters to the one we've already identified. Then we can use that basis to form our new set of parameters for NMinimize to work on. In our example case the situation is trivial, since the whole set of $n=4$, $m=1$ eigenfunctions consists of 3 elements, and we've already identified two of them, so no need in further NMinimize. So\nOrthogonalize[{{Sqrt[3/10], -(1/Sqrt[2]), 1/Sqrt[5]},\n               {Sqrt[3/10], 1/ Sqrt[2], 1/Sqrt[5]},\n               {1, 1, 1}}] // FullSimplify\n\n\n{{Sqrt[3/10], -(1/Sqrt[2]), 1/Sqrt[5]}, {Sqrt[3/10], 1/Sqrt[2], 1/Sqrt[5]}, {-Sqrt[(2/5)], 0, Sqrt[3/5]}}\n\nThe third element of the output list is the third eigenfunction (in the $|n,l,m\\rangle$ basis). We can find that associated eigenvalue is $A_z=0$.", "meta": {"post_id": 89659, "input_score": 35, "output_score": 41, "post_title": "Eigenfunctions of the Runge-Lenz vector"}}
{"input": "This question is a consequence of another question of mine which is about spin.\nHere is my spin question.\nWhat is the difference between these two fields? How do they occur? Am I right if I say that a magnetic field is about photons (because they occur between N and S poles of a magnet) and an electric field is about electrons? How they are related?\nFinally; when and why do we use the word \"electromagnetism\"?", "output": "Electric forces are attractive or repulsive forces between \"charged objects\", e.g. comb and dry hair after some friction. Charged objects are those that carry some nonzero electric charge $Q$. The lightest \u2013 and therefore easiest to move \u2013 charged particle is the electron so the surplus or deficit of electrons is the most typical reason why some objects are charged.\nMagnetic forces are attractive or repulsive forces between magnets, like magnetized pieces of iron. The amount of \"magnetic dipole\" carried by a magnet is completely independent of its electric charge. They're as independent as the gravitational and electrostatic forces i.e. as independent as the mass and the charge of an object.\nFor centuries, these two forces were thought of as independent. Only a few centuries ago, due to Faraday and others, relationships between the electric and magnetic forces began to be uncovered. Magnets may be produced by coils \u2013 by electric charges moving in loops. They become indistinguishable from bar magnets. Similarly, moving magnets produce electric fields.\nIn the middle of the 19th century, because of these \"mutual influences\" between electricity and magnetism, a unified theory was gradually found. Because electricity and magnetism influence each other, we need to talk about a whole \u2013 electromagnetism or, to point out that magnetism is related to moving electric charges, electrodynamics (dynamics sort of means \"motion\" or \"reasons for motion\"). \nJames Clerk Maxwell wrote the unified equations for electricity and magnetism which exhibited a near perfect symmetry between electricity and magnetism. They are two independent \"siblings\" but they affect one another and the inner mechanisms in them are analogous. Maxwell's theory also implied that there are electromagnetic waves \u2013 disturbances in space where the electric field goes up and down and so does the magnetic field which is excited by the electric one and vice versa. Moreover, he proved that light was a special example of the electromagnetic wave.\nIn the 20th century, it was realized that the existence of the other force follows from one force (e.g. magnetism followed from electricity) due to a symmetry between inertial observers who are moving relatively to each other, i.e. due to the Lorentz symmetry which underlies Einstein's special relativity. It was also found out that the electromagnetic waves may be thought of as collections of photons and that the exchange of the photon is the \"reason\" behind electric as well as magnetic forces.\nSo the photons are the messengers of electromagnetism \u2013 both electricity and magnetism. Electrons are the most important carriers of the electric charge which means that they're the most important particles that produce the electric and magnetic (when electrons are moving or spinning) fields. These fields arise and affect other pieces of matter (especially electrons) due to the \"messenger role\" of the photons. Photons are \"units\" of the electromagnetic waves.", "meta": {"post_id": 95815, "input_score": 17, "output_score": 38, "post_title": "What is the difference between an electric and a magnetic field?"}}
{"input": "$SU(2)$ is the covering group of $SO(3)$. What does it mean and does it have a physical consequence? \nI heard that this fact is related to the description of bosons and fermions. But how does it follow from the fact that $SU(2)$ is the double cover of $SO(3)$?", "output": "After the answers by joshphysics and user37496, it seems to me that a last remark remains. \nThe quantum relevance of the universal covering Lie group in my opinion is (also) due to a fundamental theorem by Nelson. That theorem  relates Lie algebras of symmetric operators with unitary representations of a certain Lie group generated by those operators. The involved Lie group, in this discussion, is always a universal covering.\nIn quantum theories one often encounters a set of operators $\\{A_i\\}_{i=1,\\ldots, N}$ on a common Hilbert space ${\\cal H}$ such that:\n(1) They  are symmetric (i.e. defined on a dense domain $D(A_i)\\subset {\\cal H}$ where $\\langle A\\psi|\\phi\\rangle = \\langle \\psi|A\\phi\\rangle$)\nand\n(2) they enjoy the commutation relations  of some Lie algebra  $\\ell$:\n$$[A_i,A_j]= \\sum_{k=1}^N iC^k_{ij}A_k$$\non a common invariant domain ${\\cal D}\\subset {\\cal H}$.\nAs is known, given an abstract Lie algebra $\\ell$ there is (up to Lie group isomorphisms) a unique simply connected Lie group ${\\cal G}_\\ell$ such that its Lie algebra coincide with $\\ell$. ${\\cal G}_\\ell$ turns out to be the universal covering of all the other Lie groups whose Lie algebra is $\\ell$ itself.\nAll those groups, in a neighbourhood of the identity are isomorphic to a corresponding neighbourhood of the identity of ${\\cal G}_\\ell$. (As an example just consider the simply connected $SU(2)$ that is the universal covering of $SO(3)$) so that they share the same Lie algebra and are locally identical and differences arise far from the neutral element. \nIf (1) and (2) hold, the natural question is:\nIs there a strongly continuous unitary representation ${\\cal G} \\ni g \\mapsto U_g$ of some Lie group  $\\cal G$ just admitting $\\ell$ as its Lie algebra, such that \n$$U_{g_i(t)} = e^{-it \\overline{A_i}}\\:\\: ?\\qquad (3)$$\nWhere $t\\mapsto g_i(t)$ is the one-parameter Lie subgroup of $\\cal G$ generated by (the element $a_i$ of $\\ell$ corresponding to) $A_i$ and $\\overline{A_i}$ is some self-adjoint extension of $A_i$.\nIf it is the case, $\\cal G$ is a continuous symmetry group for the considered physical system, the self adjoint operators $\\overline{A_i}$ represent physically relevant observables. If time evolution is included in the center of the group (i.e. the Hamiltonian is a linear combination of the $A_i$s and commutes with each of them) all these observables are conserved quantities.\nOtherwise the situation is a bit more complicated, nevertheless  one can define conserved quantities parametrically depending on time and belonging to the Lie algebra of the representation (think of the boost generators when $\\cal G$ is $SL(2,\\mathbb C)$). \nWell, the fundamental theorem by Nelson has the following statement.\nTHEOREM (Nelson)\nConsider a set of operators $\\{A_i\\}_{i=1,\\ldots, N}$ on a common Hilbert space ${\\cal H}$ satisfying (1) and (2) above. If ${\\cal D}$ in (2) is a dense subspace such that the symmetric operator\n$$\\Delta := \\sum_{i=1}^N A_i^2$$\nis essentially self-adjoint on $\\cal D$ (i.e. its adjoint is self-adjoint or, equivalently, $\\Delta$ admits a unique self-adjoint extension, or equivalently its closure $\\overline{\\Delta}$ is self-adjoint), then:\n(a) Every $A_i$ is essentially self-adjoint on $\\cal D$,\nand\n(b) there exists a strongly continuous unitary representation on $\\cal H$ of the unique simply connected Lie group ${\\cal G}_\\ell$ admitting $\\ell$ as Lie algebra, completely defined by the requirements:\n$$U_{g_i(t)} = e^{-it \\overline{A_i}}\\:\\:,$$\nwhere $t\\mapsto g_i(t)$ is the one-parameter Lie subgroup of ${\\cal G}_\\ell$ generated by (the element $a_i$ of $\\ell$ corresponding to) $A_i$ and $\\overline{A_i}$ is the unique  self-adjoint extension of $A_i$ coinciding to $A_i^*$ and with the closure of $A_i$.\nNotice that the representation is automatically unitary and not projective unitary: No annoying phases appear.\nThe simplest example is that of operators $J_x,J_y,J_z$. It is easy to prove  that $J^2$ is essentially self adjoint on the set spanned by vectors $|j,m, n\\rangle$. The point is that one gets this way unitary representations of $SU(2)$ and not $SO(3)$, since the former is the unique simply connected Lie group admitting the algebra of $J_k$ as its own  Lie algebra.\nAs another  application, consider $X$ and $P$ defined on ${\\cal S}(\\mathbb R)$ as usual. The three symmetric operators $I,X,P$ enjoy the Lie algebra of Weyl-Heisenberg Lie group. Moreover $\\Delta = X^2+P^2 +I^2$ is essentially self adjoint on ${\\cal S}(\\mathbb R)$, because it admits a dense set of analytic vectors (the finite linear combinations of eigenstates of the standard harmonic oscillator). Thus these operators admit unique self-adjoint extensions and are generators of a unitary representation of the (simply connected)  Weyl-Heisenberg Lie group. This example holds also replacing $L^2$ with another generic Hilbert space $\\cal H$ and $X,P$ with operators verifying CCR on an dense invariant domain where $X^2+P^2$ (and thus also $X^2+P^2 +I^2$) is essentially self adjoint. It is possible to prove that the existence of the unitary rep of the Weyl-Heisenberg Lie group, if the space is irreducible, establishes the existence of a unitary operator from ${\\cal H}$ to $L^2$ transforming  $X$ and $P$ into the standard operators. Following this way one builds up an alternate  proof of Stone-von Neumann's theorem.\nAs a last comment, I stress that usually ${\\cal G}_\\ell$ is not the group acting in the physical space and this fact may create some problem: Think of $SO(3)$ that is the group of rotations  one would like to represent at quantum level, while he/she ends up with a unitary representation of $SU(2) \\neq SO(3)$. Usually nothing too terrible arises this way, since the only consequence is  the appearance of annoying phases as explained by Josh, and overall phases do not affect  states. Nevertheless sometimes some disaster takes place: For instance, a physical system cannot assume  quantum states that are coherent superpositions of both integer and semi-integer spin. Otherwise an internal phase would take place after a $2\\pi$ rotation. What is done in these cases is just to forbid these unfortunate superpositions. This is one of the possible ways to realize superselection rules.", "meta": {"post_id": 96045, "input_score": 68, "output_score": 36, "post_title": "Idea of Covering Group"}}
{"input": "I just saw a documentary on Titanic. Someone in that documentary told Captain Smith \n\n\"Shall we close the water tight doors, sir?\"\n\nand the Captain replied\n\n\"No, let it be open. Let the water be distributed uniformly throughout\n  ship, so that we could lower the life boats.\"\n\nNote: The quotes are not exact but very near to exact.\n\nMy Question\nIf and if, the watertight doors were shut, was there a chance of Titanic to escape from its tragic fate? \nAnd what exactly is a water tight container?\nI presume that this is related to physics :)", "output": "You asked two questions; I am going to give a very long answer. But the TL;DR is:\nAs posed in the title: \"Was Titanic's captain's decision correct?\" - the answer is \"probably yes\"\nAs posed lower down: Was there a chance of Titanic to escape from its tragic fate?:- the answer is \"once they had hit the iceberg the way they did, no\". \nThe Titanic was considered \"unsinkable\" because any four of the sixteen compartments could be flooded and she would still float. These compartments (see picture below) were basically vertical \"walls\" throughout the ship. If the region between any two walls flooded, the water could not flow to the other compartments (when the flood doors were closed). Think of it as 16 smaller boats welded together and you get the idea.\nHowever, when you look at the diagram you will see that these \"walls\" didn't reach all the way to the top. The ship's designer was on board for the maiden voyage, and he told the captain that she would not survive - losing more than 1/4 of the buoyancy was just too much, and as the ship started to list water would start to flow over the watertight barriers, filling compartment 6, 7, ... So closing the doors would not have helped. They key was to get passengers off the boat - at which they did a terrible job (not only did they not have enough life boats, but the ones they had were not all filled because there had been really no proper training - after all, she was \"unsinkable\").\nIf they had not tried to avoid the iceberg, but had instead hit it head-on, then they would have destroyed the front compartment (maybe even two); but they could have closed the watertight doors, and the ship would have survived. The bottles on the shelf in the first class bar might not have because the impact would have thrown everything and everyone around quite badly.\nFor more details see this which is also source of this image:\n\nThe tragedy was that by attempting to avoid the collision they scraped the iceberg (most of which was underwater - there's the physics bit) and it cut open five consecutive compartments (actually - the force of the collision popped the rivets). This led to a lack of buoyancy which caused the ship to tilt - and the flooding water ended up above the level of the watertight compartments (which didn't go all the way to the top) so other compartments could flood.\nIt is probably true that leaving the watertight doors between compartments open slowed the process of tilting. Once the ship reached a certain angle, stresses became too large (bending force from the front trying to sink and the back trying to float). It is believed that the boilers (remember this was a huge steam ship) broke loose and \"fell\" through the length of the ship, punching a hole as they picked up speed. The hull may also have snapped in half as the bending stresses were far greater than she was designed to withstand. At this point, the electricity generators failed, the hole in the hull became massively bigger, and the whole thing was over in seconds.\nSource: My recollection from reading \"A Night to Remember\"\nI just realized I am writing this on the 102nd anniversary of the sinking... That may be why you just saw the documentary.\nUPDATE\nThe question \"what if they had not tried to steer away\" was still lingering in the back of my mind. Here is what I know:\n\nDuring sea trials they did an \"emergency stop\": from full power ahead (21 knots) to full power astern, it took 195 seconds to come to a stop; in that time they covered 850 yards\nIt took the officer in command of the bridge 37 seconds to react to the \"iceberg ahead\" warning: he shut off propulsion and put the helm hard to port. Because of the size of the rudder, Titanic had (steam powered) power steering.\nWhen he responded, the distance remaining was estimated at 900 feet, and the velocity was about 22 knots: close to the maximum velocity (which was 24 knots). Remember they were going for the Atlantic speed record...\n\nSo now we can do some math. \nFirst question: \nWhat kind of deceleration could they achieve with their engines hard astern?\nGiven $v=10.8m/s$ and $t=195s$, deceleration was $v/t=0.055 m/s^2$\nSecond question: \nIf they had thrown the engines full astern with 900 feet to go, how fast would they have been going on impact?\nWith $d=274m$, $v_{init}=10.8m/s$ and $a=-0.055m/s^2$, $v_{impact}=9.3m/s$\nNote - that is the speed you would go if you dropped approximately 4.4 m, or jumped from the second storey of a building. Ouch.\nThird question: \nIf they had reacted 37 seconds earlier, what would the answer be?\nWe subtract $at$ from the original answer and get $9.3 - 0.055*37 = 7.2m/s$. This corresponds to a drop from 2.6 m - a bit more than half the height from the previous answer.\nFinal question: \nHow much would the ship have crumpled with that kind of impact?\nThat's a tough one. The hull was made of 1 to 1.5 inch thick steel plates that were riveted together (and in fact it's the rivets popping that created the fatal hole in the hull). With a mass of over 53,000 tons (depends who you ask - they were going through 600 tons of coal per day so that number changed very quickly; but we're doing physics here so $5.3x10^7 kg$ is close enough) it had a momentum of \n$$9.3 * 5.3 * 10^7 = 4.9*10^{10}Nm$$\n<briefly switching to imperial units. I'll be right back>\nNow the yield strength of steel is \"around 40,000 psi\", and let's assume that only the part of the ship below the waterline is involved in the collision. With a draft of 34 feet, and estimating the bow section to be 32 feet wide, we have approximately 100 linear feet of steel, or 1200 linear inches of steel. But these plates will have had considerable reinforcement, and bending that much steel would require a lot of force. But then Titanic had a lot of momentum...\n<back to SI units>\nConsulting http://dspace.mit.edu/bitstream/handle/1721.1/77770/47046428.pdf , it is clear that the full calculation is quite complex - but photos in that thesis give us the general idea that the distortion might be \"of the order of\" 1/3 the height of the ship. That would be around 10m. If she did in fact come to a complete stop in 10 m, this would have required an acceleration of about 0.7g . So yes, there would have been casualties, especially among the fine china. Losing the front 10 m would have destroyed one compartment - but only one.\nI suspect that a lot of ice would have been broken too - after all, the yield strength of ice is quite low compared to steel (at least 15x, although the values vary tremendously). But then the hull was \"hollow\" so as soon as the bow penetrated more than a couple of feet, the ice would win.\nWould the iceberg have moved? With 9/10 of its volume below the surface, and with the iceber height comparable to the height of the ship, I am going to venture \"not really\" without attempting to do the detailed calculation.\nFinally the question of the third propeller:\nThe third propeller was mounted in line with the rudder. \n\nIn such a configuration, when the propeller is thrusting forward, the water flow past the rudder and enhances the action of the rudder. When you \"throw the engine in neutral\" as was done just before the collision, the rudder is quite a bit less effective, and the ship will turn more slowly. In the extreme case, if you could reverse the thrust on the central propeller you would have to turn the wheel the other way to get the same turning effect.\nLarge modern vessels have a \"bow thruster\" - this is a turbine that is mounted transversely near the bow, and that allows lateral force to be applied regardless of the speed of the vessel. This allows for far greater maneuverability on these long ships - much more than \"one forward one reverse\" could ever do (just think about the difference in the arm of the force).\nAnother interesting reference:\nphysics world\nI do have one lingering question in my own mind: when a sailing boat is slightly damaged in a collision, one will sometimes \"keel haul\" a sail - essentially pulling it underneath the hull so that it covers the hole and slows the rate at which water enters. I wonder whether Titanic had enough rope and cloth (and maybe steel plates) on board that a clear-thinking engineer might have carried out a similar emergency repair on the water. After all, it wasn't really necessary to stop the water from entering: it just needed to be slowed down enough to give the pumps a fighting chance; that said, the initial rate of flooding was 12x greater than the capacity of the pumps - so any \"patch\" would have had to be really quite good...\nAnd one more excellent reference (contains discussions of much of the above in a lot more depth, and probably by more qualified people) is http://www.encyclopedia-titanica.org/ . I hesitate to post it because I only just found it, and it doesn't always agree with my analysis... I may have to write another update after I have digested some of its contents.", "meta": {"post_id": 108470, "input_score": 35, "output_score": 49, "post_title": "Was Titanic's captain's decision correct?"}}
{"input": "We have seen birds sitting on uninsulated electric wires of high voltage transmission lines overhead without getting harmed, because sitting on only one wire doesn't complete any circuit. \nBut what about the potential difference between their legs? Is this not a small complete circuit? Because the wire has a potential gradient, there should be a potential difference between the bird's feet. Is this potential difference so very small that we can say the bird is sitting at a single point on the wire? If a bird of a sufficiently large size, with a wide gap between its feet, sits on a single wire, shouldn't the bird receive a shock if the potential difference is sufficient?", "output": "Here is a circuit representing the system. $R_{wire}$ is the resistance of the section of wire between the bird's legs. $R_{bird}$ is the resistance of the bird (which you can measure by sticking the two probes of the multimeter to the bird's two feet - if the cable is insulated, you will have to add the resistance of the insulation as well).\nWhen the bird lands, do everyone's lights dim? (does the bird affect how much electricity goes through)\nWhen the bird lands, the resistance between the two points (where its feet touch the wire) changes, so first we must determine whether the current coming from the transformer at the beginning of the power line changes. The resistance would go from $R_{wire}$ to: \n$$R_T = \\frac{1}{\\frac{1}{R_{wire}}+\\frac{1}{R_{bird}}}=\\frac{R_{wire} \\cdot R_{bird}}{R_{wire} + R_{bird}}$$\nAs evidenced by the fact that we use metal cables, and not birds, to transmit electricity, $R_{wire} << R_{bird}$:\n$$ R_{wire} + R_{bird} \\approx R_{bird} \\Rightarrow R_T \\approx \\frac{R_{wire} \\cdot R_{bird}}{R_{bird}}=R_{wire} $$\nTherefore, the resistance does not change much, and the current should also stay about the same because $I=V / R$. (Actually, the current will increase very slightly, because the bird's resistance will be in parallel with the wire's resistance, and this will decrease the overall resistance of the power line very slightly - thanks Nate Eldredge and Max)\nDoes the bird experience extreme voltage?\nThe potential difference between two points is $V_0 = I \\cdot R$. $I$ here is the total current passing through the wire, which we have already established does not differ much with the bird or without. So:\n\nWithout the bird we have $V_0=I \\cdot R_{wire}$. \nWith the bird we have $V_{bird}=I \\cdot R_T \\approx I \\cdot R_{wire}$ (see previous section). \n\nTherefore the voltage experienced by the bird can be approximated with $I \\cdot R_{wire}$. Once again, the wire is very conductive, so $R_{wire}$ will be small; $I$ may be large but not very large. $V_0$ will probably be a volt or less, likewise for $V_{bird}$.\nAlternatively, we can observe that resistance is proportional to length, and therefore so is voltage: $$\\frac{R_{wire}}{R_{line}} = \\frac{L_{wire}}{L_{line}} = \\frac{V_{wire}}{V_{line}} $$ \nHere:\n\n$R_{line}$ is the resistance between the two endpoints of the whole line\n$V_{line}$ is the potential between the two endpoints of the whole line (typically tens of kV)\n$L_{line}$ is the length of the entire power line (typically several kilometers)\n$L_{wire}$ is the length of wire spanned by the bird's legs (typically a few centimeters)\n\nTherefore you can appreciate that the right side of the equation is a very small number, so likewise, $V_{wire}$ must be less than a volt - and the bird experiences approximately $V_{wire}$ potential difference as well.\nDoes the bird experience extreme current?\nDespite low voltage, high current may still be dangerous to animals. As pointed out before, the amount of current passing through the bird-wire block is $I_T=V/R_T \\approx V/R_{wire}$.\nAt one of the bird feet, the current will split into $I_{wire}$ (which goes through the wire) and $I_{bird}$ (which goes through the bird), and then combine at the other foot. Because $V_T = V_{bird} = V_{wire}$, we can conclude that $I_{bird} = V_T/R_{bird}$ and $I_{wire} = V_T/R_{wire}$, therefore current and resistance of either component is inversely proportional:\n$$ \\frac{I_{bird}}{I_{wire}} = \\frac{V_T/R_{bird}}{V_T/R_{wire}} = \\frac{R_{wire}}{R_{bird}}$$\nWe previously established that $R_{wire} << R_{bird}$, so $I_{wire} >> I_{bird}$. Current must be conserved (otherwise the bird must be stealing electrons) so $I_{wire} + I_{bird} = I_T > I_{wire} >> I_{bird}$.\n$I_T$ can be pretty large for the higher capacity lines, but it's not that large - it's on the order of hundreds of amperes. Even though even 0.1 A is considered lethal to humans, the bird will experience a current $I_{bird}$ which is much smaller than this.\nRecall the inverse proportion between current and resistance: Typically, animal bodies have a resistance of a few $M \\Omega$ or a few hundred $k \\Omega$ (original research), while good metal wires a few centimeters long will have less (often much less) resistance than 1 $\\Omega$. So the current passing through the bird will be a few $\\mu A$ at most - harmless.\nIs it dangerous for the bird to open its legs wide?\nA critical factor is the ratio of the resistance of the bird's body $R_{bird}$ to the resistance of the section of wire between its 2 legs $R_{wire}$. First let's consider the the effect of opening legs on total current.\n\nWith legs closed, we get total resistance of the power line $R_{closed} = R_{line} + R_1 + \\frac{1}{\\frac{1}{R_2} + \\frac{1}{R_{bird}}}$. With legs open, $R_{open} = R_{line} + \\frac{1}{\\frac{1}{R_1 + R_2} + \\frac{1}{R_{bird}}}$. $R_{closed} > R_{open}$ (intuitively, you are replacing more of the wire with a more conductive bird/wire composite module). Accordingly, the total current through the whole power line will be higher when legs are open $I_{closed} < I_{open}$.\nFurthermore, as Ilmari Karonen pointed out, increasing $R_{wire}$ increases both the potential experienced by the bird and how much of the (now higher) total current \"splits\" off into the bird part of the circuit.\nIf the bird increases the distance between its legs hundredfold, the increase in total current on the line will be negligible. $V_{wire} = V_{bird}$ will go up hundredfold, and correspondingly, the bird will experience hundredfold-stronger current. However, for a normal bird, if we repeat our original analysis we will find that even 100 cm of cable still has negligible resistance compared to a bird, so I doubt real birds would notice a difference.\n\nWhat if you stretched a bird's legs so much that they could span the whole power line? Besides looking ridiculous, the bird would now experience tremendous potential difference. But in stretching the bird, you would also make it very thin (which increases resistance) and make it very long (which also increases resistance). So $R_{bird}$ would also be much larger and the current would still be very small. The bird would probably experience some form of discomfort, but not due to electrical phenomena.\n\nWhat if you had a giant bird that is so big, its two legs could span the whole power line, even without stretching? Resistance is proportional to length, but inversely proportional to thickness. So if the bird was well-proportioned, it would have the same resistance as a small bird. However, now the resistance of $R_{wire}$ is non-trivial - many kilometers of even very conductive wire can have significant resistance. As said earlier, if 100 A passes through the power line, the bird need only get 0.1% of that to be at risk of death, so if the bird is long enough to span enough kilometers of power line that the resistance of the line is at least a few $k\\Omega$, it will experience a very dangerous shock. Although a bird that big would also have other problems, such as the square-cube law, or current going through its head to make lightning in the upper layers of the atmosphere.", "meta": {"post_id": 109142, "input_score": 38, "output_score": 74, "post_title": "Birds sitting on electric wires: potential difference between the legs"}}
{"input": "Why is it that raindrops don't collide and 'stick together' on their descent to Earth, arriving in streams rather than separate drops?", "output": "Have a look at the Wikipedia article on raindrop formation. You'll also find lots of articles on raindrop formation and growth by Googling raindrop formation or something like that.\nRaindrops do coalesce, but they also fragment, and the eventual size is a balance of the two processes. The fragmentation occurs because of the forces from turbulent air flow. Turbulence can cause droplets to collide, in which case they may coalesce, however it can also break apart large droplets.\nIncidentally, a stream of water is unstable at low flow rates because of the Plateau-Rayleigh instability so it's very unlikely you could get a continuous stream of rain even under ideal atmospheric conditions. The closest you would get is a series of droplets in a line. However in the real world even the slightest turbulence would scatter the droplets and lead to the random distribution of droplets that we see.", "meta": {"post_id": 111917, "input_score": 28, "output_score": 39, "post_title": "Why doesn't rain fall down in streams (as opposed to drops)"}}
{"input": "I recently read that:\n\nA drop of water landing on a hot plate at 150\u00b0C (300\u00b0F) evaporates in a few seconds. A drop of water landing on a hot plate at 200\u00b0C (400\u00b0F) survives a whole minute.\n\nHow would you explain this observation using physics principles?", "output": "That is the Leidenfrost effect.  \nIf the surface is hot enough, a layer of vapor exists between the hot surface and the droplet, insulating the droplet from the full heat.  \nThe droplet levitates above the hot surface.", "meta": {"post_id": 112083, "input_score": 28, "output_score": 40, "post_title": "Why does a water drop on a hot plate at 150\u00b0C evaporate faster than on a plate at 200\u00b0C?"}}
{"input": "When you run or ride bike at night if you observe the moon you feel like he moves along with you as the same speed you are going. Why?", "output": "Suppose you're walking past a nearby tree:\n\nAs you pass the tree the angle of the line joining you and the tree changes. From your perspective it looks as if you are standing still and the tree has moved backwards.\nHowever the Moon is so far away that, as you walk, the angle of the line joining you to the Moon doesn't change by any significant amount:\n\nSo, from your perspective it looks as if the moon is keeping up with you i.e. it's traveling at the same speed as you are.\nThis effect is particularly marked if there are any nearby landmarks. For example, nearby trees seem to move backwards as you pass them, and this enhances the feeling that the Moon is moving forwards to keep up with you.", "meta": {"post_id": 114748, "input_score": 19, "output_score": 40, "post_title": "Why does one get an illusion as moon following him?"}}
{"input": "While I was walking my dog this morning, I passed over a canal filled with boats, barges, and kayaks all of different masses and moving at different speeds. I noticed that all of these vessels left behind wakes, and the waves of these wakes moved through the water at different rates, though my ability to make good observations was limited. This made me wonder: what determines the velocity of these waves?\nI know that sound travels through water at 1,480 m/s or so, but surface waves travel at different rates (tsunamis travel faster than the ripples I make in my bowl of soup when I blow on it). In particular, how is the velocity of wake waves determined?", "output": "The complete answer to that question is an open problem in fluid mechanics, as exact closed form solutions to the irrotational surface gravity water wave equations are unknown. However, under certain asymptotic approximations, we can estimate the speed of these waves. \nIrrotational inviscid surface waves are governed by Laplace's equation, i.e. \n$$\\nabla^2 \\phi = 0$$\nwhere $\\phi$ is the velocity potential. This governing equation, together with the boundary conditions \n$$\\phi_t+\\frac{1}{2}(\\nabla \\phi)^2 +gz = 0$$\n$$\\eta_t +(\\nabla \\phi)\\cdot (\\nabla \\eta) = \\phi_z$$\nwhere $\\eta$ is the free surface displacement, and these equations are evaluated at the free surface, i.e. $z = \\eta$, and the bottom boundary condition \n$\\phi_z = 0$ at $z=-h$, with h the depth of water, constitute the complete set of equations. Also, here $g$ is the acceleration due to gravity.  \nThe governing equation is linear, i.e. Laplace's equations, but the BC are nonlinear, and furthermore are evaluated at a point that we must solve for, which makes these equations very difficult to solve.\nTo make any kind of analytic progress, we make asymptotic approximations. Depending on whether you are describing deep or shallow water waves, different dimensionless parameters come into play. For linear waves however, they both share the common small parameter $\\epsilon \\equiv ak$, which describes the wave slope. \nIn this case, the governing equations, to $\\mathcal{O}(\\epsilon)$ are \n$\\nabla^2\\phi = 0$, with $\\phi_t+ g\\eta = 0$ and $\\eta_t = \\phi_z$, both evaluated at $z=0$, while $\\phi_z = 0$ at $z=-h$.\nFor simplicity let's consider waves of two dimensions, where $x$ is the horizontal direction, and $z$ is the vertical coordinate. Assuming the solutions are permanent progressive waves of the form $$\\eta = a\\ cos(kx-\\omega t)$$ with $a$ the amplitude, $k$ the wavenumber and $\\omega$ the frequency, we find that the linear governing equations imply \n$$\\omega^2 = gk \\tanh(kh)$$\nNow, if we follow waves of constant phase $\\theta = kx -\\omega t$, we see that these waves travel at a speed $c = \\omega/k$. In shallow water, $kh \\gg 1$, so that \n$$\\omega^2 \\approx ghk^2\\\\ (\\text{and}) \\\\c = \\sqrt{gh},$$\nwhile in deep water, $kh \\ll 1$ so that\n$$\\omega^2  \\approx gk\\\\ (\\text{and}) \\\\ c= \\sqrt{\\frac{g}{k}}$$ \nThe first thing we notice is that in deep water, the waves are dispersive, meaning the phase velocity depends on the wavenumber. This is why, for instance, when swells come to shore, it is the longest waves that arive first. In shallow water, to first order, the waves are not dispersive. \nTo first order, wakes are nothing more than linear superposition of waves, due to a moving point disturbance. This is known as the Kelvin ship wake problem, and I discussed a way to derive this result here. \nNow, the above description barely constitutes a summary. For instance, there are many interesting effects that happen when capillary effects are included. For deep water capillary waves\n$$\\omega^2 = Tk^3$$\nwhere $T$ is the surface tension of water. We see that for these waves, the velocity increases with wavenumber, in contrast with gravity waves. However, this equation is academic, as any description of capillary waves must necessarily include dissipation, which is significantly more difficult to model (and has only been done for nonlinear cases numerically). \nSecond order effects (eg in shallow water solitons, in deep water Stokes effects and the nonlinear Schr\u00f6dinger equation) are really interesting but involve heavier lifting.", "meta": {"post_id": 121327, "input_score": 27, "output_score": 38, "post_title": "What determines the speed of waves in water?"}}
{"input": "In this blog post, I found this picture:\n\nThere are other similar photos:\n\nand\n\nDoes the water really form golden ratio spiral in such cases? Or is the photo just a provocative example, without physics grounds for claims about \"goldness\" of the spiral?", "output": "No, this is not a golden-ratio spiral. Its closest relative is the Archimedean spiral, whose fundamental equation is $$r=a+b\\,\\theta.$$\nThis is the spiral traced out by the water thrown out by a horizontal sprinkler as it rotates: because its horizontal velocity is constant, the radius $r(t)$ of a given drop at time $t$ increases linearly with $t$, whereas the angle it propagates on is the direction of the sprinkler when it was fired, which also increases linearly with $t$; hence, there's a linear relation between $r$ and $\\theta$.\n\nImage credit: Anton Croos. I can't find a picture taken from above the sprinkler - apparently people are more careful with their cameras than you'd think.\nIn the case of your image, there is the additional action of gravity to deflect the raindrops, so the spiral will not be perfect, but the principle is the same. It's important to note that Fibonacci and golden spirals operate on a different principle and they're very hard to sustain over multiple turns, as the radius grows exponentially. This is easy to do with, say, a mollusk that eats more as it grows, but it is hard to accomplish with purely kinematical phenomena.\nKinematical phenomena do, on the other hand, more or less routinely produce archimedean, or archimedean-like spirals. My favourite is this one, which is produced by shock waves propagating at constant speed through a planetary nebula, and produced by the gas emitted by one of the stars in a closely-orbiting binary pair:\n\n\nEdit:\nThat image's now got a very close contestant, and I couldn't resist posting it here. This one is sort of, roughly more or less the same: it was produced by gas venting out of a half-spent rocket stage from a Russian ICBM which was rotating as it moved.\n\nImage source here; explanation in Phil Plait's Bad Astronomy blog here.", "meta": {"post_id": 128408, "input_score": 30, "output_score": 38, "post_title": "Is this really a golden ratio spiral?"}}
{"input": "Why can't cables used for computer networking transfer data really fast, say at the speed of light?\nI ask this because electricity travels at the speed of light. Take Ethernet cables for example, I looked them up on wikipedia. \nPropagation speed   0.64        c\n\nWhy only 64% What does propagation speed mean? I know there are other variables affecting the latency and perceived speed of computer network connections, but surely this is a bottle neck.\nIn other words, I'm asking, what is it about a fiber-optics cable that makes it faster than an Ethernet cable?", "output": "Since cables carry electricity moving at the speed of light, why aren't computer networks much faster?\n\nPerhaps I can address your confusion with a rhetorical question:\nSince air carries sound moving at the speed of sound, why can't I talk to you much faster?\nThe speed of sound is much slower than light, but at 340 m/s in air, it's still pretty damn fast. However, this isn't the speed of the channel, it is its latency. That is, if you are 340 meters away, you will hear me 1s after I make a sound. That says nothing about how fast I can communicate with you, which is limited by how effectively I can speak, and how well you can hear me.\nIf we are in a quiet room, I can probably speak very quickly and you can still hear me. If we are far apart or the environment is noisy, I will have to speak more slowly and clearly.\nWith electrical communications the situation is much the same. The speed limit is not due to the latency, but rather how fast one end can transmit with the other end still being able to reliably receive. This is limited by noise picked up from the environment and distortions introduced by the cable.\nAs it turns out, especially for long distances, it is easier (and more economical) to manufacture a fiber optic cable that does not permit outside interference and introduces very little distortion, and that is why fiber optic cables are preferred for long distance, high speed networking.\nThe reasons for optical fiber's superior properties are many, but a significant development is single-mode fiber. These are fibers which, through carefully controlled geometry and research clever enough to earn a Nobel prize, support electromagnetic propagation in just one mode. This significantly reduces modal dispersion, which has the undesirable effect of \"smearing\" or \"spreading\" pulses which encode information. This is a kind of distortion that if excessive, renders the received signal unintelligible, thus limiting the maximum rate at which information can be transmitted.\nA further advantage is that fiber optic communications operate at an extremely high frequency, which reduces chromatic dispersion, a distortion due to different frequencies propagating at different speeds. Typical wavelengths used in fiber are in the neighborhood of 1550 nm, or a frequency of around 193000 GHz. By comparison, category 6a cable is specified only up to 0.5 GHz. Now, in order to transmit information we must modulate some aspect of the signal. A very simple modulation would be turning the transmitter on and off. However, these transitions mean the signal can not consist of just one frequency of light (Fourier components), so the different frequency components of the pulse will be subject to chromatic dispersion. As we increase the carrier frequency but hold the bitrate the same, the fractional bandwidth decreases. That is, the transitions from the modulation become slower relative to the carrier frequency. Thus, chromatic dispersion is decreased, since the signal becomes more like just one frequency of light.\nModern single-mode fiber is so good that the information rate is usually limited by our technology to manufacture the receivers and transmitters at the ends, not by the cable. As an example, wavelength-division multiplexing was developed (and is constantly improved even today) to allow multiple channels to coexist on the same fiber. Several times, networks have been upgraded by upgrading the transceivers at the ends, leaving the cable unchanged. Considering the cost of upgrading a transcontinental cable, the economic advantage should be obvious.", "meta": {"post_id": 129626, "input_score": 34, "output_score": 71, "post_title": "Since cables carry electricity moving at the speed of light, why aren't computer networks much faster?"}}
{"input": "Whenever the Doppler effect is mentioned, it's typically in the context of sound waves or electromagnetic radiation. On the cosmological scale, red-shifting is also important because of the enormous speed of receding galaxies, thanks to the expansion of the universe. \nYet, red-shift is always discussed as the red-shifting of electromagnetic waves. Can gravitational waves be red-shifted? If so, could observations of them be used like red-shifted electromagnetic waves from distant sources are; that is, to figure out how fast an object is receding?", "output": "Yes, gravitational waves will undergo the same red-shift as any wave that propagates at $c$. There were probably very violent gravitational waves in the very early universe. If those waves hadn't been red-shifted, they'd be ripping us apart right now.\n\nIf so, could observations of them be used like red-shifted electromagnetic waves from distant sources are - that is, to figure out how fast an object is receding?\n\nGravitational waves have frequencies that vary over time and that also depend on the particular physical characteristics of the emitting systems. Therefore we don't know a priori what frequency a wave should have had when emitted. This is different from electromagnetic waves in a discrete spectrum.", "meta": {"post_id": 137292, "input_score": 39, "output_score": 38, "post_title": "Can gravitational waves be red-shifted?"}}
{"input": "The solar system is non-integrable and has chaos.\nThe sun-earth-moon three-body system might be chaotic. \nSo, how far into the future can we predict solar eclipses and/or lunar eclipses?\nHow about 1 million years?", "output": "On predicting planetary orbits\nA number of studies have shown that the inner solar system is chaotic, with a Lyapunov time scale of about 5 million years. This 5 million year time scale means that while one can somewhat reasonably create a planetary ephemeris (a time-based catalog of where the planets were / will be) that spans from 10 million years into the past to 10 million years into the future, going beyond that by much is essentially impossible. At a hundred million years, the position of a planet on its orbit becomes complete garbage, meaning that the uncertainties in the planetary positions exceed the orbital radii.\nWhat one can do is forgo the idea of predicting position and instead ask only about parameters that determine the size, shape, and inclination of planetary orbits. This lets one look to secular chaos as opposed to dynamic chaos, which in turn lets attempt to answer the key question, Is the solar system stable?\nThe answer to this question is \"not quite\". The key culprit is Mercury, the most chaotic of all of the planets. One factor is its small size, which magnifies perturbations from other planets. Another factor is resonances with Jupiter and Venus. Both of these planets have multiple resonances with Mercury's eccentricity (Jupiter more so than Venus), and Venus also has multiple resonances with Mercury's inclination. These resonances spell doom for Mercury. Mercury is perched on the threshold of secular chaos, and is likely to be ejected from the solar system in a few billion years.\nOn predicting eclipses\nThe issue of chaos becomes even more extreme when trying to predict eclipses, particularly solar eclipses. The Sun, Jupiter, and Venus have marked effects on the long-term behavior of the Moon's orbit. Even more importantly, however, the Moon is receding from the Earth due to tidal interactions, and this rate is not constant. The current recession rate is about twice the average rate over the last several hundred million years. Changes in the shape and interconnectivity of the oceans drastically changes the rate at which the Moon recedes from the Earth. The melting of the ice covering Antarctica and Greenland would also significantly change the recession rate, as would the Earth entering another glaciation. Even a small change destroys the ability to make long term predictions of the Moon's orbit.\nNASA developed a pair of catalogs of solar eclipses: one covering a 5,000-year period spanning from about 4000 years ago to about 1000 years into the future; the other a 10,000-year catalog of solar eclipses spanning from about 6000 years ago to about 4000 years into the future. The accuracy of these catalog degrades drastically before 3000 years ago and after 1000 years into the figure. Beyond these inner limits, the path of the eclipse over the Earth's surface becomes markedly unreliable, as does the ability to determine whether the eclipse will be partial, total, annular, or hybrid. At the outer time limits of the longer catalog, whether an eclipse did / will occur begins to become a bit dubious.\nBecause of the Earth's much larger shadow, predictions of lunar eclipses are a bit more reliable, but not much. The problem is that of exponential error growth, which is a characteristic of dynamically chaotic systems. Predictions of lunar eclipses more than a few tens of thousands of years into the future are more or less nonsense. The millions of years asked in the question: No.\nThe technique of orbital averaging once again can be of aid in determining characteristics of the Moon's orbit (but not position on the orbit). This can be augmented by geological records. Various tidal rhythmites give clues as to the paleological orbit of the Moon. A few rock formations exhibit layering that recorded the number of days in a month and the number of months in a year at the time the rock formation was created.\nReferences\nAdams, Fred C., and Gregory Laughlin. \"Migration and dynamical relaxation in crowded systems of giant planets.\" Icarus 163.2 (2003): 290-306.\nEspenak and Meeus. \"Five Millennium Canon of Solar Eclipses: -1999 to +3000.\" NASA Technical Publication TP-2006-214141 (2006).\nEspenak and Meeus. \"Ten Millennium Canon of Long Solar Eclipses.\" Eclipse Predictions by Fred Espenak and Jean Meeus (NASA's GSFC).\nLaskar, Jacques. \"A numerical experiment on the chaotic behaviour of the solar system.\" Nature 338 (1989): 237-238.\nLaskar, Jacques. \"Large scale chaos and marginal stability in the solar system.\" Celestial Mechanics and Dynamical Astronomy 64.1-2 (1996): 115-162.\nLaskar, Jacques, and Monique Gastineau. \"Existence of collisional trajectories of Mercury, Mars and Venus with the Earth.\" Nature 459.7248 (2009): 817-819.\nLithwick, Yoram, and Yanqin Wu. \"Theory of Secular Chaos and Mercury's Orbit.\" The Astrophysical Journal 739.1 (2011): 31.\nLithwick, Yoram, and Yanqin Wu. \"Secular chaos and its application to Mercury, hot Jupiters, and the organization of planetary systems.\" Proceedings of the National Academy of Sciences (2013): 201308261.\nNaoz, Smadar, et al. \"Secular dynamics in hierarchical three-body systems.\" Monthly Notices of the Royal Astronomical Society (2013): stt302.", "meta": {"post_id": 137350, "input_score": 61, "output_score": 80, "post_title": "How far ahead can we predict solar and lunar eclipses?"}}
{"input": "On a clear morning, light comes through this window (viewed from the inside)\n\nIt then hits the door on the opposite side (so viewing from the outside the door straight on the other side)\n\nThere is nothing particularly special going on. \nHowever, if I go through the door and turn around to face the door, I see this\n\nLight seems to be dispersing into the color spectrum solely because of the hole in the wooden door. Some days it's even clearer than it is today.\nWhat gives? I know light can do this through prisms, but how come it's happening with only a hole in a door?\n\nEdit\nAs per Floris' instruction, I did a little more experimenting. Here are the results (extra hint/spoiler):\n\n \n\n\n It's far from perfect because I made the hole using a black gym bag and some masking tape, and used a handheld mirror to reflect it onto the door, but I think it shows his explanation to be correct pretty well!", "output": "You have created a rather poor pinhole camera (camera obscura). You can see an \"image\" of the sky, a green space (trees) and even a reddish brown blur that is your driveway.\nThis is not diffraction or refraction - it's geometrical (classical) optics. Because the hole is pretty big, you see a very blurry image. But basically, the light from the sky falling through the hole hits one part of the door; the light from the trees hits a slightly different part; and the light from the driveway (the lowest object on the outside) hits the highest part on the inside, after coming through the hole.\n\nIncidentally - if you took a picture from the perspective of the hole in the door, I am guessing you would see more of the sky - in your photo of the view, the sky is barely visible, but in the doorhole image it's much more prominent; and conversely, one sees less of the driveway. This is consistent with the photo being taken from a different vantage point.", "meta": {"post_id": 138003, "input_score": 92, "output_score": 121, "post_title": "Why does my wooden door disperse light into a rainbow color spectrum?"}}
{"input": "For all machines (cars, elevators, computers, etc), when size, power requirements, dimensions are scaled by a constant N, will it work just as is?\nWill a car with all its parts 10x larger still work like a normal car, just larger?", "output": "This is a great question. An influential early discussion of it was given in a 1959 talk by Richard Feynman, There's Plenty of Room at the Bottom. Basically the answer is no, machines are not linearly scalable. For example, lubrication doesn't work for very small machines. A general way of looking at this is that we have various physical quantities, and they scale in different ways. For example, area is proportional to length squared, while volume goes like length cubed. Because different things scale differently, what works on one scale doesn't work on another. A good example is the animal world -- after all, animals are a type of machine. A spider the size of an elephant would collapse under its own weight. This is because the strength of the animal's limbs go like the cross-sectional area, while the weight the limbs have to support is proportional to volume.", "meta": {"post_id": 139092, "input_score": 31, "output_score": 48, "post_title": "Are all machines linearly scalable?"}}
{"input": "I ask here intentionally not for the size of the smallest possible observed size of neutron stars, which corresponds approximately to the well-known Chandrasekhar-limit for the upper limit of the white dwarfs. This is defined by the minimal size of a stellar core to collapse into a neutron star, instead of white dwarf.\nBut, I think this is not the smallest possible neutron star mass - it is only the smallest mass that can be produced by stellar evolution processes.\nFor example, black holes have also a lower limit: the Tolman-Oppenheimer-Volkoff limit, which is around 1.5-3.0 Solar masses. Corresponding to that, the known smallest black hole is observed to be around 4 Solar masses. But this doesn't define the smallest possible size of a black hole, it only defines the smallest black hole size which can be formed. Theoretically, even Earth-sized or much more smaller black holes could exist, but there is no known process which could create them. Despite the extensive searches for micro black holes, nothing was found.\nBy analogy, I am asking is this a similar situation for neutron stars? What is the minimal mass of a neutron star, which could remain stable? Is this mass smaller than the Chandrasekhar-limit?", "output": "We think that most neutron stars are produced in the cores of massive stars and result from the collapse of a core that is already at a mass of $\\sim 1.1-1.2 M_{\\odot}$ and so as a result there is a minimum observed mass for neutron stars of about $1.2M_{\\odot}$ (see for example Ozel et al. 2012). Update - the smallest, precisely measured mass for a neutron star is now $1.174 \\pm 0.004 M_{\\odot}$ - Martinez et al. (2015).\nThe same paper also shows that there appears to be a gap between the maximum masses of neutron stars and the minimum mass of black holes.\nYou are correct that current thinking is that the lower limit on observed neutron star and black hole masses is as a result of the formation process rather than any physical limit (e.g. Belczynski et al. 2012 [thanks Kyle]).\nTheoretically a stable neutron star could exist with a much lower mass, if one could work out a way of forming it (perhaps in a close binary neutron star where one component loses mass to the other prior to a merger?). If one just assumes that you could somehow evolve material at a gradually increasing density in some quasi-static way so that it reaches a nuclear statistical equilibrium at each point, then one can use the equation of state of such material to find the range of densities where $\\partial M/\\partial \\rho$ is positive. This is a necessary (though not entirely sufficient) condition for stability and would be complicated by rotation, so let's ignore that.\nThe zero-temperature \"Harrison-Wheeler\" equation of state (ideal electron/neutron degeneracy pressure, plus nuclear statistical equilibrium) gives a minimum stable mass of 0.19$M_{\\odot}$, a minimum central density of $2.5\\times10^{16}$ kg/m$^3$ and a radius of 250 km. (Colpi et al. 1993). However, the same paper shows that this is dependent on the details of the adopted equation of state. The Baym-Pethick-Sutherland EOS gives them a minimum mass of 0.09$M_{\\odot}$ and central density of $1.5\\times10^{17}$ kg/m$^3$. Both of these calculations ignore General Relativity.\nMore modern calculations (incorporating GR, e.g.\nBordbar & Hayti 2006) get a minimum mass of 0.1$M_{\\odot}$ and claim this is insensitive to the particular EOS. This is supported by Potekhin et al. (2013), who find $0.087 < M_{\\rm min}/M_{\\odot} < 0.093$ for EOSs with a range of \"hardness\". On the other hand Belvedere et al. (2014) find $M_{\\rm min}=0.18M_{\\odot}$ with an even harder EOS.\nA paper by Burgio & Schulze (2010) shows that the corresponding minimum mass for hot material with trapped neutrinos in the centre of a supernova is more like 1$M_{\\odot}$. So this is the key point - although low mass neutron stars could exist, it is impossible to produce them in the cores of supernovae.\nEdit: I thought I'd add a brief qualitative reason why lower mass neutron stars can't exist. The root cause is that for a star supported by a polytropic equation of state $P \\propto \\rho^{\\alpha}$, it is well known that the binding energy is only negative, $\\partial M/\\partial \\rho>0$ and the star stable, if $\\alpha>4/3$. This is modified a bit for GR - very roughly $\\alpha > 4/3 + 2.25GM/Rc^2$. At densities of $\\sim 10^{17}$ kg/m$^3$ the star can be supported by non-relativistic neutron degeneracy pressure with $\\alpha \\sim 5/3$. Lower mass neutron stars will have larger radii ($R \\propto M^{-1/3}$), but if densities drop too low, then it is energetically favorable for protons and neutrons to combine into neutron-rich nuclei; removing free neutrons, reducing $\\alpha$ and producing relativistic free electrons through beta-decay. Eventually the equation of state becomes dominated by the free electrons with $\\alpha=4/3$, further softened by inverse beta-decay, and stability becomes impossible.\nEdit2: There are claims in the literature that a minimum mass or even sub-minimum mass neutron star could be created by tidal stripping during the merger of two neutron stars (or maybe a black hole and a neutron star?) - e.g. Colpi et al. (1989); Yudin et al. (2023). These would then explode in some sort of weak supernova-type event, perhaps masquerading as a kilonova.", "meta": {"post_id": 143166, "input_score": 38, "output_score": 40, "post_title": "What is the theoretical lower mass limit for a gravitationally stable neutron star?"}}
{"input": "I have read different speeds of Earth in different sources. $382\\;{\\rm km}/{\\rm s}$, $12\\;{\\rm m}/{\\rm s}$ and even $108,000\\;{\\rm km}/{\\rm h}$. Basically, it's moving too fast around the Sun. And the Solar System is moving too. So why don't we feel it and why doesn't it harm us in any way? Inertia can only be a part of it. But what's the whole reason?", "output": "Speed doesn't kill us, but acceleration does. \nWhen astronauts go into space at launch and when fighter pilots turn very tight turns at high speed they experience 'high g forces' - their bodies are accelerated very fast as they accelerate and gain speed to go into space or as the direction of their speed changes. One of the problems with this is that for fighter pilots the blood can rush to the feet (black out) or to the head (red out). Too much acceleration makes people pass out and could at extremes be fatal I guess.\nTo go around the sun in (nearly) a circular path we are acclerated by the gravity from the sun. The acceleration can be calculated by $v^2/r$ where $v$ is our speed and $r$ is the distance to the centre of the sun. This acceleration turns out to be $\\sim~0.006~m/s^2$. By contrast the acceleration that we feel here at the surface due to the gravitational pull of the earth on us is $\\sim~10~m/s^2$. So the acceleration due to travelling around the sun is so small we don't notice it. We do notice the pull of gratvity from the earth on us, but our bodies are used to it and can cope with it. \nTo think about it another way we can go very fast in a car on a motorway/highway without noticing it, the big danger is having to stop very quickly or crashing when we change speeds very rapidly - acceleration is the rate of change of speed so changing speed very rapidly is equivalent to a very high acceleration - in a car we might call this deceleration.\n[for calculation above $v=3 \\times 10^4~m/s$ and $r=1.5 \\times 10^{11}m$]\nafter good comment from hdhoundt -\nFor astronauts in orbit (e.g. in the space station) they can cope with the acceleration they experience, which holds them in orbit around the earth. Indeed they feel weightless because they are not held by the gravity of earth on the surface. Instead they and their surroundings are in 'constant free fall'. The speed of the space station in orbit is $7.71 km/s$, which is $\\sim~ 17,000 ~mph$.\nFull discussion of this topic might venture into relativity, but I think that is beyond the scope of the question.\nafter good comment from Mooing Duck -\nPerhaps even more dangerous than acceleration is jerk, which is the rate of change of acceleration and other higher order terms. Jerk would be very severe in the case of car collisions. - But also if the driver of a car or bus has to 'brake' and slow down very suddenly it can be very uncomfortable for the passengers. \nAfter good comment from Jim (and Cory)-\nGood point raised about acceleration and/or jerk on a human body. If every part (and every particle) of the body experience the same acceleration or jerk then the body will suffer significantly less (possibly no) damage compared to when one part of the body is accelerated of jerked and the acceleration or jerk is transmitted to other parts of the body by the structure of the body. The classic example here is 'whiplash' neck injury, where a jerk on the body is transmitted to the head through the neck. To reduce the damage this may cause seats in cars generally hare head rests that will support the back of the head and for people who are involved in motor sports (e.g. car racing) may wear a neck brace/support that prevents the head from swinging backwards and forwards on the neck in the event of a collision. \nAnother aspect of acceleration to all part of the body concerns rocket launch for astronauts. The rockets will be designed so that as much as possible all part of the body are equally supported and the body lies 'flat with respect to the acceleration' so that the blood in the astronaut's body does not rush to the feet or head. This is a serious consideration and Memory Foam came from research by NASA into safety for aircraft cushions and helped cushion astronauts in rockets.", "meta": {"post_id": 144736, "input_score": 19, "output_score": 41, "post_title": "Why doesn't the speed of Earth (moving through space) kill us?"}}
{"input": "In parts per million in the Earth's crust Uranium is around 1.8ppm and Gold 0.003ppm. Given that it takes far more energy to create Uranium than Gold, why is this?", "output": "Since gold is much more abundant in the universe than is uranium (by a factor of about 20:1)1, why is the situation reversed in the Earth's crust (by a factor of about 1:600)2? The answer lies in chemistry.\nUranium is chemically active. It readily oxidizes (pitchblende) and it readily combines with silicates. Uranium is a lithophile (literally, rock-loving) element3. It does not dissolve all that well in molten iron, and thus tended not migrate to the center of the Earth when the Earth differentiated. Uranium is a \"high field strength element\", one of the two classes of trace elements that are incompatible with the minerals that form the upper mantle4. When upper mantle rock undergoes a partial melt, incompatible elements such as uranium preferentially join the silicate melt rather than staying with the solid minerals. Over time, this magnifies the amount of uranium in the crust compared to that in the upper mantle5.\nGold on the other hand is rather inert chemically. It has little affinity to oxygen or sulfur. It does however readily dissolve in molten iron. Gold is a siderophile (literally, iron-loving) element3. Of the tiny bit of gold currently found in the crust, hardly any is primordial. Almost all of the primordial gold sank to the Earth's core when the planet differentiated. The gold currently found in the crust instead arrived in meteors that hit the Earth after the Earth had finished forming6.\nThe above assumes that the Bulk Silicate Earth (BSE) models of the Earth is basically correct, that the Earth formed from protoplanets and planetary embryos that had formed from material in the inner solar system, and that the proto-Earth differentiated into a core and primitive mantle. One prediction of these models is that the differentiation that created the Earth's core made the core strongly enhanced in siderophile elements and strongly depleted of lithophile elements, particularly so with regard to high refractory lithophile elements such as thorium and uranium. An opposing (not well accepted) model says that rather than being depleted of uranium, the Earth's core is uranium-enhanced, and to such an extent that there is a large georeactor at the very center of the Earth. These are testable hypotheses. Recent studies of geo-neutrinos are consistent with the BSE hypothesis, and simultaneously reject the possibility of a large georeactor at the center of the Earth7.\n\nFootnotes\n\nBased on Lodders, \"Solar system abundances of the elements.\" Principles and Perspectives in Cosmochemistry, Springer Berlin Heidelberg, 379-417 (2010), the abundance of gold to uranium by mass in chondritic meteorites is 18.1:1, 25:1 for the sun's photosphere. To one significant digit, this ratio becomes 20:1.\nFrom Lide, editor, CRC Handbook of Chemistry and Physics, 88th edition, the crustal ratio of uranium to gold is 675:1. From online resources such as web elements.com, I get ratios ranging from over 400:1 to over 600:1. I used 600:1.\nVictor M. Goldschmidt developed the concept of classifying elements as siderophile (\"iron loving\"), lithophile (\"rock loving\"), chalcophile (literally \"ore loving\", but Goldschmidt implied \"sulphur loving\"), and atmophiles (\"air loving\") in the 1920s. While Goldschmidt's initial concept of a siderophilic core surrounded by a chalcophilic layer surrounded in turn by a lithophilic outer layer didn't pan out, his classification scheme lives on. That uranium is a lithophile and gold is a siderophile is basic chemistry.\nThere are two key classes of \"incompatible elements\": Those with an abnormally large ionic radius, and those with an abnormally large field strength. Uranium and thorium fall into the latter class.\nWhile the \"incompatible elements\" are lithophiles based on chemistry, they don't fit nicely in the crystalline structures that comprise typical rock. In rock undergoing a partial melt, incompatible elements such as uranium tend to migrate to the melt because of this structural incompatibility. Over time, plate tectonics has made the incompatible elements migrate to the Earth's crust.\nThis is the conclusion of Willbold, et al., \"The tungsten isotopic composition of the Earth/'s mantle before the terminal bombardment.\" Nature 477.7363: 195-198 (2011). Others disagree. One thing is certain: Gold is an extremely rare element in the Earth's crust.\nFor example, see Bellini, et al., \"Observation of geo-neutrinos.\" Physics Letters B 687.4:299-304 (2010), Fiorentini, et al., \"Geo-neutrinos and earth's interior.\" Physics Reports 453.5:117-172 (2007), and a host of other recent papers on this topic.", "meta": {"post_id": 144758, "input_score": 87, "output_score": 133, "post_title": "In the earth's crust, why is there far more uranium than gold?"}}
{"input": "The metrology world is currently in the middle of overhauling the definitions of the SI units to reflect the recent technological advances that enable us to get much more precise values for the fundamental constants of nature than were possible when the SI was drawn up. This has already happened to the second and the meter, which are defined in terms of a caesium transition and the speed of light, and it is being extended to the other units. Thus, in the new system, known as the 'new SI',\n\nfour of the SI base units, namely the kilogram, the ampere, the kelvin and the mole, will be redefined in terms of invariants of nature; the new definitions will be based on fixed numerical values of the Planck constant ($h$), the elementary charge ($e$), the Boltzmann constant ($k$), and the Avogadro constant ($N_A$), respectively.\n\nThe proposed draft of the SI brochure gives more details, but it stops short of describing the recommended mises en pratique. For example, for the kilogram, the definition goes\n\nThe SI unit of mass, the kilogram\n\nThe kilogram, symbol kg, is the SI unit of mass; its magnitude is set by fixing the numerical value of the Planck constant to be exactly 6.626 069 57 10\u221234 when it is expressed in the SI unit for action J s = kg m2 s-1.\n\nThus we have the exact relation h = 6.626 069 57 10\u221234 kg m2 s-1 = 6.626 069 57 10\u221234 J s. Inverting this equation gives an exact expression for the kilogram in terms of the three defining constants $h$, $\\Delta \\nu$(133Cs)hfs and $c$:\n  $$\n\\mathrm{kg}\n=\\left(\\frac{h}{6.626 069 57\\times10^{\u221234}}\\right)\\mathrm{m}^{2}\\:\\mathrm s^{-1}\n=1.475521\\ldots\\times 10^{40}\\frac{h \\Delta \\nu\\left(^{133}\\mathrm{Cs}\\right)_\\mathrm{hfs}}{c^2}\n$$\n  The Planck constant is a constant of nature, whose value may be expressed as \n  the product of a number and the unit joule second, where J s = kg m2 s-1. The effect of this definition is to define the unit kg m2 s-1 (the unit of both the physical quantities action and angular momentum), and thus together with the definitions of the second and the metre this leads to a definition of the unit of mass expressed in terms of the value of the Planck constant $h$.\nNote that macroscopic masses can be measured in terms of $h$, using the \n  Josephson and quantum-Hall effects together with the watt balance apparatus, \n  or in terms of the mass of a silicon atom, which is accurately known in terms \n  of $h$ using the x-ray crystal density approach.\n\nHowever, the brochure is pretty scant as to what the specific realizations through watt balances actually imply in terms of a route from measured physical quantities to values of fundamental constants or to inferred masses. For the specific case of the watt balance, for example, the physical constants at play are much more naturally the Josephson and von Klitzing constants, $K_J=2e/h$ and $R_K=h/e^2$, if I understand correctly, so there is some re-shuffling of experimental results to be done.\nThe SI brochure is similarly vague for the other three base unit / fundamental constant pairs.\nThis brings me, then, to my specific questions. For each of these four base unit / fundamental constant pairs,\n\nwhat are the proposed experimental realizations, what are the basics of their operation, and what physical effects do they rely on?\nwhat other fundamental constants are used to go from experimentally measured values to inferred parameters? (i.e. the meter depends on the second. Does the kilogram depend on the value of the electric charge?)\nwhat specific natural constants are measured by the experiment, and how are they reshuffled to obtain final results?\n\nAdditionally, what is the dependency tree between the different definitions of the base units? What units depend on what others, either directly or indirectly?", "output": "So the BIPM has now released drafts for the mises en pratique of the new SI units, and it's rather more clear what the deal is. The drafts are in the New SI page at the BIPM, under the draft documents tab. These are drafts and they are liable to change until the new definitions are finalized at some point in 2018. At the present stage the mises en pratique have only recently cleared consultative committee stage, and the SI brochure draft does not yet include any of that information.\nThe first thing to note is that the dependency graph is substantially altered from what it was in the old SI, with significantly more connections. A short summary of the dependency graph, both new and old, is below.\n$\\ \\  $\n\nIn the following I will explore the new definitions, unit by unit, and the dependency graph will fill itself as we go along.\nThe second\nThe second will remain unchanged in its essence, but it is likely that the specific reference transition will get changed from the microwave to the optical domain. The current definition of the second reads\n\nThe second, symbol $\\mathrm{s}$, is the SI unit of time. It is defined by taking the fixed numerical value of the caesium frequency $\\Delta\\nu_\\mathrm{Cs}$, the unperturbed ground-state hyperfine splitting frequency of the caesium 133 atom, to be $9\\,192\\,631\\,770\\:\\mathrm{Hz}$, where the SI unit $\\mathrm{Hz}$ is equal to $\\mathrm{s}^{\u20131}$ for periodic phenomena.\n\nThat is, the second is actually implemented as a frequency standard: we use the resonance frequency of a stream of caesium atoms to calibrate microwave oscillators, and then to measure time we use electronics to count cycles at that frequency.\nIn the new SI, as I understand it the second will not change, but on a slightly longer timescale it will change from a microwave transition to an optical one, with the precise transition yet to be decided. The reason for the change is that optical clocks work at higher frequencies and therefore require less time for comparable accuracies, as explained here, and they are becoming so much more stable than microwave clocks that the fundamental limitation to using them to measure frequencies is the uncertainty in the standard itself, as explained here.\nIn terms of practical use, the second will change slightly, because now the frequency standard is in the optical regime, whilst most of the clocks we use tend to want electronics that operate at microwave or radio frequencies which are easier to control, so you want a way to compare your clock's MHz oscillator with the ~500 THz standard. This is done using a frequency comb: a stable source of sharp, periodic laser pulses, whose spectrum is a series of sharp lines at precise spacings that can be recovered from interferometric measurements at the repetition frequency. One then calibrates the frequency comb to the optical frequency standard, and the clock oscillator against the interferometric measurements. For more details see e.g. NIST or RP photonics.\nThe meter\nThe meter will be left completely unchanged, at its old definition:\n\nThe metre, symbol $\\mathrm{m}$, is the SI unit of length. It is defined by taking the fixed numerical value of the speed of light in vacuum $c$ to be $299\\,792\\,458\\:\\mathrm{m/s}$.\n\nThe meter therefore depends on the second, and cannot be implemented without access to a frequency standard.\nIt's important to note here that the meter was originally defined independently, through the international prototype meter, until 1960, and it was to this standard that the speed of light of ${\\sim}299\\,792\\,458 \\:\\mathrm{m/s}$ was measured. In 1983, when laser ranging and similar light-based technologies became the most precise ways of measuring distances, the speed of light was fixed to make the standard more accurate and easier to implement, and it was fixed to the old value to maintain consistency with previous measurements. It would have been tempting, for example, to fix the speed of light at a round $300\\,000\\,000 \\:\\mathrm{m/s}$, a mere 0.07% faster and much more convenient, but this would have the effect of making all previous measurements that depend on the meter incompatible with newer instruments beyond their fourth significant figure.\nThis process - replacing an old standard by fixing a constant at its current value - is precisely what is happening to the rest of the SI, and any concerns about that process can be directly mapped to the redefinition of the meter (which, I might add, went rather well).\nThe ampere\nThe ampere is getting a complete re-working, and it will be defined (essentially) by fixing the electron charge $e$ at (roughly) $1.602\\,176\\,620\\times 10^{\u201319}\\:\\mathrm C$, so right off the cuff the ampere depends on the second and nothing else.\nThe current definition is couched on the magnetic forces between parallel wires: more specifically, two infinite wires separated by $1\\:\\mathrm m$ carrying $1\\:\\mathrm{A}$ each will attract each other (by definition) by $2\\times10^{-7}\\:\\mathrm{N}$ per meter of length, which corresponds to fixing the value of the vacuum permeability at $\\mu_0=4\\pi\\times 10^{-7}\\mathrm{N/A^2}$; the old standard depends on all three MKS dynamical standards, with the meter and kilogram dropped in the new scheme. The new definition also shifts back to a charge-based standard, but for some reason (probably to not shake things up too much, but also because current measurements are much more useful for applications) the BIPM has decided to keep the ampere as the base unit.\nThe BIPM mise en pratique proposals are a varied range. One of them implements the definition directly, by using a single-electron tunnelling device and simply counting the electrons that go through. However, this is unlikely to work beyond very small currents, and to go to higher currents one needs to involve some new physics.\nIn particular, the proposed standards at reasonable currents also make use of the fact that the Planck constant $h$ will also have a fixed value of (roughly) $6.626\\,069\\times 10^{\u221234}\\:\\mathrm{kg\\:m^2\\:s^{-1}}$, and this fixes the value of two important constants.\n\nOne is the Josephson constant $K_J=2e/h=483\\,597.890\\,893\\:\\mathrm{GHz/V}$, which is the inverse of the magnetic flux quantum $\\Phi_0$. This constant is crucial for Josephson junctions, which are thin links between superconductors that, among other things, when subjected to an AC voltage of frequency $\\nu$ will produce discrete jumps (called Shapiro steps) at the voltages $V_n=n\\, \\nu/K_J$ in the DC current-voltage characteristic: that is, as one sweeps a DC voltage $V_\\mathrm{DC}$ past $V_n$, the resulting current $I_\\mathrm{DC}$ has a discrete jump. (For further reading see here, here or here.)\nMoreover, this constant gives way directly to a voltage standard that depends only on a frequency standard, as opposed to a dependence on the four MKSA standards as in the old SI. This is a standard feature of the new SI, with the dependency graph completely shaken for the entire set of base plus derived units, with some links added but some removed. The current mise en pratique proposals include stabs at most derived units, like the farad, henry, and so on.\nThe second constant is the von Klitzing constant $R_K = h/e^2= 25\\,812. 807\\,557 \\:\\Omega$, which comes up in the quantum Hall effect: at low temperatures, an electron gas confined to a surface in a strong magnetic field, the system's conductance becomes quantized, and it must come as integer (or possibly fractional) multiples of the conductance quantum $G_0=1/R_K$. A system in the quantum Hall regime therefore provides a natural resistance standard (and, with some work and a frequency standard, inductance and capacitance standards).\n\nThese two constants can be combined to give $e=K_J/2R_K$, or in more practical terms one can implement voltage and resistance standards and then take the ampere as the current that will flow across a $1\\:\\Omega$ resistor when subjected to a potential difference of $1\\:\\mathrm V$. In more wordy language, this current is produced at the first Shapiro voltage step of a Josephson junction driven at frequency $483.597\\,890\\,893\\:\\mathrm{THz}$, when it is applied to a resistor of conductance $G=25\\,812. 807\\,557\\,G_0$. (The numbers here are unrealistic, of course - that frequency is in the visible range, at $620\\:\\mathrm{nm}$ - so you need to rescale some things, but it's the essentials that matter.\nIt's important to note that, while this is a bit of a roundabout way to define a current standard, it does not depend on any additional standards beyond the second. It looks like it depends on the Planck constant $h$, but as long as the Josephson and von Klitzing constants are varied accordingly then this definition of the current does not actually depend on $h$.\nFinally, it is also important to remark that as far as precision metrology goes, the redefinition will change relatively little, and in fact it represents a conceptual simplification of how accurate standards are currently implemented. For example, NPL is quite upfront in stating that, in the current metrological chain,\n\nAll electrical measurements below 10 MHz at NPL are traceable to two quantum standards: the quantum Hall effect (QHE) resistance standard and the Josephson voltage standard (JVS).\n\nThat is, modern practical electrical metrology has essentially been implementing conventional electrical units all along - units based on fixed 'conventional' values of $K_J$ and $R_K$ that were set in 1990, denoted as $K_{J\\text{-}90}$ and $R_{K\\text{-}90}$ and which have the fixed values $K_{J\\text{-}90} = 483.597\\,9\\:\\mathrm{THz/V}$ and $R_{K\\text{-}90} = 25\\,812.807\\:\\Omega$. The new SI will actually heal this rift, by providing a sounder conceptual foundation to the pragmatic metrological approach that is already in use.\nThe kilogram\nThe kilogram is also getting a complete re-working. The current kilogram - the mass $M_\\mathrm{IPK}$of the international prototype kilogram - has been drifting slightly for some time, for a variety of reasons. A physical-constant-based definition (as opposed to an artefact-based definition) has been desired for some time, but only now does technology really permit a constant-based definition to work as an accurate standard.\nThe kilogram, as mentioned in the question, is defined so that the Planck constant $h$ has a fixed value of (roughly) $6.626\\,069\\times 10^{\u221234}\\:\\mathrm{kg\\:m^2\\:s^{-1}}$, so as such the SI kilogram will depend on the second and the meter, and will require standards for both to make a mass standard. (In practice, since the meter depends directly on the second, one only needs a time standard, such as a laser whose wavelength is known, to make this calibration.)\nThe current proposed mise en pratique for the kilogram contemplates two possible implementations of this standard, of which the main is via a watt balance. This is a device which uses magnetic forces to hold up the weight to be calibrated, and then measures the electrical power it's using to determine the weight. For an interesting implementation, see this LEGO watt balance built by NIST. \nTo see how these devices can work, consider the following sketch, with the \"weighing mode\" on the right.\n\nImage source: arXiv:1412.1699. Good place to advertise their facebook page.\nHere the weight is attached to a circular coil of wire of length $L$ that is immersed in a magnetic field of uniform magnitude $B$ that points radially outwards, with a current $I$ flowing through the wire, so at equilibrium\n$$mg=F_g=F_e=BLI.$$\nThis gives us the weight in terms of an electrical measurement of $I$ - except that we need an accurate value of $B$. This can be measured by removing the weight and running the balance on \"velocity mode\", shown on the left of the figure, by moving the plate at velocity $v$ and measuring the voltage $V=BLv$ that this movement induces. The product $BL$ can then be cancelled out, giving the weight as\n$$mg=\\frac{IV}{v},$$\npurely in terms of electrical and dynamical measurements. (This requires a measurement of the local value of $g$, but that is easy to measure locally using length and time standards.)\nSo, on one level, it's great that we've got this nifty non-artefact balance that can measure arbitrary weights, but how come it depends on electrical quantities, when the new SI kilogram is meant to only depend on the kinematic standards for length and time? As noted in the question, this requires a bit of reshuffling in the same spirit as for the ampere. In particular, the Josephson effect gives a natural voltage standard and the quantum Hall effect gives a natural resistance standard, and these can be combined to give a power standard, something like\n\nthe power dissipated over a resistor of conductance $G=25\\,812. 807\\,557G_0$ by a voltage that will produce AC current of frequency $483.597\\,890\\,893\\:\\mathrm{THz}$ when it is applied to a Josephson junction\n\n(with the same caveats on the actual numbers as before) and as before this power will actually be independent of the chosen value of $e$ as long as $K_J$ and $R_K$ are changed appropriately. \nGoing back shortly to our NIST-style watt balance, we're faced with measuring a voltage $V$ and a current $I$. The current $I$ is most easily measured by passing it through some reference resistor $R_0$ and measuring the voltage $V_2=IR_0$ it creates; the voltages will then produce frequencies $f=K_JV$ and $f_2=K_JV_2$ when passed over Josephson junctions, and the reference resistor can be compared to a quantum Hall standard to give $R_0=rR_K$, in which case \n$$\nm\n=\\frac{1}{rR_KK_J^{2}}\\frac{ff_2}{gv}\n=\\frac{h}{4}\\frac{ff_2}{rgv},\n$$\ni.e. a measurement of the mass in terms of Planck's constant, kinematic measurements, and a resistance ratio, with the measurements including two \"artefacts\" - a Josephson junction and a quantum Hall resistor - which are universally realizable.\nThe Mole\nThe mole is has always seemed a bit of an odd one to me as a base unit, and the redefined SI makes it somewhat weirder. The old definition reads\n\nThe mole is the amount of substance of a system which contains as many elementary entities as there are atoms in $12\\:\\mathrm{g}$ of carbon 12\n\nwith the caveat that\n\nwhen the mole is used, the elementary entities must be specified and may be atoms, molecules, ions, electrons, other particles, or specified groups of such particles.\n\nThe mole is definitely a useful unit in chemistry, or in any activity where you measure macroscopic quantities (such as energy released in a reaction) and you want to relate them to the molecular (or other) species you're using, in the abstract, and to do that, you need to know how many moles you were using.\nTo a first approximation, to get the number of moles in a sample of, say, benzene ($\\mathrm{ {}^{12}C_6H_6}$) you would weigh the sample in grams and divide by $12\\times 6+6=78$. However, this fails because the mass of each hydrogen atom is bigger than $1/12$ of the carbon atoms by about 0.7%, mostly because of the mass defect of carbon. This would make amount-of-substance measurements inaccurate beyond their third significant figure, and it would taint all measurements based on those.\nTo fix that, you invoke the molecular mass of the species you're using, which is in turn calculated from the relative atomic mass of its components, and that includes both isotopic effects and mass defect effects. The question, though, is how does one measure these masses, and how accurately can one do so? \nTo determine that the relative atomic mass of ${}^{16}\\mathrm O$ is $15.994\\,914\\, 619\\,56 \\:\\mathrm{Da}$, for example, one needs to get a hold of one mole of oxygen as given by the definition above, i.e. as many oxygen atoms as there are carbon atoms in $12\\:\\mathrm g$ of carbon. This one is relatively easy: burn the carbon in an isotopically pure oxygen atmosphere, separate the uncombusted oxygen, and weigh the resulting carbon dioxide. However, doing this to thirteen significant figures is absolutely heroic, and going beyond this to populate the entire periodic table is obviously going to be a long exercise in bleeding accuracy to long chemical metrology traceability chains.\nNow, as it happens, there can in fact be more accurate ways to do this, and they are all to do with the Avogadro project: the creation of a shiny sphere of silicon with a precisely determined number of ${}^{28}\\mathrm{Si}$ atoms. This is done by finding the volume (by measuring the diameter, and making sure that the sphere is really round via optical interferometry), and by finding out the spacing between individual atoms in the crystal. The cool part happens in that last bit, because the spacing is found via x-ray diffraction measurements, and those measure naturally not the spacing but instead the constant\n$$\\frac{h}{m({}^{28}\\mathrm{Si})}$$\nwhere $h$ is Planck's constant. And to top this up, the $h/m(X)$ combination can be measured directly, for example by measuring the recoil shift in atomic spectroscopy experiments (as reported e.g. here). \nThis then lets you count the number of silicon atoms in the sphere without weighing it, or alternatively it lets you measure the mass of the sphere directly in terms of $h$ (which is itself measured via the prototype kilogram). This gives a mise en pratique of the new SI kilogram (where the measured value of $h$ is replaced by its new, fixed value) but that one seems rather impractical to me. \nMore importantly, though, this gives you a good determination of the Avogadro constant: the number $N_A$ of elementary entities in a mole. And this is what enables you to redefine the mole directly as $N_A$ elementary entities, with a fixed value for $N_A$, while keeping a connection to the old standard: by weighing the silicon sphere you can measure the relative atomic mass of silicon, and this connects you back to the old chemical-metrological chain of weighing different species as they react with each other.\nIn addition to that, a fixed value of $N_A$ enables a bunch of ways to measure the amount of substance by coupling it with the newly-fixated values of other constants, which are detailed in the proposed mises en pratique.\n\nFor example, you can couple it with $e$ to get the exactly-known value of the electrical charge of one mole of electrons, $eN_A$, and then do electrolysis experiments against a current standard to get accurate counts on electrons and therefore on the aggregated ions.\nAlternatively, you can phrase the ideal gas law as $pV=nRT=n(N_Ak_B)T$ and use the newly-fixed value of the Boltzmann constant (see below) and a temperature measurement to get a fix on the number of moles in the chamber.\nMore directly, the number $n$ of moles of a substance $\\mathrm X$ in a high-purity sample of mass $m$ can still be determined via $$n=\\frac{m}{Ar(\\mathrm X)M_u}$$ where $Ar(\\mathrm X)$ is the relative mass of the species (determined as before, by chemical means, but unaffected because it's a mass ratio) and $$M_u=m_uN_A$$ is the molar mass constant, which ceases to be fixed and obtains the same uncertainty as $m_u$, equal to $1/12$ of the mass of $N_A$ carbon-12 atoms.\n\nAs to the dependency of the standards, it's clear that the mole depends only on the chosen value of $N_A$. However, to actually implement it one needs a bunch of additional technology, which brings in a whole host of metrological issues and dependence on additional standards, but which ones come in depends exactly on which way you want to measure things.\nFinally, in terms of why the mole is retained as a dimensional base unit - I'm personally even more lost than before. Under the new definition, saying \"one mole of X\" is exactly equivalent to saying \"about 602,214,085 quadrillion entities of X\", saying \"one joule per mole\" is the same as \"one joule per 602,214,085 quadrillion particles\", and so on, so to me it feels like the radian and the steradian: a useful unit, worth its salt and worthy of SIness, but still commensurate with unity. But BIPM probably have their reasons.\nThe kelvin\nContinuing with the radical do-overs, the kelvin gets completely redefined. Originally defined, in the current SI, as $1/273.16$ of the thermodynamic temperature $T_\\mathrm{TPW}$ of the triple point of water, in the new SI the kelvin will be defined by fixing the value of the Boltzmann constant to (roughly)  $k_B=1.380\\,6\\times 10^{-23}\\mathrm{J/K}$.\nIn practice, the shift will be mostly semantic in many areas. At reasonable temperatures near $T_\\mathrm{TPW}$, for example, the proposed mises en pratique state that\n\nThe CCT is not aware of any thermometry technology likely to provide a significantly improved uncertainty on $T_\\mathrm{TPW}$. Consequently, there is unlikely to be any change in the value of $T_\\mathrm{TPW}$ in the foreseeable future. On the other hand, the reproducibility of $T_\\mathrm{TPW}$, realised in water triple point cells with isotopic corrections applied, is better than $50\\:\\mathrm{\u00b5K}$. Experiments requiring ultimate accuracy at or close to $T_\\mathrm{TPW}$ will continue to rely on the reproducibility of the triple point of water.\n\nIn other words, nothing much changes, except a shift in the uncertainty from the determination of $k_B$ to the determination of $T_\\mathrm{TPW}$. It seems that this currently the case across the board of  temperature ranges, and the move seems to be to future-proof against the emergence of accurate primary thermometers, defined as follows:\n\nPrimary thermometry is performed using a thermometer based on a well-understood physical system, for which the equation of state describing the relation between thermodynamic temperature $T$ and other independent quantities, such as the ideal gas law or Planck's equation, can be written down explicitly without unknown or significantly temperature-dependent constants. \n\nSome examples of this are\n\nacoustic gas thermometry, where the speed of sound $u$ in a gas is related to the average mass $m$ and the heat capacity ratio $\\gamma$ as $u^2=\\gamma k_BT/m$, so characterizing the gas and measuring the speed of sound yields the thermodynamic temperature, or\nradiometric thermometry, using optical pyrometers and Planck's law to deduce the temperature of a body from its blackbody radiation.\n\nBoth of these are direct measurements of $k_BT$, and therefore yield directly the temperature in the new kelvin. However, the latter is the only standard in use in ITS-90, so it seems that the only direct effect of the shift is that pyrometers no longer need to be calibrated against temperature sources.\nSince the definition depends on the joule, the new kelvin obviously depends on the full dynamical MKS triplet. Metrologically, of course, matters are much more complicated - thermometry is by far the hardest branch of metrology, and it leans on a huge range of technologies and systems, and on a bunch of empirical models which are not entirely understood.\nThe candela\nThankfully, the candela remains completely untouched. Given that it depends on the radiated power of the standard candle, it depends on the full dynamical MKS triplet. I do want to take this opportunity, however, to remark that the candela has full rights to be an SI base unit, as I've explained before. The definition looks very innocuous:\n\nThe candela, symbol $\\mathrm{cd}$, is the SI unit of luminous intensity in a given direction. It is defined by taking the fixed numerical value of the luminous efficacy $K_\\mathrm{cd}$ of monochromatic radiation of vacuum wavelength $555\\:\\mathrm{nm}$ to be $K_\\mathrm{cd}=683\\:\\mathrm{cd/(W\\:sr^{-1})}$.\n\nHowever, the thing that slips past most people is that luminous intensity is as perceived by a (standardized) human eye,  ditto for luminous efficacy, and more generally that photometry and radiometry are very different beasts. Photometric quantities require access to a human eye, in the same way that dynamical quantities like force, energy and power are inaccessible to kinematical measurements that only implement the meter and the second.\n\nFurther reading\n\nThe current SI seen from the perspective of the proposed New SI. Barry N Taylor. J. Res. Natl. Inst. Stand. Technol. 116, 797-807 (2011); NIST eprint.", "meta": {"post_id": 147433, "input_score": 70, "output_score": 69, "post_title": "What are the proposed realizations in the New SI for the kilogram, ampere, kelvin and mole?"}}
{"input": "Is it possible to melt diamond? And if possible while let it cool will it became diamond again?", "output": "While I agree in principle with David Lynch's answer, I think it's good to take a closer look at the phase diagram (adapted from http://upload.wikimedia.org/wikipedia/commons/4/46/Carbon_basic_phase_diagram.png):\n\nI added the arrows to show possible paths you might follow.\nRed path: diamond would become graphite before melting; the molten carbon becomes diamond just above 10 GPa, and you cool it down while maintaining the pressure. Once the diamond is cool enough it can be depressurised slowly without changing phase (the hashed region has to be traversed carefully).\nBlue path: if you just heat your diamond, it will turn to graphite and then vaporize (sublimate) around 4000 K.\nThe green path shows the only \"sure\" way to melt diamond - starting at a very high pressure, then raising the temperature; above 5000 K one could either continue raising the temperature, or lower the pressure.\nNote that there is a real problem with doing this - there are no containers that I know of that will allow that combination of temperature and pressure to be maintained. Synthetic diamonds have been made, but typically not by growing from the melt...", "meta": {"post_id": 147896, "input_score": 21, "output_score": 43, "post_title": "Melting diamond and cool down as diamond"}}
{"input": "According to the Wikipedia page on Galaxy Types, there are four main kinds of galaxies:\n\nSpirals - as the name implies, these look like huge spinning spirals with curved \"arms\" branching out\nEllipticals - look like a big disk of stars and other matter\nLenticulars - those that are somewhere in between the above two\nIrregulars - galaxies that lack any sort of defined shape or form; pretty much everything else\n\nNow, from what I can tell, these all appear to be 2D, that is, each galaxy's shape appears to be confined within some sort of invisible plane. But why couldn't a galaxy take a more 3D form?\nSo why aren't there spherical galaxies (ie: the stars and other objects are distributed within a 3D sphere, more or less even across all axes)? Or if there are, why aren't they more common?", "output": "This whole question is a mistaken premise. There are spherical (or at least nearly spherical) galaxies! They fall into two basic categories - those elliptical galaxies that are pseudo-spherical in shape and the much smaller, so-called \"dwarf spheroidal galaxies\" that are found associated with our own Galaxy and other large galaxies in the \"Local Group\". \nOf course when you look at a galaxy on the sky it is just a two dimensional projection of the true distribution, but one can still deduce (approximate) sphericity from the surface brightness distribution and large line of sight velocity distribution for many ellipticals and dwarf spheroidals.\nDwarf spheroidal galaxies may actually be the most common type of galaxy in the universe.\nThese galaxies are roughly spherical because the stars move in orbits with quite random orientations, many on almost radial (highly eccentric) orbits with no strongly preferred axes. The velocity dispersion is usually much bigger than any rotation signature.\nThere is an excellent answer to a related question at Why the galaxies form 2D planes (or spiral-like) instead of 3D balls (or spherical-like)?\nPretty pictures:\nUK Schmidt picture of the Sculptor dwarf spheroidal galaxy (credit: David Malin, AAO)\n\nThe E0 elliptical galaxy M89 (credit Sloan Digitized Sky Survey).\n\nDetails: I have found a couple of papers that put some more flesh onto the argument that many elliptical galaxies are close-to spherical. These papers are by Rodriquez & Padilla (2013) and Weijmans et al. (2014). Both of these papers look at the distribution of apparent ellipticities of galaxies in the \"Galaxy Zoo\" and the Sloan Digitized Sky Surveys respectively. Then, with a statistical model and with various assumptions (including that galaxies are randomly oriented), they invert this distribution to obtain the distribution of true ellipticity $\\epsilon = 1- B/A$ and an oblate/prolate parameter $\\gamma = C/A$, where the three axes of the ellipsoid are $A\\geq B \\geq C$. i.e. It is impossible to say whether a circular looking individual galaxy seen in projection is spherical, but you can say something about the distribution of 3D shapes if you have a large sample.\nRodriguez & Padilla conclude that the mean value of $\\epsilon$ is 0.12 with a dispersion of about 0.1 (see picture below), whilst $\\gamma$ has a mean of 0.58 with a broader (Gaussian) dispersion of 0.16, covering the whole range from zero to 1. Given that $C/A$ must be less than $B/A$ by definition, this means many ellipticals must be very close to spherical (you cannot say anything is exactly spherical), though the \"average elliptical\" galaxy is of course not.\nThis picture shows the observed distribution of 2D ellipticities for a large sample of spiral and elliptical galaxies. The lines are what you would predict to observe from the 3D shape distributions found in the paper.\n\nThis picture from Rodriguez and Padilla show the deduced true distributions of $\\epsilon$\nand $\\gamma$. The solid red line represents ellipticals. Means of the distributions are shown with vertical lines. Note how the dotted line for spirals has a much smaller $\\gamma$ value - because they are flattened.\n\nWeijmans et al. (2014) perform similar analyses, but they split their elliptical sample into those that have evidence for significant systematic rotation and those that don't. As you might expect, the rotating ones look more flattened and \"oblate\". The slow-rotating ones can also be modelled as oblate galaxies, though are more likely to be \"tri-axial\". The slow rotators have an average $\\epsilon$ of about 0.15 and average $\\gamma$ of about 0.6 (in good agreement with Rodriguez & Padilla), but the samples are much smaller.", "meta": {"post_id": 148418, "input_score": 47, "output_score": 113, "post_title": "Why aren't there spherical galaxies?"}}
{"input": "They seem to have increased friction after going through a dishwasher. The unpleasant (to me) squeaky feel is probably slip-stick friction exciting resonance in the glassware. But why? What has happened to the surface of the glass to make it like this?", "output": "A completely clean silica surface has a very high surface energy and a very high coefficient of friction. However silica surfaces adsorb pretty much anything at the least excuse, so glassware from your cupboard will have a layer of various molecules adsorbed from its environment, and this greatly reduces the coefficient of friction.\nDishwash powder is pretty aggressive, which is not surprising when you consider what it has to wash off. In my time working in the industry the powders used high concentrations of sodium and potassium hydroxide and would not only strip the glass clean but actually dissolve off a layer of glass as well. I believe current dishwash powders are less aggressive (not least for safety considerations!) but they will still leave the glass surface very clean and hence very high friction.", "meta": {"post_id": 148953, "input_score": 46, "output_score": 69, "post_title": "Why are dishwasher washed glasses \"squeaky clean\"?"}}
{"input": "In this YouTube video, a dry cell battery, a wound copper wire and a few magnets (see image below) are being used to create what can be described as \"train\". It looks fascinating but how does this experiment work?\nUpdate 8th August 2016: This problem has been completely worked out in a paper that was published in the January 2016 issue of American Journal of Physics.\n\nLink: Am. J. Phys. 84, 21 (2016); http://dx.doi.org/10.1119/1.4933295", "output": "That's a nice video - good find :-)\nIf you run a current through a coil; it generates an magnetic field inside the coil like this:\n\n(Image from the Hyperphysics site.)\nIf the field lines are exactly parallel a bar magnet will feel no net force. However at the ends of the coil, where the field lines diverge, a bar magnet will be either pulled into the coil or pushed out of the coil depending on which way round you insert it.\nThe trick in the video is that the magnets are made of a conducting material and they connect the battery terminals to the copper wire, so the battery, magnets and copper wire make a circuit that generates a magnet field just in the vicinity of the battery. The geometry means the two magnets are automatically at the ends of the generated magnetic field, where the field is divergent, so a force is exerted on the magnets.\nThe magnets have been carefully aligned so the force on both magnets points in the same direction, and the result is that the magnets and battery move. But as they move, the magnetic field moves with them and you get a constant motion.\nIf you flipped round the two magnets at the ends of the battery the battery and magnets would move in the reverse direction. If you flipped only one magnet the two magnets would then be pulling/pushing in opposite directions and the battery wouldn't move.", "meta": {"post_id": 150033, "input_score": 53, "output_score": 51, "post_title": "How does this \"simple\" electric train work?"}}
{"input": "The general equation for the force of friction (static or kinetic) is $F_f = \\mu * F_N$, where $F_f$ is the force of friction and $\\mu$ is the coefficient of friction (its value is dependent upon the surfaces interacting on each other).\nWhy is it that this equation is so simple and does not contain any other variables that account for the force of friction on an object? Does anyone know how this equation was developed?", "output": "It's so simple because it's only a first order approximation model to how friction actually works.\nThere are several other models, but to use them you usually need more parameters or other pieces of information about the system (for example, if there are fluid lubricants involved, the pattern of the surface, the materials involved, etc).\nThe model $F_f = \\mu F_N$ is called Coulomb model of friction. It assumes 3 important laws:\n 1. Amonton's first law of friction\n\nThe magnitude of the friction force is independent of the area of contact.\n\n\nThis law dates back to Leonardo da Vinci:\n\n 2. Amonton's second law of friction\n\nThe magnitude of the friction force is proportional to the magnitude of the normal force.\n\nHere is an example of experimental data showing the dependence of friction with normal force:\n\nThe slope gives the friction coefficient: $\\mu = F_f/F_N$.\nThis also dates back to Leonardo da Vinci, who noticed that if the load of an object was doubled, its friction would also be doubled.\n 3. Coulomb's law of friction\n\nThe kinetic friction is independent of the sliding velocity.\n\nThis is only somewhat true for small changes in velocity. Some models account for this dependence:\n\na) Coulomb model (without static friction)\nb) Coulomb model + viscosity (without static friction)\nc) Coulomb model + viscosity\nd) Coulomb model + viscosity + Stribeck effect\n\nLimitations\nHere is an example of experimental data showing the dependence of friction with velocity:\n\nHere is an example showing non linearity with respect to the normal force:\n\nThe author comments on the graph above:\n\nWhat\u2019s going on here? Let\u2019s look at the data for the teflon (the blue data). I fit a linear function to the first 4 data points and you can see it is very linear. The slope of this line gives a coefficient of static friction with a value of 0.235. However, as I add more and more mass to the friction box, the normal force keeps increasing but the friction force doesn\u2019t increase as much. The same thing happens for friction box with felt on the bottom.\nThis shows that the \u201cstandard\u201d friction model is just that \u2013 a model. Models were meant to be broken.\n\nHere is another simple article about the limitations of the Coulomb model of friction.", "meta": {"post_id": 154443, "input_score": 54, "output_score": 73, "post_title": "Why is the equation for friction so simple?"}}
{"input": "Would this be because tidal deceleration causing the Earth to spin faster or are there other actions in play that I haven't considered? Would the Earth even spin faster because of the tidal deceleration?", "output": "Suppose the Moon didn't orbit the Earth at all, so it just stayed at some fixed point while the Earth rotated underneath it:\n\nIn this case every point on the equator would pass directly under the Moon every 24 hours, and we'd get a high tide every 24 hours. (There's another high tide when we're exactly on the opposite side of the earth to the moon, but let's ignore that for now.)\nBut the Moon does orbit the Earth in a prograde orbit, and that means after 24 hours the Earth has revolved once but the Moon has also moved on a bit:\n\nSo to get directly under the Moon again takes a bit longer than 24 hours. From memory it's about 45 minutes longer, so the interval between every two high tides is about 24 hours and 45 minutes.\nNow suppose the Moon moved in a retrograde orbit:\n\nThis time as you're revolving around with the Earth the Moon moves towards you, so it takes about 45 minutes less to get directly under the Moon again. If the Moon were in a retrograde orbit every two high tides would be separated by about 23 hours and 15 minutes.\nThat's why tides would be more frequent if the Moon were in a retrograde orbit. The diffrence between the prograde and retrograde orbit tide timings is about 90 minutes per 24 hours, which is about 7%. That's where your teacher gets the 7% figure from.", "meta": {"post_id": 154700, "input_score": 18, "output_score": 46, "post_title": "I was told that if the Moon had a retrograde orbit, tides would have a faster rhythm. Why is that?"}}
{"input": "Consider this picture of sun beams streaming onto the valley through the clouds.\n\nGiven that the valley is only (at a guess) 3km wide, with simple trigonometry and the angles of the beams, this gives the result that the position of the light source is being a few tens of km away at most. \nWhat is wrong with the analysis?", "output": "In addition to the excellent answers already given, here is another famous picture of an anticrepuscular ray (or better: shadow). It is not a coincidence that the shadow of the plume extends almost exactly towards the full moon. It is a consequence of the Sun, Earth and full Moon being almost aligned. So all shadows must point towards the moon at such a moment.\nJust imagine what a picture would look like with a second shuttle starting a bit more towards the right... a \"V\" shape with the Moon at the corner...\n\nImage credit: NASA, Pat McCracken.\nThis also was once the Astronomy Picture of the Day, where you can find some extra explanation.", "meta": {"post_id": 154951, "input_score": 168, "output_score": 53, "post_title": "Why do sunbeams diverge even though the sun is much more than a few kilometers away?"}}
{"input": "Hilbert space and rays:\nIn a very general sense, we say that quantum states of a quantum mechanical system correspond to rays in the Hilbert space $\\mathcal{H}$, such that for any $c\u2208\u2102$ the state $\\psi$ and $c\\psi$ map to the same ray and hence are taken as equivalent states.\n\nHow should one interpret the above in order to understand why $\\psi$ and $c\\psi$ are the same states? Clearly for $c= 0$ it doesn't hold, and for $c=1$ it is trivial, but why should this equivalence hold for any other $c$?\nKnowing Hilbert space is a complex vector space with inner product, is ray just another way of saying vectors?\nIn the case that $c$ just corresponds to a phase factor of type $e^{i\\phi}$ with $\\phi \\in \\mathbb{R},$ then obviously $|\\psi|=|e^{i\\phi}\\psi|,$ i.e. the norms didn't change, then what is the influence of $e^{i\\phi}$ at all? In other words what does the added phase of $\\phi$ to the default phase of $\\psi$ change in terms of the state of the system? \n\nProjective Hilbert space:\nFurthermore, through a process of projectivization of the Hilbert space $\\mathcal{H},$ it is possible to obtain a finite dimensional projective Hilbert space $P(\\mathcal{H}).$ In the Projective Hilbert space, every point corresponds to a distinct state and one cannot talk in terms of rays anymore.\n\nWhat does such projectivization entail in a conceptual sense? I guess in other words, how are rays projected to single points in the process? and what implies the distinctness? Is such process in any way analogous to the Gram\u2013Schmidt process used to orthonormalise a set of vectors in linear algebra?\nWhen one limits the Hilbert space to that of a certain observable of the system at hand, e.g. momentum or spin space (in order to measure the momentum and spin of a system respectively), does that mean we're talking about projective spaces already? (e.g. is the spin space spanned by up $\\left|\\uparrow\\rangle\\right.$ and down $\\left|\\downarrow\\rangle\\right.$ spins states of a system referred to as projective spin Hilbert space?)\n\nThe aim is to develop a better and clearer understanding of such fundamental concepts in quantum mechanics.", "output": "Why are states rays?\n(Answer to OP's 1. and 2.)\nOne of the fundamental tenets of quantum mechanics is that states of a physical system correspond (not necessarily uniquely - this is what projective spaces in QM are all about!) to vectors in a Hilbert space $\\mathcal{H}$, and that the Born rule gives the probability for a system in state $\\lvert \\psi \\rangle$ to be in state $\\lvert \\phi \\rangle$ by\n$$ P(\\psi,\\phi) = \\frac{\\lvert\\langle \\psi \\vert \\phi \\rangle \\rvert^2}{\\lvert \\langle \\psi \\vert \\psi \\rangle \\langle \\phi \\vert \\phi \\rangle \\rvert}$$\n(Note that the habit of talking about normalised state vectors is because then the denominator of the Born rule is simply unity, and the formula is simpler to evaluate. This is all there is to normalisation.)\nNow, for any $c \\in \\mathbb{C} - \\{0\\}$, $P(c\\psi,\\phi) = P(\\psi,c\\phi) = P(\\psi,\\phi)$, as may be easily checked. Therefore, especially $P(\\psi,\\psi) = P(\\psi,c\\psi) = 1$ holds, and hence $c\\lvert \\psi \\rangle$ is the same states as $\\lvert \\psi \\rangle$, since that is what having probability 1 to be in a state means.\nA ray is now the set of all vectors describing the same state by this logic - it is just the one-dimensional subspace spanned by any of them: For $\\lvert \\psi \\rangle$, the associated ray is the set\n$$ R_\\psi := \\{\\lvert \\phi \\rangle \\in \\mathcal{H} \\vert \\exists c \\in\\mathbb{C}: \\lvert \\phi \\rangle = c\\lvert \\psi \\rangle \\}$$\nAny member of this set will yield the same results when we use it in the Born rule, hence they are physically indistiguishable.\nWhy are phases still relevant?\n(Answer to OP's 3.)\nFor a single state, a phase $\\mathrm{e}^{\\mathrm{i}\\alpha},\\alpha \\in \\mathbb{R}$ has therefore no effect on the system, it stays the same. Observe, though, that \"phases\" are essentially the dynamics of the system, since the Schr\u00f6dinger equation tells you that every energy eigenstate $\\lvert E_i \\rangle$ evolves with the phase $\\mathrm{e}^{\\mathrm{i}E_i t}$.\nObviously, this means energy eigenstates don't change, which is why they are called stationary states. The picture changes when we have sums of such states, though: $\\lvert E_1 \\rangle + \\lvert E_2 \\rangle$ will, if $E_1 \\neq E_2$, evolve differently from an overall multiplication with a complex phase (or even number), and hence leave its ray in the course of the dynamics! It is worthwhile to convince yourself that the evolution does not depend on the representant of the ray we chose: For any non-zero complex $c$, $c \\cdot (\\lvert E_1 \\rangle + \\lvert E_2 \\rangle)$ will visit exactly the same rays at exactly the same times as any other multiple, again showing that rays are the proper notion of state.\nThe projective space is the space of rays\n(Answer to OP's 4. and 5. as well as some further remarks)\nAfter noting, again and again, that the physically relevant entities are the rays, and not the vectors themselves, one is naturally led to the idea of considering the space of rays. Fortunately, it is easy to construct: \"Belonging to a ray\" is an equivalence relation on the Hilbert space, and hence can be divided out in the sense that we simply say two vectors are the same object in the space of rays if they lie in the same ray - the rays are the equivalence classes. Formally, we set up the relation\n$$ \\psi \\sim \\phi \\Leftrightarrow \\psi \\in R_\\phi$$\nand define the space of rays or projective Hilbert space to be\n$$ \\mathcal{P}(\\mathcal{H}) := (\\mathcal{H} - \\{0\\}) / \\sim$$\nThis has nothing to do with the Gram-Schmidt way of finding a new basis for a vector space! This isn't even a vector space anymore! (Note that, in particular, it has no zero) The nice thing is, though, that we can now be sure that every element of this space represents a distinct state, since every element is actually a different ray.1\n(Side note (see also orbifold's answer): A direct, and important, consequence is that we need to revisit our notion of what kinds of representations we seek for symmetry groups - initially, on the Hilbert space, we would have sought unitary representations, since we want to preserve the vector structure of the space as well as the inner product structure (since the Born rule relies on it). Now, we know it is enough to seek projective representations, which are, for many Lie groups, in bijection to the linear representations of their universal cover, which is how, quantumly, $\\mathrm{SU}(2)$ as the \"spin group\" arises from the classical rotation group $\\mathrm{SO}(3)$.)\nOP's fifth question\n\nWhen one limits the Hilbert space to that of a certain observable of the system at hand, e.g. momentum or spin space (in order to measure the momentum and spin of a system respectively), does that mean we're talking about projective spaces already? (e.g. is the spin space spanned by up |\u2191\u27e9 and down |\u2193\u27e9 spins states of a system referred to as projective spin Hilbert space?)\n\nis not very well posed, but strikes at the heart of what the projectivization does for us: When we talk of \"momentum space\" $\\mathcal{H}_p$ and \"spin space\" $\\mathcal{H}_s$, it is implicitly understood that the \"total space\" is the tensor product $\\mathcal{H}_p \\otimes \\mathcal{H}_s$. That the total/combined space is the tensor product and not the ordinary product follows from the fact that the categorial notion of a product (let's call it $\\times_\\text{cat}$) for projective spaces is\n$$ \\mathcal{P}(\\mathcal{H}_1) \\times_\\text{cat} \\mathcal{P}(\\mathcal{H}_2) = \\mathcal{P}(\\mathcal{H}_1\\otimes\\mathcal{H}_2)$$\nFor motivations why this is a sensible notion of product to consider, see some other questions/answers (e.g. this answer of mine or this question and its answers).\nLet us stress again that the projective space is not a vector space, and hence not \"spanned\" by anything, as the fifth question seems to think.\n\n1The inquiring reader may protest, and rightly so: If our description of the system on the Hilbert space has an additional gauge symmetry, it will occur that there are distinct rays representing the same physical state, but this shall not concern us here.", "meta": {"post_id": 156907, "input_score": 40, "output_score": 38, "post_title": "Hilbert space vs. Projective Hilbert space"}}
{"input": "In my physics book after this solved example:\n\nA child of mass $m$ is initially at rest on top of a water slide at height h = 8.5m  above the bottom of the slide. Assuming that the slide is frictionless because of water, find the speed of the child at bottom of slide.\n\na comment was written:\n\nIf we were asked to find the time taken for the child to reach the bottom of the slide, methods would be of no use; we would need to know the shape of the slide and we would have a difficult problem.\n\nWhy does the author say that we would need to know the shape of the slide to find the time taken for the child to reach bottom of the slide? Can't we use Newton's first law of motion in uniform acceleration to find the time?\nwe can find velocity at bottom $v$ = $\\sqrt{2gh}$ = $13m/s$(approx)\nUsing first law $v = u + at$\n                $13 = 0 + 9.8t$\n                $t = 13/9.8$", "output": "Just for completeness, I'll explain how to obtain the time taken for an arbitrary curve.\nIf $h$ is the initial height of the child and $y$ the height once he has started falling. By energy conservation:\n$$mgh=mgy+\\frac{1}{2}mv^2\\implies v=\\sqrt{2g(h-y)}\\tag{1}\n$$\nWe know know the speed at any time. Let us denote the horizontal position as $x$.\nThe distance traveled in a very small time interval can be written as:\n$$ds=\\sqrt{dx^2+dy^2}=\\sqrt{1+\\left(\\frac{dx}{dy}\\right)^2}dy=\\sqrt{1+x'^2}dy$$\nSo the speed is:\n$$v=\\frac{ds}{dt}=\\sqrt{1+x'^2}\\frac{dy}{dt}$$\nInserting this equation into $(1)$ and integrating leads to:\n$$t=\\frac{1}{\\sqrt{2g}}\\int_0^s \\frac{\\sqrt{1+x'^2}}{\\sqrt{h-y}}dy $$\nThis integral gives you the time taken to reach the ground given any curve $y(x)$.\nFurthermore, it is possible to obtain such curve, the tautochrone, that time taken is independent of the initial point:\n\nImage source", "meta": {"post_id": 156943, "input_score": 42, "output_score": 38, "post_title": "Why do we need to know the shape of the slide to find the time to slide down it?"}}
{"input": "In a physics text book I read the following:\n\n$$e/m=1.758820150(44) \u00d710^{11} \\mathrm{C/kg} $$ \n  In this expression, $(44)$ indicates the likely uncertainty in the last two digits, $50$.\n\nHow should I understand this uncertainty? Does it mean $\\pm 44$ on the last two digits?", "output": "The digits in parentheses are the uncertainty, to the precision of the same number of least significant digits. (The meaning of the uncertainty is context-dependent but generally represents a standard deviation, or a 95% confidence interval.) So:\n$$e/m=1.758\\,820\\,1\\color{blue}{50}\\,\\color{magenta}{(44)}\u00d710^{11} \\ \\mathrm{C/kg}=\\left(1.758\\,820\\,1\\color{blue}{50}\u00d710^{11} \\pm 0.000\\,000\\,0\\color{magenta}{44}\u00d710^{11}\\right) \\ \\mathrm{C/kg}$$", "meta": {"post_id": 158589, "input_score": 26, "output_score": 38, "post_title": "Uncertainty in parenthesis"}}
{"input": "Why are emitters colored black better emitters than other colors?  Why is white a worse emitter?", "output": "Black is the best emitter because if something is black it means it's strongly coupled to the electromagnetic field.\nThermal radiation\nPhysical objects are surrounded by electromagnetic radiation.\nOne source of radiation is stars such as the sun.\nStars emit visible light, infrared radiation, and in fact a whole range of wavelengths.\nYou can see a plot of the spectrum of sunlight on Wikipedia.$^{[a]}$\nIt also turns out that matter itself emits radiation.\nBecause matter is at a nonzero temperature, the thermal \"motion\" of the atoms/molecules randomly causes them to jump to excited states, and when they jump down they can emit photons of electromagnetic radiation.\nThis is called thermal radiation.\nDifferent kinds of matter radiate their thermal energy away as electromagnetic radiation with different levels of efficiency.\nThis is roughly because the electron (or other) transitions in various materials are more or less strongly coupled to the electromagnetic field, and because different materials have more or less available transitions at each wave length.$^{[c]}$\nTherefore, for a given temperature, some materials emit their radiation faster than others.\nGood emitters are good absorbers\nNow here's the important part: materials which are good at emitting their thermal radiation are also good at absorbing incoming radiation.\nThis is actually not surprising: the process of absorbing an incoming photon is exactly the reverse of the process of emitting one, so if a material has lots of available transitions inside of it or transitions which are more strongly coupled to the electromagnetic field, then those transitions are available for both emission and absorption.\nAnd now we answer the question\nA material which is a very good absorber looks black because it absorbs all incoming light.\nWell that sounds convincing but if you think about it you would point out that I told you that good absorbers are also good emitters, so a good absorber should give off light too.\nIt shouldn't look black!\nThe key here is that it doesn't have to emit the photons at the same wavelength as it absorbs them.\nWhat generally happens is that after an e.g. visible photon comes in and gets absorbed, the energy is converted to heat, and it is later emitted by a thermal emission as described above.\nThis thermal emission may be in the infra-red range (for practical temperatures), which you can't see with your eyes.\nThat's why an object which is both a good absorber and a good emitter looks black when it's at thermal equilibrium near room temperature.$^{[d]}$\nNote that this means that black objects are actually radiating more power than white ones, you just can't easily tell because that power is in a wavelength you don't see.\nMore information\nA hypothetical object which perfectly absorbs all incoming radiation is called a black body.\nUsing quantum mechanics and statistical mechanics you can compute the amount of radiation power a black body at a given temperature should emit at each wavelength.$^{[b]}$\nInterestingly, if you look at the plot of the sun's emission, you see that it's pretty close to an ideal black body.\nEver notice that thermal blankets are shiny?\nShiny materials are weakly coupled to the electromagnetic field.\nThey're shiny precisely because they reflect incoming radiation instead of absorbing it.\nSince bad absorbers are bad emitters, this also means that when you wrap yourself in a shiny blanket you will radiate away your body heat more slowly, keeping you warmer in a cold environment.\nOf course, wearing a shiny blanket would also prevent you from warming up in the sun light.\nThe way to think about it is that the shiny thing isolates you from the surroundings: it prevents you from getting warmed by incoming radiation, and it keeps you from getting cold from outgoing radiation.\nThis is also why thermos bottles are shiny.\n$[a]$: Note that the peak radiation power from the sun is at around $500\\,\\text{nm}$ wavelength, which is right in the middle of the the visible spectrum. Coincidence?\n$[b]$: In fact, it was in trying to calculate the black body emission spectrum that folks realized that classical physics had problems. In classical physics the black body would radiate an infinite amount of power. Planck discovered that he could fix this by assuming the energy was quantized. By his own admission it was a total un-motivated hack at the time but it worked and was a major jumping-off point for quantum mechanics.\n$[c]$: For details simply refer to Fermi's Golden Rule.\n$[d]$: Of course, hotter objects look non-black colors. For example, if you heat up a piece of metal in the fire it may glow red.", "meta": {"post_id": 159856, "input_score": 30, "output_score": 43, "post_title": "Why is black the best emitter?"}}
{"input": "It is common in popular science culture to assume that Hawking radiation causes black holes to vaporize. And, in the end, the black hole would explode. I also remember it being mentioned in A Brief History of Time.\nWhy would a black hole explode? Why can't it gradually vanish to zero? What is the exact mechanism or theory which causes a black hole to explode?", "output": "The expression for the power emitted as Hawking radiation is\n$$ P = \\frac{\\hbar c^6}{15360 \\pi G^2 M^2} = 3.6\\times10^{32} M^{-2}\\ \\text{W} = -c^2 \\frac{dM}{dt},$$\nwhere the term on the far right hand side expresses the rate at which the black hole mass decreases due to the emission of Hawking radiation.\nYou can see that what happens is that the power emitted actually increases as $M$ decreases. At the same time, the rate at which the mass decreases also increases.\nSo as the black hole gets less massive, the rate at which it gets less massive increases rapidly and hence the power it emits increases very, very rapidly. \nBy solving this differential equation it can be shown that the time to evaporate to nothing is given by\n$$ t = 8.4\\times10^{-17} M^3\\ \\text{s},$$\nso for example a 100 tonne black hole would evaporate in $8.4 \\times10^{-2}\\ \\text{s}$, emitting approximately $E = Mc^2 = 9\\times 10^{21}$ joules of energy as it does so \u2013 equivalent to more than a million megatons of TNT. I guess you could call this an explosion!\nThis will be the fate of all evaporating black holes, but most will take a very long time to get to this stage (even supposing they do not accrete any matter).\nThe evaporation time is only less than the age of the universe for $M < $ a few $10^{11}\\ \\text{kg}$. A 1 solar mass black hole takes $2\\times10^{67}$ years to evaporate.\nEDIT: The Hawking radiation temperature is given by\n$$ kT = \\frac{\\hbar c^3}{8 \\pi GM}.$$\nUnless the temperature is well above the ambient temperature (at a minimum the cosmic microwave background temperature), the black hole will always absorb more energy than it radiates, and get bigger. i.e. to evaporate\n$$ \\frac{\\hbar c^3}{8 \\pi GM} > kT_{\\rm ambient}$$\n$$ M < \\frac{1.2\\times10^{23}}{T_{\\rm ambient}}\\ {\\rm kg}$$\nTherefore unless I've made a mistake, this proviso is of no practical importance other than for evaporating black holes (i.e. those with $M<10^{11}$ kg) in the early universe. \nThe temperature of a black hole goes as its evaporation timescale as $t_{\\rm evap}^{-1/3}$. The temperature of the early, radiation-dominated, universe scales as $t^{-1/2}$. Thus it appears to be the case that at some point in the past, a black hole that might have had an evaporation timescale shorter than the age of the universe is incapable of doing so.", "meta": {"post_id": 159937, "input_score": 30, "output_score": 51, "post_title": "Why would a black hole explode?"}}
{"input": "I have watched light sources such as incandescent lamps and other lamp sources; they have always made shadows. But a fluorescent lamp doesn't make any shadow. What is the reason behind the non-appearance of prominent shadow?", "output": "To complement Floris's answer, here's a quick animation showing how the shadow changes with the size of the light source.\nIn this animation, I've forced the intensity of the light to vary inversely with the surface area, so the total power output is constant ($P \\approx  62.83 \\, \\mathrm{W}$).\nThis is why the object (Suzanne) doesn't appear to get any brighter or darker, but the shadow sharpness does change:\n\nIn this scene, the spherical lamp is the only light source, except for the dim ambient lighting.\nThis makes the shadows very easily visible.\nIn a real-world scenario with other light sources (windows, for example), the effect would be less pronounced because the shadows would be more washed out.\nThe following animation shows the scenario Floris described, with a rotating long object:", "meta": {"post_id": 161406, "input_score": 85, "output_score": 234, "post_title": "Why don't fluorescent lights produce shadows?"}}
{"input": "A news story is going viral on social media networks claiming that two physicists have found a way to eliminate the Big Bang singularity, or in layman's terms (as claimed by many sensationalist news articles): The Big Bang never happened at all.\nThe paper was published in Phys. Lett. B, and it seems to me that the basic idea of the paper is that it takes the Raychaudhuri equation and replaces the geodesics with Bohmian trajectories (from Bohm's quantum analogue of the Hamilton-Jacobi equation). \nI do not hold any expertise in this area, but from whatever little I have understood (and as explained by a friend of mine, who may very well be wrong), if we do a few substitutions on this quantum Raychaudhuri equation, we would get the Friedmann equations with a few extra terms, one of which looks like a cosmological constant and another of which eliminates the Big Bang singularity. \nNow my question is: How legitimate are the claims of the authors of this paper? And if it holds any merit, does it really eliminate the Big Bang singularity?", "output": "I'm not a quantum cosmologist, but I am an early-universe cosmologist, so I can give you my opinion after having read this paper.\nThe article claims that Bohmian trajectories is a valid replacement for geodesics. This was claimed in the very beginning of the paper and not much is offered in the way of defense for this assumption. That's not to say that it's an invalid assumption, it's just that hands have been waved and they said \"Geodesics are not the trajectories you're looking for. You can use Bohmian trajectories. Move along.\"\nNext what they do is refer us to another few papers where slightly different problems have been approached using similar but slightly different methods and they say (not an actual quote) \"using a similar result to these works, and making arbitrary but not illegal substitutions, we recover the Friedman equations with higher order corrections\" That's all well and good, but did you actually do the work or did you pull the result from the similar yet different problems. And the substitutions you made make no sense.\nFrom here, the interpretations they offer are fairly evident. Using Bohmian trajectories has necessitated that there is no initial singularity. They also find the correct magnitude for a cosmological constant in one of the corrections because of how they approach it. There's a complicated term that involves unspecified real-valued functions and they replace this with things corresponding to the graviton mass that would be expected to give the current value of the cosmological constant. Then, they find though some fancy footwork and more \"convenient\" substitutions that the term would result in a cosmological constant that is related to $c^2/H_0^2$, which results in the correct order of magnitude.\nThey also show that with the Bohmian trajectories, the age of the universe tends toward infinity. What confused me here is that they used the standard method of calculating the age of the universe; the method that was designed for use with the Big Bang model. Essentially, they try to find the time since the singularity, but they automatically removed the singularity by using Bohmian trajectories. So it's obvious they should find infinity.\nNonetheless, all of the science presented in the paper is valid. The problem is that it relies so heavily on science not presented in the paper. If what they've done is correct, then the interpretations is also correct. However, there's altogether too much handwaving and unintuitive assumptions made for me to accept it without further study. And as said before, a lot of it seems to rely on similar but different approaches that were used to address similar but different problems by other physicists.\nThis is probably why the media has been able to go nuts with it. There's not enough in this paper to say it's wrong or to explicitly discredit it. There's also not enough to accept it or to use it to discredit other theories. The media sees it has the possibility of being right and that it has interpretations which don't include a Big Bang and they swarmed on it. But this paper doesn't say there wasn't a Big Bang; it says the Big Bang wasn't necessary. At best, this paper makes the possibility of no Big Bang equally likely as having a Big Bang.\nBut I don't want to sound overly pessimistic. My stance remains that if the assumptions they made are correct and if the work they did outside of their writings is correct, then the interpretations they present could be correct as well.", "meta": {"post_id": 164511, "input_score": 109, "output_score": 72, "post_title": "Why are some people are claiming that the Big Bang never happened?"}}
{"input": "That is may be an easy question, but I am not a professional. The Sun is a star, and when I look at the Sun it is usually yellow. Why are stars in the sky at night white?\nI suppose it could be due to their distance. What is the explanation?", "output": "It has more to do with physiology of the eye rather than the spectrum of light produced by stars.\nStars emit light over the full range of visible wavelengths. Hot stars emit more blue/violet light, cool stars emit more red light. The Sun is relatively neutral in that regard, so does not have a strong colouration, but many other stars in the sky have temperatures as low as 3,000K (should appear reddish) to 20,000K or more (should be blueish).\nHowever, light received by the eye has to be reasonably bright to trigger the colour sensitive cells (the cones). So whereas the Sun appears to be yellow(ish) (or to be more exact your eyes perceive the mix of wavelengths as yellowish), there are relatively few stars that are bright enough to look distinctly coloured. Betelgeuse is an example that most people see as reddish. Arcturus is distinctly orange (to me).\nBut fainter stars all appear white because they are mainly being seen by the rod cells in your eye, which are not very colour sensitive (and have no sensitivity to light at the extremes of red and blue). This is known as scotopic vision.\nAPPENDIX: I have found a few interesting links that appear to confirm this line of argument. Firstly, one can predict what stellar spectra would look like to the eye under conditions where the cone cells are operational. Here we can see that many stars would appear either pink (K-stars) through orange (M-stars). G-stars like the Sun are just off-white, whilst hot stars are distinctly blue (see also here).\nThese calculations do not include the effects of the Earth's atmosphere which preferentially absorb and scatter blue light. However, the effect of this on the colours cannot be that serious (it will have no effect at all on rod cells since they are not colour sensitive). Cone cells are sensitive over the range 450-650 nm. The typical atmospheric transmission at zenith for these wavelengths ranges from 85% to 93% (see Fig.1 of Burke et al. 2010), but would reduce to perhaps 70% to 85% for an object only 30 degrees above the horizon. Even at this low altitude, the differential effect is quite small. The colours of stars would not be changed by the atmosphere until they got quite close to the horizon. \nStars would have different colours, ranging from pale blue through to an orangey-red, if they were bright enough to excite the eye's cone cells.", "meta": {"post_id": 169969, "input_score": 40, "output_score": 82, "post_title": "Why are stars white?"}}
{"input": "The Andromeda galaxy is 2,538,000 light years away, so if we view Andromeda from a telescope, we see Andromeda how it was 2,538,000 years ago. Now the diameter of the visible universe is 92 billion light years so if we say that we are at the center so the radius is 46 billion light years. So, if we see the farthest we can from our point, that will be 46 billion light years, so it means that we have seen the universe how it was 46 billion years ago, so why can't we say that universe was born 46 billion years ago?\nAnd if still someone argues that 13.8 billion years ago universe was born then we should have seen the universe of how it was even before the singularity.\nAnd if my logic of 49 billion years seems right then the thing we say that universe was born 13.8 billion years ago should be wrong, shouldn't it?\nHoping for a excellent answer with excellent explanation! :)", "output": "There are two parts to your question. First, why can we see things \"46 billion light years away\" if the Universe is only about 13.8 billion years old? Because the Universe is expanding. How far does a photon travel in 13.8 billion years in an expanding Universe? It depends on the rate of expansion. I'll give a simplified example to illustrate the point: \nImagine a Universe that is 10 billion years old. Its expansion history is simple. It started out with size $R$, which remained constant for 5 billion years, then the size suddenly doubled to $2R$, and remained constant for another 5 billion years. So, after 10 billion years, how far is the photon from its starting point? Well, it travels 5 billion light years in the first 5 billion years. When the size of the Universe doubles, so does the space between it and its point of origin, so just after the doubling it is 10 billion light years from where it started. Then in the next 5 billion years it travels another 5 billion light years, ending 15 billion light years from where it started. Notice that the constant speed of light from special relativity comes through intact here - the photon ends 15 billion light years from where it started after 10 billion years, but always moves at speed $c$ and only \"travelled\" 10 billion light years. Obviously a sudden doubling of size is not realistic, but the same idea applies to a more gradual, smooth expansion. Note that the expansion does not necessarily need to be \"faster than light\" (whatever that means). Any expansion at all will mean that the photon will be further from its starting point than expected in a static Universe when it arrives.\nSecond part to your question: why can't we see the Big Bang? Because a photon cannot reach us directly from the Big Bang. On a sunny day, I can see the Sun clearly because most of its photons that I observe leave the solar surface and travel along unimpeded to reach me. If it's cloudy, there's still sunlight - solar photons are reaching me - but I can't see the Sun directly because the photons are scattered along the way by the clouds. The early Universe was \"cloudy\" - it was full of an ionized plasma that scattered photons very frequently. As the Universe expanded and the plasma cooled, it eventually became transparent to the photons and the \"Big Bang photons\" have been travelling more or less without scattering ever since. This \"surface of last scattering\" is visible as the cosmic microwave background, and is the closest we'll get to seeing the Big Bang (except perhaps we could observe neutrinos or gravity waves from beyond the CMB because they are not scattered as strongly in the early Universe).", "meta": {"post_id": 178008, "input_score": 31, "output_score": 40, "post_title": "Why haven't we seen the big bang?"}}
{"input": "Let me start by saying that I understand the definitions of the Lie and covariant derivatives, and their fundamental differences (at least I think I do). However, when learning about Killing vectors I discovered I don't really have an intuitive understanding of the situations in which each one applies, and when to use one over the other.\nAn important property of a Killing vector $\\xi$ (which can even be considered the definition) is that $\\mathcal{L}_\\xi\\, g = 0$, where $g$ is the metric tensor and $\\mathcal{L}$ is the lie derivative. This says, in a way, that the metric doesn't change in the direction of $\\xi$, which is a notion that makes sense. However, if you had asked me how to represent the idea that the metric doesn't change in the direction of $\\xi$, I would have gone with $\\nabla_\\xi g = 0$ (where $\\nabla$ is the covariant derivative), since as far as I know the covariant derivative is, in general relativity, the way to generalize ordinary derivatives to curved spaces.\nBut of course that cannot be it, since in general relativity we use the Levi-Civita connection and so $\\nabla g = 0$. It would seem that $\\mathcal{L}_\\xi\\, g = 0$ is be the only way to say that the directional derivative of $g$ vanishes. Why is this? If I didn't know that $\\nabla g = 0$, would there be any way for me to intuitively guess that \"$g$ doesn't change in the direction of $\\xi$\" should be expressed with the Lie derivative? Also, the Lie derivative is not just a directional derivative since the vector $\\xi$ gets differentiated too. Is this of any consequence here?", "output": "Nice question. One way to think about it is that given a metric $g$, the statement $\\mathcal L_Xg = 0$ says something about the metric, whereas $\\nabla_Xg = 0$ says something about the connection. Now what $\\mathcal L_Xg = 0$ says, is that the flow of $X$, where defined, is an isometry for the metric, while $\\nabla_Xg = 0$ says that $\\nabla$ transports a pair of tangent vectors along the integral curves of $X$ in such a way that their inner product remains the same. \nAs an example, consider the upper half plane model of the hyperbolic plane. Its metric is $y^{-2}(dx^2 + dy^2)$, so clearly $\\partial_x$ is a Killing vector field; its flow, horizontal translation, is an isometry. The fact that $\\nabla_{\\partial_x}g = 0$ doesn't say anything about $g$, but it does say that Euclidean parallel transport is compatible with this directional derivative of the connection.\nNow consider $\\partial_y$. This of course is not a Killing vector field, since vertical translation is not an isometry. The connection however can be made such (by the theorem of Levi-Civita) that a pair of tangent vectors can be parallel transported in such a way that the inner product is preserved.\nEDIT\nI think I have a more illustrative example: consider the sphere embedded in $\\Bbb R^3$. Pick an axis and take the velocity vector field $\\xi$ associated to rotation around the axis at some constant angular velocity. Also consider a second vector field $\\zeta$ that is everywhere (in a neighbourhood of the equator, extend in any smooth way toward the poles) proportional to $\\xi$, but that has constant velocity everywhere, something like in this image \n\n(downloaded from this page).\nObviously $\\xi$ is a Killing field, as it integrates to an isometry. An immediate way to see that $\\zeta$ is not, is by noting that curves parallel to the equator remain parallel to the equator under the flow of $\\zeta$, hence so do their tangent vectors. What happens to a curve whose tangent vector at the equator points toward a pole, is that the flow of $\\zeta$ moves the point at the equator over a smaller angle than a point above the equator, so these two vectors don't remain perpendicular. For parallel transport on the other hand, two perpendicular tangent vectors to a point at the equator will remain perpendicular both under $\\xi$ and in $\\zeta$, since they only depend on the restriction to the vector fields to the equator, where they are equal. This doesn't say anything about the vector field generating an isometry, i.e. being a Killing vector field.", "meta": {"post_id": 179388, "input_score": 65, "output_score": 47, "post_title": "Lie derivative vs. covariant derivative in the context of Killing vectors"}}
{"input": "$L$ is a linear operator acting on hilbert space $V$ of dimension $n$, $L: V \\to V$. The trace of a linear operator is defined as sum  of diagonal entries of any matrix representation in same input and output basis of $V$. But if $L$ is a linear operator acting on $V \\otimes V$ and I want to take partial trace over the first/second system, it makes sense to me when the operator is expressed in dirac notation, eg a linear operator acting $ H \\otimes H$ where $H$ is a 2-dimensional hilbert space in dirac notation is \n        $$L_{AB} = |01\\rangle \\langle 00 | +|00\\rangle \\langle 10 | $$\n        $$tr_A(L_{AB})=|1\\rangle \\langle 0 |$$\n        $$tr_B(L_{AB})=|0\\rangle \\langle 1 |$$\nhere $\\{|0\\rangle , |1\\rangle \\}$ is an orthonormal basis for $H$. But how is the partial trace found and defined in terms of the matrix representation of the linear operator. Does the input and output basis have to be the same to define partial trace similar to definition of trace ?", "output": "To take the partial trace you need to build the sum over the matrix elements w.r.t. the same input and output basis, as you probably already used to calculate the partial traces you gave. In Dirac notation this is often written as: \n$$ tr_A(L_{AB}) =\\sum_i \\langle i|_A L_{AB} |i\\rangle_A=\\langle0|0\\rangle\\langle 0|0\\rangle (|1\\rangle\\langle0|)_B+\\langle1|0\\rangle\\langle 1|1\\rangle \\left(|0\\rangle\\langle0|\\right)_B\\\\ =(|1\\rangle\\langle0|)_B\n$$\nWhat is implicit to this notation, is that you leave the part of the operator which acts on the space B untouched. In principle what you do is to multiply the square matrix by rectangular matrices to obtain a smaller matrix:\n$$\ntr_A(L_{AB})=\\sum_i [(\\langle i|\\otimes id)L_{AB}(|i\\rangle\\otimes id)]\n$$\nIf you want to think of matrices, just represent the tensor products via Kronecker products:\n$$\ntr_A(L_{AB})= \\left(\\array{1&0&0&0\\\\0&1&0&0}\\right)\\cdot \\left(\\array{0&0&1&0\\\\1&0&0&0\\\\0&0&0&0\\\\0&0&0&0} \\right)\\cdot \\left( \\array{1&0\\\\0&1\\\\0&0\\\\0&0}\\right)=\\left(\\array{0&0\\\\1&0} \\right)\n$$\n(I just wrote the surviving term (where $i=0$).)", "meta": {"post_id": 179671, "input_score": 39, "output_score": 48, "post_title": "How to take partial trace?"}}
{"input": "Nielsen and Chuang mention in Quantum Computation and Information that there are two kinds of measurement : general and projective ( and also POVM but that's not what I'm worried about ).\nGeneral Measurements\n\nQuantum measurements are described by a collection $\\left \\{ M_{m} \\right \\}$ of measurement operators. These are operators acting on the state space of the system being measured. The index $m$ refers to the measurement outcomes that may occur in the experiment. If the state of the quantum system is $|\\psi \\rangle$ immediately before the measurement then the probability that result m occurs is given by $$ p\\left ( m \\right ) = \\left\\langle \\psi | M_{m}^{\\dagger}M_{m} |\\psi \\right\\rangle $$\n  and the state of the system after the measurement is $$\\frac{M_{m}|\\psi\\rangle}{\\sqrt{ \\left \\langle \\psi | M_{m}^{\\dagger}M_{m} |\\psi \\right\\rangle}}$$\n  The measurement operators satisfy the completeness equation $$\\sum_{m} M_{m}^{\\dagger}M_{m} = I$$\n\nProjective Measurements\n\nA projective measurement is described by an observable, $M$, a Hermitian operator on the state space of the system being observed. The observable has a spectral decomposition, $$M = \\sum_{m} mP_{m}$$ where $P_{m}$ is the projector onto the eigenspace of $M$ with eigenvalue $m$. The possible outcomes of the measurement correspond to the eigenvalues, $m$, of the observable. Upon measuring the state $|\\psi\\rangle$, the probability of getting result $m$ is $$p(m) = \\langle\\psi|P_{m}|\\psi\\rangle$$ Given that outcome $m$ occurred, the state of the quantum system immediately after the measurement is $$\\frac{P_{m}|\\psi\\rangle}{\\sqrt{p(m)}}$$\n\nProjective Measurements are special cases of General measurements when the measurement operators are Hermitian and orthogonal projectors.\nIn the introductory course I took on QM, we were introduced to measurements but were not told that they were actually projective. I am assuming that similar courses in other universities are doing the same. :(\nMy questions are : \n\nIs that the only difference between these two types of measurement?\nIs there a case where the measurement operators are not orthogonal projectors? \nWhat do the measurement operators intuitively mean? Where and how are they used?\n\nI am an undergraduate student of Electrical Engineering with one semester of experience in quantum mechanics. I am currently working on a project on quantum computing with spins.\nEDIT : \nConsider the measurement operators given by \n$$M_{1} = \\sqrt{\\frac{\\sqrt{2}}{1 + \\sqrt{2}}} |1\\rangle\\langle1|$$\n$$M_{2} = \\sqrt{\\frac{\\sqrt{2}}{1 + \\sqrt{2}}} \\frac{(|0\\rangle - |1\\rangle)(\\langle 0| - \\langle 1|)}{2}$$\n$$M_{3} = \\sqrt{I - M_{1}^{\\dagger}M_{1} - M_{2}^{\\dagger}M_{2}}$$\nThey satisfy all the conditions required for general measurement operators. But when the rules for general measurements are used to calculate the state $|\\psi_{2}\\rangle$ after a result \"2\" is obtained, $|\\psi_{2}\\rangle$ turns out to be given by $$|\\psi_{2}\\rangle = \\frac{|0\\rangle - |1\\rangle}{\\sqrt{2}} $$ which is most definitely not an eigenstate!!", "output": "Note: There is a short summary at the bottom.\n\nThis is actually also described in Nielsen&Chuang: You don't learn about general measurements, because they are completely equivalent to projective measurements + unitary time evolution + ancillary systems, all of which is described in your usual QM formalism.\nThe Measurement Postulate\nLet's start from the beginning. Let us first formulate the usual postulate of quantum mechanics, as you know it:\n\nMeasurement Postulate (first course):\nMeasurements are described by projection valued measures defined by the spectral measure of an observable (self-adjoint operator). The post measurement state the projection onto the subspace of the measurement.\n\nNow in addition to this, we have a bunch of other postulates, in particular, we have the postulate that the quantum evolution is governed by the Schr\u00f6dinger equation thus time evolution is a unitary evolution. That's all very nice, but when you go to your lab, you discover that that's not what happens.\nAs is pointed out in Nielsen & Chuang, it seems that sometimes, the quantum state is destroyed after measurements (the measurement is not a \"non-demolition-measurement\"), so the state after measurement does not seem to be well-described by a projection onto this eigenspace. But also, you'll actually find out that your evolution is not according to a Hamiltonian and it is not unitary. Energy might enter the system or leave it, depending on what you do.\nWhy is that? The key problem to realize is that all of the postulates in your first course refer to what we call a \"closed system\". None of them actually state this requirement, but they all need it. Only in a closed system is energy conserved (much like in classical mechanics), so we can expect time evolution to be unitary. Just as well, only in a closed system can we expect that measurements are always described by projective measurements.\nTime Evolution of Open Quantum Systems\nSo, what about open quantum systems, i.e. systems where in addition to our system $S$ with a Hilbert space $\\mathcal{H}_S$, we have an uncontrolled environment $E$ (such as in the lab)? Let's consider time evolution as a training case, because it is much easier to understand from classical intuition - incidentally, we have the same problem in classical mechanics!\nIn an open system, as long as we know what the environment is doing, we can assign a Hilbert space $\\mathcal{H}_E$, compute the Hamiltonian on the combined system $\\mathcal{H}_S\\otimes \\mathcal{H}_E$, do time evolution and trace out the environment (the partial trace is the equivalent of forgetting the environment and only considering the system $S$). In other words, having prepared a state $\\rho_S$ of the system and assuming it is not correlated with an environment state $\\rho_E$ (this can be debated upon), the time-evolved state $\\rho_S$ is given by\n$$ T(\\rho)= \\operatorname{tr}_E(U(\\rho_S\\otimes \\rho_E)U^*) $$\nwhere $\\operatorname{tr}_E$ is the partial trace. But this is very cumbersome. We don't always know what the environment is doing. So instead of saying that the open quantum system is part of a bigger, closed system which undergoes a unitary time evolution $U$, we can directly specify the time-evolution by specifying $T$. Then, $T$ will not be a unitary time-evolution, but a completely positive map. In classical mechanics, you do the same: Instead of considering the Lagrangian/Hamiltonian of the whole system, which you might not know, you can also try to consider only a part of that system and describe it by a master equation (this is routinely done in statistical mechanics). The same can be done in quantum mechanics, i.e. by the quantum master equation.\nSo what I want to argue is the following:\n\nUsing unitary time evolution or completely positive maps is ultimately the same (mathematically).\nIn the lab, you will always have noise from the environment so your system will never be closed.\nUnitary time evolutions are clumsy, because they need you to specify the environment completely, which might be hard or nearly impossible to do, so it is much nicer to only work with the open system.\nThe definition of a completely positive map lets you do that. Therefore, it is a \"better\" postulate in a physical sense, because it eliminates key problems when applying the model to your lab.\n\nMeasurements in Open Quantum Systems\nEssentially, we now have to do the exact same thing for measurements that we did for unitary time evolution. How do measurements look like if you restrict them to a subsystem?\n[A small aside: Let's throw in another complication: Measurements are not really instantaneous, some of them take time. For example, suppose you have an atom with three states with different energies, one very much excited $E_3$ and two less excited states (one may be the ground state, let's call them $E_1$ and $E_2$). So you know that your system will be in either of the last states. Measuring which one of these, you can shine a laser with one of the two transition energies to the excited state, say the laser energy is $E_3-E_1$. If you get induced emission, your system was in state $E_1$, if you don't, it has to be in $E_2$. This of course takes time, so the system will evolve (and it won't be a free evolution, because the laser is doing something), so a simple measurement is not just a projective measurement, but we can hardly ever fully separate it from some time evolution. Often, this is no problem, sometimes it might be.]\nWhat happens if we do this? How does the measurement look like on subsystems? Well, it turn out that just as completely positive maps are the restrictions of unitary time evolution, POVMs are the restrictions of measurements.\nYou can also see this from Naimark's dilation theorem: This theorem basically tells us that every POVM ultimately is a projective measurement if we factor in some environment. So in this sense, the POVM approach and the usual projective measurements are mathematically equivalent, if one always factors in the environment + maybe some additional unitary evolution. However, we have the same as above:\nThe formalism of POVMs is better suited to work with, because it does not require us to actually know or even think of the environment. We can get our measurement operators from the experiment and don't have to worry about them being projections or not (in the latter case, the system is surely not closed)\nSo the POVM formalism doesn't give us anything new formally and mathematically, but it is a better way to think about actual quantum systems, which are usually not closed systems.\nGeneral Measurements and a new Postulate\nNow we have POVMs. We could replace our postulate by the POVM postulate, which would cover the outcomes of experiments very well. So why don't we do it? Why don't Nielsen & Chuang do it?\nBecause we have actually lost something: The POVM was really only introduced to compute outcome probabilities, but if we start out with a POVM, it's not clear how we obtain a post-measurement state. Very often, we don't care, but sometimes we do, so we should think about this again (for example, when we consider \"the optimal way to distinguish a set of quantum states\", we at the moment don't care about the post-measurement state, so POVMs are all we need).\nThis \"problem\" of the post-measurement state can be addressed in several ways, one way is to take a POVM with effect operators $E_i$, specify a square root $M_i^*M=E$ and define a general measurement (which, in addition to the fact that for every generalized measurement $\\{M_m\\}_m$, $E_m:=M^*M$ defines a POVM tells you that the formalism of POVMs and general measurements is mathematically equivalent). Now, square roots are not unique, so in order to talk about the post measurement state, you'll have to refer to experiments (or specify the environment and define the measurement there, which will provide you with a unique projective measurement on the closed system).\n[If you want yet another way to think about this, you can pick yet another formalism, quantum instruments which essentially does the same thing.]\nSo in the end, we replace our old (closed system) postulate by the general (open system) postulate:\n\nMeasurement Postulate (Nielsen&Chuang):\nMeasurements are described by a collection of measurement operators $\\{M\\}_m$ that are not necessarily projections but fulfill $\\sum_m M^*_mM_m=\\mathbf{1}$. The post measurement state upon measurement of $m$ is the state after application of $M_m$.\n\nFrom what I have argued above, it should not come as a surprise that the two postulates are mathematically equivalent. More precisely, if we augment POVMs/general measurements by unitary time evolution and the introduction of environment systems, any such measurement should really come from a projective measurement. This was my original post:\nSketch of Proof of the Equivalence of the two postulates\nThis is described on page 94 to 95 in Nielsen & Chuang:\nLet $\\{M\\}_m$ be a \"general measurement\" with $m=1,\\ldots,n$ on a Hilbert space $\\mathcal{H}$. Define $U\\in \\mathcal{B}(\\mathcal{H}\\otimes \\mathbb{C}^n)$ (i.e. $U$ is a bounded operator on the composite system) via definining:\n$$ U|\\psi\\rangle|0\\rangle= \\sum_{m=1}^n (M_m|\\psi\\rangle)|m\\rangle $$\nwhere $|m\\rangle$ is the standard orthonormal basis of $\\mathbb{C}^n$. Then you can show that $U$ can be extended to a unitary operation $U\\in \\mathcal{B}(\\mathcal{H}\\otimes \\mathbb{C}^n)$.\nNow you define the projective measurement $P$ with projections $$P_m:=\\mathbf{1}_{\\mathcal{H}}\\otimes |m\\rangle\\langle m|$$\nand what you can show is that first performing $U$ and then measuring the projective measurement $P$ and tracing out the system $\\mathbb{C}^n$ (\"forgetting\" about the system) is equivalent to performing the generalized measurement $M_m$. In particular:\n$$ \\frac{P_m U|\\psi\\rangle |0\\rangle}{\\sqrt{\\langle \\psi|\\langle 0|U^*P_mU|\\psi\\rangle|0\\rangle}}= \\frac{(M_m|\\psi\\rangle)|m\\rangle}{\\sqrt{\\langle \\psi|M_m^*M_m|\\psi\\rangle}} $$\nand the probabilities also add up. So general measurements add nothing new.\nAbout Closed (Quantum) Systems:\nWe have of course constructed the environment. Who tells us that this is the \"real\" physical environment or that the measurement in the real closed system is actually also projective? No one, actually. This is one other assumption that I've been making implicitly. However, I believe that this system has another deeper problem: Coming from the experimental/operational side, what actually is a closed quantum system? Unless (maybe) we consider the whole universe, we can never actually work with a completely closed system - and we can't consider the whole universe. I believe that there are actually arguments (higher level/quantum foundations) that tell us that the postulates are completely equivalent if there exists a closed quantum system, but this is philosophical.\nBut this means that we did add something \"new\": We got rid of the necessity of closed systems (if we also replace all the other axioms).\nLessons learned: (tl;dr)\nSo, what's the essence? I have argued that generalized measurements are nothing new, neither physically, nor mathematically, if we know about the difference of open and closed quantum systems. Therefore, they don't add anything that you didn't get from the old formalism already, so that your Quantum Mechanics 101 course is not wrong (barring problems with the definition of \"closed quantum systems\").\nHowever, POVMs (or maybe general measurements) are the \"right\" way to think about measurements. The paradigm of open quantum systems, which is very important for real world experiments is inherently inscribed into POVMs and they also tell us why sometimes, measurements seem not repeatable in the lab. So POVMs are not some theoretical construct floating in philosophy space (closed quantum systems), but more operational descriptions of measurements. In addition, they are better to work with when describing real world situations.\nAs a final note: General measurements are not considered heavily in the literature. Peter Shor was so kind as to point out an (old) example of their use with this Peres, Wooters paper (paywall!). Usually however, I find that people work with POVMs instead of general measurements.", "meta": {"post_id": 184524, "input_score": 48, "output_score": 56, "post_title": "What is the difference between general measurement and projective measurement?"}}
{"input": "In talking about Higgs mechanism, the first part is always some introduction to the concept of spontaneous  symmetry breaking (SSB), some people saying that Higgs mechanism is the results of SSB of local gauge symmetry, some people says that we can formulate Higgs mechanism in a gauge invariant way, some people also says that we need only a non-zero vaccum expectation value... I am confused about this different or maybe same point of views.\nIn this post: How does the Higgs mechanism work? , the most highly voted answer, I still can't feel how SSB worked in Higgs mechanism. It seems that the validity of the last part, the appearance of a mass term for $A$, is guaranteed if we have a non-zero equilibrium value $\\phi_0$ to expand around. I do not see that the requirement that the phase of the field $\\phi$ need to be fixed at some particular value to generate mass term. Thus it seems to me it is not true that SSB is really indispensable for Higgs mechanism.\nTo put it simply:\nThe spontaneous breaking of what is attributed to Higgs mechanism?\n\nlocal gauge symmetry\n\nglobal symmetry, since breaking of a \"gauge symmetry\" should not have any effect on physics. In Higgs mechanism, the really broken symmetry is a global one. Mathematically, it is similar in looking as fixing a gauge, but one should not think of it as a spontaneous breakdown of local gauge symmetry.\n\nother.\n\n\nIs SSB really indispensable for Higgs mechanism?\n\nyes, Higgs mechanism is relied on the SSB of some symmetry (above question), the other approaches of description eventually has spontaneously broke some symmetry.\n\nNo, the SSB is just one way to describe Higgs mechanism (or even not a complete way), what is really need is the non-zero vacuum expectation value, for example in the linked post the requirement for the mass term to occur is to have some non-zero expectation value of $\\phi$ to expand around, we do not need the phase of the field to be fixed, thus the symmetry is not broken.\n\nOther.\n\n\nsome reference materials:\n\nIs Elitzur's theorem valid only in lattice field theory? States that SSB of local gauge symmetry is impossible.\n\nGauge invariant accounts of the Higgs mechanism in the abstract states that:\n\n\n\ngauge symmetries merely reflect a redundancy in the state description\nand therefore the spontaneous breaking can not be an essential\ningredient. Indeed, as already shown by Higgs and Kibble, the\nmechanism can be explained in terms of gauge invariant variables,\nwithout invoking spontaneous symmetry breaking\n\n\nIs electromagnetic gauge invariance spontaneously violated in superconductors? In the introduction it says:\n\n\nIn particular, we emphasize that global U(1) phase rotation symmetry,\nand not gauge symmetry, is spontaneously violated, and show that the\nBCS wave function is, contrary to claims in the literature, fully\ngauge invariant", "output": "It is frequently stated the Higgs mechanism involves spontaneous breaking of the gauge symmetry. This is, however, entirely wrong. In fact, gauge symmetries cannot be spontaneously broken. \nA standard argument for this is that gauge symmetries are not actual symmetries, they are just a\nreflection of a redundancy in our description the system; two states related by\na gauge transformation are actually the same physical state. Thus, a gauge\nsymmetry is physically a \"do-nothing transformation\" and thus it does not make\nsense for it to be\nspontaneously broken.\nThis argument does seem like a bit of a cop-out, though -- I could just declare\nany symmetry to be a ``do-nothing transformation'' by fiat if I wanted to.\nA more satisfying explanation is: even if we interpret\ngauge symmetries as real symmetries, they can never be spontaneously broken.\nThis result is known as Elitzur's theorem, and it's quite easy to\nunderstand why it should be true.  Let's focus on classical thermal systems\n-- quantum systems at zero temperature map onto classical thermal systems in\none higher space dimension so the argument should carry over.\nFirst recall the\nhand-waving argument for why spontaneous symmetry breaking can take place in,\nsay, the 2-D Ising model at finite temperature. The 2-D Ising model has two symmetry-breaking ground states: all\n$\\uparrow$ and all $\\downarrow$. But, if I want to get between them by local\nthermal fluctuations then I have to create a domain and grow it until it\nencompasses the whole system, which implies an extensive energy penalty due to\nthe energy cost of the domain wall. Thus, at low temperatures transitions\nbetween the two ground states are exponentially suppressed in the system size\nand so the system gets stuck in either all $\\uparrow$ or all $\\downarrow$, so\nthe symmetry is spontaneously broken. (The same argument shows why the\n1-D Ising model cannot have spontaneous symmetry breaking at finite\ntemperature, because there is no extensive energy penalty to get from all\n$\\uparrow$ to all $\\downarrow$.)\nOn the other hand, since a gauge symmetry is a local symmetry, this\nargument breaks down. Any two symmetry-breaking ground states are related by a\nsequence of local gauge transformations, which (since they commute with the\nHamiltonian) have exactly zero energy penalty. Thus, there is no energy barrier\nbetween different ground states, and the system will explore the entire space of\nground states -- so no symmetry-breaking. We expressed everything here in terms\nof classical thermal systems, but it will be important for later that the quantum version of no\nsymmetry breaking is that the Hamiltonian must have a unique ground state\n(at least with appropriate boundary conditions), because degenerate ground\nstates can always couple to each other through quantum fluctuations to create a\nsuperposition state with lower energy.\nSo now that we have established that the Higgs mechanism does not, and cannot,\ncorrespond to spontaneous symmetry breaking, let's take a look at what's really\nhappening. For simplicity we will look at the simplest case, namely (quantum, $T = 0$)\n$\\mathbb{Z}_2$ lattice gauge theory. This comprises two-dimensional quantum systems on\nall the vertices and links of a square lattice. The ones on the vertices\ncomprise the \"matter field\" and the ones on the links comprise the \"gauge\nfield\". We denote the Pauli matrices on the links by $\\sigma_{ab}^x$, etc. and on\nthe vertices by $\\tau_{a}^x$, etc.\nThe Hamiltonian is\n$$\n  H = -g \\sum_{\\langle a, b\\rangle} \\sigma^x_{ab} - \\frac{1}{g} \\sum_{\\square}\n  \\sigma^z \\sigma^z \\sigma^z \\sigma^z - \\lambda \\sum_{a} \\tau^x_a -\n  \\frac{1}{\\lambda} \\sum_{\\langle a, b \\rangle} \\tau_a^z \\sigma^z_{ab} \\tau_b^z\n$$\n[the second-term is a sum of four-body $\\sigma^z$ interactions on squares of the lattice (\"plaquettes\"), and $\\langle a, b \\rangle$ means a sum over nearest neighbor pairs of vertices.]\nThis Hamiltonian has a gauge symmetry $\\tau^x_a \\prod_{\\langle a, b \\rangle}\n\\sigma^x_b$ for each vertex $a$.\nOne can map out the phase diagram of this Hamiltonian in detail, but here we\nwill just want to focus on the \"Higgs\" phase, which occurs when $g$ and\n$\\lambda$ are small so that the second and fourth terms dominate. We will take\nthe limit $g \\to 0$, claiming without proof that the $g$ small but not\nzero case is qualitatively similar. In this limit the ground state must be a\n$+1$ eigenstate of the product of $\\sigma^z$\naround every plaquette (\"no-flux\" condition). If the model is defined on a space with no\nnon-contractible loops, this implies that we can write, for every ``no-flux''\nconfiguration, $\\sigma^z_{ab} = \\widetilde{\\sigma}^z_a \\widetilde{\\sigma}^z_b$\nfor some choice of $\\{ \\widetilde{\\sigma}^z_a \\} = \\pm 1$.\nHence, all \"no-flux\" configurations can be made to satisfy $\\sigma^z_{ab} = 1$\nby an appropriate gauge transformation. Thus, under this gauge-fixing condition, the Hamiltonian reduces to the\ntransverse-field quantum Ising model on the matter fields:\n\\begin{equation}\n  H_{gf} = -\\lambda \\sum_{a} \\tau^x_a - \\frac{1}{\\lambda} \\sum_{\\langle a,b \\rangle} \\tau_a^z \\tau_b^z\n\\end{equation}\nwhich we know will have a symmetry-breaking phase (i.e. a two-fold degenerate\nground state) for small $\\lambda$. This is\nthe Higgs phase.\nQ: But hang on, now, doesn't Elitzur's theorem say that gauge symmetries can't be\nspontaneously broken?\nA: Well, actually in fixing the gauge we used up the local\npart of the gauge symmetry, and the above Hamiltonian $H_{gf}$ only has a\n$\\mathbb{Z}_2$ global symmetry. Thus, it does not violate\nElitzur's theorem for it to have spontaneous symmetry breaking.\nQ: But what about the original Hamiltonian, $H$? It had a\n  gauge symmetry, and it's equivalent to the new Hamiltonian $H_{gf}$, which has\n  spontaneous symmetry-breaking, so the original Hamiltonian must have\nspontaneous symmetry-breaking too?\nA: You have to be very careful about the sense in which $H$ and $H_{gf}$ are\nequivalent, because the \"gauge-fixing\" transformation which relates them\nisn't unitary (since it's many-to-one). Still, if one thinks hard enough and\nuses the fact that $H$ is invariant under the gauge symmetry, it\nis not hard to show that there is a correspondence between eigenstates of $H$\nand of $H_{gf}$. However, because the two degenerate ground states of $H_{gf}$ are\nrelated by a gauge transformation, they actually correspond only to a single\nunique ground state of $H$, in accordance with Elitzur's theorem. This unique\nground state $|\\Psi\\rangle_H$ of $H$ can be found in terms of the ground states  $|\\Psi\\rangle_{H_{gf}}$ of $H_{gf}$ by\nsymmetrizing them to make them gauge-invariant, i.e.\n\\begin{equation}\n  |\\Psi\\rangle_H = \\sum_{\\mathcal{G}} \\mathcal{G} |\\Psi\\rangle_{H_{gf}},\n\\end{equation}\nwhere the sum is over all possible gauge transformations $\\mathcal{G}$ (since\nthe two degenerate ground states are related by a gauge transformation, this\ngives the same $|\\Psi\\rangle_H$ regardless of which one you choose to be\n$|\\Psi\\rangle_{H_{gf}}$.)\nSo in summary, the Higgs mechanism appears to resemble spontaneous symmetry breaking in a particular choice of gauge, but this is an illusion. The true ground state is unique and gauge-invariant.", "meta": {"post_id": 190416, "input_score": 45, "output_score": 47, "post_title": "What role does \"spontaneous symmetry breaking\" play in the \"Higgs Mechanism\"?"}}
{"input": "I'm working on something and I need to know the wavelength of the laser pointer that I'm using. \nCan you suggest me a way, using some optics formulae, or anything else to calculate the wavelength?", "output": "Your iPhone is a pretty good grating. I just did a simple experiment with an iPhone, a green laser pointer and a sheet of graph paper. \nThis was the result:\n\nThe display of the iPhone 6 has a resolution of 326 ppi - meaning we have a \"grating spacing\" of 25.4/326=0.0779 mm. Different models have different resolutions - make sure you find out what your phone has and don't just use the above. 6 Plus has 401 dpi, the 5 and 5s have 326 dpi. You can use pretty much any screen you happen to have lying around... if you can find the pixel size, you can use it.\nIn the image I see 5 peak separations over 7 squares (of 1/4 inch each), making the spacing 8.9 mm*\nThe grid paper was 127 cm from the face of the phone. We can calculate the wavelength by looking at the following diagrams:\n\nSimilar triangles tell us that $\\frac{s}{D}=\\frac{\\lambda}{d}$ from which it follows that\n$$\\lambda = \\frac{s\\cdot d}{D}= 546 nm $$\nThat is pretty close to the 532 nm usually quoted for a laser pointer. Setting this up with a larger distance to the screen would have allowed more accurate estimation of the peak separation. Still - this got me to 3% without an optical bench (kitchen counter and kitchen ceiling, one hand holding laser pointer while taking picture with the other hand... Yes I would say 3% is OK and you can easily do better.)\n\n*Looking more closely at the image, the dot spacing is a little bit less than 5/7 - using a ruler on the image I get about 8.75 mm. That improves the estimate to 541 nm... getting within 2% of the actual value. I doubt my exercise book paper is more accurate than that.\nAs @Benjohn pointed out you could try to use the front facing camera. It takes all kinds of things out of the equation but you lose some resolution. Here was my first attempt:\n\nI then repeated it with a 6 Plus (finer resolution screen):\n\nIt looks possible to deduce the peak spacing directly from that...\nAfterword\nSo I did play around a bit more with the data. First, I re-measured the distance from the kitchen counter to the ceiling and found that the width of my tape measure wasn't what I thought it was. This made the distance 1 cm larger than I originally had it; also, using some autocorrelation and filtering functions, I found the \"true\" peak spacing was 8.85 mm, and my new estimate of the wavelength from the first image was updated to 539 nm.\nNext I tried to use the last image - \"self calibrated\" image taken with the front facing camera of the 6 Plus. It is hard to get good specs on the camera: from metadata I found the focal length was 2.65 mm, but the pixel size is more elusive. I tried two different methods: in the first method I placed a ruler at exactly 12\" (\u00b1 0.1\") from the front of the camera, and could see 25 cm (\u00b1 3 mm). With 960 pixels across, this puts the angular resolution (angle / pixel) at about 0.87 mrad. Taking a picture of a ruler at this distance and analyzing the spacing between lines gave me a value of 0.88 mrad. This is within the error I expect from this measurement.\nThe \"blobs\" in the last photo were hard to measure accurately - but again some Fourier magic came to my rescue and I determined them to be spaced about 10.1 pixels apart. With the iPhone 6 plus having a finer grid, this gave me a wavelength of 564 nm. Not as good as the other measurement - but not bad for such a blobby image.\nRe. the Fourier magic: this is the autocorrelation of the image after summing along Y dimension and performing a convolution with a Ricker filter first:\n\nAnd a peak finding algorithm found the following peaks (after fitting to the central five points this was the residuals plot):\n\nIt can be seen that the peak spacing in the blob image could be estimated with remarkable precision. I attribute the fact that the final answer was \"not that great\" to the lack of careful calibration of the camera - not the image obtained. There is hope for this method.\nCDs and DVDs\nI was curious how well CDs and DVDs might work, so I rigged up a slightly better experiment. Distance from disk to screen was 163 cm, and laser pointer was clamped to reduce motion.\nWith the DVD (Blank Fujifilm 4.7 GB DVD-R), the first maxima were at 170 cm from the central spot, and it was quite easy to pick the location within a couple of mm (spot was narrower in the direction I was measuring).\n\nThere is some ghosting, but the central peak is not hard to pick out.\nFor the CD (Very Best of Fleetwood Mac, disk 1), the angles of diffraction were smaller and I could see the first and second maximum on each side of the reflected central spot; however, the second one was so spread out it was not easy to pick a clear center:\n\nI am not sure if we are seeing unequal spacing between tracks at work, or multiple reflections in the CD coating - I suspect the latter as the effect was much stronger at the lower-angle second peak.\nAt any rate, the deflection angle could be calculated for each case as $\\tan^{-1}\\frac{s}{D}$:\nDVD - 46.17\u00b0\nCD  - 20.98\u00b0\n\nThese angles are no longer \"small\" so we need to be a bit more careful about our equations. We can see that $\\frac{\\lambda}{d}=\\sin\\theta$ and $\\frac{S}{D}=\\tan\\theta$. If we assume the wavelength is known, we find the track spacing from this experiment:\n$$d = \\frac{\\lambda}{\\sin\\theta}$$\nThis gives \nDVD:  737 nm\nCD:  1486 nm\n\nthe nominal spacing for a DVD is 740 nm, and for a long-playing CD it can be 1500 nm - but CD's can vary quite a bit, depending on the recording length they want to achieve. Unless you know what your disk is, CD's should not be relied upon as accurate gratings. The 737 nm vs 740 nm is an astonishing 0.5% error; it may well be that the 1486 nm measured was in fact 1500 nm, and also within 1% error. If you had seen me balancing on a chair while measuring the distance between spots on the ceiling with a tape measure, you would not have expected me to get that close...\nOne final word: \nThe screen of an iPhone 6 is not perfectly flat, and if you happen to be measuring reflection of your laser pointer close to the edge it is possible you will get a different answer. To first order, all the diffraction peaks will be deflected by the same amount - but if there is appreciable curvature an accurate measurement will show a small difference. It would take a careful setup (proper clamps etc) to detect this; and it would detract from the \"cool kitchen counter experiment\" atmosphere of this one.", "meta": {"post_id": 191189, "input_score": 72, "output_score": 127, "post_title": "How to measure the wavelength of a laser pointer?"}}
{"input": "Underground atomic bomb tests are done in a deep, sealed hole.  Not all underground tests eject material on the surface. In this case, they are only noticeable as earthquakes, according to German Wikipedia on nuclear tests. There seems to be no bulge above the explosion site afterwards.\nI assume the explosion creates a cavity. Also, I assume that rocks are not very compressible, more so for rocks deep under ground, without many gas-filled pores.\nI'd like to understand where the volume of the rock goes. Is it one or more of these:\n\nRock is compressible, and the surrounding rock is just squished a little after the explosion.\nThe ground is elastic, and there is no cavity after the explosion.\nThere is a bulge on the surface, it's just too flat to be noticeable, but has a large volume.\nthe cavity is so small that the bulge on the surface is so flat that it is not noticeable.\nThere are enough pores filled with compressible gas in rocks generally, which end up with higher gas pressure after they lost some or most volume, with the total lost volume being the same as the cavities volume.\n\nRegarding compressibility,\n\"Geologic materials reduces in volume only when the void spaces are\nreduced, which expel the liquid or gas from the voids.\"\n(Wikipedia: Compressibility - Earth science)\nThe answer of LDC3 hints that it can be assumed that the ground chosen for nuclear tests is most probably not porous, to avoid migration of radioactive isotopes.\nFrom this, it could be concluded that compressibility is not an important factor, which is certainly counterintuitive.\nThere are probably some more options, and it may be more than one mechanism.\nBut where does that volume mainly come from?", "output": "There is an interesting diagram in the wiki article on underground nuclear testing - the picture file is here\nThis shows that the crater you get from a nuclear explosion depends on the depth of burial:\n\nI think the most interesting diagrams are the ones labeled (e) and (f) - where the explosion happens at great depth. In that case, you get a \"tight packing\" of the soil above in a way that I think is similar to the mechanism that causes sugar to \"settle\" if you first fill a bowl to the rim, and then tap the bowl gently. The shock wave that travels through the soil (or the sugar) causes individual grains to find a more energetically favorable orientation - so they are a little more tightly packed. This can result in a crater.\nNow whether you consider this \"compacting voids\" is a matter of opinion. But it's a real effect. Of course, very close to the nuclear reaction the heat will be so great that the rock will liquify; as a liquid it might be able to pack more tightly, although that depends on many factors.", "meta": {"post_id": 191777, "input_score": 40, "output_score": 36, "post_title": "In atomic bomb tests under ground, where does the displaced volume of the rocks go?"}}
{"input": "In the case of a supernova explosion it is possible to create heavy elements through fusion. Supernovae have a tremendous amount of energy in a very small volume but not as much energy per volume as there was in our early universe. So, what is the major difference? Why didn't the Big Bang create heavy elements?", "output": "Heavy elements couldn't form right after the Big Bang because there aren't any stable nuclei with 5 or 8 nucleons. \n Source: Wikipedia (user Pamputt)\nIn the Big Bang nucleosynthesis, the main product was $^4He$, because it is the most stable light isotope: 20 minutes after the Big Bang, helium-4 represented about 25% of the mass of the Universe, and the rest was mostly $^1H$. There was only 1 nucleus of deuterium and helium-3 for each $10^5$ protons, and 1 nucleus of $^7Li$ for each $10^9$ protons.\nGiven these abundances, the most probable reactions to yield heavier elements would be $^1H + {}^4He$ and $^4He + {}^4He$, but neither produces stable nuclei. So instead we have only $^2H + {}^7Li \\to {}^9Be$ and $^4He + {}^7Li \\to {}^{11}B$. This reactions are extremely unlikely, since lithium was so scarce. It is predicted that one of these nuclei was form for $10^{16}$ protons. Abundance of the previous elements and cooling of the universe prevented the formation of even heavier elements.\nOn the other hand, in the first stars carbon formed in the triple alpha process, which is only possible with the density and helium abundance found in stars, and takes a lot of time. Subsequent nuclear fusions create heavier elements up to iron, and the energy released in the supernova explosion allows the synthesis of even heavier elements.\nReferences\nAlain Coc, Jean-Philippe Uzan, Elisabeth Vangioni: Standard big bang nucleosynthesis and primordial CNO Abundances after Planck JCAP10(2014)050 arxiv:1403.6694", "meta": {"post_id": 199632, "input_score": 86, "output_score": 75, "post_title": "Why didn't the Big Bang create heavy elements?"}}
{"input": "Why are golden mirrors yellow? \nDo they add a yellow component to the spectrum or absorb non-yellow components?\nIf they absorb, then why are they used in telescopes being imperfect?\nIf they add a yellow component, then where do they take energy for it from?\nJWST mirrors are coated with gold\n\nDo they add some corrections in the on-board computer to compensate for the color of gold?", "output": "I've made this into an answer because it's too long for a comment, and I really want to show the pictures.\nIt is tempting to think of visible light as \"close enough\" to (near by wavelengths) and to conclude that \"yes, actually, the yellow does affect it. I want a mirror without an obvious tint\" \nHowever you are wrong, Physics will slap you down.\nExhibit A\n\n(There's a book called Optics by Eugine Hecht that has a picture of some such lenses, but I couldn't find that picture. This is the best I found with quite a bit of googling)\nThis lens is made from \"silicon or germanium\" according to this link (where I found the picture) - I could have swore it was steel, anyway!\nThis lens is completely opaque to us, but to actual infrared cameras (the 1-$\\mu$ sort of wavelengths) this is probably a good lens!\nLet us go further.\nExhibit B\nFor reference this is 22.5cm tall\n\nThis is a lens for radiowaves. As you can just about see, it doesn't even \"refract\" our visible light, that light just goes right through the MASSIVE GAPS in the mesh. However to radiowaves, this is a lens!\nExhibit C\nFinally, we come to visible light, I took this picture (bit of shameless \"I'm proud of this\", I know):\n\nAs you can probably tell from the soft background and such it was taken with a lens with a very large aperture (50mm f/1.4), and as you can (hopefully not) see the different wavelengths of light have actually gone different paths through the lens. Notice:\n\nAs you can see, \"glass\" isn't even very good at treating the visible wavelengths the same way. A picture is worth a thousand words.\n\nI used a good lens, which is why the effect is so small, but this shows the principle behind it.\nExhibit D\n\nThis is a microwave door - it is opaque to microwaves, but as you can see, lets visible light through. (See Faraday Cage)\nExhibit E\nWiFi. It can pass through walls and doors.\nIt should be clear now that light doesn't exactly behave like what our brain calls \"light\" \nFinally\nI hope this helps. As you can see - WAAAY to long for a comment.", "meta": {"post_id": 200932, "input_score": 51, "output_score": 65, "post_title": "Why are gold mirrors yellow?"}}
{"input": "There seem to be two different things one must consider when representing a symmetry group in quantum mechanics:\n\nThe universal cover: For instance, when representing the rotation group $\\mathrm{SO}(3)$, it turns out that one must allow also $\\mathrm{SU}(2)$ representations, since the negative sign a \"$2\\pi$ rotation\" induces in $\\mathrm{SU}(2)$ is an overall phase that doesn't change the physics. Equivalently, all representations of the Lie algebra are what we seek. ($\\mathfrak{so}(3) = \\mathfrak{su}(2)$, but although every representation of the algebra is one of the universal cover, not every representation of the algebra is one of $\\mathrm{SO}(3)$.)\nCentral extensions: In conformal field theory, one has classically the Witt algebra of infinitesimal conformal transformations. From the universal cover treatment one is used to in most other cases, one would expect nothing changes in the quantum case, since we are already seeking only representation of an algebra. Nevertheless, in the quantization process, a \"central charge\" appears, which is often interpreted to arise as an \"ordering constant\" for the now no longer commuting fields, and we have to consider the Virasoro algebra instead.\n\nThe question is: What is going on here? Is there a way to explain both the appearence of universal covers and central extensions in a unified way?", "output": "Yes. Both universal covers and central extensions incurred during quantization come from the same fundamental concept:\nProjective representations\nIf $\\mathcal{H}$ is our Hilbert space of states, then distinct physical states are not vectors $\\psi\\in\\mathcal{H}$, but rays, since multiplication by a complex number does not change the expectation values given by the rule\n$$ \\langle A\\rangle_\\psi = \\frac{\\langle \\psi \\vert A \\vert \\psi \\rangle}{\\langle \\psi \\vert \\psi \\rangle}$$\nnor the transition probabilities\n$$ P(\\lvert \\psi \\rangle \\to \\lvert \\phi \\rangle) = \\frac{\\lvert \\langle \\psi \\vert \\phi \\rangle\\rvert^2}{\\langle \\phi \\vert \\phi \\rangle\\langle \\psi \\vert \\psi \\rangle}$$\nThe proper space to consider, where every element of the space is indeed a distinct physical state, is the projective Hilbert space\n$$ \\mathrm{P}\\mathcal{H} := \\mathcal{H} /\\sim$$\n$$ \\lvert \\psi \\rangle \\sim \\lvert \\phi \\rangle :\\Leftrightarrow \\exists c\\in\\mathbb{C}: \\lvert \\psi \\rangle = c\\lvert\\phi\\rangle$$\nwhich is just a fancy way to write that every complex ray has been shrunk to a point. By Wigner's theorem, every symmetry should have some, not necessarily unique, unitary representation $\\rho : G \\to \\mathrm{U}(\\mathcal{H})$. Since it has to descend to a well-defined ray transformation, the action of the symmetry is given by a group homomorphism into the projective unitary group $G \\to \\mathrm{PU}(\\mathcal{H})$, which sits in an exact sequence\n$$ 1 \\to \\mathrm{U}(1) \\to \\mathrm{U}(\\mathcal{H}) \\to \\mathrm{PU}(\\mathcal{H}) \\to 1$$\nwhere $\\mathrm{U}(1)$ represents the \"group of phases\" that is divided out when passing to the projective space. It is already important to notice that this means $\\mathrm{U}(\\mathcal{H})$ is a central extension of $\\mathrm{PU}(\\mathcal{H})$ by $\\mathrm{U}(1)$.\nTo classify all possible quantumly allowed representations of a symmetry group $G$, we need to understand the allowed Lie group homomorphisms $\\sigma : G\\to\\mathrm{PU}(\\mathcal{H})$. Since linear representations are nicer to work with than these weird projective things, we will look at\nClassifying projective representations by unitary linear representations\nFor any $g\\in G$, choose a representative $\\Sigma(g)\\in\\mathrm{U}(\\mathcal{H})$ for every $\\sigma(g)\\in\\mathrm{PU}(\\mathcal{H})$. This choice is highly non-unique, and is essentially responsible for how the central extension appears. Now, since for any $g,h\\in G$ we have $\\sigma(g)\\sigma(h) = \\sigma(gh)$, the choices of representatives must fulfill\n$$ \\Sigma(g)\\Sigma(h) = C(g,h)\\Sigma(gh)$$\nfor some $C : G\\times G\\to\\mathrm{U}(1)$. Applying associativity to $\\Sigma(g)\\Sigma(h)\\Sigma(k)$ gives the consistency requirement\n$$ C(g,hk)C(h,k) = C(g,h)C(gh,k)\\tag{1}$$\nwhich is also called the cocycle identity. For any other choice $\\Sigma'$, we must have\n$$ \\Sigma'(g) = f(g)\\Sigma(g) $$\nfor some $f : G \\to \\mathrm{U}(1)$. $\\Sigma'$ has an associated $C'$, and so we get\n$$ C'(g,h)\\Sigma'(gh) = \\Sigma'(g)\\Sigma'(h) = f(g)f(h)C(g,h)f(gh)^{-1}\\Sigma'(gh)$$\nwhich yields the consistency requirement\n$$ C'(g,h)f(gh) = f(g)f(h)C(g,h)\\tag{2}$$\nTherefore, projective representations are classified giving the choice of unitary representatives $\\Sigma$, but those that are related by $(2)$ give the same projective representation. Formally, the set\n$$ H^2(G,\\mathrm{U}(1)) := \\{C : G\\times G \\to \\mathrm{U}(1)\\mid C \\text{ fulfills } (1)\\} / \\sim$$\n$$ C \\sim C' :\\Leftrightarrow \\exists f : (2) \\text{ holds }$$\nclassifies the projective representations of $G$. We want to use it to construct a unitary representation of something that classifies the projective representation:\nDefine $G_C := G \\times_C \\mathrm{U}(1)$ for any representative $C$ of an element in $H^2(G,\\mathrm{U}(1)$ by endowing the Cartesian product $G \\times \\mathrm{U}(1)$ with the multiplication\n$$ (g,\\alpha)\\cdot(h,\\beta) := (gh,\\alpha\\beta C(g,h))$$\nOne may check that it is a central extension, i.e. the image of $\\mathrm{U}(1)\\to G \\times_C\\mathrm{U}(1)$ is in the center of $G_C$, and\n$$ 1 \\to \\mathrm{U}(1) \\to G_C \\to G \\to 1$$\nis exact. For any projective representation $\\sigma$, fix $\\Sigma,C$ and define the linear representation\n$$ \\sigma_C : G_C \\to \\mathrm{U}(\\mathcal{H}), (g,\\alpha) \\mapsto \\alpha\\Sigma(g)$$\nConversely, every unitary representation $\\rho$ of some $G_C$ gives a pair $\\Sigma,C$ by $\\Sigma(g) = \\alpha^{-1}\\rho(g,\\alpha)$.\nTherefore, projective representations are in bijection to linear representations of central extensions.\nOn the level of the Lie algebras, we have $\\mathfrak{u}(\\mathcal{H}) = \\mathfrak{pu}(\\mathcal{H})\\oplus\\mathbb{R}$, where the basis element $\\mathrm{i}$ of $\\mathbb{R}$ generates multiples of the identity $\\mathrm{e}^{\\mathrm{i}\\phi}\\mathrm{Id}$. We omit the $\\mathrm{Id}$ in the following, whenever a real number is added to an element of the Lie algebra, it is implied to be multiplied by it.\nRepeating the arguments above for the Lie algebras, we get that the projective representation $\\sigma : G \\to \\mathrm{PU}(\\mathcal{H})$ induces a representation of the Lie algebra $\\phi : \\mathfrak{g}\\to\\mathfrak{pu}(\\mathcal{H})$. A choice of representatives $\\Phi$ in $\\mathfrak{u}(H)$ classifies such a projective representation together with an element $\\theta$ in\n$$ H^2(\\mathfrak{g},\\mathbb{R}) := \\{\\theta : \\mathfrak{g}\\times\\mathfrak{g} \\to \\mathbb{R}\\mid \\text{ fulfills } (1') \\text{ and } \\theta(u,v) = -\\theta(v,u)\\} / \\sim$$\n$$ \\theta \\sim \\theta' :\\Leftrightarrow \\exists (b : \\mathfrak{g}\\to\\mathbb{R}) :\\theta'(u,v) = \\theta(u,v) + b([u,v])$$\nwith consistency condition\n$$ \\theta([u,v],w) + \\theta ([w,u],v) + \\theta([v,w],u) = 0 \\tag{1'}$$\nthat $\\theta$ respects the Jacobi identity, essentially.\nThus, a projective representation of $\\mathfrak{g}$ is classified by $\\Phi$ together with a $\\theta\\in H^2(\\mathfrak{g},\\mathbb{R})$. Here, the central extension is defined by $\\mathfrak{g}_\\theta := \\mathfrak{g}\\oplus\\mathbb{R}$ with Lie bracket\n$$ [u\\oplus y,v\\oplus z] = [u,v]\\oplus\\theta(u,v)$$\nand we get a linear representation of it into $\\mathfrak{u}(\\mathcal{H})$ by\n$$ \\phi_\\theta(u\\oplus z) := \\Phi(u) + a$$\nAgain, we obtain a bijection between projective representations of $\\mathfrak{g}$ and those of its central extensions $\\mathfrak{g}_\\theta$.\nUniversal covers, central charges\nWe are finally in the position to decide which representations of $G$ we must allow quantumly. We distinguish three cases:\n\nThere are no non-trivial central extensions of either $\\mathfrak{g}$ or $G$. In this case, all projective representations of $G$ are already given by the linear representations of $G$. This is the case for e.g. $\\mathrm{SU}(n)$.\n\nThere are no non-trivial central extensions of $\\mathfrak{g}$, but there are discrete central extensions of $G$ by $\\mathbb{Z}_n$ instead of $\\mathrm{U}(1)$. Those evidently also descend to projective representations of $G$. Central extensions of Lie groups by discrete groups are just covering groups of them, because the universal cover $\\overline{G}$ gives the group $G$ as the quotient $\\overline{G}/\\Gamma$ by a discrete central subgroup $\\Gamma$ isomorphic to the fundamental group of the covered group. Thus we get that all projective representations of $G$ are given by linear representations of the universal cover. No central charges occur. This is the case for e.g. $\\mathrm{SO}(n)$.\n\nThere are non-trivial central extensions of $\\mathfrak{g}$, and consequently also of $G$. If the element $\\theta\\in H^2(\\mathfrak{g},\\mathbb{R})$ is not zero, there is a central charge - the generator of the $\\oplus\\mathbb{R}$ in $\\mathfrak{g}_\\theta$, or equivalently the conserved charge belonging to the central subgroup $\\mathrm{U}(1)\\subset G_C$. This happens for the Witt algebra, where inequivalent $\\theta(L_m,L_n) = \\frac{c}{12}(m^3 - m)\\delta_{m,-n}$ are classified by real numbers $c\\in \\mathbb{R}$.", "meta": {"post_id": 203944, "input_score": 95, "output_score": 95, "post_title": "Why exactly do sometimes universal covers, and sometimes central extensions feature in the application of a symmetry group to quantum physics?"}}
{"input": "Why is the shape of the fringes in Young's double slit experiment hyperbolic? Morever what type of fringe pattern is obtained if slits are almost perpendicular to the screen?\n\nCan someone explain it to me with detailed mathematical calculations and images if possible? \nThis qoura link is not so rigorous.", "output": "I will give you the mathematical details at the last, first just visualize what is going on. I am assuming that slits are like pinholes because if you took into account that they are thin rectangles then fringes won't be exactly hyperbolic and it will be mixed problem of interference and diffraction.\nIn all the diagrams and animations, blue axis is Z, red is X and green is Y.\nThis is how a fringe looks on a screen (Pink) perpendicular to the y-axis(green) when two slits A and B are placed along the z-axis(Blue). \n\nNow a lot of people explain this by saying that:\n\"A fringe is obtained when path difference of interfering waves is constant. So, the locus of that point from which the difference between the distances from A and B to that point is constant is a Hyperbola. Hence, the fringes are Hyperbolic.\" This is true if we are looking, for the locus of those points, on a plane which passes through A & B. As the gif below shows different planes passing through A and B contain those hyperbolas:\n\nBut, that's not true, in general, if you are looking for the points in a plane which doesn't pass through points A and B. For example, if you look for fringes in a plane that is perpendicular to the line joining A and B, then the fringes will be CIRCULAR.\n\nBecause, it is true that for each plane passing through A and B locus of those points is a hyperbola, and whole 3D space can be thought as made up of infinite planes passing through points A & B, the locus in 3D space will be all those hyperbolas combined to form a hyperboloid; as shown below:\n\nNow if we want to find locus on any plane we can just take the intersection of this hyperboloid with the plane.\nMathematical Details:\nI will first prove that the locus is hyperboloid and then will take the intersections to find fringe shapes on desired planes.\nLet A be $(0,0,a)$ and B be $(0,0,-a)$. Coordinates are in the order (x,y,z). Locus of points which have a constant path difference is:\n$\\sqrt{(z+a)^2+(x^2)+(y^2)}-\\sqrt{(z-a)^2+(x^2)+(y^2)} = d $\n$\\sqrt{(z+a)^2+(x^2)+(y^2)} =\\sqrt{(z-a)^2+(x^2)+(y^2)} + d $\nSquaring both sides:\n${(z+a)^2+(x^2)+(y^2)} ={(z-a)^2+(x^2)+(y^2)} + 2\\sqrt{(z-a)^2+(x^2)+(y^2)}d + d^2 $\n$4za  = 2\\sqrt{(z-a)^2+(x^2)+(y^2)}d + d^2$\n$(2za - \\frac{d^2}{2})^2 = ((z-a)^2+(x^2)+(y^2)) d^2 $\nRe-arrange to get:\n$z^2 - \\frac{x^2 + y^2}{\\frac{4a^2}{d^2} -1} = \\frac{d^2}{4}$\nLet $\\frac{4a^2}{d^2} -1=k^2$\nSo you get: $z^2 - \\frac{x^2 + y^2}{k^2} = \\frac{d^2}{4}$\nNow, $x^2 + y^2 = {\\rho}^2$\n,where $\\rho$ is the distance of any point from z-axis or if you know cylindrical coordinates, it is the cylindrical radius.\nOur equation now becomes:\n$z^2 - \\frac{{\\rho}^2}{k^2} = \\frac{d^2}{4}$\nSo, it is a hyperboloid.\nIf the screen is perpendicular to y-axis(green axis), the equation of the plane would be $y = h$. Substitute $y=h$ in the equation of hyperboloid, you will get an equation of hyperbola (in x and z):\n$z^2 - \\frac{x^2}{k^2} = \\frac{d^2}{4} - \\frac{h^2}{k^2} $\nIt is shown below as as the black curve of intersection: \n\nIf the screen is perpendicular to line joining A and B (or perpendicular to z-axis) then substitute $z = h$ in the equation of the hyperboloid and you will get a circle in x and y, giving you the circular fringes $x^2 + y^2 = (h^2 - \\frac{d^2}{4})k^2$ as shown below as the black curve of intersection:", "meta": {"post_id": 210375, "input_score": 10, "output_score": 36, "post_title": "Why is the shape of the fringes in Young's double slit experiment hyperbolic?"}}
{"input": "While I was making a morning coffee at work, some sugar from the spoon started to fly away, seemingly towards some foam cups. Can this be explained by magnetism?", "output": "Electro-magnetism is a good guess, simply because it's the only force you commonly see that's powerful enough. It's not very useful as an explanation, though, because almost everything you see around you is due to electro-magnetism (e.g. the way the spoon holds together in the first place, or the light that allows you to see the sugar, or the way the water \"sticks\" to having a fluid surface, or the way the individual atoms of the sugar stick together...). The real question is \"What kind of EM is responsible?\"\nIt's not ferro-magnetism (the kind you see with old-school fridge magnets) - neither the foam nor the sugar are ferro-magnetic. It's not para-magnetism either.\nIt's not due to molecular nor atomic bonds (the kind that holds molecules together, or the residual force that causes e.g. hydrogen bridges) - the distance involved is too large.\nIt's not dia-magnetism (remember those frog levitation videos?). That would require massive magnetic fields.\nI could go on, but there's plenty of other cases that obviously don't apply, so let's skip to the end:\nThe interesting point is that plastics are usually electric isolants. This is very important, because it means that when they acquire a charge imbalance, it's not equalised very quickly - the current can't flow readily. This means that it's possible for one side to have a slight positive charge, while the other side has a slight negative charge (in a metal, in contrast, the charges would \"mix\" to maintain an overall neutral charge).\nThis leads to another common sight of electromagnetism in the common household \u2013 static electricity. And this is most likely what's happening here - the cup is statically charged, which causes attraction between the slightly charged cup, and the sugar which is also slightly charged in turn (if we assume the cup is slightly positively charged, it will attract negative charges in the sugar, causing a slight charge imbalance in the sugar as well - and now you have slightly positive + slightly negative, resulting in a net attraction).\nFinally, to answer your title question, Can sugar be affected by a magnetic field?\nYes. Sugar is made out of parts which interact using the electro-magnetic force, and thus it can be affected by a magnetic field. In the end, it's that simple. Even if it was even a tiny residual force (1 proton + 1 electron aren't exactly \"zero\" charge), it would allow interaction. So if you want to be exact, only the objects that don't interact in EM at all can be non-affected by a magnetic field - for example, neutral neutrinos, or the (more or less) hypothetical dark energy and dark matter (the thinking is that they're dark precisely because they don't interact with EM - this includes visible light as well as magnetism).", "meta": {"post_id": 221395, "input_score": 24, "output_score": 36, "post_title": "Can sugar be affected by a magnetic field?"}}
{"input": "In the recent paper http://arxiv.org/abs/1509.03612, page 37. They say that a torus can be described by the equation $$y^2=x(z-x)(1-x)$$\nwhere $x$ is a coordinate on the base $\\mathbb{P}_1$.\nCould someone explain why the torus is described by this equation? Naively, I would think that the torus is described by $$\\left(R-\\sqrt{x^2+y^2}\\right)^2+z^2=r^2$$\nwhere $R$ and $r$ are the two radii of the two circles of the torus. What's the connection between these two equation?", "output": "Basically, this is related to the theory of Riemann surfaces. Such surfaces arise in complex analysis when one tries to extend the complex plane to make multi-valued functions well-defined. \nTake a simpler example first. Consider the function $f(z) = \\sqrt{ z}$. This function is not single valued since $f( e^{2\\pi i } z ) = - f(z)$. The usual way this is described is to state that this function has a branch cut along a ray passing through the origin. With Riemann surfaces, what we wish to do is to find a manifold that locally looks like the complex plane ${\\mathbb C}$, but globally may take some funny shape in such a way that makes $f(z)$ a well-defined function on that surface. For $\\sqrt{z}$, one might define the Riemann surface as a 2-sheeted complex plane with the following property - Start at a point on sheet 1, $z$. Then rotate by $2\\pi$, i.e. $z \\to e^{2\\pi i } z$ and instead of reaching the original point (which would be the case if the surface was $\\mathbb C$), we reach the corresponding point on sheet 2. A second rotation by $2\\pi$ so that $z \\to e^{4\\pi i} z$ however, does bring us back to the same point. On such a surface, $f(z)$ becomes a totally well-defined function since $z$ and $e^{2\\pi i}z$ are distinct points. \nAt least for this function and more generally for $z^{\\frac{1}{n}}$, such Riemann surfaces are beautifully drawn out (for visual help) on Wikipedia\nThe picture is simple. Whenever a function has branch cuts, we define the Riemann surface so that when you move through the branch cut, you reach a different sheet. When you reach the same branch cut on the second sheet, you come back to the first sheet. \nNow, let us describe the analogous procedure for the function\n$$\nf(z) = \\sqrt{ ( z - 1 )(z+1)( z - \\tau ) (z+\\tau) } \n$$\nHere is a drawing that hopefully explains the structure. I believe its harder to explain in words.\nLet me explain a bit here. The first drawing the branch cut structure of this function on $\\mathbb C$. In the second drawing I define a 2-sheeted Riemann surface as shown. The blue and white arrows indicate how one should move past the sheets when going through the branch cuts. In the third drawing I have simply placed the two sheets on top of one another so that the structure is clear. In the very last step, I have added the points at infinity for both the sheets. In doing so, the complex plane compactifies onto the sphere, leaving behind the torus!\nThis is how a torus can be understood as the Riemann surface corresponding to the function $f(z) = \\sqrt{ ( z^2 - 1 )( z^2 - \\tau^2 ) } $. Note that the only important thing here is the branch cut structure of the complex function. The function that you have written down also has the same branch cut structure once the point at infinity is included (which we did in describing the torus anyway). This is shown clearly in the last drawing above.", "meta": {"post_id": 222620, "input_score": 20, "output_score": 37, "post_title": "Equation of a torus"}}
{"input": "I know they used springs for clocks way back in the day and now it's all lithium ion batteries.\nFor reference, consider the Iphone that has a battery with a capacity of 5 Watt hours (18,000 joules).\nFor portable energy sources, fuel cells have been investigated, but they have a lot of down falls (mainly they're dangerous and not particularly efficient). Super capacitors are great, but they cannot handle large voltages because the electrolyte in them will break down; sadly it will still be a long time before we can replace chemical batteries with capacitors. So, what about springs? Of course, it's a lot more work to convert the mechanical energy into electrical, but look at how sophisticated some mechanical watches are. I don't think there is a lack of ingenuity to make a gear reduction and a miniature generator. Though I'm not sure about getting 18 kJ of energy into a spring of a convenient size for a cell phone, but it was noted by a manufacturer as being \"... one of the most efficient energy storage devices available\"\nWould it be feasible/practical to do so?", "output": "We tend to think that our modern electronic devices are very energy-efficient so mechanical mainsprings etc. must be enough but they're not. After all, the (Intel i7) microprocessors have over 1 billion transistors per chip and each transistor has to consume some nonzero (and not \"totally\" negligible) energy, after all, to do an operation and they do billions of operations per second.\nThe mainsprings are an extremely lousy storage of energy. The total mechanical energy of such a mainspring may be calculated as $E=\\int F\\cdot d\\ell$. This integral is comparable to the longitudinal force of the mainspring multiplied by the change of its length after it unwinds.\nWhen the numbers are substituted, the mainspring 2824-2 in a wristwatch only contains 0.3 joules. One may basically view the energy as extensive and fill a volume with mainsprings. The energy stored in these mechanical devices will be 1530 joules per liter. It is just 1.5 kilojoules per liter.\nThis is tiny compared to the energy stored in gasoline \u2013 35 megajoules per liter which is 20,000 times more concentrated energy than the energy in mainsprings. The energy stored in the same volume of batteries will be comparable to gasoline (because both of them are based on the chemical energy of electronic orbitals), just a little bit lower. Lithium-ion batteries have about 4 megajoules per liter, about 9 times lower than gasoline, see the table here\n\nhttps://en.wikipedia.org/wiki/Energy_density#Energy_densities_of_common_energy_storage_materials\n\nLithium-ion batteries still store 3,000 times more energy than the mainspring of the same volume. It shouldn't be surprising microscopically. The mainspring only rearranges macroscopic pieces of the metal which only uses relatively small forces we may afford not to make the spring too dangerous when it cracks. On the other hand, the chemical energy (gasoline, lithium-ion) uses the much larger forces that keep the atoms together or apart etc. They store the near-maximum chemical energy in every atom or every pair of adjacent atoms, so to say.\nThe nuclear energy stored per kilogram is over 1 million times greater than the gasoline; and it is almost 1 billion times more concentrated energy than gasoline on the per-volume basis (because the uranium etc. is denser). An even more shocking comparison is the uranium-vs-mainspring comparison on the per-volume basis: uranium (nuclear) is about 1 trillion times more concentrated form of useful energy than the mainsprings. (If we could get lots of antimatter and annihilate it against matter, we would gain another factor of nearly 1,000 in the energy content per liter \u2013 almost 1 quadrillion times denser useful energy than in mainsprings \u2013 and no further improvement would be possible.)\nFor those reasons, the mainsprings are a romantic old-fashioned solution but it is not practical for the modern devices which consume much more energy than what a mainspring may give.\nOrdinary people know quite something about how much energy batteries can carry. They have batteries e.g. in portable small vacuum cleaners (not to mention Tesla cars) and they may easily see that the amount of mechanical work that the vacuum cleaner (let alone car) may perform with new batteries would be enough to wind a mainspring many times.\nBecause this question is literally about the approximate calculation of energy, qualitative physical mechanisms behind different types of storages, and the same order-of-magnitude estimates (in atomic physics etc.) that a part of our physics PhD qualifying exams at Rutgers were full of, I strongly disagree with the users who classified this question as an \"off-topic question on engineering\" before they closed it.", "meta": {"post_id": 226156, "input_score": 27, "output_score": 49, "post_title": "Why don't they use springs as an energy source for cell phones?"}}
{"input": "Considering that $7$ TeV is more or less the same kinetic energy as a mosquito flying, why is it considered to be a great amount of energy at the LHC?\nI mean, a giant particle accelerator that can only provide 7 TeV of energy? (14 in the mass center, if I understood well). Is it because particles are so small that this amount of energy, in proportions, is then really huge?", "output": "$7\\ \\mathrm{TeV}$ is not that much kinetic energy, that has been covered by your question and previous answers.\nHowever, in the context of a proton, with a rest mass of $1.672\\times10^{\u221227}~\\mathrm {kg}$ (very, very little mass), when a single proton has $7\\ \\mathrm{TeV}$ then it is traveling at a specific speed:\n$$E= mc^2$$ \\begin{align}E& = E_0 + E_\\mathrm k\\\\ E_\\mathrm k&=E- E_0\\\\ &= mc^2 -m_0c^2\\\\ &= \\gamma m_0c^2 - m_0c^2\\\\ &= m_0c^2 \\left(\\frac{1}{\\sqrt{1-\\frac{v^2}{c^2}}}- 1\\right)\\\\ \\implies  1+ \\frac{E_\\mathrm k}{m_0c^2}&=  \\frac{1}{\\sqrt{1-\\frac{v^2}{c^2}}}\\\\ \\implies {\\sqrt{1-\\frac{v^2}{c^2}}}&=\\frac{1}{1 + \\frac{E_\\mathrm k}{m_0c^2}}\\\\ \\implies 1-\\frac{v^2}{c^2} &= \\left(\\frac{1}{1 + \\frac{E_\\mathrm k}{m_0c^2}}\\right)^2 \\\\ \\implies \\frac{v}{c}&=\\sqrt{1 -\\left(\\frac{1}{1 + \\frac{E_\\mathrm k}{m_0c^2}}\\right)^2 } \\end{align}\nFor a proton at $7\\ \\mathrm{TeV}$, this is $99.9999991\\ \\%$ times the speed of light\nSource\nNow, keep in mind this is for each proton in two beams, each proton having $7\\ \\mathrm{TeV}$, traveling through a superconductor cooled by helium, and then colliding for a sum of $14\\ \\mathrm{TeV}$ in each proton-proton collision.\nEach beam contains $2\\,808$ 'bunches' of protons, and each 'bunch' contains $1.15 \\times 10^{11}$ protons, so each beam then consists of $362\\ \\mathrm{MJ}$ (megajoules).\nThis gives the total kinetic energy of $724\\ \\mathrm{MJ}$ just in the beams alone: about 7 times the kinetic energy as landing a 55-tonne aircraft at typical landing speed according to the Joules Orders of Magnitude Wikipedia page, or with that $59~\\mathrm{ m/s}$ landing speed, 218.9 tonnes, so about a safely loaded Airbus A330-200 (maximum takeoff weight of 242 tonnes)\n\nAdd to that the energy required to keep the ring supercooled enough so it remains superconductive, accelerate the beam in the first place, keep accelerating it so it doesn't lose velocity, light and heat and power the facility.\n\n\"At peak consumption, usually from May to mid-December, CERN uses about 200 megawatts of power, which is about a third of the amount of energy used to feed the nearby city of Geneva in Switzerland. The Large Hadron Collider (LHC) runs during this period of the year, using the power to accelerate protons to nearly the speed of light. CERN's power consumption falls to about 80 megawatts during the winter months.\"\n- Powering CERN", "meta": {"post_id": 229480, "input_score": 44, "output_score": 86, "post_title": "Why is 7 TeV considered as a big amount of energy?"}}
{"input": "As far as I understand, one requires that in order for the scalar product between two vectors to be invariant under Lorentz transformations $x^{\\mu}\\rightarrow x^{\\mu^{'}}=\\Lambda^{\\mu^{'}}_{\\,\\,\\alpha}x^{\\alpha}$, we require that the metric $\\eta_{\\mu\\nu}$ transform as $\\eta_{\\mu\\nu}\\rightarrow \\eta_{\\mu^{'}\\nu^{'}}=\\Lambda^{\\alpha}_{\\,\\,\\mu^{'}}\\eta_{\\alpha\\beta}\\Lambda^{\\beta}_{\\,\\,\\nu^{'}}$. \n[Since we require that $x^{\\mu^{'}}x_{\\mu^{'}}=x^{\\alpha}x_{\\alpha}\\Rightarrow x^{\\mu^{'}}x_{\\mu^{'}}=\\eta_{\\mu^{'}\\nu^{'}}x^{\\mu^{'}}x^{\\nu^{'}}=\\eta_{\\mu^{'}\\nu^{'}}\\Lambda^{\\mu^{'}}_{\\,\\,\\alpha}\\Lambda^{\\nu^{'}}_{\\,\\,\\beta}x^{\\alpha}x^{\\beta}=x^{\\alpha}x_{\\alpha}=\\eta_{\\alpha\\beta}x^{\\alpha}x^{\\beta}$].\nWhat confuses me, is that I've been reading up on the cosmological constant problem and in several sets of notes it is claimed that the contribution of the vacuum energy density to the energy-momentum tensor should be of the form $$T^{vac}_{\\mu\\nu}=-\\rho^{vac}g_{\\mu\\nu}$$ the argument being that the vacuum must be Lorentz invariant and the only Lorentz invariant tensor is the metric tensor $\\eta_{\\mu\\nu}$ (apart from the Levi-Civita tensor (density)). \nI don't see how this is the case by looking at $\\eta_{\\mu^{'}\\nu^{'}}=\\Lambda^{\\alpha}_{\\,\\,\\mu^{'}}\\eta_{\\alpha\\beta}\\Lambda^{\\beta}_{\\,\\,\\nu^{'}}$, how is it obvious that this is Lorentz invariant? Shouldn't it be something like $\\eta_{\\mu^{'}\\nu^{'}}=\\eta_{\\mu\\nu}$?\nApologies if this is a stupid question, but I'm just having a mental block over it.", "output": "I believe it can be useful to define the following concepts (I won't be very formal here for pedagogical reasons):\nAny event can be described through four real numbers, which we take to be: the moment in time it happens, and the position in space where it takes place. We call this four numbers the coordinates of the event. We collect these numbers in a tuple, which we call $x\\equiv (t,\\boldsymbol r)$. These numbers depend, of course, on which reference frame we are using: we could, for example, use a different origin for $t$ or a different orientation for $\\boldsymbol r$. This means: for $x$ to make sense, we must pick a certain reference frame. Call it $S$ for example.\nHad we chosen a different frame, say $S'$, the components of the same event would be $x'$, i.e., four real numbers, in principle different from those before. We declare that the new reference frame is inertial if and only if $x'$ and $x$ are related through\n$$\nx'=\\Lambda x \\tag{1}\n$$\nfor a certain matrix $\\Lambda$, that depends, for example, on the relative orientations of both reference frames. There are certain conditions $\\Lambda$ must fulfill, which will be discussed in a moment.\nWe define a vector to be any set of four real numbers such that, if its components in $S$ are $v=(v^0,\\boldsymbol v)$, then in $S'$ its components must be\n$$\nv'=\\Lambda v \\tag{2}\n$$\nFor example, the coordinates $x$ of an event are, by definition, a vector, because of $(1)$. There are more examples of vectors in physics, for example, the electromagnetic potential, or the current density, the momentum of a particle, etc.\nIt turns out that it is really useful to define the following operation for vectors: if $u,v$ are two vectors, then we define\n$$\nu\\cdot v\\equiv u^0 v^0-\\boldsymbol u\\cdot\\boldsymbol v\\tag{3}\n$$\nThe reason this operation is useful is that it is quite ubiquitous in physics: there are many formulas that use this. For example, any conservation law, the wave equation, the Dirac equation, the energy-momentum relation, etc.\nWe define the operation $\\cdot$ through the components of the vectors, but we know these components are frame-dependent, so if $\\cdot$ is to be a well-defined operation, we must have\n$$\nu\\cdot v=u'\\cdot v' \\tag{4}\n$$\nbecause otherwise $\\cdot$ would be pretty useless.\nThis relation $(4)$ won't be true in general, but only for some matrices $\\Lambda$. Thus, we declare that the matrices $\\Lambda$ can only be those which make $(4)$ to be true. This is a restriction on $\\Lambda$: only some matrices will represent changes of reference frames. Note that in pure mathematics, any invertible matrix defines a change of basis. In physics only a subset of matrices are acceptable changes of basis.\nSo, what are the possible $\\Lambda$'s that satisfy $(4)$? Well, the easier way to study this is to rewrite $(3)$ using a different notation: define \n$$\n\\eta=\\begin{pmatrix} 1 &&&\\\\&-1&&\\\\&&-1&\\\\&&&-1\\end{pmatrix} \\tag{5}\n$$\nThis is just a matrix that will simplify our discussion. We should not try to find a deep meaning for $\\eta$ (it turns out there is a lot of geometry behind $\\eta$, but this is not important right now). Using $\\eta$, its easy to check that $(3)$ can be written as\n$$\nu\\cdot v=u^\\mathrm{T}\\eta v \\tag{6}\n$$\nwhere in the r.h.s. we use the standard matrix product. If we plug $v'=\\Lambda v$ and $u'=\\Lambda v$ here, and set $u\\cdot v=u'\\cdot v'$, we find that we must have\n$$\n\\Lambda^\\mathrm{T} \\eta \\Lambda=\\eta \\tag{7}\n$$\nThis is a relation that defines $\\Lambda$: any possible change of reference frame must be such that $(7)$ is satisfied. If it is not, the $\\Lambda$ cannot relate two different frames. This relation is not in fact a statement of how $\\eta$ transforms (as you say in the OP), but actually a restriction of $\\Lambda$. It is customary to say that $\\eta$ transforms as $(7)$, which will be explained in a moment. For now, just think of $(7)$ as what are the possible matrices $\\Lambda$.\nAt this point, it is useful to introduce index notation. If $v$ is a vector, we call its components $v^\\mu$, with $\\mu=0,1,2,3$. On the other hand, we write the components of changes of frames $\\Lambda^\\mu{}_\\nu$. With this notation, $(2)$ can be written as\n$$\nv'^\\mu=\\Lambda^\\mu{}_\\nu v^\\nu \\tag{8}\n$$\nAlso, using index notation, the product of two vectors can be written as\n$$\nu\\cdot v=\\eta_{\\mu\\nu}u^\\mu v^\\nu \\tag{9}\n$$\nwhere $\\eta_{\\mu\\nu}$ are the components of $\\eta$.\nIndex notation is useful because it allows us to define the following concept: a tensor is an object with several indices, e.g. $A^{\\mu\\nu}$. But not any object with indices is a tensor: the components of a tensor must change in different frames of reference, such that they are related through\n$$\n\\begin{align}\n&A'^{\\mu\\nu}=\\Lambda^\\mu{}_\\rho \\Lambda^\\nu{}_\\sigma\\ A^{\\rho\\sigma} \\\\\n&B'^\\mu{}_\\nu=\\Lambda^\\mu{}_\\rho(\\Lambda^\\mathrm{T})_\\nu{}^\\sigma\\ B^\\rho{}_\\sigma\\\\\n&C'^{\\mu\\nu}{}_\\pi{}^\\tau=\\Lambda^\\mu{}_\\rho \\Lambda^\\nu{}_\\sigma (\\Lambda^\\mathrm{T})_\\pi{}^\\psi \\Lambda^\\tau{}_\\omega\\ C^{\\rho\\sigma}{}_\\psi{}^\\omega\n\\end{align}\\tag{10}\n$$\nand the obvious generalisation for more indices: for every upper index, there is a factor of $\\Lambda$, and for every lower index, a factor of $\\Lambda^\\mathrm{T}$. If the components of an object with indices don't satisfy  $(10)$ then that object is not a tensor. According to this definition, any vector is a tensor (with just one index).\nI don't like to use index notation too much: $v'=\\Lambda v$ is easier that $v'^\\mu=\\Lambda^\\mu{}_\\nu v^\\nu$, don't you think?. But sometimes we have to use index notation, because matrix notation is not possible: when using tensors with three or more indices, matrices cannot be used. Tensors with one index are just vectors. You'll hear sometimes that matrices are tensors with two indices, which is not quite true: if you remember from your course on linear algebra, you know that when you make a change of basis, matrices transform like $M\\to C^\\mathrm{T} M C$, which is like $(10)$ in the case of one upper/one lower index. Therefore, matrices are like tensors with one uppe/one lower index. This is the reason we wrote $\\Lambda$ as $\\Lambda^\\mu{}_\\nu$. This is a matrix, but it is also a tensor.\nAlso, $(7)$ pretty much looks like $(10)$, right? This is the reason people say $(7)$ expresses the transformation properties of $\\eta$. While not false, I you recommend not to take this too seriously: formally, it is right, but in principle $\\eta$ is just a set of numbers that simplifies our notation for scalar products. It turns out you can think of it as a tensor, but only a-posteriori. In principle, it is not defined as a tensor, but it turns out it is. Actually, it is a trivial tensor (the only one!) whose components are the same in every frame of reference (by definition). If you were to calculate what are the components of $\\eta$ in another frame of reference using $(10)$, you'll find out that they are the same. This is stated as the metric is invariant. We actually define it to be invariant. We define what a change of reference frame through the restriction of $\\eta$ being invariant. It doesn't make sense to try to prove $\\eta$ is invariant, as this is a definition. $(7)$ doesn't really prove $\\eta$ is invariant, but actually defines what a change of reference is.\nFor completeness I'd like to make the following definitions:\n\nWe say an object is invariant if it takes the same value on any frame of reference. You can check that if $v$ is a vector, then $v\\cdot v$ takes the same value on any frame, i.e., $v^2$ is invariant.\nWe say an object is covariant if it doesn't take the same value on every frame of reference, but the different values are related in a well defined way: the components of a covariant object must satisfy $(10)$. This means tensors are covariant by definition.\n\nFor example, a vector is not invariant because its components are frame-dependent. But as vectors are tensors, they are covariant. We really like invariant objects because they simplify a lot of problems. We also like covariant objects because, even though these objects are frame-dependent, they transform in a well-defined way, making them easy to work with. You'll understand this better after you solve many problems in SR and GR: in the end you will be thankful for covariant objects.\nSo, what does it mean for $\\eta$ to be invariant? It means its components are the same in every (inertial) frame of reference. How do we prove this? we actually can't, because we define this to be true. How can we prove $\\eta$ is the only invariant tensor? We can't, because it is not actually true. The most general invariant tensor is proportional to the metric. Proof: let $N^\\mu{}_\\nu$ be an invariant tensor by definition. Then, as it is a tensor, we have\n$$\nN'=\\Lambda^\\mathrm{T}N\\Lambda \\tag{11}\n$$\nBut we also must have $N'=N$ for it to be invariant. This means $\\Lambda^\\mathrm T N\\Lambda=N$. Multiply on the right by $\\eta \\Lambda^\\mathrm{T} \\eta$ and use $(7)$ to get $[N,\\Lambda^\\mathrm{T}]=0$. By Shur's Lemma, $N$ must be proportional to the identity. QED.\n\nAnd what about the Levi-Civita symbol? we are usually told that it is also an invariant tensor, which is not actually true: it is invariant, but it is not a tensor, it is a pseudo-tensor. In SR it doesn't satisfy $(10)$ for any $\\Lambda$, but only for a certain subset of matrices $\\Lambda$ (check Proper Orthochronus Lorentz Group), and in GR it is a tensor density (discussed in many posts on SE).\nThe proof of the covariance of the LC symbol is usually stated as follows (you'll have to fill in the details): the definition of the determinant of a matrix is can be stated as $\\text{det}(A)\\varepsilon^{\\mu\\nu\\sigma\\rho}=\\varepsilon^{abcd}A^\\mu{}_a A^\\nu{}_b A^\\rho{}_c A^\\sigma{}_d$. The proper Orthochronus Lorentz Group consists of the subset of matrices with unit determinant, i.e., $\\text{det}(\\Lambda)=1$. If you use this together with the definition of $\\text{det}$, you get $\\varepsilon^{\\mu\\nu\\rho\\sigma}=\\varepsilon^{abcd}\\Lambda^\\mu{}_a\\Lambda^\\nu{}_b\\Lambda^\\rho{}_c\\Lambda^\\sigma{}_d$, which is the same as $(10)$ for the object $\\varepsilon^{\\mu\\nu\\rho\\sigma}$. This proves that, when restricted to this subset of the Lorentz Group, the Levi-Civita symbol is a tensor.\n\nRaising and Lowering indices: this is something that is usually made more important that it really is. IMHO, we can fully formulate SR and GR without even mentioning raising and lowering indices. If you define an object with its indices raised, you should keep its indices where they are. In general there is no good reason as why would someone want to move an index. That being said, I'll explain what these are, just for completeness.\nThe first step is to define the inverse of the metric. Using matrix notation, the metric is its own inverse: $\\eta \\eta=1$. But we want to use index notation, so we define another object, call it $\\zeta$, with components $\\zeta^{\\mu\\nu}=\\eta_{\\mu\\nu}$. With this, you can check that $\\eta\\eta=1$ can be writen as $\\eta_{\\mu\\nu}\\zeta^{\\nu\\rho}=\\delta^\\mu_\\rho$, where $\\delta$ is the Kronecker symbol. For now, $\\delta$ is just a symbol that simplifies the notation. Note that $\\zeta$ is not standard notation, but we will keep it for the next few paragraphs.\n(People usually use the same letter for both $\\eta$ and $\\zeta$, and write $\\eta_{\\mu\\nu}=\\eta^{\\mu\\nu}$; we'll discuss why in a moment. For now, note that these are different objects, with different index structure: $\\eta$ has lower indices and $\\zeta$ has upper indices)\nWe can use $\\eta$ and $\\zeta$ to raise and lower indices, which we now define.\nLet's say you have a certain tensor $A^{\\mu\\nu}{}_\\rho$. We want to define what it means to raise the index $\\rho$: it means to define a new object $\\bar A$ with components\n$$\n\\bar A^{\\mu\\nu\\rho}\\equiv \\zeta^{\\rho\\sigma}A^{\\mu\\nu}{}_\\sigma \\tag{12}\n$$\n(this is called to raise the index $\\rho$ for obvious reasons)\nUsing $(10)$ you can prove that this new object is actually a tensor. We usually drop the bar $\\bar{\\phantom{A}}$ and write $A^{\\mu\\nu\\rho}$. We actually shouldn't do this: these objects are different. We can tell them apart from the index placement, so we relax the notation by not writing the bar. In this post, we'll keep the bar for pedagogical reasons.\nIn an analogous way, we can lower an index, for example the $\\mu$ index: we define another object $\\tilde A$, with components\n$$\n\\tilde A_\\mu{}^\\nu{}_\\rho\\equiv \\eta_{\\mu\\sigma} A^{\\sigma\\nu}{}_\\rho \\tag{13}\n$$\n(we lowered $\\mu$)\nThis new object is also a tensor. The three objects $A,\\bar A,\\tilde A$ are actually different, but we can tell them apart through the indices placement, so we can  drop the tildes and bars. For now, we won't.\nWe'll discuss the usefulness of these operations in a moment. For now, note that if you raise both indices of the metric, you get\n$$\n\\bar{\\bar{\\eta}}^{\\mu\\nu}\\equiv\\zeta^{\\mu\\rho}\\zeta^{\\nu\\sigma} \\eta_{\\rho\\sigma}=\\zeta^{\\mu\\rho}\\delta^\\nu_\\rho=\\zeta^{\\mu\\nu} \\tag{14}\n$$\nwhich means that $\\bar{\\bar{\\eta}}=\\zeta$. As we usually drop the bars, this means that we can use the same letter $\\eta$ for both objects. In principle, they are different: $\\eta_{\\mu\\nu}$ is the metric, and $\\zeta^{\\mu\\nu}$ is its inverse. In practice, we use $\\eta_{\\mu\\nu}$ and $\\eta^{\\mu\\nu}$ for both these objects, and even call them both metric. From now on, we will use $\\eta$ both for the metric and its inverse, but we keep the bars for other objects.\nWith this in mind, we get the following important result:\n$$\n\\eta_{\\mu\\nu}\\eta^{\\nu\\rho}=\\delta_\\mu^\\rho \\tag{15}\n$$\nwhich is actually a tautology: it is the definition of the inverse of the metric.\nSo, what is the use of these operations? for example, what do we get if we lower the index of a vector $v$? Well, we get a new tensor, but it is not a vector (you can check that $(2)$ is not satisfied), so we call it a covector. This is not really important in SR, but in other branches of physics vectors and covectors are really really different.\nSo, what is the covector associated to $v$? Call this covector $\\bar v$. Its components will be $\\bar v_\\mu=\\eta_{\\mu\\nu} v^\\nu$ by definition. Why is this useful? Well, one reason is that by lowering an index, the scalar product $\\cdot$ turns into standard matrix product:\n$$\nu\\cdot v=\\bar u v \\tag{16}\n$$\nas you can check (compare this to $(3)$ or $(6)$). So in principle, raising and lowering indices is supposed to simplify notation. Actually, in the end, you'll see that people write $uv$ instead of $u\\cdot v$ or $u_\\mu v^\\mu$. So you see that the notation is simplified without the need of raising/lowering any index.\nThe following fact is rather interesting: we know that if we raise both indices of the metric we get the metric again. But what do we get if we raise only one index to the metric? that is, what is $\\bar \\eta$?, or, put it another way, what is $\\eta^\\mu{}_\\nu$? Well, according to the definition, it is\n$$\n\\eta^\\mu{}_\\nu=\\eta_{\\nu\\rho}\\eta^{\\mu\\rho}=\\delta^\\mu_\\nu \\tag{17}\n$$\nwhere I used $(15)$. This means that $\\bar \\eta=\\delta$: the metric is the same object as the Kronecker symbol, which is a cool result. As we know that raising and lowering indices from a tensor results in a new tensor, we find that the Kronecker symbol is actually a tensor! We can even prove this from the definition of tensors, i.e., we can check that $(10)$ is satisfied for $\\delta$. But we don't need to: we know that it must be true (check it if you want to).\n\nAs a side note: you (as many people) write prime marks on the indices, while I (as many others) write the primes on the tensors. IMHO the latter convention is the best, because it is the tensor what is changing, not the indices. For example, what you wrote $\\eta_{\\mu'\\nu'}=\\eta_{\\mu\\nu}$ looks better when written $\\eta'_{\\mu\\nu}=\\eta_{\\mu\\nu}$, because the $\\mu\\nu$ component of both objects are equal, and not the $\\mu'$ is equal to the $\\mu$ component (which actually makes no sense and makes the indices mismatched).", "meta": {"post_id": 230495, "input_score": 25, "output_score": 42, "post_title": "Lorentz invariance of the Minkowski metric"}}
{"input": "I was reading this and it says that Microsoft put a server farm at the bottom of the ocean because it's cooler there. Particularly it seems to imply that it get's colder as you go deeper, \"Since ocean water gets pretty cold toward the sea floor...\" But I know that pressure causes heat, for example it is responsible for igniting fusion at the center of the sun.. what gives?", "output": "There's two main misconceptions in your question that cause your confusion.\nFirst, pressure doesn't cause higher temperature. This misconception is probably a result of a massive oversimplification with relation to the ideal gas equation. The actual relation is \"increasing the pressure of an ideal gas while volume remains constant increases the temperature of the gas\".\nTwo notable things here:\n\nWater and other liquids are barely compressible, so they behave nothing like an ideal gas (which is perfectly compressible). Ideal liquid doesn't compress at all.\nTemperature only increases as you put more stuff in the same volume. That is, it isn't pressure that increases temperature, it's compression. If you compress a volume of air, the temperature will rise, and if you release it again, the temperature will drop again.\n\nSecond, any closed system evolves toward thermal equillibrium. In simple terms, if you leave a hot coffee on your table, it will eventually cool down to room temperature. Even though compression increases temperature, this doesn't mean that constant pressure keeps producing more and more heat. When you compress a lot of air into a soccer ball, it will feel hot to the touch. But as it exchanges heat with the environment, it will cool down. This is very useful, of course, because it allows you to expend energy to cool things down, like in your A/C :) \nWhat effect this has on pressure in turn again depends on the properties of the material you're working with. If you have a volume of air in a bottle, as you cool it down, the gas pressure decreases. If you heat it up, the pressure increases. This is the reason why you need to tweak the pressure in your car's tires even if they aren't leaking - you need to adjust for current temperature.\nHowever, with a liquid, this isn't anywhere as simple. While there is a relation between temperature and density, it's nowhere near as big as in an ideal gas. The same goes with pressure and density - if it didn't, you wouldn't be able to walk (imagine that your legs would shorten by half every time you raised one leg - that just wouldn't work).\nSo, let's put this to use in our ocean example. Undisturbed, water will tend to be \"vertically ordered\" by density. Usually, this means that warmer water will tend to rise up, while colder water will tend to go down. So the weird thing is actually how relatively warm in the depths. The ocean floor tends to be around the same temperature, regardless of how warm or cold the upper layers are.\nThere's two main reasons for that, specific to water:\n\nThe water anomaly - the peak of density occurs around 4 \u00b0C in water; both increasing and decreasing temperature from this point results in lower density. The effect is very important, because it means that even during winter, the bottom layers of lakes will have temperature around 4 \u00b0C even when the surface is frozen. And ice is actually a pretty good insulator too :) EDIT: As noted by David, this doesn't occur in ocean water, due to the high salinity which pushes the peak below freezing (around -4 \u00b0C). So in an ocean, the deepest layers are formed of water between about 0 \u00b0C to 3 \u00b0C.\nIce - when water freezes, it forms ice, which has lower density than water. This is somewhat unusual (solids are usually higher-density than liquids), and it means that as water bodies start to freeze, it rises again.\n\nWith supercooled water, this effect is even more pronounced - a water at -30 \u00b0C has about the same density as water at 60 \u00b0C.\nOceans cool mostly by evaporation - the surface layers of water \"spontaneously\" changing state from liquid to gaseous. You get a balancing act between energy lost to evaporation, and incoming sunlight. However, there's a huge gap between the surface and the deeps, a lot of water mass - the incoming sunlight is nowhere near enough to warm ocean waters throughout. So you get warm surface waters, then a gradient of cooler and cooler water, and finally about 0-3 \u00b0C in the deep. To illustrate how big this gap is, about 90% of the worldwide ocean water is in the 0-3 \u00b0C range (hence the \"nowhere near enough sunlight to heat the whole thing through\").\nOf course, a 4 \u00b0C body of water is great for cooling systems running at 40 \u00b0C and more. Air is actually a pretty good insulator, so air cooling gets tricky with large systems. Water, on the other hand, is pretty thermally conductive, and it easily convects, so cooling a huge data centre becomes almost trivial.\nEDIT:\nLet me address the Sun part, since there seems to be some confusion there as well.\nNuclear fusion is something that happens very infrequently. Two nuclei must come very close together to fuse, and they need enough kinetic energy to overcome the repulsion between each other (since both have the same electric charge).\nThe first problem is solved by increasing density. The more nuclei you have in the same volume, the higher the likelihood of close contact. This is where pressure comes in - that's how you get a higher density. Stars are made of plasma, and plasma is easily compressible, similar to a gas, so as pressure increases, so does density. How compressed is it? Well, the Sun's core, where the fusion reactions are actually happening, contains 34% of the Sun's mass, in only 0.8% of the Sun's volume. In the centre, the density is around 150 times the density of liquid water. The pressure is about 100 000 times the pressure in the Earth's core, and about 100 000 000 times the pressure of the water on the bottom of the Mariana trench.\nThe second problem is solved by increasing the kinetic energy of the individual nuclei. In other words, increasing the temperature. Just like with compressing air, pressure is only a one-off deal in increasing temperature; the fusion reaction in the Sun was started using the residual heat of the collapse of matter forming the star (the gravitational potential energy) - I'm not sure how much of a factor was compression in particular. But again, this was only responsible for the initial ignition - today, the reaction is running entirely on the heat produced by fusion and the pressure supplied by gravity (which is actually lowered by the outward pressure of the energy released in the core - the two pressures form a stable equilibrium).\nAs a side note, despite the high temperatures and pressures, the fusion reaction powering the Sun is incredibly weak. If we could magically reproduce the same conditions on the Earth, it wouldn't really be usable for power generation at all - the energy produced is about 300 Watts per cubic metre at the very centre. To have a comparison, this is comparable to power density of a compost heap, and less than the power density of human metabolism. Yes, your own body is producing more power than the same volume of the centre of the Sun. I unsuccessfully tried to find data on power density of fission reactors, but a single CANDU reactor produces about 900 MW (that's \"million watts\"), and it sure isn't three million times as big.", "meta": {"post_id": 233409, "input_score": 76, "output_score": 82, "post_title": "Why is it cold on the sea floor if pressure heats things?"}}
{"input": "In Richard Rhodes' book, The Making of the Atomic Bomb, I was reading about the Trinity nuclear test. High speed photos were taken and this one is from <1ms after the detonation. The book mentions the irregular spikes at the bottom of the image, but does not explain them. Is there a specific reason or explanation for these  odd spikes in the relatively spherical explosion?\n\n\nNuclear explosion photographed less than one millisecond after detonation. From the Tumbler-Snapper test series in Nevada, 1952, showing fireball and \"rope trick\" effects. The fireball is about 20 meters in diameter in this shot", "output": "The answer is in wikipedia\n\nThe photograph on the right shows two unusual phenomena: bright spikes projecting from the bottom of the fireball, and the peculiar mottling of the expanding fireball surface.\nThe surface of the fireball, with a temperature over 20,000 kelvin, emits huge amounts of visible light radiation (more than 100 times the intensity at the sun's surface). Anything solid in the area absorbs the light and rapidly heats. The \"rope tricks\" which protrude from the bottom of the fireball are caused by the heating, rapid vaporization and then expansion of mooring cables (or specialized rope trick test cables) which extend from the shot cab (the housing at the top of the tower that contains the explosive device) to the ground. Malik observed that when the rope was painted black, spike formation was enhanced, and if it were painted with reflective paint or wrapped in aluminium foil, no spikes were observed \u2013 thus confirming the hypothesis that it is heating and vaporization of the rope, induced by exposure to high-intensity visible light radiation, which causes the effect. Because of the lack of mooring ropes, no \"rope trick\" effects were observed in surface-detonation tests, free-flying weapons tests, or underground tests.", "meta": {"post_id": 233798, "input_score": 49, "output_score": 77, "post_title": "Cause for spikes in Trinity nuclear bomb test"}}
{"input": "Last night my daughter was asking why a mirror \"always does that\" (referring to reflecting a spot of light). To help her figure it out, I grabbed my green laser pointer so she could see the light traveling from the source and reflecting off the mirror.\nBut as we were playing, I noticed something strange.\nRather than one spot, there were several. When I adjusted the angle to something fairly obtuse\n\nThe effect became quite pronounced\n\nAnd when you looked closely, you could actually see several beams\n\n(Of course, the beams actually looked like beams in real life. The picture gives the beams an elongated hourglass shape because those parts are out of focus.)\nI made these observations:\n\nThe shallower the angle, the greater the spread of the split beams and resulting dots.\nThe directionality of the reflection is due to the orientation of the mirror, not the laser pointer itself. Indeed, by rotating the mirror 360\u00b0 the string of dots would make a full rotation as well.\nI can count at least 8 individual dots on the wall, but I could only see 6 beams with the naked eye.\nIf you look at the split beam picture you can see a vertical line above the most intense dots. I didn't observe any intense spots of light there.\n\nAnd when I looked closely at the spot where the beam hit the mirror\n\nyou can see a double image. This was not due to camera shake, just the light reflecting off the dust on the surface of the glass, and a reflection of that light from the rear surface of the mirror.\nIt's been a few years since college physics, I remembered doing things like the double split experiment. I also remembered that light seems like it does some strange things when it enters liquid/prisms. I also know that the green laser has a certain wavelength, and you can measure the speed of light with a chocolate bar and a microwave.\nWhy does the mirror split the laser beam? How does that explain the effects that I saw? Is there any relation to the double split experiment, or the wavelength/speed of light?", "output": "You are seeing ghosting in a second surface mirror; most laser applications with mirror(s) - the good or critical ones - use what is called a first surface mirror. The other answers did explain it fairly well already but I wanted to add some terminology and a photo to help explain.\n\nExample of a second surface mirror (left) and a first surface mirror (right). In both pictures, the pen is touching the surface of the mirror. \"Ghosting\" (a faint reflection from the first layer) is visible in the left image.\nImage and caption from Wikipedia: https://en.wikipedia.org/wiki/First_surface_mirror", "meta": {"post_id": 241050, "input_score": 151, "output_score": 95, "post_title": "Why does a mirror split my laser beam?"}}
{"input": "Why is a second equal to the duration of 9,192,631,770 periods of radiation corresponding to the transition between two hyperfine levels of the ground state of the caesium-133 atom?\nWhy is the number of periods so complicated? \nIt could be any simple number, why is it exactly 9,192,631,770?", "output": "That number, 9192631770, was chosen to make the new definition of the second as close as possible to the less precise old second definition.  This means that--except for the most precise measurements--instruments calibrated before the new second was defined would not have to be recalibrated.", "meta": {"post_id": 243144, "input_score": 63, "output_score": 120, "post_title": "Why is a second equal to the duration of exactly 9,192,631,770 periods of radiations?"}}
{"input": "My question is concerning wikipedia article on Oh-my-God particle, to be precise, this paragraph:\n\nThis particle had so much kinetic energy it was travelling at 99.99999999999999999999951% the speed of light. This is so near the speed of light that if a photon were travelling with the particle, it would take 220,000 years for the photon to gain a 1 centimeter lead. Also, due to special relativity effects, from the proton's reference frame it would have only taken it around 10 seconds to travel the 100,000 light years across the Milky way galaxy. [1]\n\nI would like to see demonstration how the special relativity effect allows the particle to travel the distance in 10 seconds. \nEDIT:\nThanks for all responses, I have one more question: you all explain the situation from the \"Proton reference frame\". What about from \"Observer reference frame\"? We can imagine the observer (and also the whole universe around) moving at 99.99999999999999999999951% the speed of light comparing to the \"stationary\" proton. How will the proton look from this reference frame?\nEDIT2: \nThis was not a homework, just a weekend curiosity while reading wikipedia :-)", "output": "Key point in your quote is: \"from protons reference frame\". In the reference frame, travelling at a relativistic speed, length contraction is experienced. All the lengths in the direction of travel of the particle are contracted by Lorentz factor: $$ l'=\\frac{l}{\\gamma}$$\n$$ \\gamma = \\frac{1}{\\sqrt{1- \\frac{v^2}{c^2}}}$$\nSo $ \\gamma = \\frac{1}{\\sqrt{1-(0.9999999999999999999999951})^2}=3.19*10^{11}. $\nIn the reference frame of the particle, Milkyway is contracted by this factor. So the proton sees it only $2.96 * 10^9 m$ long. Now you can do the usual calculation to find time using the new contracted length and see that it would take only $2.96 * 10^9/ 3*10^8 = 9$ seconds to cross the Milkyway.\nLength contraction is kind of a consequence of 4D space-time we live in. If you look at time dilation (which also can be used to derive this result but is less intuitive in my opinion), the length contraction naturally arises from it. If you want to know more about length contraction you can easily more information on it. It is a topic which is usually well explained in any special relativity book,and I bet there are a lot of question on the topic on this website, search tags length-contraction and special-relativity.", "meta": {"post_id": 245898, "input_score": 21, "output_score": 52, "post_title": "Oh-my-god particle: How can it get through Milky way in 10 seconds?"}}
{"input": "I know that stars having a mass greater than or equal to 8 solar masses are termed \"massive stars\". But why is the cut-off 8 solar masses?", "output": "The division is conventionally made at the boundary between where stars end their lives as white dwarf stars and where more massive stars will end their lives in core collapse supernovae.\nThe boundary is set both empirically, by observations of white dwarfs in star clusters, where their initial masses can be estimated, and also using theoretical models.\nThe division is not arbitrary, it is of fundamental significance in studying the chemical evolution of a galaxy. The nucleosynthetic products of massive stars are fundamentally different to those of lower mass stars. The products also get recycled into the interstellar medium in a rather different way. Further, massive stars will affect the interstellar medium through supernova explosions in a manner that just doesn't occur in lower mass stars.\nThe reason for the 8 solar mass division (it is uncertain by about 1 solar mass and also depends to a certain extent on rotation and the initial metallicity of the star, so is not a sharp threshold) is that this is where the carbon/oxygen core (during He shell burning)$^{1}$ becomes hot enough to ignite further fusion. Core burning continues through to iron-peak elements, then there is a core mass collapse, a violent supernova and large quantities of processed material (O, Mg, Ne, Si, r-process elements) are ejected at high speeds. A neutron star or black hole remnant is formed. In lower mass stars, the core becomes degenerate, supported by electron degeneracy pressure, and core nucleosynthesis halts. The star ends its life by expelling the majority of its envelope (mostly H and He, with some enrichment with C, N and s-process elements) at low speeds through stellar winds. The degenerate core becomes a white dwarf.\n$^{1}$ Actually it may be possible to go a step further along the fusion ladder and still avoid a supernova. Stars with a mass just a little more than 8 solar masses (and possibly even as high as 10.5 solar masses -Garcia-Berro 2013) may produce Oxygen/Neon white dwarfs as the final outcome.", "meta": {"post_id": 246438, "input_score": 23, "output_score": 49, "post_title": "Why is the cut off mass for massive stars 8 solar masses? Why can't it be 10-11 solar masses or so?"}}
{"input": "Every advert I come across for LED bulbs advertise them as the equivalent of a higher W incandescent bulbs. \nThis makes no sense to me, if the room requires 40W to lighten it up then it'll always require 40W of energy. How is it possible for 6W of energy to do the job? What am I missing here?", "output": "A 40W incandescent light bulb has a luminous efficiency of 1.9%. That means only 1.9%, or 0.76W, of the energy consumed by the bulb ends up as visible light.\nLED bulbs have an efficiency of around 10% - the efficiency depends on the design and can be as high as 15% or as low as 8%. So a 6W LED bulb will produce between 0.9 and 0.48W of visible light.\nThe claim that a 6W LED bulb produces as much light as a 40W incandescent bulb requires the efficiency of the LED bulb to be 12.7%, which is well within the range of efficiencies that LED bulbs can achieve.", "meta": {"post_id": 252802, "input_score": 62, "output_score": 128, "post_title": "How is 6W equivalent to 40W, as claimed by adverts for LED light bulbs?"}}
{"input": "Clearly this is a hypothetical question.\nSay we bring a star baseball player into NASA, prep them appropriately for a mission in space, and fly them up to the International Space Station. They go on a spacewalk with a baseball, and at the apoapsis (highest, slowest point in the orbit) throw it retrograde as hard as they can. Could they decelerate the baseball enough that its periapsis (lowest, fastest point in the orbit) dips into Earth's atmosphere enough to de-orbit the ball over time?\n(Let's assume that the ball must de-orbit within about 10 years or less. 10,000 years is too long. Also, let's neglect any loss in mobility that a space suit might cause.)", "output": "John Rennie already gave the practical answer considering the atmosphere, noting that without doing anything objects near the ISS will deorbit quickly from drag. But that's letting reality get in the way of a good physics problem. I'll show that while a human can't send a ball crashing into the surface in one orbit, they can come close.\nThe ISS is listed as having a typical orbital velocity of $v = 7.66\\times10^3\\ \\mathrm{m/s}$. For a test particle in orbit around the Earth, gravitational parameter $GM_\\oplus = 3.98\\times10^{14}\\ \\mathrm{m^3/s^2}$, a circular orbit (which we'll assume for concreteness and simplicity) will have a semimajor axis (i.e. radius) of\n$$ a_0 = \\frac{GM_\\oplus}{v^2} = 6.79\\times10^6\\ \\mathrm{m}. $$\nIt will have a specific energy of $\\epsilon_0 = -GM_\\oplus/2a_0 = -v^2/2$, and a specific angular momentum of $h_0 = a_0v$.\nYour first instinct1 might be to throw the ball down with speed $\\Delta v$. This will add velocity perpendicular to its current velocity, so the change in energy is simple: $\\epsilon_\\mathrm{down} = \\epsilon_0 + \\Delta\\epsilon_\\mathrm{down}$, $\\Delta\\epsilon_\\mathrm{down} = (\\Delta v)^2/2$. Because the added velocity is along the radial direction, angular momentum does not change: $h_\\mathrm{down} = h_0$.\nGiven $\\epsilon$ and $h$, we can calculate the corresponding $a$ and $e$ (eccentricity) according to\n$$ a  = -\\frac{GM_\\oplus}{2\\epsilon}, \\qquad e  = \\sqrt{1-\\frac{h^2}{GM_\\oplus a}}. $$\nFrom there it's a simple matter to find the perigee according to\n$$ r_\\mathrm{per} = (1-e) a. $$\nPlugging in numbers for $\\Delta v = 100\\ \\mathrm{mph} = 44.7\\ \\mathrm{m/s}$, this gets us\n$$ r_\\mathrm{per,down} = 6.75\\times10^{6}\\ \\mathrm{m}. $$\nHowever, you can do better by throwing directly backward. This is the most efficient way to lower perigee. In this case, the new specific kinetic energy is $k_\\mathrm{back} = (v-\\Delta v)^2/2$, meaning the energy changes by $\\Delta\\epsilon_\\mathrm{back} = k_\\mathrm{back} - v^2/2$. The angular momentum also changes in this case: $h_\\mathrm{back} = a_0 (v-\\Delta v)$. Plugging in numbers gets us\n$$ r_\\mathrm{per,back} = 6.64\\times10^6\\ \\mathrm{m}. $$\nNow it turns out the highest point on Earth is Chimborazo, with an elevation above the center of the Earth of $r = 6.38\\times10^6\\ \\mathrm{m}$. Thus you could not force the ball to hit any part of the Earth with with velocity. However, the effect is not negligible. If we look at values of $r_\\mathrm{per}/r$, we started out at $1.064$ and got to either $1.059$ (throwing down) or $1.040$ (throwing backward).\nHow far into the atmosphere does throwing backward get you? According to this tool for the NRLSISE-00 atmosphere model, the density of the atmosphere going from an altitude of $415\\ \\mathrm{km}$ to $259\\ \\mathrm{km}$ increases by a factor of about $30$. Thus whatever drag the ISS experiences can be increased quite a bit with just a small change to the orbit.\n\nHow fast would you need to throw the ball to deorbit it in the absence of an atmosphere? If we throw backward, our old $a = a_0$ will be our new apogee. We want our new perigee to be the altitude $r$. Solving $r_\\mathrm{apo,per} = (1 \\pm e) a$ for $a$ tells us we want a new semimajor axis of $a = (a_0+r)/2$. Backtracking through $\\epsilon = -GM_\\oplus/2a$ this tells us what the new energy is and thus what the change in velocity must be (since we can only change kinetic energy with an instantaneous impulse). The answer is $120.\\ \\mathrm{m/s} = 268\\ \\mathrm{mph}$. This relatively small number compared to the orbital velocity is a reflection of just how close low-Earth orbit is to the surface compared to the radius of Earth.\n\n1Unless you've played Kerbal Space Program.", "meta": {"post_id": 253944, "input_score": 33, "output_score": 38, "post_title": "If we threw a baseball from the ISS, could we deorbit the ball?"}}
{"input": "I couldn't find any simple texts explaining the Kosterlitz-Thouless transition.  More specifically can someone explain the role of vortices in the transition.\nedit: links explaining the transition in a simple manner are also appreciated.  Also the explanation does not have to be mathematically rigorous, a qualitative explanation is just fine.\nedit 2:  To be clear, I know generally why it happens.  I believe it has to do with the crystal lattice having 4 fold symmetry (lattice atoms arranged in square fashion), and thus, the atoms do not have an easy axis to align there magnetic moments.  As a result, some weird vortices are created.", "output": "The Berezinskii-Kosterlitz-Thouless (BKT) scenario is one of the most beautiful transitions that is ubiquitous in 2d systems (though it can also occur in higher dimensions for particular kinds of models) that surprisingly requires non-perturbative effects (i.e. topological defects) to be realized. To understand all the fuss (and the nobel) around this transition, perhaps a bit of context might be useful.\nThere is a celebrated theorem in equilibrium statistical mechanics, the Mermin-Wagner-Hohenberg-Coleman theorem, that essentially tells us that a continuous symmetry cannot be broken spontaneously at any finite temperature in dimensions two or lower. This is because the goldstone modes generated upon breaking breaking a continuous symmetry have strong fluctuations in $d=1,2$ leading to the symmetry being restored at long distances (for $T>0$).\nNow for a 2d superfluid or superconductor the relevant order parameter is a complex scalar field $\\psi=|\\psi|e^{i\\phi}$ with a phase shift $U(1)$ symmetry. So immediately, one would imagine that the 2d superconducting or superfluidity transition would never occur at finite temperature (and hence these states would never exist in the thermodynamic limit). The same conclusion is reached for the XY ferromagnet ($O(2)$ classical spins on a 2d lattice) or a 2d nematic liquid crystal. What Kosterlitz and Thouless went on to show was that the theorem was true in that no continuous symmetry is spontaneously broken at finite temperature, but there still was a continuous phase transition (with a diverging correlation length) at some finite temperature in these systems. This is an important discovery as until then the Landau-Ginzburg paradigm used to describe continuous phase transitions and critical phenomena always associated spontaneous symmetry breaking with the transition (note that however it was rather well known that a first order transition didn't require any such symmetry breaking, c.f the regular Liquid-Gas transition). Later on, Polyakov extended this scenario to gauge theories (in the hope of describing confinement in QCD), resulting in some very nice work showing, for example, 2+1 \"compact\" QED has a gapped spectrum in the IR due to topological excitations (Phys. Lett. B 59, 1975, Nucl. Phys. B 120, 1977) and the SU($N$) Thirring model has a fermions condensing with finite mass in the IR without breaking the chiral symmetry of the theory (E. Witten, Nucl. Phys. B 145, 1978). It was also further extended by D. Nelson and B. Halperin in the context of 2d melting of crystalline solids (Phys. Rev. B 19, 1979) leading to the prediction of a new liquid crystalline hexatic phase.\nAfter this very long preamble, let us now look at what the transition is really all about. The simplest model that exhibits the BKT transition is the XY model. Consider a 2d lattice with unit 2d vectors at each site. Each vector $\\vec{S}_i$ (at site '$i$') being in the plane is specified by a single angle $\\theta_i$\n$$\n\\vec{S}_i=(\\cos\\theta_i,\\sin\\theta_i)\n$$\nThe model is now specified by the Hamiltonian of the system, which includes nearest neighbour interactions that prefer to align near by spins. In the absence of an external field, we have\n\\begin{align}\n\\beta\\mathcal{H}&=-\\dfrac{J}{k_B T}\\sum_{\\langle i,j\\rangle}\\vec{S}_i\\cdot\\vec{S}_j\\\\\n&=-\\dfrac{J}{k_B T}\\sum_{\\langle i,j\\rangle}\\cos(\\theta_i-\\theta_j)\n\\end{align}\nwhere $J>0$ is the interaction coupling constant. Now at low temperatures, as the fluctuations in the angles are going to be small, at long distances, we take the continuum limit of the lattice model assuming the angle field is slowly varying. Therefore writing $\\theta_i-\\theta_j=a\\nabla\\theta(x)\\cdot\\hat{e}_{ij}+O(a^2)$, where $a\\rightarrow0$ is the lattice spacing and $\\hat{e}_{ij}$ is the unit vector along the lattice bond joining sites $i$ and $j$, we get\n$$\n\\beta\\mathcal{H}_{\\mathrm{cont.}}=\\dfrac{\\beta J}{2}\\int\\mathrm{d}^2x\\ |\\nabla\\theta|^2\n$$\nFor small fluctuations ($\\theta\\ll 1$), the fact that $\\theta(x)$ is an angular variable is irrelevant, allowing us to compute the two point correlation function as the partition function is given by a gaussian integral.\n$$\n\\langle|\\theta(q)|^2\\rangle=\\dfrac{k_B T}{J\\ q^2}\n$$\nInverse Fourier transforming this, gives us\n\\begin{gather}\n\\langle\\theta(x)^2\\rangle=\\dfrac{k_B T}{2\\pi J}\\ln\\left(\\dfrac{L}{a}\\right)\\\\\n\\langle[\\theta(x)-\\theta(0)]^2\\rangle=\\dfrac{k_B T}{2\\pi J}\\ln\\left(\\dfrac{x}{a}\\right)\n\\end{gather}\n$L$ is the system size (IR cutoff) and $a$ the lattice spacing (UV cutoff). Hence as $L\\rightarrow\\infty$, $\\langle\\vec{S}(x)\\rangle=0$ implying the absence of long-ranged order and\n$$\n\\langle\\vec{S}(x)\\cdot\\vec{S}(0)\\rangle=\\left(\\dfrac{x}{a}\\right)^{-\\frac{k_BT}{2\\pi J}}\n$$\nThe two-point spin correlation goes to 0 as $x\\rightarrow\\infty$ denoting the absence of long ranged order (this is once again just the Mermin-Wagner theorem) though the decay is very slow. It is temperature dependent power law, instead of the usual exponential decay (with a finite correlation length) expected for a disordered phase. So the low temperature phase of the XY model has what is called quasi-long ranged order (QLRO) with infinite correlation length ($\\xi=\\infty$). As additional non-linearities coming from the gradient expansion can be shown to be irrelevant at long distances (in the RG sense), one is immediately led to believe that this power law decay persists for all temperatures. This is evidently wrong, as common sense (and also high temperature loop expansions of the lattice model) would tell us that at high temperatures, the interaction is irrelvant leaving each spin essentially independent and random, leading to decorrelations over a few lattice spacings.\nThe resolution is then obtained by noting that in forgetting the angular nature of $\\theta(x)$, the continuum gaussian \"spin wave\" theory does not account for windings of the angular phase field from $0$ to $2\\pi$. These are called vortices (and anti-vortices), and they correspond to topological defects in the $\\theta(x)$ field (which is then not defined at the core of the defect). They are perfectly reasonable configurations on the lattice whose continuum limit corresponds to point singularities in the angle field.\n\nNote that these configurations never appear in a perturbative gradient expansion and are hence non-perturbative in nature. At the continuum level, the vortex is a singular solution of the euler-lagrange equation.\n$$\n\\nabla^2\\theta=0\\\\\n\\oint_{\\Gamma}\\mathrm{d}s\\cdot\\nabla\\theta=2\\pi q\n$$\nwhere $\\Gamma$ is closed loop encircling the origin and $q$ is the integer \"charge\" of the vortex. This basically says that as you go once around the origin, the phase field $\\theta$ goes from $0$ to $2\\pi q$ (which is the same as $0$ for a periodic function as $q$ is an integer). Now for a single such defect, we have $|\\nabla\\theta|=q/r$ ($r$ being the radial coordinate), we can compute its energy to be,\n$$\nE_q=\\pi J q^2\\ln\\left(\\dfrac{L}{a}\\right)\n$$\nwhich diverges logarithmically in the thermodynamic limit. Hence single defects are never excited, but defect pairs with opposite charges (dipoles) have a finite energy and can be excited at finite temperature. Neglecting interactions for the time being, there is a very simple hand waving argument for the existence of a phase transition. The energy of a single free defect diverges, but at finite $T$ one must look at the free energy which includes entropic contributions too. The number of ways a single defect of size $\\sim a^2$ can be placed in a area of $L^2$ is roughly $(L/a)^2$. taking the logarithm to get the entropy, we have for the free energy\n$$\nF=E_q-TS=(\\pi J q^2-2 k_B T)\\ln\\left(\\dfrac{L}{a}\\right)\n$$\nAs the lowest charge excitations correspond to $q=1$, we have for $T>T_c=\\pi J/(2 k_B)$, the free energy becomes negative, which means that there is a proliferation of free defects in the system as entropy wins over the defect energetics. Including defect interactions doesn't change this picture (even $T_c$ remains the same). At $T=T_c$, one obtains a universal power law decay (upto log corrections)\n$$\n\\langle\\vec{S}(x)\\cdot\\vec{S}(0)\\rangle=\\left(\\dfrac{x}{a}\\right)^{-\\eta}\n$$\nwith $\\eta(T_c)=1/4$. Above $T_c$, we have a finite correlation length ($\\langle\\vec{S}(x)\\cdot\\vec{S}(0)\\rangle\\sim e^{-x/\\xi}$), which diverges exponentially fast as one approaches the transition form above.\nSo, here we have a model in which both low and high temperature phases are disordered, but there is a phase transition at finite $T$ that involves the proliferation and unbinding of pairs of topological defects. Thinking of the defects as electric charges, the transition is then from an insulating low temperature phase to a conducting plasma with freely moving ions at higher temperature.", "meta": {"post_id": 255909, "input_score": 35, "output_score": 41, "post_title": "What is the Kosterlitz -Thouless transition?"}}
{"input": "There is a device available for about $\\$40$, which fits in the palm of the hand, runs on two AA batteries, and can measure distances up to $50\\,{\\rm ft}$ to an accuracy of $\\sim \\frac{1}{8}''$ ($\\sim 3\\,{\\rm mm}$).\nLight travels $300,000\\,{\\rm km}\\,{\\rm s}^{-1}$, so it takes about $0.01\\,{\\rm ns}$ to travel the $3\\,{\\rm mm}$ equivalent to the device accuracy. If the device was counting ticks of a clock to measure the laser round-trip time (and therefore round-trip distance), the timing circuit would have to be running at about $50\\,{\\rm GHz}$. That's a pretty fast clock!\nIs that how these devices actually work? Run a very fast clock to measure off round-trip time, or is there some other principle of optics which is used in conjunction with cheap and simple electronics?", "output": "EDIT updated (improved) description of phase detection circuit\n\nThere are two principles used in these systems.\nThe first is the time-of-flight principle. As you noted, if you wanted to get down to 3 mm accuracy, you need timing resolution of 20 ps (20, not 10, because you would be timing the round trip of the light). That's challenging - certainly not the realm of cheap consumer electronics. The problem is not only the need to detect a fast edge - you have to detect the actual reflected pulse, and not every other bit of noise around. Signal averaging would be your friend: sending a train of pulses and timing their average round trip time helps. This immediately suggests that continuous modulation would probably work better - it has an inherent filtering characteristic.\nThat leads to the second way to get an accurate measurement: by comparing the phase of the emitted and returned signal. If you modulate your laser at a modest 300 MHz, the wave length of one complete \"wave\" is 1 m; to measure a change in distance of 3 mm (6 mm round trip), it is sufficient to detect a phase shift of $\\frac{6}{1000}\\times 2\\pi$. This is quite trivial with a circuit that squares the transmitted and reflected wave, then takes the XOR of the two signals and averages the result. Such a circuit will give minimum voltage when the two signals are exactly in phase, and maximum voltage when they are exactly out of phase; and the voltage will be very linear with phase shift. You then add a second circuit that detects whether signal 2 is high when signal 1 has a rising edge: that will distinguish whether signal 1 or signal 2 is leading.\n\nPutting the output of the logic gates into a low pass filter (resistor and capacitor) and feeding it into a low speed 12 bit ADC is sufficient to determine the phase with high accuracy. There are ready made circuits that can do this for you - for example, the AD8302\nThe only problem with the phase method is that you will find the distance modulo half the wavelength; to resolve this, you use multiple frequencies. There is only a single distance that has the right wavelength for all frequencies.\nA possible variation of this uses a sweeping frequency source, and detects the zero crossings of the phase - that is, every time the phase detector output is zero (perfectly in phase) you record the modulation frequency at which this occurred. This can easily be done very accurately - and has the advantage that \"detecting zero phase\" doesn't even require an accurate ADC. A wise man taught me many years ago that \"the only thing you can measure accurately is zero\". The distance would correspond to the round trip time of the lowest frequency which has a zero crossing - but you don't necessarily know what that frequency is (you may not be able to go that low). However, each subsequent zero crossing will correspond to the same increase in frequency - so if you measure the $\\Delta f$ between zero crossings for a number of crossings, you get an accurate measure of the distance. \nNote that a technique like that requires very little compute power, and most of the processing is the result of very simple signal averaging in analog electronics.\nYou can read for example US patent application US20070127009 for some details on how these things are implemented.\nA variation of the above is actually the basis of an incredibly sensitive instrument called the lock-in amplifier. The principle of a lock-in amplifier is that you know there is a weak signal at a known frequency, but with unknown phase (which is the case for us when we look at the reflected signal of a modulated laser). Now you take the input signal, and put it through an IQ detector: that is, you multiply it by two signals of the same frequency, but in quadrature (90\u00b0 phase shift). And then you average the output over many cycles. Something interesting happens when you do that: the circuit acts, in effect, as a phase sensitive bandpass filter, and the longer you wait (the more cycles' output you average over), the narrower the filter becomes. Because you have both the I and the Q signals (with their phase shift), you get both amplitude and phase information - with the ability to recover a tiny signal on top of a hug amount of noise, which is exactly the scenario you will often have with a laser range finder. See for example the wiki article.\nThe quadrature detection becomes quite trivial when you use a clock at twice the modulation frequency, and put two dividers on it: one that triggers on the positive edge, and one that triggers on the negative edge. A couple of (fast, electronic) analog switches and a simple RC circuit complete the project. You can now sweep the driving frequency and watch the phase on the two outputs \"wrap\" - and every time it makes a full circle, you have increased the frequency by an amount $\\Delta f = \\frac{c}{2d}$ where $c$ is the speed of light, and $d$ is the distance to the target. Which has turned a very hard measurement into a really easy one.", "meta": {"post_id": 255947, "input_score": 86, "output_score": 82, "post_title": "How do laser \"tape measures\" work?"}}
{"input": "The idea for this question comes from an example in cryptography, where supposedly 256-bit symmetric keys will be enough for all time to come (brute-forcing a 256-bit key is sort-of equivalent to counting to $2^{255}$, with some constant in front of it). While I don't really doubt this, I think it is an interesting thought experiment to what number (approximately of course) a theoretical \"perfectly efficient\" (define this as you want) computer, with infinite time and all the energy (including matter but not dark matter) in our galaxy available could count to. Counting to $x$ is defined as having some physical object go through $x$ different, predefined, measurable states. Sadly I'm missing the theoretical background to do this calculation myself properly, I could try it but I would have no idea if I missed something essential. I hope a \"fun\" question like this isn't out of scope for this site (feel free to direct me to a better place to ask this).\nAlternatively: What about all the energy in the known Universe?\nSince the idea for this question was key-length in cryptography, feel free to consider (or not consider) Grover's algorithm.\nEdit: As a comment suggests, if there's no good answer on what to consider a \"perfectly efficient computer\", maybe just take the values for a known processor.", "output": "A \"perfectly efficient\" computer can mean many things, but, for the purposes of this answer, let's take it to mean a reversible computer (explained further as we go). \nThe theoretical lower limit to energy needs in computing is the Landauer Limit, which states that the forgetting of one bit of information requires the input of work amounting $k\\,T\\,\\log 2$ so as to comply with the second law of thermodynamics. If the computer is reversible, i.e. its state at all times can be inferred its state at any other time, then there is no theoretical lower limit to its energy needs. By state here we mean the computer theoretical state of the CPU, not the physical quantum state (the former being a very small part of the latter; microscopic laws are reversible so that the full quantum state at any time can always in theory be inferred from the full quantum state at any time). An example of a nonreversible computation is one where you add two numbers and write the result over the memory formerly occupied by the addends. The two addends cannot be inferred from the computer's state (i.e. the sum) after the addition has taken place. Briefly, the reason for this situation is that if your calculation forgets, Nature does not, so if you erase memory, then that \"erased\" information must somehow wind up encoded in the full quantum state of the computer since microscopic laws are indeed reversible. The only way a system can \"absorb more information\", i.e. fully encode its past in its quantum state, is by accessing more and more quantum states, and that almost always means by getting hotter [see 1]. So, somewhere along the line you have to add energy to make this happen, and eventually you'll need to cool the computer to keep it working. The second law of thermodynamics then shows that if we want to keep the computer at a constant macrostate, we need to input the amount of work prescribed by Landauer's principle to do so[see ref. 2]. \nNow let's look at your problem. Counting can clearly be made into a reversible computation: each step is invertible and you can imagine simply clocking a simple digital counter backwards to achieve this. So in theory we could build a quantum (or other reversible) computer to count with no energy input whilst it is counting. However, when tallying up the forgetting of information, one needs to take into account initialization. That is, you need to begin with initialized registers to count with. You start your machine up by initializing them all to nought ..... but that means that there is a quantum state of each register that is \"forgotten\" as the machine is initialized. So, if you need memory of $N$ bits for your counting, you need to come up with $N\\,k\\,T\\,\\log 2$ joules to get your reversible computer initialized. Wikipedia tells me the Milky Way's mass is estimated to be $10^{12}$ solar masses, or about $2\\times 10^{30}\\times 10^{12}\\times 10^{17} =2\\times 10^{59}$ joules. If you can cool your computer to the temperature of the Cosmic Background Microwave Radiation, or $2.7{\\rm K}$, then the Landauer limit implies you can buy the initialization of $2\\times 10^{59} / (2.7\\times 1.38\\times 10^{-23}\\times \\log 2) \\approx 8\\times 10^{81}$ bits. You can't run your computer below $2.7{\\rm K}$ since it would then need energy for artificial cooling below its environment. \nSo that's then your rough answer: in theory you could count to the number :\n$$2^{8\\times 10^{81}}$$\nwith a reversible implementation of a counter given the stated energy budget.\nAnother limit that may be of interest in from the cryptographic viewpoint is the Bremmermann Limit, which limits how fast computations can evolve into their successive steps.\nIt should be noted how difficult it is to achieve the Landauer limit. If our counter forgets even one bit per counting cycle, the limit reduces to the still colossal $2\\times 10\u02c6{81}$. Yockey [see reference 3] claims in the early chapters of his book that the phenomenon of DNA replication during cell division thought of as a computer algorithm is the most efficient computation known, and consumes roughly one order of magnitude more energy than the Landauer limit, that is, roughly $10 k\\,T$ per forgotten bit. In the light of the Landauer limit, modern computers are staggeringly inefficient. 32Gbyte of RAM being overwritten at 1GByte per second and consuming 5 watts at 300K in being so (these are the figures for the computer these words are being written on) represents a forgetting that is eleven orders of magnitude more wasteful ($5 / (8\\times 10^9 \\times k \\times 300\\,\\log 2)\\approx 2\\times 10^{11}$) than the Landauer limit.\n\nReferences and Footnotes:\n[1]: To deepen your understanding of this statement, try working out and plotting the Shannon entropy of specification of the state of an ensemble of $N$ quantum harmonic oscillators at thermodynamic equilibrium as a function of temperature (answer: $\\left(\\frac{e^{\\beta_\\omega } \\beta_\\omega }{1-e^{\\beta_\\omega }}+\\log \\left(e^{\\beta_\\omega }-1\\right)\\right)/\\log (2)$ bits per oscillator, where $\\beta_\\omega = \\hbar\\omega/(k\\,T)$). You can immediately see what's going on: the Boltzmann probability distribution is here proportional to $p(n)\\propto\\exp\\left(-(n+\\frac{1}{2}) \\frac{\\hbar\\,\\omega}{k\\,T}\\right)$ and the tail gets longer, \"accessing more states\" as $T$ rises).\n[2] An excellent review paper for these concepts is\nCharles Bennett, \"The Thermodynamics of Computation: A Review\", Int. J. Theo. Phys., 21, No. 12, 1982)\n[3] \"Information Theory, Evolution, and the Origin of Life\", Hubert P. Yockey As a non biologist I don't feel qualified to judge this text. I did feel, however, that I understood the early chapters whence I gleaned the assertion about the efficiency of DNA replication well enough to be reasonably confident in the assertion's soundness, but I found most of the text beyond Chapter 2 utterly incomprehensible.", "meta": {"post_id": 257323, "input_score": 95, "output_score": 136, "post_title": "If we had a \"perfectly efficient\" computer and all the energy in the Milky-way available, what number could it count to?"}}
{"input": "In the search for neutrinos, Cowan and Reines discovered the electron anti-neutrino and named it as such. Why is the particle they discovered the anti-variety?\nThe reason we call electrons 'electrons' and not 'anti-electrons' is because the electrons are the variety we see all around us, as opposed to positrons. Since this makes it seem arbitrary, I figured it would have been more logical for the particle they discovered to just be a neutrino. This makes me believe that it's not just arbitrary, so what exactly was the reason?", "output": "To maintain lepton number as a conserved quantity.\nConsider, in detail, what's going on in a beta decay (well, I'm going to ignore the nuclear context). The reaction is then\n$$ n \\longrightarrow p^+ + e^- + \\nu \\,,$$\nwhere you should take the symbol $\\nu$ to mean some neutrino (without prejudice about matter-type or anti-matter-type for the moment).\nThere are zero leptons in the LHS of the equation, and on the RHS there is the electron (which counts as one lepton) and the neutrino. If we want lepton number to be conserved in the reaction (we do) then that has to have lepton number -1, which makes it an anti-particle. So, written properly the reaction is\n$$ n \\longrightarrow p^+ + e^- + \\bar{\\nu} \\,.$$\nLater still it was recognized as necessary to assign a flavor to the neutrino and the symbol becomes $\\bar{\\nu}_e$, but that's another story.", "meta": {"post_id": 262251, "input_score": 36, "output_score": 40, "post_title": "Why was the first discovered neutrino an anti-neutrino?"}}
{"input": "How did a gravitational wave travel from Livingston, Louisiana to Hanford, Washington in 7 milliseconds, when they are separated by 10 milli-light seconds (3002\u00a0km)?", "output": "The time delay depends on the direction the wave is travelling. If it is travelling along the line connecting Livingston and Hanford then the delay time would indeed be the Livingston-Hanford distance divided by $c$:\n\nHowever suppose the wave was travelling normal to the line connecting the two detectors. In that case the wave would arrive at both of them at exactly the same time and the delay would have been zero:\n\nSo the delay can be anything from zero up to $d/c$ depending on the direction the wave is travelling. The only real upset would be if the delay was greater than $d/c$ as that would mean the wave was travelling slower than light.", "meta": {"post_id": 262563, "input_score": 27, "output_score": 61, "post_title": "Why were the GW detections at Livingston and Hanford separated by 7 ms if the light travel time between them is 10 ms?"}}
{"input": "I was reading \"The Sixth Extinction: An Unnatural History\", by Elizabeth Kolbert, and there she comments that high level of $CO_{2}$ in the atmosphere lowers the pH of oceans (which makes sense) and, consequently, diminishes sound absorption:\n\nWHY is ocean acidification so dangerous? The question is tough to answer only because the list of reasons is so long. Depending on how tightly organisms are able to regulate their internal chemistry, acidification may affect such basic processes as metabolism, enzyme activity, and protein function. Because it will change the makeup of microbial communities, it will alter the availability of key nutrients, like iron and nitrogen. For similar reasons, it will change the amount of light that passes through the water, and for somewhat different reasons, it will alter the way sound propagates. (In general, acidification is expected to make the seas noisier.) \n\nI do understand that sound absorption depends on the material properties of the medium, but it is not trivial to me that more acidic water should have a different absorption than neutral water. Could anyone explain the physical mechanism behind this? \n(I'm not exactly sure that this belongs here, but since it deals with material properties, I thought it would fit better here than in Chemistry SE)", "output": "Hard though it is to believe, pH does have an effect on sound absorption in water.\nThere are some reactions that are affected by pressure, that is pressure changes their equilibrium. One example is the equilibrium between boric acid and the borate ion:\n$$ B(OH)_4\\,^- + H^+ \\rightarrow B(OH)_3 + H_2O $$\nIncreasing pressure pushes the reaction over to the right, and in doing so it absorbs energy. That energy comes from the energy in the sound wave, so unlikely though it may seem the chemical reaction absorbs sound. When the pressure is released the reaction moves back to the left, but the energy is released as heat not sound. The net result is sound energy gets converted to heat.\nThe problem with lowered pH is that as you lower the pH that moves the equilibrium to the right so there is less borate and more boric acid. That leaves less borate to absorb the sound. So lowered pH means less sound absorption.\nIf you're interested there is an article about this in Scientific American, and a more rigorous scientific publication here (sadly not available online). Lemon helpfully provided this link, Investigation of chemical sound absorption in sea water, and Googling should find you more relevant publications.\nThe effect is very small, not least because boric acid/borate concentrations in seawater are small. However sound propagates for huge distances in water - hundreds of miles. So even a small change in the water chemistry can have a measurable effect. The first of the papers I linked mentions that:\n\nSound attenuation in the low-frequency range is primarily due to boric acid relaxation and is a function of the seawater pH. \n\n(my emphasis)\nWhether that effect is actually big enough to deafen dolphins is a matter of some debate.", "meta": {"post_id": 265331, "input_score": 53, "output_score": 69, "post_title": "Why does sound absorption in oceans depend on the pH?"}}
{"input": "I'm curious as to what the Moon's orbit around the Sun looks like. If there's an answer, what's the intuition for it? Here are some things I'm assuming when trying to tackle this question:\n\nThe Moon's orbit must be concave toward the Sun.\nThe Moon speeds up as it goes toward the Sun, and it slows down as it moves away.\nFor an observer on the Earth, the Moon appears to orbit the Earth roughly $13$ times a year.\nThe Earth, the Moon, and the Sun remain in the same plane.", "output": "The Moon's orbit must be concave toward the Sun.\n\n\nThe Moon's orbit with respect to the Sun is always convex. This is easily proven by comparing the minimum possible gravitational acceleration of the Moon toward the Sun (5.7 mm/s2) and the maximum possible gravitational acceleration of the Moon toward the Earth (3.1 mm/s2). The acceleration vector, and hence the curvature, is always inward.\nThis means the Moon's orbit about the Sun doesn't look like either of the two images below:\n\n(Source: https://blogs.discovermagazine.com/badastronomy/2008/09/29/the-moon-that-went-up-a-hill-but-came-down-a-planet/#.V3xtsDcgtOo)\nPhil Plait is normally very good. This is one of those places where he was bad. The Moon's orbit about the Sun instead looks like this:\n\n(Source: http://www.math.nus.edu.sg/aslaksen/teaching/convex.html)\nA close-up view:\n\n(Source: http://www.wired.com/2012/12/does-the-moon-orbit-the-sun-or-the-earth/)\n\n\nThe Moon speeds up as it goes toward the Sun, and it slows down as it moves away.\n\n\nYes and no. The \u201cyes\u201d part is that the dominant feature of the Moon's orbit about the Sun is that the Moon orbits the Sun with the Earth. Ignoring the Moon's acceleration toward the Earth, the Moon's acceleration toward the Sun is greatest now in early July when the Earth/Moon system is closest to the Sun than at any other time.\nThe \u201cno\u201d part: The Moon is moving slightly away from the Sun when the Moon is in the second and third quarters. This is when the acceleration toward the Earth coincides with the acceleration toward the Sun. In the fourth and first quarters, the acceleration toward the Earth is directed against the acceleration toward the Sun, slowing the Moon down a bit with respect to the Sun.\n\nFor an observer on the Earth, the Moon appears to orbit the Earth roughly 13 times a year.\n\nThis is correct. More on this below.\n\nThe Earth, the Moon, and the Sun remain in the same plane.\n\nThis is incorrect. As noted by Diracology in his answer, the Moon's orbit about the Earth is slightly inclined with respect to the Earth's orbit about the Sun.\n\nNote that one of the sites I referenced (http://www.wired.com/2012/12/does-the-moon-orbit-the-sun-or-the-earth/) asked whether the Moon orbits the Earth or the Sun. That blog erroneously came up with the answer that the Moon orbits the Sun rather than the Earth. Looking at acceleration or the shape of the orbit is the wrong way to look at the question \u201cDoes object A orbit object X or object Y?\u201d\nOne answer to the question of \u201cdoes the Moon orbit the Earth or the Sun?\u201d is \u201cYes!\u201d \"Orbit\" is not a mutually exclusive term. If one insists on a singular answer, the right way to look at things is via energy rather than acceleration. Since the Moon is gravitationally bound to the Earth, the Moon does indeed orbit the Earth.", "meta": {"post_id": 266426, "input_score": 57, "output_score": 49, "post_title": "What does the Moon's orbit around the Sun look like?"}}
{"input": "I'm a highschool sophomore, bear this is mind when answering this question, in other words, the answer doesn't need to be in total layman terms, but it should be understandable by an applied highschool student.\n\nI have no idea what a standing wave is. Please, explain?\nBonus question: How is a standing wave related to the atomic orbit? It is my understanding that the atomic orbit is a mathematical function that describes the probability of an electron being at a certain place, but it is also the image of this function in terms of real space, (i.e. the actual 3 dimensional volume around the nucleus that a particular electron calls \"home\").", "output": "An animation is worth a million words:", "meta": {"post_id": 268454, "input_score": 18, "output_score": 47, "post_title": "What is a standing wave?"}}
{"input": "As you might already know, frequency of musical notes is arranged in a such a way that if, for example, an A note has frequency of $x$, another A note which is placed one octave higher would produce frequency of $2x$.\nSo here's my childhood toy glockenspiel:\n\nThis is where my question raised. If wave speed inside the bars were the same, as in strings of a guitar, then we would expect two notes that are one octave apart, like the two C's, would have a 2:1 length ratio. But measurement shows that they are designed in approximately 7:5 ratio or maybe $\\sqrt2$.\nNow I'm wondering what exactly causes this speed variation? Thickness or width doesn't vary meaningfully so it must be about the length but how would length of a bar affect wave speed inside it is what I'm asking here. And why this doesn't happen for strings.\nI'll measure and report length, width and thickness of the bars if necessary.", "output": "The answer to this question has significant overlap with my answer on piano tuning. There, I discuss how a thick wire has an extra restoring force, in addition to its tension, from its resistance to bending. This modifies the usual wave equation to\n$$v^2 \\frac{\\partial^2 y}{\\partial x^2} - A \\frac{\\partial^4 y}{\\partial x^4} = \\frac{\\partial^2 y}{\\partial t^2}.$$\nThis case is the other way around: the tension is negligible, so we only have the 'extra' term. The wave equation becomes\n$$-A \\frac{\\partial^4 y}{\\partial x^4} = \\frac{\\partial^2 y}{\\partial t^2}.$$\nPlugging in an ansatz of $\\cos(kx-\\omega t)$ gives the dispersion relation\n$$Ak^4 = \\omega^2.$$\nThat is, $\\omega \\propto k^2$. Since $k$ is inversely proportional to length,\n$$\\omega \\propto 1/L^2$$\nas desired. A bar $\\sqrt{2}$ times shorter makes a tone twice as high.\n\nAs you saw, the wave speed must change for the results to make sense. The phase velocity of a wave is $v_p = \\omega / k$, and this is constant only for the simplest dispersion relation, the ideal wave equation $\\omega = vk$. In this case, we have $\\omega \\propto k^2$, which implies $v_p \\propto k$. Waves with shorter wavelength, like the ones on the smaller bars, travel faster.\nBut this doesn't mean anything about the smaller bars is different. The phase velocity changes because wave propagation is fundamentally different on bars than strings; it exhibits dispersion.", "meta": {"post_id": 269669, "input_score": 60, "output_score": 68, "post_title": "Why aren't the lengths of the bars on a toy glockenspiel proportional to the wavelengths?"}}
{"input": "According to this article, a muon decays into one electron and two neutrinos.\nAccording to this article, elementary particles or fundamental particles are particles \"whose substructure is unknown, thus it is unknown whether it is composed of other particles.\"  I have also seen somewhere that it is a particle that cannot be reduced into other constituent particles.\nWhile perhaps not a sure thing, seems like the decay indicates that the muon may be just a composite particle, perhaps consisting of one electron and two neutrinos?\nBased on this, why does the muon fit with the above definition of an elementary or fundamental particle?\nI realize there are much more complicated, historical reasons as to why it was included in the Standard Model, but this question is just related so how it fits (or doesn't fit) the stated definition above.\nIt seems to me that we really can only get solid evidence of elementary vs. composite when we smash the particles together and see what comes out and compare that to all the masses, energies and momentum before and after?  Until we do that with muons, how can we know with much certainty?\nAnd perhaps we'll have a better answer with a Muon collider:   https://en.wikipedia.org/wiki/Muon_collider\nTo that point, seems that electrons may not be fundamental after all:\nhttps://www.sciencedaily.com/releases/2016/04/160404111559.htm", "output": "Addressing misconceptions\nFirst, I address some misconceptions in your question.\n\nthe decay indicates that the muon may be just a composite particle\n\nThe fact that the muon decays at all is not evidence that it's composite. It's tempting to say that if a particle $A$ can decay into $B$ and $C$, then it must be \"made of\" $B$ and $C$. However, this doesn't work out, because almost all particles have multiple decay channels. For example, hydrogen in the $2s$ state can release a photon to go to the $1s$ state, but it can also rarely do this by releasing two photons. As a more extreme example, parapositronium can completely annihilate, turning into two photons, but it can also turn into four. \nWe think about particle decay in terms of couplings of quantum fields to each other: an excitation in one field can decay into excitations in others. As Feynman put it, those final excitations don't exist \"inside\" the original one, any more than the word \"cat\" is bouncing around inside you because you can spend energy to say it. \n\nTo that point, seems that electrons may not be fundamental after all: https://www.sciencedaily.com/releases/2016/04/160404111559.htm\n\nThis article is about some of the weird ways that large collections of electrons in solids can behave collectively, but it's not related to whether or not electrons themselves are composite. It's important to keep this in mind when reading news releases, because the people who study what electrons in solids do unfortunately tend to give the resulting phenomena the same names as the particles we search for in colliders, leading to a lot of popular confusion. \nAnswering the question\nWith that in mind, you're still right, in the sense that it's completely natural to think that the muon might be composite. If you were a scientist in the 1950s, for example, the muon would be just one more particle discovered along with a zoo of mesons and hadrons. Today, we know that all of those mesons and hadrons turned out to be composites of quarks. So why not think of the muon as composite as well?\nIndeed, in the early days, the similarity of the muon and electron was taken as possible evidence that the muon was an excited state of the electron, just like the $2s$ state is an excited state of hydrogen. If this were the case, one would expect the muon to often decay by emitting a photon, $\\mu \\to e \\gamma$, but this was found not to be the case. Instead, the decays involving neutrinos dominate. \nNow you might ask, why can't the muon be a composite of the electron bound to some neutrinos? This idea doesn't work out because there's no force we know of that would do the job: even in the 1950s it was known that neutrinos interacted extremely weakly. Getting a neutrino to interact with an electron at all is less likely than winning the lottery, so it seems extremely unlikely that it would be simultaneously possible to bind them together.\nAnother difficulty of any composite muon theory is explaining the muon g-factor, which determines its magnetic moment. Elementary particles are expected to have $g \\approx 2$. The composite proton and neutron violate this by a good margin,\n$$g_p \\approx 5.59, \\quad g_n \\approx -3.82$$\nwhile the electron and muon have \n$$g_e \\approx 2.002, \\quad g_\\mu \\approx 2.002.$$\nThat $0.002$ isn't evidence for compositeness either, because it's precisely what you would expect for a perfectly elementary particle, once you include quantum field theoretic effects. In fact, the electron and muon $g$-factors have been measured to far more decimal places than I've shown, and the results match the Standard Model prediction to great precision. Making the electron and muon composite without upsetting this agreement would seem to require a seriously contrived model, or a miracle.\nA meta-difficulty\nThese already are big difficulties, but if you imagine being a scientist in the 1950s, the quark model had its own problems (such as the complete nonobservability of individual quarks), but it earned support because of its ability to account for huge numbers of hadrons, and predict new ones. And today, people consider theories where the Higgs boson is composite, because it helps give it an appropriate mass. \nThe meta-difficulty for the muon is that it's only worth trying to make it composite if there's some payoff you expect, such as (1) the completion of a theoretical picture, (2) new predictions, or (3) ways to calculate quantities (such as the muon mass) that we otherwise have to take as inputs. \nThe first reason doesn't apply, because the muon already has a perfectly good place in the Standard Model: it has to be there because of the family structure of the theory, and this structure is rigid enough that without the muon, the Standard Model would be mathematically inconsistent because of gauge anomalies.\nThe second reason doesn't apply, either. It's not like we have a series of weird particles lying around that could be explained as further composites of the electron. And since we've measured properties of the muon to exquisite precision, just about any theory of muon compositeness will make \"predictions\" that we already know to be wrong! You have to work extremely hard just to avoid that. (Admittedly, the muon $g$-factor does seem to deviate a bit from the predicted value, and this does receive attention -- it's just that compositeness isn't the kind of thing that would help here.)\nThe third reason could potentially apply. However, explaining the masses of particles like the electron and muon is an infamously hard problem, even if you don't take them as composite. Certainly, heads would turn if you came up with a simple theory that gave the muon-electron mass ratio to many decimal places, but decades of failed attempts have made this seem unlikely. \nIf you just disregarded these reasons, and made a contrived model where the muon was composite, tuning all the constants involved to precisely the values needed to hide all deviations from the Standard Model, then it would \"work\"... but it would also be scientifically useless. \nOf course, it's also completely possible that muons might turn out to be non-elementary, because in science it's impossible to ever prove a negative! At the moment, this possibility is not under active investigation. But it's not heresy either. If sufficiently strange experimental results appeared in the future, scientists could be right back to tinkering with composite electrons and muons, trying their best to understand the results, and the universe.", "meta": {"post_id": 274858, "input_score": 47, "output_score": 55, "post_title": "Why are muons considered to be elementary particles in the Standard Model?"}}
{"input": "The light from the center of andromeda isn't blue-shifted, according to images from the Hubble space telescope, but the light from the areas around the center is blueshifted. Is there a reason for this in general relativity?", "output": "I am going to attempt an explanation based on this image that you posted a link to in the comments.\nWhat you are looking at here is a broad-band visible wavelength colour image of the Andromeda galaxy. The colours you see are the colours of the stars, gas and dust that make up the galaxy. Stars can be red if they are cool, or if they are seen through large quantities of dust, which tends to be concentrated in the plane and spiral arms of the galaxy.\nBlue stars tend to be hot, massive and therefore young (since massive stars have short lives). They tend to be found in spiral arms and close to the galactic plane.\nWhat you are seeing here is that in the outskirts of the galaxy, the starlight is dominated by some hot, young stellar populations that are comparatively unobscured by dust. In contrast, towards the centre in the \"bulge\" you are seeing an older population of stars, predominantly in the form of red giants and cool main sequence stars. Hence these do not look blue. \nThese colours have nothing to do with redshift. The average motion of Andromeda towards us is about 300 km/s. This produces a blueshift in visible light (550nm) of a mere 0.55nm, which will not affect the perceived visible colour at all. In fact if such small shifts were perceptible in the colour of an image then the rotation of Andromeda, of around $\\pm 250$ km/s, would be even more readily seen, in that one side of the galaxy would be red and one blue! Clearly that is not the case.", "meta": {"post_id": 275251, "input_score": 5, "output_score": 59, "post_title": "Why is Andromeda only partially blue-shifted?"}}
{"input": "It is said that immediately after the Big Bang, the fundamental forces of nature were unified. It is also said that later they decoupled, becoming separate forces.\nIndeed, if we look at the list of states of matter on Wikipedia we see:\n\n\nWeakly symmetric matter: for up to $10^{\u221212}$ seconds after the Big Bang the strong, weak and electromagnetic forces were unified.\n\nStrongly symmetric matter: for up to $10^{\u221236}$ seconds after the Big Bang, the energy density of the universe was so high that the four forces of nature \u2014 strong, weak, electromagnetic, and gravitational \u2014 are thought to have been unified into one single force. As the universe expanded, the temperature and density dropped and the gravitational force separated, a process called symmetry breaking.\n\n\n\nNot only is it said that the forces were once unified, but this is also somehow related to the states of matter.\nI want to understand all of this better. What does it truly mean, from a more rigorous standpoint, to say that the forces were unified and later decoupled? How this relate to the states of matter anyway?", "output": "When we say that the forces were unified, we mean that the interaction was described by a single gauge group. For example, in the original grand unified theory, this group was $SU(5)$, which spontaneously broke down to $SU(3) \\times SU(2) \\times U(1)$ as the universe cooled. These three components yield the strong, weak, and electromagnetic forces respectively.\nI'll try to give a math-free explanation of what this means. To do so I'll have to do a decent amount of cheating.\n\nFirst, consider the usual strong force. Roughly speaking, the \"strong charge\" of a quark is a set of three numbers, the red, green, and blue color charges. However, we don't consider the strong force three separate forces because these charges are related by the gauge group: a red quark can absorb a blue anti-red gauge boson and become blue. In the case of the strong force, we call those bosons gluons, and there are 8 of them.\nAt regular temperatures, the strong force is separate from the electromagnetic force, whose charge is a single number, the electric charge, and whose gauge boson is the photon. There is no gauge boson that converts between color charge and electric charge; the two forces are independent, rather than unified.\nWhen we say all the forces were unified, we mean that all of the Standard Model forces were described by a common set of charges, which are intermixed by 24 gauge bosons. These gauge bosons are all identical in the same way that the 8 gluons are identical. In particular, you can't point at some subset of the 24 and say \"these are the gluons\", or \"this one is the photon\". They were all completely interchangeable.\n\nAs the universe cooled, spontaneous symmetry breaking occurred. To understand this, consider slowly cooling a lump of iron to below the Curie temperature. As this temperature is passed, the iron spontaneously magnetizes; since the magnetization picks out a specific direction, rotational symmetry is broken.\nIn the early universe, the same process occurred, though the magnetization field is replaced with an analogue of the Higgs field. This split apart the $SU(5)$ gauge group into the composite gauge group we have today. \nThe process of spontaneous symmetry breaking is closely analogous to phase transitions, like the magnetization of iron or the freezing of water, which is why we talk about 'strongly/weakly unified' matter as separate states of matter. Like the iron, which state we are in is determined by the temperature of the universe. However, a exact theoretical description of this process requires thermal quantum field theory.", "meta": {"post_id": 275428, "input_score": 36, "output_score": 56, "post_title": "What does it mean to say that \"the fundamental forces of nature were unified\"?"}}
{"input": "I'm a PhD student in mathematics and I have no problem in understanding what irreducible representation are. I mean that the mathematical side is not a particular problem. Nevertheless I have some problems in understanding why and in which sense these irreducible representations are considered as particles. What does this mean that if I have two electrons I have two irreducible representations of some group? And in this case of which dimension? And if they collide what do I get? Another representation? Can I get the equation of motion from this view? etc...\nI know that this question should be already answered here somewhere, but I cannot find it anywhere explicitly stated in plain English. Can someone explain to me in plain English what's the point here?", "output": "As you probably know, the Lie group of physical transformations of a quantum system acts on the Hilbert space of states of the system by means of a (strongly-continuous projective-) unitary representation of the group. $G \\ni g \\mapsto U_g$.  This action is effective also on the observables of the system, represented by self-adjoint operators: The action of $g$ on the observables $A$ is $U_gAU^*_g$. The latter represents the observable $A$ after the action of the transformation $g$ on the physical system. This transformation has a twice intepretation. We can imagine that either it acts on the system or on the reference frame, our choice does not matter in this discussion.\nNow let us focus on physics. There are natural elementary systems, called elementary particles. These systems are completely determined by fixing some real numbers corresponding to the values of some observables. Within the most elementary version of the story, these numbers are the mass $m$ which \nmay attain a few positive numbers experimentally observed ad recorded,\nand the spin $s$ which may attain any number in  $\\{1/2, 1, 3/2,...\\}$. Different values of the pair $(m,s)$ mean different particles. \nThese numbers have the property that they are invariant under the action of the most general symmetry group, I mean the (proper orthochronous) Poincar\u00e9 group.  A type of particle has the same fixed numbers $m$ and $s$ independently from the reference frame we use to describe it  and the various reference frames are connected by the transformation of Poincar\u00e9 group.\nPassing to the theoretical quantum description of an elementary particle, in view of my initial remark, we are committed to suppose that its Hilbert space supports a representation of Poincar\u00e9 group ${\\cal P} \\ni g \\mapsto U_g$ (I omit technical details). Moreover there must be observables representing the mass $M$ and the spin $S$ that, on the one hand they must be invariant under the action of the group, i.e., $U_gM U_g^* =M$ and $U_gS U_g^* =S$ for every $g \\in \\cal P$. On the other hand they must assume fixed values $M=mI$ and $S=sI$.\nWigner noticed that a sufficient condition to assure the validity of these constraints  is that ${\\cal P} \\ni g \\mapsto U_g$ is irreducible.\nIndeed, $M$ and $S$ can be defined using the self-adjoint generators of the representation, since they are elements of the universal enveloping algebra of the representation of the Lie algebra of $\\cal P$ induced by the one of $\\cal P$ itself. As expected, one finds $U_gM U_g^* =M$ and $U_gS U_g^* =S$ for every $g \\in \\cal P$. But, if $U$ is also irreducible, re-writing the identities above as \n$U_gM  =M U_g$ and $U_gS  =S U_g$ for every $g \\in \\cal P$, Schur's lemma entails that $M=mI$ and $S=sI$ for some real numbers $s,m$.\nTo corroborate Wigner's idea  it turns out that the two constants $m$ and $s$ are really sufficient to bijectively classify all possible strongly-continuous unitary irreducible representations of $\\cal P$ with \"positive energy\" (the only relevant in physics). \nThe mathematical theory of representations of ${\\cal P}$ autonomously fixes the possible values of $s$ and they just coincide with the observed ones. The values of $m$ are not fixed by the theory of representations where any value $m\\geq 0$ would be possible in principle, though not all $m \\geq 0$ correspond to the masses of observed elementary particles.\nIf you have many elementary particles, the Hilbert space of the system is the tensor product of the Hilbert spaces of the elementary particles and there is a corresponding unitary representation of Poincar\u00e9 group given by the tensor product of the single irreducible representations. Obviously, the overall representation is not irreducible.\nADDENDUM. I would like to specify that the irreducible representations of the group of Poincar\u00e9 I discussed above are the faithful ones whose squared mass is non-negative. Moreover, there is another parameter which classifies the irreducible representations of  Poincar\u00e9 group. It is a sign corresponding to the sign of energy. Finally not all particles  fit into Wigner's picture.", "meta": {"post_id": 277986, "input_score": 52, "output_score": 52, "post_title": "Why are particles thought of as irreducible representations, in plain English?"}}
{"input": "I try to read up on diffraction limiting and gaussian beams, but it always gives a result saying it\u2019s characterized by an angle which is the edges of a cross section of a cone. Which says nothing on the physical limits of how I choose that angle.  It just describes (once far away from the narrowest point) the shape of a cone: width is proportional to distance from the narrowest spot.\nSo what\u2019s to prevent you from describing a laser that's arbitrarily tight, at some arbitrary distance, and learning that the required angle is very close to 0?\nWhat, in principle, prevents this from happening?\nIn Robert L. Forward\u2019s \u201chard science fiction\u201d novel he based the lightsail description on actual research but did not go into detail in the novel.  As a plot point, the senders had to enlarge the size of a focusing device (probably a zone plate) to send the beam for breaking, so the larger sending aperture was necessary for a longer distance.  Now they didn\u2019t finish in time due to funding but saved the mission by doubling the light frequency instead. So that sounds like a diffraction effect.\nI suppose the relationships of what is possible is simply scaled by wavelength, and once you divide that out there is some relationship between the possible size of the emitter, size of the target, and separation between them?  Why does making the emitter larger allow the target to be smaller?\nTo use some concrete numbers, suppose the target is a lightsail 1 light year away, and it is 1 Mm in diameter.  The wavelength in Forward\u2019s story was green light, and if higher frequency allows better focus than the best beam would be the highest frequency that doesn\u2019t start causing issues by breaking bonds in the atoms reflecting it, so just past visible where UV begins.  What size emitter (final focusing device) would be needed?", "output": "So what\u2019s to prevent you from describing a laser that's arbitrarily tight, at some arbitrary distance, and learning that the required angle is very close to 0?\n\nThe half angle of divergence is given by \n$$\\theta = \\frac{\\lambda}{\\pi w_0}$$\nwhere $w_0$ is the beam diameter at its narrowest point (the waist, or focal point), and $\\lambda$ is the optical wavelength.\nTypically with a laser the waist point is at the output aperture of the laser cavity, and the beam diverges from there. If you built your laser with a converging output, you'd push the waist point out along the z direction (the direction of propagation) but you'd also reduce the waist diameter, so ultimately increase the divergence angle. \nSo you can't choose to produce an arbitrarily small divergence angle unless you're prepared to build a laser with an arbitrarily large output aperture.\n\nTo use some concrete numbers, suppose the target is a lightsail 1 light year away, and it is 1 Mm in diameter.\n\n1 light year is about $10^{16}$ meters. So you need a divergence angle on the order of $10^6 / 10^{16}$, or $10^{-10}$ radians. You need a beam waist of\n$$ w_0 > \\frac{\\lambda}{\\pi \\theta} $$\nIf your wavelength is 500 nm, this means a waist of at least 1600 m. In practice I expect there would be \"unique engineering challenges\" in designing optics close enough to ideal to achieve this kind of divergence. I've never heard of beam divergence being measured in units smaller than milliradians, but I don't know what's been achieved in hero experiments.", "meta": {"post_id": 279872, "input_score": 36, "output_score": 40, "post_title": "How well can a laser be focused over interstellar range?"}}
{"input": "Why do we use AC (Alternating Current) for long distance transmission of electrical power?\nI know that AC is such a current that changes polarity (magnitude and direction) and has fixed poles.", "output": "The first point to make is: We don't always use AC. There is such a thing as high voltage DC for long-distance power transmission. However its use was rare until the last few decades, when relatively efficient DC-to-AC conversion techniques were developed. \nThe second point is to debunk the common answer given, which is \"because DC won't go long distances\". Sure it will. In fact DC is sometimes better for long distance (because you don't have capacitive or EM radiation losses). \nBut, yes, AC has been used traditionally. The \"why\" is because of a series of \"a leads to b leads to c leads to...\":\n\nYou want to lose as little power as possible in your transmission lines. And all else being equal, the longer the distance, the more power you'll lose. So the longer the distance, the more important it is to cut the line losses to a minimum. \nThe primary way that power lines lose power is in resistive losses. They are not perfect conductors (their resistance is non-zero), so a little of the power that goes through them is lost to heat - just as in an electric heater, only there, of course, heat is what we want! Now, the more power is being carried, the more is lost. For a given amount of power being transferred, the resistive loss in the transmission line is proportional to the square of the current! (This is because power (in watts) dissipated in a resistance is equal to current in amperes, squared, multiplied by the resistance in ohms. These losses are commonly called \"I-squared-R\" losses, pronounced \"eye-squared-arr\", \"I\" being the usual symbol for current in electrical work.) So you want to keep the current as low as possible. Low current has another advantage: you can use thinner wires. \nSo, if you're keeping the current low, then for the same amount of power delivered, you'll want the voltage high (power in watts = EMF in volts multiplied by current in amps). e.g. to halve the current, you'll need to double your voltage. But this will cut your losses to one fourth of what they were! That's a win. Now high voltage does have its issues. The higher the voltage, the harder it is to protect against accidental contact, short circuits, etc. This means higher towers, wider spacing between conductors, etc. So you can't use the highest possible voltage everywhere; it isn't economical. But in general, the longer the transmission line, the higher the voltage that makes sense. \nUnfortunately you can't deliver power to the end use point (wall outlets and light sockets) at the high voltages that make sense for the long distance transmission lines. (that could be several hundred thousand volts!) Practical generators can't put out extremely high voltages either (they would arc horrendously). So you need an easy way to convert from one voltage to another. \nAnd that's most easily done with AC and transformers. Transformers can be amazingly efficient: power distribution transformers routinely hit 98 or 99 percent efficiency, far higher than any mechanical machine. \n\nBy contrast, to convert DC voltages you essentially have to convert to AC, use a transformer, and then convert back to DC. The DC-to-AC step, in particular, will have losses. Modern semiconductors have made this a lot better in recent years, but it still  generally isn't worth doing until you're talking about very long transmission lines, where the advantages of DC outweigh the conversion losses. \nAnother reason that AC prevailed over Edison's DC was that the AC system scaled better, as it permitted a small number of power plants far from the city, instead of a large number of small plants about a mile apart. Edison didn't just want to sell light bulbs; he (or, rather, his investors) wanted to sell lighting systems to businesses. There was no power distribution network and he didn't want to have to build one before selling light bulbs. At first he was selling lighting systems to commercial buildings, maybe some large apartment buildings; each building would have its own independent generator in the basement, just as you typically have water heaters today.  He was initially successful because he (unlike other developers of light bulbs) was selling and installing complete systems, generator and switchgear and wiring and all, not just bulbs. \nThis would have saved a lot of the clutter of overhead wires in cities, but it was clear that this would not work well for small businesses or homes (what homeowner or shopkeeper wants to worry about keeping a generator running?). Westinghouse wanted to build a hydroelectric power generation plant at Niagara Falls - one plant to run all of New York City and beyond. Tesla designed an entire AC distribution system  involving AC induction generators, step-up transformers to boost their output as necessary for long distances, then conversion through a series of step-downs to what is called \"distribution voltage\", and then finally to the lines that are connected to houses and light commercial buildings. This was a far more scalable system than Edison's. And, of course, AC works for light bulbs as well as for motors. \nSpeaking of that... Yet another reason for preferring AC is that AC, and particularly the three-phase AC that Westinghouse's system used (everywhere except at the last drop, from pole distribution transformer to house), was and remains far better for running high-power motors. All practical motors are really AC motors at heart; \"DC\" motors use commutators to switch the polarity to the coils back and forth as needed, to maintain rotation - essentially they make their own AC internally. But commutators require brushes, which wear out and require maintenance; they make sparks (which interfere with radio), etc. Whereas an AC induction motor needs no commutator nor even slip rings. AC power transmission systems start with three-phase AC generators and maintain three-phase right up to the pole transformer. So they can easily deliver three-phase where it's needed (medium and larger commercial and industrial), but the pole transformer can tap off single-phase for homes and light commercial use. \nThree-phase AC power distribution has another advantage in not needing a dedicated \"return\" wire. (Just FYI, the system Tesla originally designed for Westinghouse was two-phase. They changed to three-phase after the work of Mikhail Dolivo-Dobrovolsky in 1888-1891.)\nDuring the \"war of the currents\" Edison made much of the greater danger of AC. It's true that a given level of current, through a given path through the body, is more dangerous at AC than at DC. That's because AC at power line frequencies will cause involuntary muscle contractions - paralysis - and heart fibrillation at far lower current than DC (about a tenth). (See allaboutcircuits.com) However the end-user connectors were designed to minimize risk of contact with live parts, and we keep making them better in that regard. \n(Aside: I have long held that the electrical transformer should be regarded as one of the basic machines, along with the lever, the inclined plane, the block and tackle, etc. They have the same property of trading off one thing for another. In the case of the mechanical basic machines it's power traded for distance, for an equivalent amount of work done; in the transformer it's voltage for current, at equivalent power. Hydraulic cylinder master-slave pairs should be in the \"simple machines\" list too. ;) )", "meta": {"post_id": 280611, "input_score": 57, "output_score": 101, "post_title": "Why do we use AC for long distance transmission?"}}
{"input": "A few months ago, there were press releases about a possible second Higgs mode unveiled by LHC experiments. Or perhaps a new particle even more surprising like a graviton ... There was no certainty about this new particle because experiments didn't get the 5-sigma precision on the measures.\nI'd like to know whether this new particle is now officially out or not, and a bit more information about it (its nature, mass, etc. if known).", "output": "One of the searches performed at the LHC consists in selecting events in which two high energy photons are produced ($\\gamma\\gamma$ channel) and in computing their invariant mass - the energy of the photon pair in its rest frame $m_{\\gamma\\gamma}$ - distribution. The standard-model predicts these events to be fairly common (mainly produced by direct QCD processes), and the SM prediction is called the \"background\". The $m_{\\gamma\\gamma}$ distribution of this background is quite smooth and if a new particle were to decay into two photons, there might appear a clean, significant peak around the particle mass in the data on top of the background.\n(There are many other ways new physics could alter the distribution shape, but this is one of the easiest, and also more or less what happens in the Higgs case, who can decay into two photons).\nIn 2015, the ATLAS and CMS experiments at the LHC collected around 3 $\\text{fb}^{-1}$ of data at a center of mass energy of 13 TeV. Their independent analyses both revealed a mild excess of events above background around a mass of 750 GeV, for which one of the simple explanations was a new spin-0 or spin-2 particle decaying into two photons.\n\n(Source: http://resonaances.blogspot.fr/)\nHowever, because of the finite amount of events, it was very well plausible that this excess was nothing but a statistical fluctuations - we had been 'lucky' and observed more events then there should be on average for $m_{\\gamma\\gamma}$ around 750 GeV \u2014 and the analysis uses a frequentist approach to evaluate the probability to observe more extreme fluctuations that the excesses observed. This probability is required to be higher than approximately $10^{-7}$ (5 'sigmas') but it was closer to 3 sigmas (corresponding to a probability $\\sim 10^{-4}$). Moreover, since a large mass range was probed, it was not so unlikely to get at least one excess of this amplitude. This effect is called the Look-Elsewhere Effect. Once accounted for, it reduced the significance down to 1.9 sigma if I recall correctly in the case ATLAS' spin-0 search.\nFor these reasons, more data needed to be collected in order to conclude about the nature of this excess (true signal of new physics or just a statistical fluctuation).\nThe LHC collected much more data this year and in August ATLAS and CMS experiments published their new results at ICHEP based on roughly 15 $fb^{-1}$ of data. It appears that the excess is now gone.\n\n(Source: http://resonaances.blogspot.fr/)", "meta": {"post_id": 285236, "input_score": 21, "output_score": 36, "post_title": "What news about the second Higgs mode (or the mysterious particle) is anticipated to be seen at LHC around 750 GeV?"}}
{"input": "Why is it that there exists a classical macroscopic field of photons and gravitons but not that of $Z, W^{\\pm}$ bosons, gluons or Higgs boson?", "output": "There are slightly different answers for each particle type.\n\nMacroscopic photon and graviton fields can exist because these forces are long-ranged, which is directly related to the force carriers being massless. The $W$ and $Z$ bosons are extremely massive, so they're very short ranged and we can't see their effects on a macroscopic scale.\nAnother problem is that classical macroscopic fields arise from quantum fields through coherent states, which require many particles. Since the $W$ and $Z$ are so heavy, this is impossible at everyday energies.\nGluons are massless, but there's no macroscopic gluon field because the strong interaction becomes stronger at low energies, strong enough to bind color charged particles together. As a result, every macroscopic object we see has exactly zero color charge, so we see no gluon field.\nThe Higgs boson is massive, but there is a macroscopic Higgs field, in the sense that the field value is nonzero due to spontaneous symmetry breaking. You are, in some sense, measuring this field every time you measure the mass of an elementary particle. However, you can't make macroscopic waves in the Higgs field (i.e. excitations about the constant field value) for the same reason as the $W$ and $Z$.", "meta": {"post_id": 287718, "input_score": 26, "output_score": 38, "post_title": "Why we don't have macroscopic fields of Higgs bosons or gluons?"}}
{"input": "What does the Pauli Exclusion Principle mean if time and space are continuous?\nAssuming time and space are continuous, identical quantum states seem impossible even without the principle. I guess saying something like: the closer the states are the less likely they are to exist, would make sense, but the principle is not usually worded that way, it's usually something along the lines of: two identical fermions cannot occupy the same quantum state", "output": "Real particles are never completely localised in space (except possibly in the limit case of a completely undefined momentum), due to the uncertainty principle. Rather, they are necessarily in a superposition of a continuum of position and momentum eigenstates.\nPauli's Exclusion Principle asserts that they cannot be in the same exact quantum state, but a direct consequence of this is that they tend to also not be in similar states.\nThis amounts to an effective repulsive effect between particles.\nYou can see this by remembering that to get a physical two-fermion wavefunction you have to antisymmetrize it.\nThis means that if the two single wavefunctions are similar in a region, the total two-fermion wavefunction will have nearly zero probability amplitude in that region, thus resulting in an effective repulsive effect.\nTo see this more clearly, consider the simple 1-dimensional case, with two fermionic particles with partially overlapping wavefunctions.\nLet's call the wavefunctions of the first and second particles $\\psi_A(x)$ and $\\psi_B(x)$, respectively, and let us assume that their probability distributions have the form:\n\nThe properly antisymmetrized wavefunction of the two fermions will be given by:\n$$\n\\Psi(x_1,x_2) = \\frac{1}{\\sqrt2}\\left[ \\psi_A(x_1) \\psi_B(x_2)- \\psi_A(x_2) \\psi_B(x_1) \\right].\n$$\nFor any pair of values $x_1$ and $x_2$, $\\lvert\\Psi(x_1,x_2)\\rvert^2$ gives the probability of finding one particle in the position $x_1$ and the other particle in the position $x_2$.\nPlotting $\\lvert\\Psi(x_1,x_2)\\rvert^2$ we get the following:\n\nAs you can clearly see from the picture, for $x_1=x_2$ the probability vanishes. This is an immediate consequence of Pauli's exclusion principle: you cannot find the two identical fermions in the same position state.\nBut you also see that, the more $x_1$ is close to $x_2$, the smaller is the probability, as it must be due to continuity of the wavefunction.\nAddendum: Can the effect of Pauli's exclusion principle be thought of as a force in the conventional $F=ma$ sense?\nThe QM version of what is meant by force in the classical setting is an interaction mediated by some potential, like the electromagnetic interaction between electrons.\nThis corresponds to additional terms in the Hamiltonian, which says that certain states (say, same charges very close together) correspond to high-energy states and are therefore harder to reach, and vice versa for low-energy states.\nPauli's exclusion principle is conceptually entirely different: it is not due to an increase of energy associated with identical fermions being close together, and there is no term in the Hamiltonian that mediates such \"interaction\" (important caveat here: this \"exchange forces\" can be approximated to a certain degree as \"regular\" forces).\nRather, it comes from the inherently different statistics of many-fermion states: it is not that identical fermions cannot be in the same state/position because there is a repulsive force preventing it, but rather that there is no physical (many-body) state associated with them being in the same state/position.\nThere simply isn't: it's not something compatible with the physical reality described by quantum mechanics.\nWe naively think of such states because we are used to reasoning classically, and cannot wrap our heads around what the concept of \"identical particles\" really means.\nOk, but what about things like degeneracy pressure then?\nIn some circumstances, like in dying stars, Pauli's exclusion principle really seems to behave like a force in the conventional sense, contrasting the gravitational force and preventing white dwarves from collapsing into a point.\nHow do we reconcile the above described \"statistical effect\" with this?\nWhat I think is a good way of thinking about this is the following:\nyou are trying to squish a lot of fermions into the same place.\nHowever, Pauli's principle dictates a vanishing probability of any pair of them occupying the same position.\nThe only way to reconcile these two things is that the position distribution of any fermion (say, the $i$-th fermion) must be extremely localised at a point (call it $x_i$), different from all the other points occupied by the other fermions.\nIt is important to note that I just cheated for the sake of clarity here: you cannot talk of any fermion as having an individual identity: any fermion will be very strictly confined in all the $x_i$ positions, provided that all the other fermions are not.\nThe net effect of all this is that the properly antisymmetrized wavefunction of the whole system will be a superposition of lots of very sharp peaks in the high dimensional position space.\nAnd it is at this point that Heisenberg's uncertainty comes into play: very peaked distribution in position means very broad distribution in the momentum, which means very high energy, which means that the more you want to squish the fermions together, the more energy you need to provide (that is, classical speaking, the harder you have to \"push\" them together).\nTo summarize: due to Pauli's principle the fermions try so hard to not occupy the same positions, that the resulting many-fermion wavefunction describing the joint probabities becomes very peaked, highly increasing the kinetic energy of the state, thus making such states \"harder\" to reach.\nHere (and links therein) is another question discussing this point.", "meta": {"post_id": 288762, "input_score": 37, "output_score": 60, "post_title": "What's the point of Pauli's Exclusion Principle if time and space are continuous?"}}
{"input": "I have a conjecture about quantum channels.  On which examples should I test it before I try to prove it, ask it on StackExchange, or write a paper about it?\n(Note: This is meant to be a reference question.  But whenever I have a conjecture, I do test it on the channels listed, and it has saved me a lot of time trying to prove wrong statements.)", "output": "The following is a list of channels you can use to test your conjecture. (Some are special cases of subsequent ones -- it makes more sense to first test the special cases.)  Here, $d$ is the dimension of the space. \n\nThe identity channel:\n$$\n\\mathcal E(\\rho)=\\rho\\ .\n$$\nThe fully depolarizing channel:\n$$\n\\mathcal E(\\rho) = \\mathrm{tr}(\\rho)\\,\\tfrac1d\\mathbb I\\ .\n$$\nThe depolarizing channel:\n$$\n\\mathcal E(\\rho) = \\gamma\\rho + (1-\\gamma)\\mathrm{tr}(\\rho)\\,\\tfrac1d\\mathbb I\n$$\nfor $-\\tfrac1d\\le\\gamma\\le1$.\nThe dephasing channel\n$$\n\\mathcal E(\\rho) = \\gamma\\rho + (1-\\gamma)Z\\rho Z\n$$\nfor qubits (with $Z$ the Pauli $Z$ matrix), and possibly some suitable generalizations for $d>2$.  If your conjecture is not rotationally symmetric, test rotated versions as well.\nThe \"Wirf weg und mach neu\u2122\" (\"throw away and make new\") channel:\n$$\n\\mathcal E(\\rho) = \\mathrm{tr}(\\rho)\\,\\sigma\n$$\nwith $\\sigma$ a density matrix. Obviously a generalization of 2, but test e.g. pure states $\\sigma$.\nThe Holevo-Werner channel:\n$$\n\\mathcal E(\\rho) = \\tfrac{1}{d-1}(\\mathrm{tr}(\\rho)\\,\\mathbb I -\\rho^T)\\ ,\n$$\nwhere $\\rho^T$ is the transposition.\nEntanglement breaking channels:\n$$\n\\mathcal E(\\rho) = \\sum_i \\mathrm{tr}(\\rho F_i) \\sigma_i\n$$\nwith $\\sigma_i$ density matrices and the $F_i$ a POVM (i.e., $F_i\\ge0$ and $\\sum F_i=\\mathbb I$).  Obviously a generalization of 5: These are all channels which can be realized by first measuring the input and then preparing a new output conditioned on the measurement outcome.  (You might want to test specific instances of these, like $F_i$ projectors onto subspaces, and $\\sigma_i$ supported in the same subspace, etc.)\n\nIf your conjecture has passed all examples: Congratulations!  It is probably true, and you can start proving it!", "meta": {"post_id": 291810, "input_score": 35, "output_score": 39, "post_title": "Canonical examples of quantum channels"}}
{"input": "In another post, I claimed that there was obviously an oscillating charge in a hydrogen atom when you took the superposition of a 1s and a 2p state. One of the respected members of this community (John Rennie) challenged me on this, saying:\n\nWhy do you say there is an oscillating charge distribution for a hydrogen atom in a superposition of 1s and 2p states? I don't see what is doing the oscillating.\n\nAm I the only one that sees an oscillating charge? Or is John Rennie missing something here? I'd like to know what people think.", "output": "In this specific instance you are correct. If you have a hydrogen atom that is completely isolated from the environment, and which has been prepared in a pure quantum state given by a superposition of the $1s$ and $2p$ states, then yes, the charge density of the electron (defined as the electron charge times the probability density, $e|\\psi(\\mathbf r)|^2$) will oscillate in time.\nIn essence, this is because the $2p$ wavefunction has two lobes with opposite sign, so adding it to the $1s$ blob will tend to shift it towards the positive-sign lobe of the $p$ peanut. However, the relative phase of the two evolves over time, so at some point the $p$ signs will switch over, and the $1s$ blob will be pushed in the other direction.\nIt's worth doing this in a bit more detail. The two wavefunctions in play are\n$$\n\\psi_{100}(\\mathbf r,t) = \\frac{1}{\\sqrt{\\pi a_0^3}} e^{-r/a_0} e^{-iE_{100}t/\\hbar}\n$$\nand\n$$\n\\psi_{210}(\\mathbf r, t) = \\frac{1}{\\sqrt{32\\pi a_0^5}} \\, z \\, e^{-r/2a_0} e^{-iE_{210}t/\\hbar},\n$$\nboth normalized to unit norm. Here the two energies are different, with the energy difference\n$$\\Delta E = E_{210}-E_{100} = 10.2\\mathrm{\\: eV}=\\hbar\\omega = \\frac{2\\pi\\,\\hbar }{405.3\\:\\mathrm{as}}$$\ngiving a sub-femtosecond period. This means that the superposition wavefunction has a time dependence,\n$$\n\\psi(\\mathbf r,t) \n= \\frac{\\psi_{100}(\\mathbf r,t) + \\psi_{210}(\\mathbf r,t)}{\\sqrt{2}}\n=\n\\frac{1}{\\sqrt{2\\pi a_0^3}} \ne^{-iE_{100}t/\\hbar}\n\\left(\ne^{-r/a_0} \n+\ne^{-i\\omega t}\n\\frac{z}{a_0}\n\\frac{\n e^{-r/2a_0}\n }{\n 4\\sqrt{2}\n}\n\\right)\n,\n$$\nand this goes directly into the oscillating density:\n$$\n|\\psi(\\mathbf r,t)|^2\n=\n\\frac{1}{2\\pi a_0^3}\n\\left[\ne^{-2r/a_0}\n+\n\\frac{z^2}{a_0^2}\n\\frac{\n e^{-r/a_0}\n }{\n 32\n}\n+\nz\n\\cos(\\omega t)\n\\,\n\\frac{e^{-3r/2a_0}}{2\\sqrt{2}a_0}\n\\right]\n.\n$$\nTaking a slice through the $x,z$ plane, this density looks as follows:\n\nMathematica source through Import[\"http://halirutan.github.io/Mathematica-SE-Tools/decode.m\"][\"https://i.stack.imgur.com/KAbFl.png\"]\nThis is indeed what a superposition state looks like, as a function of time, for an isolated hydrogen atom in a pure state.\nOn the other hand, a word of warning: the above statement simply states: \"this is what the (square modulus of the) wavefunction looks like in this situation.\" Quantum mechanics strictly restricts itself to providing this quantity with physical meaning if you actually perform a high-resolution position measurements at different times, and compare the resulting probability distributions. (Alternatively, as done below, you might find some other interesting observable to probe this wavefunction, but the message is the same: you don't really get to talk about physical stuff until and unless you perform a projective measurement.)\nThis means that, even with the wavefunction above, quantum mechanics does not go as far as saying that \"there is oscillating charge\" in this situation. In fact, that is a counterfactual statement, since it implies knowledge of the position of the electron in the same atom at different times without a (state-destroying) measurement. Any such claims, tempting as they are, are strictly outside of the formal machinery and interpretations of quantum mechanics.\nAlso, and for clarity, this superposition state, like any hydrogen state with support in $n>1$ states, will eventually decay down to the ground state by emitting a photon. However, the lifetime of the $2p$ state is on the order of $1.5\\:\\mathrm{ns}$, so there's room for some four million oscillations of the superposition state before it really starts decaying.\nA lot of atomic physics was forged in a time when a nanosecond was essentially instantaneous, and this informed a lot of our attitudes towards atomic superposition states. However, current technology makes subpicosecond resolution available with a modest effort, and femtosecond resolution (and better) is by now routine for many groups. The coherent dynamics of electrons in superposition states has been the name of the game for some time now.\nIt's also important to make an additional caveat: this is not the state that you will get if you initialize the atom in the excited $2p$ state and wait for it to decay until half of the population is in the ground state. In a full quantum mechanical treatment, you also need to consider the quantum mechanics of the radiation field, which you usually initialize in the vacuum, $|0\u27e9$, but that means that after half the population has decayed, the state of the system is\n$$\n|\\Psi\u27e9= \\frac{|1s\u27e9|\\psi\u27e9+|2p\u27e9|0\u27e9}{\\sqrt{2}},\n$$\nwhere $|\\psi\u27e9$ is a state of the radiation field with a single photon in it, and which is therefore orthogonal to the EM vacuum $|0\u27e9$. What that means is that the atom and the radiation field are entangled, and that neither can be considered to even have a pure quantum state on its own. Instead, the state of the atom is fully described (for all experiments that do not involve looking at the radiation that's already been emitted) by the reduced density matrix obtained by tracing out the radiation field,\n$$\n\\rho_\\mathrm{atom} \n= \\operatorname{Tr}_\\mathrm{EM}\\mathopen{}\\left(|\\Psi\u27e9\u27e8\\Psi|\\right)\\mathclose{}\n=\\frac{|1s\u27e9\u27e81s|+|2p\u27e9\u27e82p|}{2},\n$$\nand this does not show any oscillations in the charge density.\n\nFoundational issues about interpretations aside, it's important to note that this is indeed a real, physical oscillation (of the wavefunction, at least), and that equivalent oscillations have indeed been observed experimentally.\nDoing it for this hydrogen superposition is very challenging, because the period is blazingly fast, and it's currently just out of reach for the methods we have at the moment. (That's likely to change over the next five to ten years, though: we broke the attosecond precision barrier just last week.)\nThe landmark experiment in this regard, therefore, used a slightly slower superposition, with a tighter energy spacing. In particular, they used two different fine-structure states within the valence shell of the Kr+ ion, i.e. the states $4p_{3/2}^{-1}$ and $4p_{1/2}^{-1}$, which have the same $n$ and $L$, but with different spin-orbit alignments, giving different total angular momenta, and which are separated by\n$$\\Delta E=0.67\\:\\mathrm{eV}=2\\pi\\hbar/6.17\\:\\mathrm{fs}.$$\nThat experiment is reported in\n\nReal-time observation of valence electron motion. E. Goulielmakis et al. Nature 466, 739 (2010).\n\nThey prepared the superposition by removing one of the $4p$ electrons of Kr using tunnel ionization, with a strong ~2-cycle pulse in the IR, which is plenty hard to get right. The crucial step, of course, is the measurement, which is a second ionization step, using a single, very short ($<150\\:\\mathrm{as}$) UV burst of light.\nHere the superposition you're probing is slightly more complicated than the hydrogen wavefunction the OP asks about, but the essentials remain the same. Basically, the electron is in a superposition of an $l=1,m=0$ state, and an $l=1,m=1$ state, with an oscillation between them induced by the difference in energy given by the spin-orbit coupling.\nThis means that the shape of the ion's charge density is changing with time, and this will directly impact how easy it is for the UV pulse to ionize it again to form Kr2+. What you end up measuring is absorbance: if the UV ionizes the system, then it's absorbed more strongly.\nThe absorbtion data therefore shows a clear oscillation as a function of the delay between the two pulses:\n\n\n\nThe pictures below show a good indication of how the electron cloud moves over time. (That's actually the hole density w.r.t. the charge density of the neutral Kr atom, but it's all the same, really.) However, it's important to note that the pictures are obviously only theoretical reconstructions.\nAnyways, there you have it: charge densities (defined as $e|\\psi(\\mathbf r)|^2$) do oscillate over time, for isolated atoms in pure superposition states.\n\nFinally, the standard caveats apply: the oscillations caused in quantum mechanics by superpositions are only valid for pure, isolated states. If your system is entangled with the environment (or, as noted above, with the radiation it's already emitted), then this will degrade (and typically kill) any oscillations of local observables. If the overall state of the world is in some meaningful superposition of energy eigenstates, then that state will indeed evolve in time. However, for heavily entangled states, like thermal states or anything strongly coupled to the environment, any local observables will typically be stationary, because each half of an entangled state doesn't even have a proper state to call its own.", "meta": {"post_id": 293359, "input_score": 43, "output_score": 84, "post_title": "Is there oscillating charge in a hydrogen atom?"}}
{"input": "I have found this specific image here (Loong found out that it is the Soviet Joe 4 test of the 400 kiloton RDS-6 warhead at the Semipalatinsk test site on August 12, 1953):\n\nAlso an impressive Youtube Video of the same explosion\nAs you see, an inverted trumpet cloud is forming around\nthe rising mushroom stem. I have never seen this strange\npicture before.\nMy educated guess is that the mushroom is rising through\na layer of supersaturated air (which cannot form clouds\nnormally because of missing seeds provided now by the explosion),\ncausing fog which is pushed evenly outside by the high air \npressure inside the stem.\n\nIs there a name for the phenomenon of the trumpet cloud?\nIs my explanation correct and if not, what is the cause\nof the trumpet?", "output": "This is called a 'skirt' or 'bell' and it is indeed a condensation effect: humid air is entrained by the rising column, and water then condenses out as the pressure falls.  These droplets, if they get big enough fast enough, then fall with respect to the rising air, resulting in these skirts.\nCondensation phenomena are fairly common with nuclear (and other large) explosions.\nThis is covered in the Wikipedia article.", "meta": {"post_id": 302154, "input_score": 37, "output_score": 40, "post_title": "Nuclear bomb mushroom cloud with trumpet formation"}}
{"input": "To keep the question brief: in bridge design, why is the arch structure favoured compared to a simple flat one?\nIn other words, how does the curved platform alter the force decomposition of the load on the bridge, such that it can uphold larger loads? I imagine that intuitively the load is no longer applied in a fully normal  manner (orthogonal) onto the bridge, but I cannot convince myself.", "output": "Fracture happens under tension - that is, when you pull on something hard enough, it rips. The key to understanding the arc design hinges on understanding that it lowers the maximum tensile force.\nTake a simple beam, support it at the ends, and hang something off the center:\n\nTension at the bottom, and compression at the top, are needed to balance the torque created by the vertical forces of the supports, and the load in the middle. Obviously, the further apart the supports are, or the greater the load, the greater the tension. When that tension reaches a critical value the beam will fail.\nNow if we shape the bridge into an arc, we get this:\n\nThe additional lateral forces on the arc cause compression in the beam, this reduces the net tension at the bottom and makes the beam better able to support the load. You can make things even better by spreading the load more evenly, designing the shape of the arc to better optimize the load distribution, etc - but the diagram should give you a sense of the underlying principle.\nUpdate\nThe lateral forces are perhaps most easily understood by looking at a V shaped structure: you know intuitively that such a structure would collapse unless you provide some torque at the apex to keep the legs together, or provide sufficient friction at the base of the legs to keep them together. You can also see that the force needed near the hinge (which is provided by the red \"tension\" stress in my upper diagram) would need to be much greater than the force provided by friction at the bottom (lateral forces from the support on the arch).", "meta": {"post_id": 302461, "input_score": 30, "output_score": 50, "post_title": "Why are arched bridges stronger than flat bridges?"}}
{"input": "I am wondering whether there is some systematical approach to find Feynman diagrams for S-matrix (or to be more precise for $S-1$ since I am interested in scattering amplitude). For example in $\\phi^3$ theory and its variations (e.g. $\\phi^2\\Phi$) there is ridiculous amount of diagrams even on two-loop level. I am particularly interested in $\\phi\\phi \\rightarrow \\phi\\phi$ or $\\phi\\Phi \\rightarrow \\phi\\Phi$ scattering. \nWhat I usually do (for this kind of scattering) is this:\n\nI draw tree level diagrams\nOne-loop diagrams are obtained from tree level diagrams by connecting lines together with single additional line in every possible manner (e.g. adding loop on internal line or connecting external leg and internal line ...)\nTwo-loop diagrams are obtained from one-loop diagrams by adding a line as in previous point. I do not add loops on external legs since those are irrelevant (at least for S-matrix).\nSome of the options generated with this algorithm result in the same diagrams - I use Wick's theorem to check if diagrams are in correspondence with the same contraction or not, if yes - then redundant diagrams are erased.\n\nI think that above algorithm should work (please correct me if I am wrong), however it is very cumbersome and impractical. It also does not work for $\\phi^4$ theories since one can not simply \"connect lines\" there - but this does not make much trouble because $\\phi^4$ has pretty simple diagrams up to two-loop level.\nSo my question is - is there some useful method how to obtain Feynman diagrams at least up to two-loop level in scalar field theory(ies)? Keep in mind I am beginner in QFT.", "output": "OP has discovered on their own a primitive application of the Schwinger-Dyson equations. Congratulations!\nA very gentle introduction to the Schwinger-Dyson equations.\n... or how to calculate correlation functions without Feynman diagrams, path integrals, operators, canonical quantisation, the interaction picture, field contractions, etc.\nNote: we will include operators and Feynman diagrams anyway so that the reader may compare our discussion to what they already know. The diagrams below have been generated using the LaTeX package TikZ. You can click on the edit button to see the code. Feel free to copy, modify, and use it yourself. \nNote: we will not be careful with signs and phases. Factors of $\\pm i$ may be missing here and there. \nConsider an arbitrary QFT defined by an action $S$. The most important object in the theory is the partition function, $Z$. Such an object can be defined either in the path-integral formalism or in the operator formalism (cf. this PSE post):\n\\begin{equation}\nZ[j]\\equiv N^{-1}\\int\\mathrm e^{iS[\\varphi]+j\\cdot\\varphi}\\mathrm d\\varphi\\equiv\\langle \\Omega|\\mathrm T\\ \\mathrm e^{ij\\cdot\\phi}|\\Omega\\rangle\\tag1\n\\end{equation}\nwhere $N$ is a normalisation constant; $\\Omega$ is the vacuum state; and $\\mathrm T$ is the (covariant) time ordering symbol.\nIn either case, one can show that $Z[j]$ satisfies the functional differential equation\n\\begin{equation}\n\\color{red}{(iS'[\\delta]-j)Z[j]\\equiv 0}\\tag2\n\\end{equation}\nknown as the Schwinger-Dyson (SD) equation. (Here, $\\delta=\\frac{\\delta}{\\delta j}$ denotes functional differentiation with respect to $j$.)\nA fascinating fact about the SD equation is that it can be used to introduce a third formulation of QFT, together with the path-integral and the operator formalisms. In the SD formulation, one forgets about path-integrals and operators. The only object is the partition function $Z[j]$, which is defined as the solution of the SD equation. The only postulate is SD, and everything else can be derived from it.\nIn this answer we shall illustrate how the standard perturbative expansion of QFT is contained in SD. Intuitively speaking, the method is precisely OP's algorithm \"take the lower order, and connect any two lines in all possible ways\". For completeness, we stress that SD also contains all the non-perturbative information of the theory as well (e.g., the Ward-Takahashi-Slavnov-Taylor identities), but we will not analyse that.\nScalar theory.\nOur main example will be so-called $\\phi^4$ theory:\n\\begin{equation}\n\\mathcal L=\\frac12(\\partial\\phi)^2-\\frac12 m^2\\phi^2-\\frac{1}{4!}g\\phi^4\\tag3\n\\end{equation}\nwhere $\\phi\\colon\\mathbb R^d\\to\\mathbb R$ is a real scalar field.\nThe SD equation for the partition function is\n\\begin{equation}\n\\left[\\partial^2\\frac{\\delta}{\\delta j(x)}+m^2\\frac{\\delta}{\\delta j(x)}+\\frac{1}{3!}g\\frac{\\delta^3}{\\delta j(x)^3}-ij(x)\\right]Z[j]\\equiv 0\\tag4\n\\end{equation}\nIf take a functional derivative of this equation of the form\n\\begin{equation}\n\\frac{\\delta}{\\delta j(x_1)}\\frac{\\delta}{\\delta j(x_2)}\\cdots \\frac{\\delta}{\\delta j(x_n)}\\tag5\n\\end{equation}\nand then set $j\\equiv 0$, we get\n\\begin{equation}\n\\begin{aligned}\n(\\partial^2+m^2)G(x,x_1,&\\dots,x_n)+\\frac{1}{3!}gG(x,x,x,x_1,\\dots,x_n)=\\\\\n&=i\\sum_{m=1}^n\\delta(x-x_m)G(x_1,\\dots,\\hat x_m,\\dots,x_n)\n\\end{aligned}\\tag6\n\\end{equation}\nwhere the hat $\\hat\\cdot$ over an argument means that it is to be omitted. Here, $G(x_1,\\dots,x_n)$ is the $n$-point function,\n\\begin{equation}\nG(x_1,\\dots,x_n)\\equiv \\langle 0|\\mathrm T\\ \\phi(x_1)\\cdots\\phi(x_n)|0\\rangle\\tag7\n\\end{equation}\nwhich in the SD formalism is defined as\n\\begin{equation}\nG(x_1,\\dots,x_n)\\equiv \\frac{\\delta}{\\delta j(x_1)}\\frac{\\delta}{\\delta j(x_2)}\\cdots \\frac{\\delta}{\\delta j(x_n)}Z[j]\\bigg|_{j=0}\\tag8\n\\end{equation}\nWe see that the SD equations are nothing but a system of partial differential equations for the correlation functions. In general, these equations are impossible to solve explicitly (essentially, because they are non-linear), so we must resort to approximation methods, i.e, to perturbation theory.\nLet us begin by introducing the inverse of $(\\partial^2+m^2)$,  the propagator:\n\\begin{equation}\n\\Delta(x)\\equiv (\\partial^2+m^2)^{-1}\\delta(x)=\\int\\frac{\\mathrm e^{ipx}}{p^2-m^2+i\\epsilon}\\frac{\\mathrm dp}{(2\\pi)^d}\\tag9\n\\end{equation}\nWe may use the propagator to integrate the SD equations as follows:\n\\begin{equation}\n\\begin{aligned}\n\\color{red}{G(x,x_1,\\dots,x_n)}&\\color{red}{=\\frac{1}{3!}g\\int\\Delta(x-y)G(y,y,y,x_1,\\dots,x_n)\\,\\mathrm dy+}\\\\\n&\\color{red}{+i\\sum_{m=1}^n\\Delta(x-x_m)G(x_1,\\dots,\\hat x_m,\\dots,x_n)}\n\\end{aligned}\\tag{10}\n\\end{equation}\nwhich is a system of coupled integro-differential equations of the Fredholm type, whose solutions can formally be written as a Liouville-Neumann series in powers of $g$. This is the basis of perturbation theory. Moreover, these equations are precisely the formalisation of OP's algorithm.\nWe stress that the whole paradigm of perturbation theory is contained in equation $(10)$. In particular, one need not introduce Feynman diagrams at all: the perturbation series can be extracted directly from $(10)$. That being said, and to let the reader compare our upcoming discussion to the standard formalism, let us introduce the following graphical notation: a four-vertex is represented by a node with four lines, and a propagator is represented by a line\n\nand the $n$-point function is represented as a disk with $n$ lines:\n\nIn graphical terms, one typically represents the SD equations $(10)$ as follows:\n\nPerturbation theory is based on the (somewhat unjustified) assumption that a formal power series of the form\n\\begin{equation}\\tag{14}\nG\\sim G^{(0)}+g G^{(1)}+g^2G^{(2)}+\\cdots+\\mathcal O(g^k)\n\\end{equation}\nshould be, in a certain sense, a good approximation to the real $G$. In practice, this series is observed to be asymptotic, so things work rather well as long as $g\\ll 1$.\nThe first thing we notice is that, due to equation $(10)$, the term of order zero in $g$ satisfies\n\\begin{equation}\\tag{15}\nG^{(0)}(x,x_1,\\dots,x_n)=i\\sum_{m=1}^n\\Delta(x-x_m)G^{(0)}(x_1,\\dots,\\hat x_m,\\dots,x_n)\n\\end{equation}\nwhich, by iteration, leads to\n\\begin{equation}\\tag{16}\n\\color{red}{G^{(0)}(x_1,\\dots,x_n)=\\sum_\\mathrm{pairings}\\prod i\\Delta(x_i-x_j)}\n\\end{equation}\nwhich is usually known as Wick's theorem.\nThe higher orders satisfy\n\\begin{equation}\n\\begin{aligned}\nG^{(k)}(x,x_1,\\dots,x_n)&=\\frac{1}{3!}\\int\\Delta(x-y)G^{(k-1)}(y,y,y,x_1,\\dots,x_n)\\,\\mathrm dy+\\\\\n&+i\\sum_{m=1}^n\\Delta(x-x_m)G^{(k)}(x_1,\\dots,\\hat x_m,\\dots,x_n)\n\\end{aligned}\\tag{17}\n\\end{equation}\nWith this, we see that we may calculate any correlation function, to any order in perturbation theory, as an iterated integral over combinations of propagators. To calculate the $n$-point function to order $k$, we need the $(n-1)$-point function to order $k$, and the $(n+3)$-function to order $k-1$, which can be iteratively calculated, by the same method, in terms of the corresponding correlation functions of lower $k$. When $k$ becomes zero we may use Wick's theorem, which means that the algorithm terminates after a finite number of steps. Let us see how this works in practice.\nWe begin by the zero order approximation to the two-point function. By Wick's theorem, we see that the propagator provides us with a very crude approximation to the two-point function,\n\\begin{equation}\\tag{18}\nG^{(0)}(x_1,x_2)=i\\Delta(x_1-x_2)\n\\end{equation}\nwhich, as expected, agrees with the diagram\n\nBy a similar analysis (Wick's theorem), the four-point function is given, to zero order in perturbation theory, by\n\\begin{equation}\n\\begin{aligned}\nG^{(0)}(x_1,x_2,x_3,x_4)&=i\\Delta(x_1-x_2)i\\Delta(x_3-x_4)\\\\\n&+i\\Delta(x_1-x_3)i\\Delta(x_2-x_4)\\\\\n&+i\\Delta(x_1-x_4)i\\Delta(x_2-x_3)\n\\end{aligned}\\tag{20}\n\\end{equation}\nwhich, once again, agrees with the diagrams\n\nWe next calculate the first order approximation to the two-point function; using $(17)$, we see that it is given by\n\\begin{equation}\\tag{22}\nG^{(1)}(x_1,x_2)=\\frac{1}{3!}\\int\\Delta(x_1-y)G^{(0)}(y,y,y,x_2)\\,\\mathrm dy\n\\end{equation}\nWe already know the value of the factor $G^{(0)}(y,y,y,x_2)$:\n\\begin{equation}\\tag{23}\n-G^{(0)}(y,y,y,x_2)=3\\Delta(y-y)\\Delta(x_2-y)\n\\end{equation}\nso that\n\\begin{equation}\\tag{24}\nG^{(1)}(x_1,x_2)=\\frac{i}{2}\\int\\Delta(x_1-y)\\Delta(y-y)\\Delta(x_2-y)\\,\\mathrm dy\n\\end{equation}\nwhich is precisely what the one-loop diagram predicts:\n\nWe can use the same technique to compute the first order correction to the four-point function. The reasoning is the same as before; equation $(17)$ reads\n\\begin{equation}\n\\begin{aligned}\nG^{(1)}(x_1,x_2,x_3,x_4)&=\\frac{1}{3!}\\int\\Delta(x-y)G^{(0)}(y,y,y,x_2,x_3,x_4)\\,\\mathrm dy\\\\\n&+i\\Delta(x_1-x_2)G^{(1)}(x_3,x_4)\\\\\n&+i\\Delta(x_1-x_3)G^{(1)}(x_2,x_4)\\\\\n&+i\\Delta(x_1-x_4)G^{(1)}(x_2,x_3)\n\\end{aligned}\\tag{26}\n\\end{equation}\nFrom our previous calculation, we already know the value of $G^{(1)}(x_1,x_2)$; on the other hand, the term $G^{(0)}(y,y,y,x_2,x_3,x_4)$ can be efficiently computed using Wick's theorem; in particular,\n\\begin{equation}\n\\begin{aligned}\niG^{(0)}(y,y,y,x_2,x_3,x_4)=\\,&3\\Delta(y-y)\\Delta(y-x_2)\\Delta(x_3-x_4)\\\\\n+&3\\Delta(y-y)\\Delta(y-x_3)\\Delta(x_2-x_4)\\\\\n+&3\\Delta(y-y)\\Delta(y-x_4)\\Delta(x_2-x_3)\\\\\n+&6\\Delta(y-x_2)\\Delta(y-x_3)\\Delta(y-x_4)\n\\end{aligned}\\tag{27}\n\\end{equation}\nso that\n\\begin{equation}\n\\begin{aligned}\n-G^{(1)}(x_1,x_2,x_3,x_4)&=\\frac12\\Delta(x_1-x_2)\\int\\Delta(x_3-y)\\Delta(y-y)\\Delta(x_4-y)\\,\\mathrm dy\\\\\n&+\\frac12\\Delta(x_1-x_3)\\int\\Delta(x_2-y)\\Delta(y-y)\\Delta(x_4-y)\\,\\mathrm dy\\\\\n&+\\frac12\\Delta(x_1-x_4)\\int\\Delta(x_2-y)\\Delta(y-y)\\Delta(x_3-y)\\,\\mathrm dy\\\\\n&+\\frac{1}{2}\\Delta(x_3-x_4)\\int\\Delta(x_1-y)\\Delta(y-y)\\Delta(y-x_2)\\,\\mathrm dy\\\\\n&+\\frac{1}{2}\\Delta(x_2-x_4)\\int\\Delta(x_1-y)\\Delta(y-y)\\Delta(y-x_3)\\,\\mathrm dy\\\\\n&+\\frac{1}{2}\\Delta(x_2-x_3)\\int\\Delta(x_1-y)\\Delta(y-y)\\Delta(y-x_4)\\,\\mathrm dy\\\\\n&+\\int\\Delta(x_1-y)\\Delta(y-x_2)\\Delta(y-x_3)\\Delta(y-x_4)\\,\\mathrm dy\n\\end{aligned}\\tag{28}\n\\end{equation}\nwhich, as expected, agrees with the value of the one-loop diagrams:\n\nAs a final example, let us compute the second order correction to $G(x_1,x_2)$, to wit,\n\\begin{equation}\\tag{30}\nG^{(2)}(x_1,x_2)=\\frac{1}{3!}\\int\\Delta(x_1-y)G^{(1)}(y,y,y,x_2)\\,\\mathrm dy\n\\end{equation}\nwhere $G^{(1)}(y,y,y,x_2)$ is given by $(26)$. The final result is\n\\begin{equation}\n\\begin{aligned}\nG^{(2)}(x_1,x_2)&=\\frac{1}{3!}\\int\\Delta(x_1-y)\\Delta(y-z)\\Delta(z-y)\\Delta(z-y)\\Delta(z-x_2)\\,\\mathrm dy\\,\\mathrm dz\\\\\n&+\\frac{1}{3}\\int\\Delta(x_1-y)\\Delta(y-y)\\Delta(y-z)\\Delta(z-z)\\Delta(z-z)\\,\\mathrm dy\\,\\mathrm dz\\\\\n&+\\frac{1}{3}\\int\\Delta(x_1-y)\\Delta(y-z)\\Delta(z-z)\\Delta(z-y)\\Delta(y-z)\\,\\mathrm dy\\,\\mathrm dz\n\\end{aligned}\\tag{31}\n\\end{equation}\nwhich, once again, agrees with the value of the diagrams\n\nContinuing this way, we may calculate any correlation function to any order in perturbation theory. It is interesting to note that this method allows one to compute any correlation function, to any order in perturbation theory, by a rather efficient method. In particular, we didn't need to draw any Feynman diagram (although we drew them anyway, for the sake of comparison), and neither did we have to compute any symmetry factor. In fact, I have a strong suspicion that numerical computations of higher order loop corrections use some variation of this algorithm. A simple application of this algorithm in Mathematica can be found in this Mathematica.SE post.\nThe reader will also note that no vacuum bubbles have been generated in the calculation of correlation functions. Recall that when working with path integrals or the Dyson series, such diagrams are generated and subsequently eliminated by noticing that they also appear in the denominator. Such graphs are divergent (both at the level of individual diagrams and at the level of summing them all up), so their cancellation is dubious. Here, the diagrams simply don't appear, which is an advantage of the formalism.\nYukawa theory.\nFor completeness, let us mention how this works in more general theories: those with non-scalar fields. The philosophy is exactly the same, the main obstacle being the notation: indices here and there make the analysis cumbersome.\nAssume you have a field $\\phi_a(x)$ which satisfies\n\\begin{equation}\\tag{33}\n\\mathscr D\\phi(x)=V'(x)\n\\end{equation}\nfor some matrix-valued differential operator $\\mathscr D$, and some vector-valued operator $V'$. In term of the action, $\\mathscr D\\phi=S_0'$ and $V'=S'_\\mathrm{int}$, where $S_0$ is the quadratic part of $S$ and $S_\\mathrm{int}$ is the rest of terms.\nWith this, the SD equations read\n\\begin{equation}\\tag{34}\n\\mathscr D_1 \\langle\\phi_1\\cdots\\phi_n\\rangle=i\\langle V'_1\\phi_2\\cdots\\phi_n\\rangle+\\sum_{m=2}^n\\delta_{1m}\\langle \\phi_2\\cdots\\hat\\phi_m\\cdots\\phi_n\\rangle\n\\end{equation}\nwhere I have introduced the short-hand notation $i=(x_i,a_i)$. Also, $\\delta_{ij}=\\delta_{a_ia_j}\\delta(x_i-x_j)$.\nBy analogy with our discussion above, we see that the algorithm is essentially the same, but now the propagator is $\\mathscr D^{-1}$, and there is a factor of $V$ on every vertex.\nLet me sketch how this works in the Yukawa theory with a scalar field $\\phi$ and a Dirac field $\\psi$, interacting through $V=g\\phi\\bar\\psi\\psi$. The Lagrangian reads\n\\begin{equation}\\tag{35}\n\\mathcal L=i\\bar \\psi\\!\\!\\not\\!\\partial\\psi-m\\bar\\psi \\psi+\\frac{1}{2}(\\partial \\phi)^2-\\frac{1}{2}M^2\\phi^2-g\\phi\\bar\\psi\\psi\n\\end{equation}\nwith $\\psi\\colon\\mathbb R^d\\to \\mathbb C_a$ and $\\phi$ as before.\nThe equations of motion are\n\\begin{equation}\n\\begin{aligned}\n-(-i\\!\\!\\not\\!\\partial+m)\\psi=g\\phi\\psi\\equiv U\\\\\n-(\\partial^2+M^2)\\phi=g\\bar\\psi\\psi\\equiv V\n\\end{aligned}\\tag{36}\n\\end{equation}\nAs usual, we define the propagators as\n\\begin{equation}\n\\begin{aligned}\n(-i\\!\\!\\not\\!\\partial+M) S_{12}&=\\delta_{12}\\\\\n(\\partial^2+m^2) \\Delta_{12}&=\\delta_{12}\n\\end{aligned}\\tag{37}\n\\end{equation}\nthat is,\n\\begin{equation}\n\\begin{aligned}\nS(p)&=\\frac{1}{\\!\\!\\not\\!p-m+i\\epsilon}\\\\\n\\Delta(p)&=\\frac{1}{p^2-m^2+i\\epsilon}\n\\end{aligned}\\tag{38}\n\\end{equation}\nWe now need to introduce the correlation functions. Let me use a hybrid notation which I hope will simplify the notation as much as possible:\n\\begin{equation}\\tag{39}\niG(1^\\alpha,2_\\beta,3,\\dots)\\equiv\\langle \\Omega|\\mathrm T\\ \\psi^\\alpha(x_1) \\bar\\psi_\\beta(x_2)\\phi(x_3)\\cdots|\\Omega\\rangle\n\\end{equation}\nor, in other words, every upper index corresponds to $\\psi$; every lower index corresponds to $\\bar\\psi$; and every space-time point with no indices corresponds to $\\phi$. In terms of the partition function, the correlation function is defined as\n\\begin{equation}\\tag{40}\niG(1^\\alpha,2_\\beta,3,\\dots)\\equiv \\left[\\frac{\\delta}{\\delta \\eta_\\alpha(x_1)}\\frac{\\delta}{\\delta \\bar\\eta^\\beta(x_2)}\\frac{\\delta}{\\delta j(x_3)}\\cdots\\right]Z[\\eta,\\bar\\eta,j]\\bigg|_{j=\\eta=\\bar\\eta=0}\n\\end{equation}\nWith this, the SD equations of the theory read\n\\begin{equation}\n\\begin{aligned}\niG(1^\\alpha,2_\\beta,3,\\dots)&=\\int S_{1y}^\\alpha{}_\\gamma\\langle U^\\gamma(y)\\bar\\psi_\\beta(x_2)\\phi(x_3)\\cdots\\rangle \\mathrm dy\\\\\n&+iS^\\alpha_{12\\beta}\\langle\\phi(x_3)\\cdots\\rangle+\\cdots\\\\\niG(1,2,3^\\alpha,\\dots)&=\\int \\Delta_{1y}\\langle V(y)\\phi(x_2)\\psi^\\alpha(x_3)\\cdots\\rangle\\mathrm dy\\\\\n&+i\\Delta_{12}\\langle\\psi^\\alpha(x_3)\\cdots\\rangle+\\cdots\n\\end{aligned}\\tag{41}\n\\end{equation}\nMore generally, given an arbitrary correlation function $G$, the corresponding SD equations are obtained by replacing any field by its propagator and vertex function, and adding all possible contact terms with the same propagator. In fact, the general structure of the SD equations is rather intuitive: it is simply given by what index placement suggests; in general there is one and only one way to match up indices on both sides of the equation so that the propagators and fields are contracted in the correct way.\nThe calculation of $G$ is rather similar to that of the scalar theory above. As before, we assume it makes sense to set up a power series in $g$,\n\\begin{equation}\\tag{42}\nG=G^{(0)}+gG^{(1)}+g^2G^{(2)}+\\cdots\n\\end{equation}\nPerturbation theory is obtained by constructing $G^{(k)}$ from the known value of the correlation functions of lower order.  For example, the one point function $iG(1)=\\langle\\phi(x_1)\\rangle$ satisfies\n\\begin{equation}\\tag{43}\nG(1)=g\\int \\Delta_{1y} G(y_\\alpha, y^\\alpha)\\mathrm dy\n\\end{equation}\nTo lowest order, $G^{(0)}(1)=0$; the first correction reads\n\\begin{equation}\n\\begin{aligned}\niG^{(1)}(1)&=i\\int \\Delta_{1y} G^{(0)}(y_\\alpha, y^\\alpha)\\mathrm dy=\\\\\n&=-i\\int  \\Delta_{1y}\\text{tr}(S_{yy})\\mathrm dy\n\\end{aligned}\\tag{44}\n\\end{equation}\nwhere the negative sign is due to the fermionic statistics of $\\psi,\\bar\\psi$ (or, equivalently, of their corresponding sources, $\\eta,\\bar\\eta$). In particular,\n $iG^{(0)}(1_\\alpha, 2^\\alpha)=\\langle\\bar\\psi_\\alpha(x_1)\\psi^\\alpha(x_2)\\rangle=-\\langle\\psi^\\alpha(x_2)\\bar\\psi_\\alpha(x_1)\\rangle=-\\text{tr}(S_{21})$; more generally, we always have a negative sign associated to traces over fermionic indices.\nThe expression above agrees with the standard one-loop Feynman diagram, to wit\n\nwhere the dashed line represents a scalar propagator and a solid one a spinorial one.\nSimilarly, the two point function $i G(1,2)=\\langle\\phi_1\\phi_2\\rangle$ satisfies\n\\begin{equation}\\tag{46}\ni G(1,2)=ig\\int  \\Delta_{1y} G(y_\\alpha, y^\\alpha,2)\\mathrm dy+i\\Delta_{12}\n\\end{equation}\nAs usual, to lowest order we have $G^{(0)}(1,2)=\\Delta_{12}$; the first correction is\n\\begin{equation}\\tag{47}\ni G^{(1)}(1,2)=i\\int  \\Delta_{1y} G^{(0)}(y_\\alpha, y^\\alpha,2)\\mathrm dy=0\n\\end{equation}\nsince  $G^{(0)}(y_\\alpha, y^\\alpha,2)=0$. In order to calculate the next correction we need the three point function, which satisfies\n\\begin{equation}\\tag{48}\ni G(1^\\alpha,2_\\beta,3)=ig\\int S_{1y}^\\alpha{}_\\gamma  G(y,y^\\gamma,2_\\beta,3)\\mathrm dy+S^\\alpha_{12\\beta} G(3)\n\\end{equation}\nthat is,\n\\begin{equation}\n\\begin{aligned}\ni G^{(1)}(1^\\alpha,2_\\beta,3)&=i\\int  S_{1y}^\\alpha{}_\\gamma  G^{(0)}(y,y^\\gamma,2_\\beta,3)\\mathrm dy+S^\\alpha_{12\\beta} G^{(1)}(3)=\\\\\n&=-\\int  \\Delta_{3y}(S_{1y}S_{y2})^\\alpha{}_\\beta -\\Delta_{3y}S^\\alpha_{12\\beta}\\text{tr}(S_{yy})\\mathrm dy\n\\end{aligned}\\tag{49}\n\\end{equation}\nwhich agrees with the one-loop diagrams\n\nWith this, we now have what we need in order to compute the first non-trivial correction to the two-point function $G(1,2)$:\n\\begin{equation}\n\\begin{aligned}\ni G^{(2)}(1,2)&=i\\int  \\Delta_{1y} G^{(1)}(y_\\alpha, y^\\alpha,2)\\mathrm dy=\\\\\n&=\\int  \\Delta_{1y}\\Delta_{2z}\\text{tr}(S_{yz}S_{zy})-\\Delta_{1y}\\Delta_{z2}\\text{tr}(S_{yy})\\text{tr}(S_{zz})\\ \\mathrm dy\\,\\mathrm dz\n\\end{aligned}\\tag{51}\n\\end{equation}\nwhich agrees with the diagrams\n\nFinally, the fermionic two-point function $G(1^\\alpha,2_\\beta)$ satisfies\n\\begin{equation}\\tag{53}\ni G(1^\\alpha,2_\\beta)=ig\\int  S_{1y}^\\alpha{}_\\gamma  G(y,y^\\gamma,2_\\beta)\\mathrm dy+iS^\\alpha_{12\\beta}\n\\end{equation}\nwhich, to order zero in $g$, becomes $G^{(0)}(1^\\alpha,2_\\beta)=S^\\alpha_{12\\beta}$, as expected. The first correction is\n\\begin{equation}\\tag{54}\niG^{(1)}(1^\\alpha,2_\\beta)=i\\int  S_{1y}^\\alpha{}_\\gamma  G^{(0)}(y,y^\\gamma,2_\\beta)\\mathrm dy=0\n\\end{equation}\nsince $G^{(0)}(y,y^\\gamma,2_\\beta)=0$.\nTo second order in $g$,\n\\begin{equation}\n\\begin{aligned}\ni G^{(2)}(1^\\alpha,2_\\beta)&=i\\int  S_{1y}^\\alpha{}_\\gamma  G^{(1)}(y,y^\\gamma,2_\\beta)\\mathrm dy=\\\\\n&=-\\int  \\Delta_{yz} (S_{1y}S_{yz}S_{z2})^\\alpha{}_\\beta-(S_{1y}S_{y2})^\\alpha{}_\\beta\\Delta_{yz}\\text{tr}(S_{zz})\\mathrm dy\\,\\mathrm dz\n\\end{aligned}\\tag{55}\n\\end{equation}\nwhich, as one would expect, agrees with the one-loop Feynman diagram\n\nThe calculation of higher order correlation functions, to higher loop orders, is analogous.  Hopefully, the worked out examples above are enough to illustrate the general technique. It's a nice formalism, isn't it?", "meta": {"post_id": 304869, "input_score": 27, "output_score": 36, "post_title": "Systematic way to draw all inequivalent Feynman diagrams"}}
{"input": "I took this photograph a few days ago, during sunrise, using my smartphone camera and digital zoom:\n\nIt seems that the sun is in front of the building. How is this explained?", "output": "You are seeing the effect of a combination of blurring - caused by an imperfect optical system - and saturation.\nBlurring: ideally, a lens should map a point source into a point source. In reality, it is mapped into something slightly wider than that. If the image is well-focused, the lens is free of imperfections, and diffraction due to the finite size of the lens (aperture) is minimal, then that approximation is close to true. In your case, it's clear by looking at the image of the building that there is significant blurring: probably this is due to the image being slightly out of focus; perhaps atmospheric blur (scatter - light fog?) is contributing.  There is also something called blooming where excess exposure on one pixel causes some signal to appear on neighboring pixels. All these things contribute to a blurring of bright objects in your picture (like the sun).\nSaturation: the sun is much, much brighter than the building. The exposure setting of your camera is such that an intensity that is a small fraction of the intensity of the sun causes a \"fully on\" pixel in the image.\nIn the following image I try to illustrate how a point source that is imaged through an out-of-focus lens becomes slightly blurred:\n\nI believe that in your image, the saturation is sufficient that the edge of the sun really corresponds to part of the blurred image of the sun, as illustrated in this next image which shows the convolution of a top hat function (\"the sun\") with a Gaussian of different widths (\"good\" and \"out of focus\" lens). \n\nThe \"saturation\" line shows a possible intensity at which pixels would appear white: as you can see, for the values I chose the sun would appear larger than it really is - and therefore it would appear to \"cut through\" the edge of the building. Which gives the illusion that it must be in front.\nHere is a 2D demonstration of what is going on - I hope the picture and legends are self-explanatory:\n\nI had to use log scale a couple of times because the sun is so much brighter than the \"building\" and background in this image.", "meta": {"post_id": 306612, "input_score": 55, "output_score": 71, "post_title": "What causes the Sun to appear to be in front of a building in this picture?"}}
{"input": "In classical mechanics, we perform a Legendre transform to switch from $L(q, \\dot{q})$ to $H(q, p)$. This has always been confusing to me, because we can always write $L$ in terms of $q$ and $p$ by just taking the expression for $\\dot{q}(q, p)$ and stuffing it in. \nIn thermodynamics, we say $U$ is a function of $S$, $V$, and $N$ because\n$$dU = T dS + p dV + \\mu dN,$$\nwhich is exceptionally simple. But for the Lagrangian, we instead generally have\n$$dL = (\\text{horrible expression})\\, dq + (\\text{horrible expression})\\, d\\dot{q}$$\nIn this case, I see no loss in 'naturalness' to switch to $q$ and $p$, so what's the real difference between considering $L(q, \\dot{q})$ and $L(q, p)$?", "output": "We should abandon the \"naive\" langauge of functions depending on coordinates and consider functions as maps between mathematical spaces, which are only expressed in local coordinates after their domains have been defined.\nThe starting point for both the Lagrangian and the Hamiltonian formalism is a configuration space $Q$, whose coordinates are called $q^i$. It should be thought of as the space of positions of the system under considerations. The two formalisms now immediately take different paths: Lagrangian mechanics takes place on the tangent bundle $TQ$, Hamiltonian mechanics on the cotangent bundle $T^\\ast Q$. The local coordinates on $TQ$ are denoted $(q^i,\\dot{q}^i)$, the local coordinates on $T^\\ast Q$ are $(q^i,p_i)$. Note that, since there is no metric on $Q$, you do not have a canonical identification of tangents and cotangents and therefore cannot switch between the description freely as one might be used to from Riemannian geometry. Note furthermore that $\\dot{q}$ is not the derivative of anything - it's simply a notation for a new coordinate.\nThe Lagrangian is a function $L : TQ\\to \\mathbb{R}$. Given it, we may define a function $f : TQ\\to T^\\ast Q$ in local coordinates by\n$$ f(q,\\dot{q}) = \\left(q,\\frac{\\partial L}{\\partial \\dot{q}}(q,\\dot{q})\\right)$$\nand the associated Hamiltonian $H : T^\\ast Q \\to \\mathbb{R}$ in local coordinates as the Legendre transform\n$$ H(q,p) = \\sup_{\\dot{q}}\\left(p_i \\dot{q}^i - L(q,\\dot{q})\\right).$$\nIt should be clear here that neither $H(q,\\dot{q})$ nor $L(q,p)$ are meaningful objects in this context - $H$ and $L$ act on different spaces, you cannot feed a $p$ into $L$ at all. Observe now that $f$ does permit us to do this in some sense, only rigorously: If $f$ is invertible, one may define a \"co-Lagrangian\" or \"Hamiltonian Lagrangian\" $L_H : T^\\ast Q \\to\\mathbb{R}$ by $L_H(q,p) = L(f^{-1}(q,p))$. Crucially, $L$ and $L_H$ are different functions and should, for clarity's sake, never be denoted by the same symbol.\nThe expression in the definition of the Legendre transform obtains its extremum at\n$$ p_i = \\frac{\\partial L}{\\partial \\dot{q}^i}(q,\\dot{q}),$$\nwhich means that \n$$ H(q,p) = p_i\\dot{q}^i - L(q,\\dot{q})\\tag{0}$$\nholds exactly for a triple $(q,\\dot{q},p)$ such that \n$$f(q,\\dot{q}) = (q,p).\\tag{1}$$\nNote that the fact that $H$ does not depend on $\\dot{q}$ means that $\\dot{q}$ in eq. (0) is implicitly a function $\\dot{q}(q,p)$ as defined implicitly by eq. (1).\nOnly when we impose the relation eq. (1) there is a functional relation between the $q,\\dot{q},p$, otherwise there is not. This is why, as abstract functions, the Lagrangian is not a function of $p$ and the Hamiltonian is not a function of $\\dot{q}$ - these are coordinates on different spaces with no relation to each other. It is only when we impose eq. (1) in order to express the Hamiltonian without the extremisation procedure prescribed in the Legendre transform that they become related, and not necessarily uniquely so. If $f$ is not invertible, then the Lagrangian system is a gauge theory and the Hamiltonian system is constrained - both terms which essentially mean that the relation between the $p$ and the $\\dot{q}$ is not uniquely defined.\nFinally, let me address a closely related confusion which nevertheless crops up because of the same reason, i.e. not respecting the actual domains functions are defined on. The $q,\\dot{q}$ arguments of the Lagrangian are independent, and become dependent only when we consider a path $\\gamma: I\\to Q$, which induces a path $\\tilde{\\gamma} : I\\to TQ, t\\mapsto (\\gamma(t),\\dot{\\gamma}(t))$ on the tangent bundle, where $\\dot{\\gamma}$ now denotes the actual time derivative, i.e. the tangent vector field to $\\gamma$. The action is a function $S : [I,Q]\\to\\mathbb{R}$, where $[I,Q]$ denotes the space of all maps $I\\to Q$, and is defined as\n$$ S[\\gamma] = \\int_I L(\\tilde{\\gamma}).$$\nWhen now considering this action, the physicist often writes the coordinates of $\\tilde{\\gamma}$ as $(q(t),\\dot{q}(t))$, and it is only in this context that $\\dot{q}(t)$ truly is a time-dependent function and the derivative of $q(t)$.", "meta": {"post_id": 307794, "input_score": 20, "output_score": 36, "post_title": "Why exactly do we say $L = L(q, \\dot{q})$ and $H = H(q, p)$?"}}
{"input": "The mass of a carbon 14 atom is $14.003\\,241\\,988\\,7\\:\\mathrm{u}$, nitrogen 14 has a mass of $14.003\\,074\\,004\\,78\\:\\mathrm{u}$, and the rest-mass of an electron is $0.000\\,548\\,579\\,9\\:\\mathrm{u}$\nIn $\\beta^-$ decay,\n$$_6^{14}\\mathrm C \\ \\longrightarrow \\ _7^{14}\\mathrm N + e^- + \\nu_e^+. $$\nThe mass of nitrogen and an electron is substantially larger than that of the carbon atom, so where did the extra mass-energy come from?", "output": "One needs to be very careful in doing mass-energy balances in nuclear decay reactions, especially in beta-decay (electron or positron)\nThe reaction as written in the OP is correct, and is exactly as it is normally written but is slightly misleading (not the fault of the OP!).\nConsider an individual carbon-14 atom on the LHS of the reaction.  It consists  of 6 protons, 8 neutrons, and six orbital electrons.  The orbital electrons are not involved in the nuclear reaction, and are usually ignored.\nThe major product of the decay of this carbon-14 atom is an atom of nitrogen-14.  But this atom still has the same six orbital electrons as the parent carbon -14.\nHowever, the atomic masses are tabulated for the whole neutral atom.  So the mass used for the carbon-14 atom is correct, but the mass used for the daughter nitrogen-14 atom is actually too large by the mass of the seventh orbital electron found in a neutral atom.  To emphasize, the actual reaction product has six orbital electrons, while the mass used is for a seven-orbital-electron nitrogen-14 atom. \nSo, one needs to subtract an electron from the tabulated nitrogen-14 atom, and then add back in the mass of the actual beta-particle produced in the reaction.\nThis is the same as just using the tabulated atomic mass values, and not including the beta-particle mass.", "meta": {"post_id": 308617, "input_score": 21, "output_score": 43, "post_title": "In $_6^{14}\\mathrm C$ decay, how is mass-energy conserved?"}}
{"input": "My question is in the title: Do black holes have a moment of inertia?\nI would say that it is: $$I ~\\propto~ M R_S^2,$$ where $R_S$ is the Schwarzschild radius, but I cannot find anything in the literature.", "output": "The angular velocity of a Kerr black hole with mass $M$ and angular momentum $J$ is\n$$ \\Omega = \\frac{J/M}{2M^2 +  2M \\sqrt{M^2 - J^2/M^2}} $$\nThe moment of inertia of an object can be thought of as a map from the object's angular velocity to its angular momentum. However, here we see that the relationship between these two quantities is non-linear. If we want to think of moment of inertia in the usual sense, we should linearise the above equation. When we do so, we find the relationship\n$$ J = 4 M^3 \\Omega \\qquad (\\mathrm{to\\ first\\ order})$$\nAnd so the moment of inertia is\n$$ I = 4 M^3 $$\nIn other words, the expression you guessed is correct, and the constant of proportion is unity. Note that since the Schwarschild radius of a black hole is merely twice its mass, and since the only two parameters that describe the black hole are its mass and angular momentum, any linear relationship between the angular velocity and angular momentum of our black hole must be of the form $J = k\\, M R_S^2\\, \\Omega$ on dimensional grounds.\nNote that $G = c = 1$ throughout.\n\nEDIT. \nAs pointed out in the comments, it's not obvious how one should define the angular velocity of a black hole. At the risk of being overly technical, we can do this as follows. First consider the Killing vector field $\\xi = \\partial_t + \\Omega \\partial_\\phi$ (using Boyer-Lindquist coordinates), where $\\Omega$ is defined to be as above. The orbits, or integral curves, of this vector field are the lines $\\phi = \\Omega t + \\mathrm{const.}$, which correspond to rotation at angular velocity $\\Omega$ with respect to a stationary observer at infinity.\nOne can show that this vector field is tangent to the event horizon, and its orbits lying on the event horizon are geodesics. These geodesics hence rotate at angular velocity $\\Omega$ (with respect to an observer at infinity), and hence it is natural to interpret the quantity $\\Omega$ as the angular velocity of the black hole. Whether it is possible to make a more definite statement than this I do not know.", "meta": {"post_id": 310881, "input_score": 28, "output_score": 40, "post_title": "Do black holes have a moment of inertia?"}}
{"input": "How much does thermal expansion affect neutron stars? Would the loss of temperature cause a neutron star to be more densely packed and thus collapse into a black hole?", "output": "The answer by @RobJeffries is correct, at least 95-99% of the time (and possibly all the time), and also the best answer to this question.  But just for the curious, some people do talk about newly formed, meta-stable neutron stars (usually in the form of 'magnetars') which collapse afte short periods of time from the combination of cooling and rotational deceleration.  Most models suggest that the rotational deceleration is a more important factor which leads to the collapse: the newly formed neutron stars can be spinning near 'breakup velocity'---where material on the equator is rotating quickly enough that it almost detaches.  The strong magnetic fields of magnetars, however, are believed to be effective at transferring angular momentum out, and slowing down this rotation.  The material on the NS loses that rotational support, and thus NS which were on the verge of collapse may cross the threshold and turn into a black-hole.\nThis model, which is highly theoretical, is used to explain extended emission in some Gamma Ray Bursts (which, people think, require black holes to be formed).  The idea is a meta-stable magnetar is formed, which continues to power xray (and some other) emission and ejecta, before later collapsing to a black-hole (after 10s to 100s of seconds, usually).\nL\u00fc et al. 2015 - The Millisecond Magnetar Central Engine in short GRBs \nRowlinson et al. 2013 - Signatures of magnetar central engines in short GRB light curves \nLasky et al. 2013 - Nuclear Equation of State from Observations of Short Gamma-Ray Burst Remnants", "meta": {"post_id": 312824, "input_score": 34, "output_score": 37, "post_title": "Can a neutron star become a black hole via cooling?"}}
{"input": "Quantum mechanics allows us to describe a particle as a wave, and also a collection of particles, which a car happens to be. What separates a typical wave from a classical particle is that the position is not well defined for a wave.\nI think that it is hard to tell exactly how big an atom is, because the electron of the atom may be anywhere, but the probability of finding the electron gets very small as you look far away from the nuclei. I think in some sense the atom is as large as we want, depending on the definition.\nWhen a car drives past me, is the position of the car separate from my position in a quantum mechanical way, or is it correct to say that \"part\" of the car hit \"part\" of me? I understand that no matter the answer the force from the hit is so small that it is negligible in every way, but that is not the core of the question.\nIn addition, if I made any wrong claims, please correct me, thanks in advance.", "output": "Asher's comment written above is simply wrong, and the reason is rather fundamental in quantum mechanics. \"The car slightly hits you\" isn't how it works in quantum mechanics.\nThe reason is that weak effects \u2013 such as very small but nonzero values of the wave function of an electron very far from the nucleus \u2013 do not cause tiny but observable effects like they do in classical physics.\nInstead, the wave function has a probabilistic interpretation. So its being nonzero very far from the nucleus means that there is a small probability that a finite effect takes place.\nSo in quantum mechanics, you can ask whether a car hit you \u2013 whether some reaction took place. In quantum mechanics, questions about physical systems (including this one) have to be answered by measurements, otherwise they are physically and scientifically meaningless.\nAnd quantum mechanics predicts some probabilities for one outcome of the measurement or another. If only 0.0001% of the integrated $\\int |\\psi|^2$ of the electron was located at the distance $R$ equal to the distance of your body from the car, then it means that there was a 99.9999% probability that no interaction has taken place at all.\nOn the other hand, there is a 0.0001% probability that some interaction did take place, but it wouldn't be a small interaction. It would be a rather large one, such as the ionization of one atom \u2013 of the car or your body.\nAgain, in quantum mechanics, small wave functions don't mean small forces. They mean finite (not so small) jumps happening with tiny probabilities.\nAgain, it's very likely that you didn't get hit by a car in the morning at all.\nOne can give as many serious examples of that as we want. For example, when a radioactive nucleus decays, the wave function for an alpha particle gradually grows outside the nucleus. It doesn't mean that the alpha particle is \"weakly felt\" at all times. Instead, it means that there is some probability that the nucleus has decayed up to some moment, and some probability that it remained intact.\nAlso, one may consider collisions of particles, such as those at the LHC. Various quantum processes may take place; they are described by Feynman diagrams. The two colliding protons have an infinite cross section to interact through the electrostatic repulsion. So yes, there was always some interaction of this electrostatic kind. It's equivalently interpreted as the certainty that some very soft photons are being emitted. (One could say that the car-body contact above was electrostatic elastic between two electrons as well, in that case, it would always occur.)\nBut there are also other, short-range forces, that predict finite cross sections. In some reactions, some finite process like that \u2013 accompanied by the production of pions etc. \u2013 can take place. But in others, it strictly doesn't take place. The atoms effectively interact e.g. with van der Waals forces that decrease as a faster power law of the distance and they have a finite cross section. So when we talk about similar interactions between the whole atoms, then the interaction probably didn't occur at all \u2013 strictly zero at a probability that is almost 100%.", "meta": {"post_id": 319706, "input_score": 26, "output_score": 51, "post_title": "Did I get hit by a car this morning?"}}
{"input": "A while ago it was raining and I noticed that, on sloped pavement, water was flowing in very regular consistent periodic waves, as you see below.\nHowever, I realized I had no idea why this should be happening. There was nothing uphill actually creating these waves, and they continued down as far as the pavement went, despite the rain that was falling on them along the way.\nWhy wasn't the water flowing down smoothly, or irregularly?\nWhat causes the noticeable wavelike patterns? Is there a  name for this phenomenon?", "output": "These waves are called \"roll waves.\" They are due to an instability in shallow shear flows. The analysis is much  too complex for a short answer, but if you google \"Roll Wave\" you will find  more images and links to technical articles.  If you are not bothered by a little mathematics  you will find  a  discussion of the cause of the instability starting on page  259  in these online lecture notes: https://courses.physics.illinois.edu/phys508/fa2016/amaster.pdf\nAfter the waves have formed due to the instability, the actual form -- a series of breaking waves -- is due to the non-linear propagation effect described by md2perpe  -- the deeper the water the faster the wave.", "meta": {"post_id": 319819, "input_score": 88, "output_score": 82, "post_title": "Why does rainwater form moving waves on the ground? Is there a name for this effect?"}}
{"input": "What is special about Maxwell's equations? If I have read correctly, what Maxwell basically did is combine 4 equations that were already formulated by other physicists as a set of equations. Why are these 4 equations (out of large numbers of mathematical equations in electromagnetism) important? Or What is special about these 4 equations?", "output": "Maxwell's equations wholly define the evolution of the electromagnetic field.  So, given a full specification of an electromagnetic system's boundary conditions and constitutive relationships (i.e. the data defining the materials within the system by specifying the relationships between the electric / magnetic field and electric displacement / magnetic induction), they let us calculate the electromagnetic field at all points within the system at any time. Experimentally, we observe that knowledge of the electromagnetic field together with the Lorentz force law is all one needs to know to fully understand how electric charge and magnetic dipoles (e.g. precession of a neutron) will react to the World around it. That is, Maxwell's equations + boundary conditions + constitutive relations tell us everything that can be experimentally measured about electromagnetic effects (including quibbles about the Aharonov-Bohm effect, see 1). Furthermore, Maxwell's equations are pretty much a minimal set of equations that let us access this knowledge given boundary conditions and material data, although, for example, most of the Gauss laws are contained in the other two given the continuity equations. For example, if one takes the divergence of both sides of the Amp\u00e8re law and applies the charge continuity equation $\\nabla\\cdot\\vec{J}+\\partial_t\\,\\rho=0$ together with an assumption to $C^2$ (continuous second derivative) fields, one derives the time derivative of the Gauss electric law. Likewise, the divergence of the Faraday law yields the time derivative of the Gauss magnetic law.\nMaxwell's equations are also Lorentz invariant, and were the first physical laws that were noticed to be so. They're pretty much the simplest linear differential equations that possibly could define the electromagnetic field and be generally covariant; in the exterior calculus we can write them as $\\mathrm{d}\\,F = 0;\\;\\mathrm{d}^\\star F = \\mathcal{Z}_0\\,^\\star J$; the first simply asserts that the Faraday tensor (a covariant grouping of the $\\vec{E}$ and $\\vec{H}$ fields) can be represented as the exterior derivative $F=\\mathrm{d} A$ of a potential one-form $A$ and the second simply says that the tensor depends in a first order linear way on the sources of the field, namely the four current $J$. This is simply a variation on Feynman's argument that the simplest differential equations are linear relationships between the curl, divergence and time derivatives of a field on the one hand and the sources on the other (I believe he makes this argument in volume 2 of his lecture series, but I can't quite find it at the moment).\n\n1) Sometimes people quibble about what fields define experimental results and point out that the Aharonov-Bohm effect is defined by the closed path integral of the vector magnetic potential $\\oint\\vec{A}\\cdot\\mathrm{d}\\vec{r}$ and thus ascribe an experimental reality to $\\vec{A}$. However, this path integral of course is equal to the flux of $\\vec{B}$ through the closed path, therefore knowledge of $\\vec{B}$ everywhere will give us the correct Aharonov-Bohm phase for to calculate the electron interference pattern, even if it is a little weird that $\\vec{B}$ can be very small on the path itself.", "meta": {"post_id": 322598, "input_score": 23, "output_score": 38, "post_title": "What is special about Maxwell's equations?"}}
{"input": "When you have made some stupid mistakes on a blackboard, you quickly want to erase it with a wet sponge before anyone sees them. So you clean the blackboard and within a minute the blackboard is clean and dry again! \nI was wondering why the board is drying so quickly compared to other surfaces. Does it absorb the water or is it all due to \"good\" evaporation?", "output": "[Already said] A blackboard is not porous, i.e. it actually never takes up much water from the sponge in the first place (and if you were to squeeze out more than a little, it would just run down to the bottom).\n[Already said] Yet the surface is hydrophilic, i.e. the water that does stay on the board forms a very thin film instead of droplets (as you'd get on a plastic or freshly wiped glass surface), and together with the slightly rough texture this makes for a large surface area to only a very small volume of water. This surface is where evaporation takes place; the larger, the better.\nThe board is mounted vertically. That's the ideal configuration for convection: water vapour has a lower density than air, so close to the surface (which, because of the second point, quickly evaporates a lot of water into the air directly next to it) the air rises up, and because the entire surface is aligned in the same direction and air can efficiently stream along the surface from below (turbulence helps further), there's a steady supply of unsaturated air into which more water can evaporate unhindered.\n[Already said] The bulk of the board is usually metallic, i.e. it has good thermal conductivity. To the touch (which emits heat into the board), one perceices it therefore as cold, but to the evaporating water (which requires heat) the same property has a warming effect. That keeps the evaporation speed high, both directly and through preventing the reduced temperature from mitigating the convection-causing density reduction.", "meta": {"post_id": 324273, "input_score": 35, "output_score": 49, "post_title": "Why does a blackboard dry very quickly?"}}
{"input": "Geiger and Marsden's experiment led Rutherford to believe that the positive charge and most of the mass of the atom was concentrated in a small region. I understand what led him to conclude the way the positive charge is positioned in the atom. But how did he conclude that most of the mass was in a small region (the nucleus)?\nHow did the distribution of the mass matter after all? Given that the electric force is greater than the gravitational force by many magnitudes, the force between the positice charge and the electrons was predominantly electric. \nSo how did Rutherford conclude that most of the mass is in the nucleus?", "output": "This is a good example of how Science works.\nGeiger and Marsden observed that some of the alpha particles were being backscattered. This is inconceivable if the alpha particle is scattered by a lighter particle. \nIf one considers a particle of mass $m$ and initial velocity $v_1$ striking a target of mass $m'$ at rest, without changing its direction, then its final velocity $v_2$ can assume two possible values,\n$$v_2=v_1,\\quad\\mathrm{or}\\quad v_2=-v_1\\left(\\frac{m'-m}{m'+m}\\right).$$\nThe second solution gives that backscattering is only possible if the target has greater mass than the incident particle. By the time, the mass of the electron was known to be much smaller than the mass of the alpha particle so a backscattering event would imply that the scattering centers were in fact heavy positive nuclei. And indeed those scatterings were observed. \nTo formally check this, Rutherford obtained a formula for the number of scattered particles as a function of the scattering angle using the hypothesis of heavy nuclei (which is justified by the above paragraph). Geiger and Marsden did the experiment and the data agreed with Rutherford formula.", "meta": {"post_id": 326320, "input_score": 29, "output_score": 41, "post_title": "How did Rutherford conclude that most of the mass (as well as the positive charge) was concentrated in the nucleus?"}}
{"input": "In the above image, the curves for different temperature dont intersect anywhere. Stefan-Boltzmann law and Wien displacement law dont preclude the intersection. \nIs it because if, for example, they cross each other at some longer wavelength somewhere (after the peak), then that would imply that the body with the lower temperature emits more power than that with the higher temperature for the wavelengths after the crossing point? If yes, then why is that not possible?", "output": "Here are two reasons they can't cross, one from statistical mechanics and one from pure thermo.\n\nMicroscopically, each frequency of light is produced by an independent mode. So asking why the curves don't cross is just asking why the amount of energy in a mode goes up as the temperature goes up, i.e. why the heat capacity is positive. That's true almost all the time, and systems for which it's not true aren't even thermodynamically stable.\nImagine placing two blackbodies right next to each other. The hotter one must transfer energy to the cooler one, or else we've violated the Second Law of Thermodynamics, so hotter objects must overall emit more. But we can also place a filter in between the blackbodies that only lets a very narrow band of frequencies though. So to avoid breaking the Second Law, a hotter blackbody must emit more at all frequencies.\n\nA more direct proof is to go all the way to Planck's law, but that's not necessary: we can prove the curves can't cross with general principles, without knowing much about the details.", "meta": {"post_id": 327748, "input_score": 22, "output_score": 39, "post_title": "Why don't Wien displacement law curves cross?"}}
{"input": "I was recently reading Griffiths' Introduction to Quantum Mechanics, and I stuck upon a following sentence:\n\nbut $\\Psi$ must go to zero as $x$ goes to $\\pm\\infty$ - otherwise the wave function would not be normalizable.\n\nThe author also added a footer:\n\"A good mathematician can supply you with pathological counterexamples, but they do not arise in physics (...)\".\nCan anybody give such a counterexample?", "output": "Take a gaussian (or any function that decays sufficiently quickly), chop it up every unit, and turn all the pieces sideways.", "meta": {"post_id": 331976, "input_score": 40, "output_score": 73, "post_title": "Normalizable wavefunction that does not vanish at infinity"}}
{"input": "I was carrying out a photoelectric effect experiment when I realised that the $365$ nm line in the mercury spectrum was surprisingly visible when shone onto a piece of paper. This lies in the UV spectrum, and it is not visible directly. However, I could see it clear as day when it was shone onto a piece of white paper.\nMy conclusion is that the particular reflection happening in this scenario is causing the wavelength to change. (Either the wavelength is \"spreading out\", so that it is not just $365$ nm, but some range of values centred at $365$, or the overall wavelength has shifted up.)\nI've tried to figure out if there is a property of diffuse reflections that would result in a change in wavelength, but I haven't come to any conclusion.\nAn explanation of this effect would be greatly appreciated, thank you!", "output": "Paper sometimes contains a fluorescer to make it look whiter. I would guess that the light you are seeing is coming from fluorescence induced by the UV light.\nIn fluorescence some of the original light energy is lost to lattice vibrations so the emitted light has a longer wavelength than the absorbed light.\nYou can see the shift in wavelength if you use a violet light source (such as a simple laser pointer). On dark/non-fluorescent surfaces, you see the violet light reflected. However, on fluorescent surfaces, like white paper, you will see blue light. While not as cool as the effect with a mercury lamp where bands appear out of nowhere, it does visibly showcase one light shifting to a longer wavelength of light due to fluorescence.", "meta": {"post_id": 335087, "input_score": 29, "output_score": 48, "post_title": "Why is UV light visible when reflected off paper?"}}
{"input": "My intuition tells me if gases conduct electricity, it should happen at high pressure, then the atoms will be closer together and electric field can ionize them. \nBut my textbook says low pressure is favoured for the gas discharge. Doesn't this mean discharge happens more vigorously in a vacuum which is absurd? May I know how low pressure contributes to the discharge?", "output": "At high pressure, the mean free path of electrons is quite low. The electrons don't get enough time to get accelerated. If the electrons don't accelerate for long, they can't gain the high velocity or kinetic energy that is required to ionize other atoms.\nWhile your argument that if there are more atoms, more electrons can be obtained through ionization makes sense, you don't account for the fact that only high energy electrons can ionize electrons from the gas atoms. If there are too many gas atoms, the electrons collide much before they have enough kinetic energy to ionize the atoms. If you cannot get a high number of electrons moving, you won't get sufficient current.\nWhen the gas pressure is low (but not too low), the electrons get enough time (or distance) to accelerate. By the time they collide with an atom, they have gained enough kinetic energy from the electric field to ionize other atoms. Even though there are not many atoms from which electrons can be obtained compared to a gas at high pressure, there is more than enough to produce a measurable current.\nIf the gas pressure goes too low, your argument comes to play. There won't be enough atoms to ionize and the conductivity decreases.\n\nMathematical Details:\n$$V_{B} = \\frac{Bpd}{ln(Apd) - ln(ln(1 + \\frac{1}{\\gamma_{se}}))}$$\nwhere $V_B$ is the breakdown voltage (minimum voltage required to observe a measurable current), $p$ is the pressure of the gas, $d$ is the distance between the electrodes, $A$ is the saturation ionization of the gas and $\\gamma_{se}$ is the secondary electron emission coefficient and $B$ is a constant which is related to the ionization energy.\n\nIntution:\nWhen the pressure is too low, it is difficult to obtain significant number of electrons to produce a measurable current.\nFor a pressure which is not too low nor too high, how conductivity varies can be understood as follows.\nIf a free electron was moving through two electrodes with a potential difference of $V$ in a perfect vacuum, the kinetic energy gained by the electron is:\n$$K.E = eV$$\nLet the distance between the electrodes be $L$. If the electron travels a distance $x$ (mean free path) before colliding with an atom, the kinetic energy gained by the electron is:\n$$K.E = e(Ex) = ex\\frac{V}{L}$$\nAn electron needs to have at least $W$ (let's call this work function) energy to ionize an atom.\nIf significant ionization must occur, then:\n$$K.E \\ge W$$\n$$ex\\frac{V}{L} \\ge W \\tag{1}$$\nThe mean free path of an electron is proportional to (if not equal) the mean free path of the gas. The mean free path of a gas varies as follows:\n$$\\lambda = k\\frac{T}{P}\\tag{2}$$\nSubstiuting equation $(2)$ in equation $(1)$, we get:\n$$k_1 \\frac{T}{P}\\frac{V}{L} \\ge W$$\nLet us consider $P$ and $L$ as variables and fix $T$ (we assume that we are performing the experiment at constant temperature)\n$$V \\ge k_2 PL$$\nThe minimum $V$ required to see a observable current is given by:\n$$V_{min} = V_{\\text{breakdown}} = V_{B} = k_2PL$$", "meta": {"post_id": 339283, "input_score": 30, "output_score": 45, "post_title": "Why do gases conduct at low pressure?"}}
{"input": "I live about 2 miles from a race track.\nSome days the noise from testing is extremely noticeable, Other days despite the exact same testing activity, there is little-to-no noise at all.\nThis is mostly effected by the direction of the wind.\nHow does the wind direction affect sound propagation? Given the speed of sound vs the speed of wind is generally only a few percent, why and how does it make such a dramatic difference?", "output": "Since the mechanism is so well written on Reddit in here, I won't even try to rephrase it. Here it is:\n\nYes, wind has an effect on the speed of sound, and this effect has\n  interesting ramifications for the propagation of sound outdoors.\nAn acoustic wave, as you know, is a mechanical wave traveling through\n  a medium. The sound we deal with most often is carried through the\n  medium of air, at a speed of around 343 m/s.\nWind is the bulk motion of air in a given direction.\nWhen you combine these two ideas together, you get that sound is a\n  wave moving through a moving medium. Unsurprisingly, that means that\n  the velocity of acoustic wave is equal to the speed of the wave plus\n  the speed of wind in that direction. IE, if the wind is moving at 20\n  mph (8.9 m/s), then sound will travel downwind at 351.9 m/s, upwind at\n  334.1 m/s, and crosswind at the regular 343 m/s. Note that it takes a significant windspeed to appreciably alter the sound speed in any\n  given direction.\nWhat's really interesting is how windspeed gradients alter the path\n  that sound takes through the air. As a rule, sound waves bend towards\n  regions of lower sound speed (an effect known as refraction that's a\n  direct result of Snell's law). Couple this with the fact that\n  windspeed tends to increase with greater distance from the ground, and\n  you find that sound refracts downward when moving downwind and upward\n  when it's moving upwind.\nSound tends to emanate from sources in roughly all directions. Some\n  goes towards the listener, some goes away from the listener, and some\n  shoots up into the sky. When you consider the effect of refraction,\n  the question becomes \"Does more sound go into the sky or to the\n  source?\" As it turns out, it will depend on where you stand with\n  respect to the wind.\nIf I'm listening to someone far away talking, and there is wind, I\n  probably want to stand downwind of them. Why? Because the sound that\n  normally goes up into the atmosphere will instead refract downwards\n  towards me, focusing on me. Conversely, if I was standing upwind, the\n  sound would refract up and away from me, causing me to receive a lower\n  effective level.\n\n@Farcher suggested temperature gradient in the comments which in my opinion has quite small effect.\nThanks to Reddit user therationalpi.", "meta": {"post_id": 341704, "input_score": 39, "output_score": 46, "post_title": "Why does wind direction significantly affect sound propagation?"}}
{"input": "The name of the particle (resonance?) in the recent announcement Observation of the doubly charmed baryon $\\Xi^{++}_{cc}$ is complicated. I'm sure it's standard notation but I don't know how to \"decode\" it.\nIs it possible to explain the Xi and the two super-scripts and subscripts? A short description would be fine. I'm wondering if the two plus signs indicate a double charge or isospin or something else, but I'm guessing that the double c's are related to \"doubly charmed\" in the title.", "output": "The PDG naming scheme for hadrons is the authoritative source on this.\nThe easy bit is the superscript: that's just the charge. $++$ means a charge of $+2$.\nThe symbols for baryons are based on those chosen for the baryons formed of light quarks ($u$, $d$, $s$). They encode the isospin and quark content. The rules are relatively straightforward, but I'll refer you to the naming scheme for the full list.\nA light-quark $\\Xi$ has a quark content of $uss$ or $dss$. A heavy-quark $\\Xi$ retains the single $u$ or $d$ and replaces one or both of the $s$ quarks with a $c$ and/or a $b$. This is denoted in the subscript: e.g. a $\\Xi_c$ has $dsc$ or $usc$.", "meta": {"post_id": 343474, "input_score": 29, "output_score": 37, "post_title": "How to \"decipher\" the symbol for the recently announced doubly-charmed baryon?"}}
{"input": "I know this seems like a simple question, but I'm trying to debate with a flat earth theorist. I asked him to explain why can the ISS visibly be seen orbiting the Earth with the naked eye, and he put this question to me instead.\nHe asked: \n\n\"How can a full moon be observed south of an observer's location, despite the fact that if the moon is illuminated by the sun, an observer has to be almost directly between the sun and the moon to observe a full moon?\"", "output": "To answer the question, your friend needs to understand that the sun is not a little thing on the other side of the globe. It is very large, and it only looks small because it is far away. Also the moon is not small and close. So the light of the sun can easily shine past the earth and onto the moon.\nThe other anwsers are also good, but you're not likely to change the flat-earther's mind, because it has more in common with a religion than a science. For example, it demands belief. For example, it has angels and devils. It takes a special skill to change people's religion (not a skill I admire). I've paid attention to it because in its present form it has a strong anti-semitic component. To see what I mean, here's an exposition. Look at \"proofs\" 197-199.\nFlat-earth devotees have thought about these issues a lot longer and harder than most of us, so they have ready answers to objections. It takes a while to build up a store of debunkings of those answers. I won't try to list them all, but just do a little. Casual debunkings get shot down immediately.\nAccording to the flat-earth model, the earth is a disk with the north pole at the center, and they think the Gleason map accurately represents the world.\nOn this map, the lines of latitude form circles around the north pole, and they are the correct distance apart. The radius of the equator is about 6250 miles.\nThere are tropics of Cancer and Capricorn, and Arctic and Antarctic circles.\nAt the outer edge is what they call the \"Ice Wall\" that holds the oceans in.\nThey say the sun is luminous and it circles the north pole at a radius that depends on the season, cycling between the two tropics. The moon does something similar.\nThere are numerous explanations of how this produces sunrise, sunset, and night, but you can see that they all start to fall apart even before you get to the southern hemisphere.\nFor one example, sun's behavior on the equinox is problematic.\nFor another, it's not clear how sextants or astrolabes could measure latitude.\nFor another, it's not clear how sundials could work anywhere, especially in the southern hemisphere.\nThe long and short of this is: Be careful, it's quicksand. Discussions go in circles, laced with invective. The only reason I care is it has scary ramifications. I know that's outside the scope of this forum, but I don't think we can afford to ignore it.", "meta": {"post_id": 345033, "input_score": 19, "output_score": 39, "post_title": "How can a full moon be seen south of an observer's location?"}}
{"input": "I have just experienced a snowfall and I am not so clear on how it works.\nThree days after a short day of snowfall, and having 2 min | 17 max degrees Celsius, full sunny scarcely cloudy each day, there is still some snow persisting in shadow and dark places. \nThis is contrary to my intuition: I would've expected all the snow to have melted and disappeared after the first sunny day, or after the second. Yet we are on the third day and still some snowman heads are alive.\nIs it because the snow contains salt? Or does the snow create low temperature air around itself? Or does the daily morning humidity turn the snow into ice blocks that are harder to melt and more solid to scatter sun rays?", "output": "Just as a complement to Ziggurat's answer: you can try to estimate the time required for the sun to melt a certain quantity of snow by yourself.\n\nThe energy required to melt a mass $m$ of snow is $$Q=L m$$ where $L$ is the latent heat of fusion. For ice, $L=334$ kJ/kg.\nThe density of snow $\\rho$ ranges from $100$ to $800$ kg/m$^3$\nSolar irradiance $I$ ranges from $150$ to $300$ W/m$^2$.\nThe albedo of snow (percentage of reflected sunlight) $A$ ranges from $0.2$ for dirty snow to $0.9$ for freshly fallen snow.\n\nIf the surface exposed to sunlight is $S$, the absorbed energy in the time interval $\\Delta t$ will be \n$$E_{in}=(1-A) IS \\Delta t$$\nIf $V$ is the snow volume, the energy required to melt it will be\n$$E_{melt} =L \\rho V$$\nEquating these two expressions we get\n$$\\Delta t = \\frac{L \\rho V}{(1-A)IS}$$\nAssuming $A=0.9$, $\\rho=300$ kg/m$^3$ and $I=200$ W/m$^2$, we get, for a sheet of snow of surface $1$ m$^2$ and thickness $1$ cm, $\\Delta t \\simeq 5 \\cdot 10^4$ s, i.e. $\\simeq 14$ hours.\nThis is a very rough estimate that doesn't consider conduction processes. But anyway, you can see that even if we assume a pretty high irradiance we need a considerably long time to melt a modest quantity of snow. If the snow is in the shade, the value of $I$ will be less. Also, for snowmen, since we would be talking about compressed snow, the value of $\\rho$ could be $2-2.5$ times larger.", "meta": {"post_id": 346407, "input_score": 36, "output_score": 54, "post_title": "Why does snow stay after a snowfall?"}}
{"input": "If a tennis ball and a bowling ball are dropped of a rooftop, they hit the ground at the same time. But if they are rolled down a slope, the bowling ball rolls faster. Why?", "output": "The easy explanation is that the tennis ball is hollow.\nWhen you merely drop the objects, they are subjected to the same acceleration - the aceleration due to gravity - and nothing else. Conservation of energy then says that their gravitational potential energy should be completely transformed into kinetic energy at the ground:\n$$mg\\Delta h=\\frac{1}{2}mv^2\\to v=\\sqrt{2g\\Delta h}$$\nSince the initial heights $\\Delta h$ are equal, they both have the same velocity as each other (though not constant in time) no matter how far they fall and, thus, hit at the same time.\nHowever, when you roll them down the roof, the initial gravitational potential energy, $mg\\Delta h$, is transformed not only into kinetic energy, but also into rotational energy. The rotational energy of something is $\\frac{1}{2}I\\omega^2$, where $I$ is the moment of inertia (the rotational equivalent of mass) and $\\omega$ is the angular velocity ($\\omega=v/r$; the velocity of the object divided by its radius).\nThis is all well and good, so the difference between the bowling ball and the tennis ball is now because the bowling ball is solid and the tennis ball is hollow. When just dropped, there is no difference. However, when rolling, the different distributions of mass affect the moments of inertia differently. A solid sphere has $I=\\frac{2}{5}mr^2$, while a hollow sphere (I know the tennis ball is not perfectly hollow, but let's make this approximation, okay?) has $I=\\frac{2}{3}mr^2$. What does this mean? Well, let's do the math (math is fun!).\nFor the bowling ball, we have:\n$$mgh=\\frac{1}{2}\\left(I\\omega^2+mv^2\\right)=\\frac{1}{2}\\left(\\frac{2}{5}mr^2\\cdot\\frac{v^2}{r^2}+mv^2\\right)\\to v=\\sqrt{\\frac{10}{7}gh}$$\nWhereas, for the tennis ball, we have:\n$$mgh=\\frac{1}{2}\\left(I\\omega^2+mv^2\\right)=\\frac{1}{2}\\left(\\frac{2}{3}mr^2\\cdot\\frac{v^2}{r^2}+mv^2\\right)\\to v=\\sqrt{\\frac{6}{5}gh}$$\nNotice that the mass of either ball is mostly irrelevant and that, since $\\sqrt{\\frac{10}{7}}>\\sqrt{\\frac{6}{5}}$, the forward velocity, $v$, of the bowling ball is greater than that of the tennis ball; just because one is hollow and one is solid.\nIt's also worth noting that the radius, as you may have concluded, does not ideally affect the forward velocity. This is something easily shown through the equations above as well as experimentally. Grab some solid spheres of different radii and roll them down an incline (I work in a physics teaching lab, so believe me when I say I've done this many times), you should see they hit the bottom at the same time. Yay! Physics is cool!", "meta": {"post_id": 349042, "input_score": 30, "output_score": 72, "post_title": "Why does a bowling ball roll down faster on a slope than a tennis ball, yet both hits the ground at the same time if they're dropped from the rooftop?"}}
{"input": "Basically I'm wondering what is the nature of an out of focus image. Is it randomized information? Could the blur be undone by some algorithm?", "output": "Yes, it's called deconvolution. Here are some examples of deconvolved images from microscopes:\n\n\n\nI found these by Googling for \"example of deconvolved image from a microscope\".\nIt's possible by shooting lasers through the lens and generating a map of ray data that can be used in the deconvolution algorithm. I have also seen this done with an in focus image and deconvolved to bring a completely different plane into focus.", "meta": {"post_id": 349847, "input_score": 72, "output_score": 38, "post_title": "Could a computer unblur the image from an out of focus microscope?"}}
{"input": "I am not planning on staring into the sun during an eclipse or any other time.\nI have been reading about how no variety of regular sunglasses are safe enough to view the eclipse with. I'm not talking about being able to see things clearly, but just actual eye safety. \nFrom what I understand it is the ultraviolet light that causes damage to the retina, but maybe it is more complicated. \nHow do my eyes get hurt if I am looking at the sun through so called \"100% UV protection\" and what makes the eclipse glasses sold in stores different?\nedit: To clarify this is not about how the rays from the sun are dangerous, but about why \"100% UV blocking\" sunglasses fail. Do other dangerous rays get through? Is the \"100%\" marketing? Essentially, in what way are the best consumer sunglasses inadequate for looking at an eclipse.\nAnswers about pupil dilation and what makes an eclipse more dangerous for naked-eye viewers are not what I'm after.", "output": "You are correct that almost always it is the UV content of sunlight and not its power that is the main hazard in staring at the Sun. \nThe lighting during a total eclipse is one of those situations outside the \"almost always\". Eclipses did not weigh heavily on our evolution, so we are ill kitted to deal with them.\nMoreover, UV sunglasses are not designed to attenuate direct sunlight, only reflected sunlight.\nNormally, the eye's pupil is shrunken to about a millimeter diameter in bright sunlight. This means that it admits about a milliwatt of sunlight, which, for healthy retinas, is nowhere near enough to do thermal damage (see my answer here for further discussion).\nDuring an eclipse, the pupil dilates to about $7\\,\\mathrm{mm}$ diameter to adapt for the low light levels of the eclipse's twilight. Thus its aperture is fifty times bigger than it normally is in sunlight. This means it admits a great deal more UV than normal (and the corona, at $100\\,000\\,\\mathrm K$, radiates a great deal of this). You're getting about $50$ times the dose you would normally get even looking directly at the Sun. \nFurthermore, suddenly the diamond ring phase begins, and high levels of sunlight reach the retina before the pupil can shrink again. The latter happens only very slowly. So even thermal damage is a risk here.", "meta": {"post_id": 352914, "input_score": 49, "output_score": 43, "post_title": "Why aren't 100% UV blocked sunglasses safe to view an eclipse with?"}}
{"input": "Here is a picture of my power adapter. You can see in has one green LED lit when charging.\n\nNow here is a picture of my mirror with beveled edges. When I view the power adapter in the mirror, I see three (3) projections of the LED:  the original, plus two \"ghost\" LEDs (one on either side). \n\nCan someone explain how the mirror's bevels are able to cause these triplicate projections?  And why does it only appear to affect the LED (except near the edges)?  If the mirror had a different bevel pattern (for example, in the following image), would it affect the number of \"ghost\" projections?\n\n\nUPDATE:  For what it's worth, I took another picture late at night, with the camera lens as close to the mirror as possible to maximize the angle of reflection.  Doing this showed me 6 (!) ghost projections, which is (mostly) in line with @Agent_L's answer (There are actually many more \"after\", but as every next one is, let's say, 90% dimmer than the previous, only the first is noticeable.).  Apologies for the poor image quality.", "output": "I believe this is what's happening:\n\n\nThe first \"beforeghost\" is the faint reflection off the surface of the\nglass.\nThe second solid image is the intended reflection off metalized layer.\nThe third \"afterghost\" is the faint internal reflection off the inside of the glass, then properly reflected again off the metalized layer.\n\nThere are actually many more \"after\", but as every next one is around 96% dimmer than the previous (exact number courtesy of Jan Hudec), only the first is noticeable. They're all spaced nicely and evenly, because this spacing is determined by the thickness of the glass.\nThis effect has only coincidental relation to the beveled edge. If the glass is very thin, all images appear so close to each other that they appear as blur, not distinct images. The glass has to be quite thick - and thick mirrors tend to have large, decorative bevels. (Also, the observed object needs to be small and standing out - just what your LED is.)\nSimilar effects happen in eyeglasses, and those are sometimes specially treated to minimize it, known as \"antireflection coating\".\nAn effect similar to \"afterghost\" is deliberately exploited in so called \"infinity mirrors\". Instead of internal reflection they employ a second, partially transmissible mirror faced inside to increase the reflection into useful levels.", "meta": {"post_id": 356551, "input_score": 77, "output_score": 143, "post_title": "Why does my beveled mirror make triplicate \"ghosts\"?"}}
{"input": "So my friend and I had a debate. He stated that we don't have to worry about the sun consuming the Earth \u2500 we'll already be broken apart by then. He states that as the sun expands, its Roche limit will also expand. The Earth will have been broken apart long before the sun touches its orbit.\nI'm arguing that the sun isn't changing mass (ignoring Mercury, Venus, and solar winds) and its gravitational force won't change, ergo eventually the boundary of the sun will be further than the Roche limit. The Earth will stay intact as it gets cooked.\nWhich, if either, of us is correct?", "output": "You are correct, and your friend is not.\nSo long as the Sun remains spherically symmetric, its gravitational field can be replaced with the field of a point mass at its centre of mass, which is what determines the Roche limit (so, in particular, it fixes both the gravitational field and the gravitational field gradient at any position you care to name). The radial extent of the mass distribution is irrelevant so long as the spherical symmetry is retained.\nI should also say I find it dubious that the Earth would break apart even if it did skim the Roche limit of some other body, because the Roche limit sets the break-apart point for systems that are bound gravitationally, i.e. for loose piles of rubble held together by their own gravity. This is not the case for the Earth, which is held together by strong chemical bonds in the rock of the mantle and core. Given a strong enough gravitational field gradient you can imagine the Earth getting torn apart, but this will happen a good bit further in than the Roche limit, I should think.", "meta": {"post_id": 357882, "input_score": 27, "output_score": 39, "post_title": "As the sun expands, will its Roche limit also expand?"}}
{"input": "I am reading The Elegant Universe by Brian Greene.\nIn many places it's directly/indirectly mentioned that the LHC may not be able to detect (with the current technology) heavy particles to prove Super-Symmetry.\nWhat prevents such accelerators from detecting such heavy particles?\nI always thought it would be the opposite as heavy particles can make a stronger impression on detectors than light particles.", "output": "It's not detecting the particles that is hard, it's making them in the collisions.\nAlthough the LHC collision energy is 14TeV, collisions aren't between the protons but rather between individual quarks inside the protons. Since the energy is shared between the three quarks in a proton the actual quark-quark collision energy is a lot less than 14TeV. Even then, for various reasons to do with conservation of momentum not all that energy can go into creating new particles. The end result is that it's hard to create particles much about above a TeV in weight. More on this in What is the maximal particle mass one can create via the LHC? Can we create dark-matter particles via the LHC? if you want to pursue this further.\nThe upshot is that if the heavy particles have a mass much greater than a TeV the LHC can't create them, and obviously if they can't be created they can't be detected. All is not completely lost since we might be able to detect heavy particles indirectly by the influence they have on the collisions we can detect. Even so the upper mass limit is still restricted.", "meta": {"post_id": 358956, "input_score": 23, "output_score": 42, "post_title": "Why can't the LHC detect heavy particles?"}}
{"input": "I've already read the below questions (and their answers) regarding neutrinos vs. electromagnetic waves propagating through space, but I'm still not clear on something.\n\nNeutrinos arrived before the photons (supernova)\nThe delay between neutrinos and gammas in a supernova, and the absolute mass scale of neutrinos\nNeutrino Speed in Supernova\nSpeed of neutrinos (Especially dmckee's answer)\n\nGiven that\n\nLight from SN 1987A arrived 2 or 3 hours after its neutrinos, implying that it was \"slowed down\" relative to the neutrinos\nLight from SN Refsdal has been \"lensed\" multiple times to re-appear on time scales of several decades, implying that light interacts with matter (mass)\nNeutrinos interact extremely little with matter but are known to have mass and energy\n\nQuestion\nWhy did neutrinos (with their mass and momentum) arrive before the light (considered to be massless) from SN 1987A?  Considering SR and GR, this seems to be a contradiction.  What am I missing?\nPostscript\nI've tried desperately to avoid using the word \"photon\" above (in reference to light) after learning of the Lamb Controversy\u2122 (via related discussions here and here on Phys SE).", "output": "Both neutrinos and photons were produced in the core of the star but photons have a much stronger probability of interacting with the outer layer of the star than the neutrinos. Thus the photons were trapped whereas the neutrinos easily escaped. This has nothing to do with mass and all to do with the cross-section of interaction with protons/electrons for photons on one hand and for neutrinos on the other.\nReading @dmckee's answer made me realise that the phrasing of the previous paragraph makes it sound like the light flash we observe might be due to those photons eventually escaping. This is not what I meant: it would take millions of years for those photons to escape, as is well known for our own Sun. It is only because the outer layers of the star are eventually blown off that we see a light flash.\nI should also have pointed out that electron neutrinos can escape only in the early stages of the collapse of type II supernovae. As the density increases beyond a few times $10^{11} \\text{g}\\ \\text{cm}^{-3}$, the scattering of neutrinos with stellar matter is sufficient to make the timescale of the diffusion of neutrinos out of the star shorter than the collapse timescale. This is a combination of increasing density (and therefore increasing interactions) and accelerating collapse. So the neutrino flash measured on Earth came from the very beginning of the evolution into a supernova.\nLet me add some orders of magnitude. The cross-section of photon-electron scattering is of the order of $10^{-24} \\text{cm}^2$. Compare this with the neutrino-nucleon scattering. It varies as the square of the neutrino energy:\n$$\\sigma_\\nu \\approx 10^{-44} E_\\nu^2\\ \\text{cm}^2$$\nwith the energy in MeV. So that's 20 orders of magnitude, give or take.\nWhere does this huge difference come from? Neutrinos interact solely through the weak interaction whereas photons interact through the electromagnetic interaction with charged nuclei and electrons in the star plasma. So this is just a reflection of the relative strength of both interactions. There is no reason it should be like that: it is just the way our universe is! We would not be here to discuss these matters if it were not, actually\u2026", "meta": {"post_id": 359002, "input_score": 41, "output_score": 71, "post_title": "Why do the neutrinos (with mass) from a supernova arrive before the light (no mass)?"}}
{"input": "I know that quantum mechanics is sometimes called 0+1 dimensional quantum field theory. What is the meaning? How should we understand it?", "output": "In field theory, a field can be thought of as a map from the spacetime $M$, usually a Lorentzian manifold---a particularly popular choice is $\\Bbb R^{1,n-1}$ (Minkowski space)---to some other space. For instance, a scalar field $\\phi$ can be viewed as a map $\\phi:M\\to \\Bbb R$, or equivalently as a global section of the trivial (real) line bundle over $M$. The spacetime $M^n$ has one timelike direction and $n-1$ spacelike directions, and one can say that one studies $(n-1)+1$-dimensional field theory.\nWhen doing mechanics, what do we use for a \"field\"? The position of the particle(s)! The position depends only on time, and hence we have maps $x_i:\\Bbb R\\to \\Bbb R^n$ (in case the space in which the particles move is not simply $\\Bbb R^n$, the target may be some other Riemannian manifold of dimension $n$) and fitting this into the general QFT picture we can identify $\\Bbb R$ as our \"spacetime\", where we now have no spatial directions and only a timeline direction. Thus, we may call the theory a $0+1$-dimensional field theory. After quantization, one obtains a $0+1$-dimensional quantum field theory.", "meta": {"post_id": 361856, "input_score": 25, "output_score": 36, "post_title": "Why is quantum mechanics called 0+1 dimensional QFT?"}}
{"input": "I was reading up on the Clay Institute's Millenium prizes in mathematics.\nAnd I noticed the Navier-Stokes equations were described as minimally understood.\nAs far as I was taught in physics a few weeks ago(SCQF Level 6), they are used but solutions to them are hard to find in three dimensions because they require large amounts of computational power due to the complexity of the equations and so approximations are used.\nHow were the equations discovered in the first place if we can't solve them?", "output": "I just wanted to give a more concrete idea of how we know these equations even though we have trouble proving analytical theorems about them.\nStuff moving in space\nConsider any stuff (as in, any conserved quantity) distributed over space. We know that we can describe this with a time-dependent density field $\\rho(x,y,z,t)$ such that any little volume $dV$ has some amount of stuff $\\rho~dV$ at that point. We also know that this stuff might be flowing around over time and we formally treat this by saying that we want to know the flow through a little flat surface of area $dA,$ which is oriented in the $\\hat n$ direction: that is, the surface is normal to $\\hat n$ and \"positive\" flow will be in the $+\\hat n$ direction. Combined together this is a vector $d\\mathbf A = \\hat n~dA$ and there is some vector field $\\mathbf J(x,y,z,t)$ such that the amount of stuff which flows through this area over a time $\\delta t$ is $\\delta t~d\\mathbf A\\cdot\\mathbf J(x,y,z,t).$ With $\\rho$ and $\\mathbf J$ we know almost everything. Since the stuff is conserved, we can say that in this box of volume $dV,$ if the amount of stuff in the box changes, it is either because there was a net flow into or out of the sides of the box, so we are doing some $\\iint d\\mathbf A\\cdot \\mathbf J$ which turns out by Gauss's theorem to be just $dV~\\nabla\\cdot\\mathbf J,$ or else it came from outside the system we're studying, so there is some term $dV~\\Phi$. Equating that to the change in the box $dV~(\\partial\\rho/\\partial t)$ gives the simple starting equation $${\\partial \\rho\\over\\partial t} = -\\nabla\\cdot \\mathbf J + \\Phi.$$Now when we've got a flow field $\\mathbf v(x,y,z,t)$ dictating how a fluid flows, the most dominant transport term is that the box flows downstream, $\\mathbf J = \\rho~\\mathbf v + \\mathbf j$ for some deviation $\\mathbf j.$ Usually the principal deviation then comes from Fick's law, that there is a flow proportional to the difference in density between adjacent points, $\\mathbf j = -D~\\nabla \\rho,$ but there may be more complex terms there; in particular we shall see pressure here.\nConservation of momentum\nThe key point here is that $p_x$, the momentum in the $x$-direction, is a stuff. It is a known conserved quantity. It is conserved as a direct result of Newton's third law which turns out, under Emmy Noether's celebrated theorem, to be the same as the statement that the laws of physics are the same at position $x$ as they are at position $x+\\delta x$, for a suitable definition of \"laws of physics.\" We are pretty sure about this, and we are pretty sure that the momentum of the fluid itself in the $x$-direction must therefore also be conserved, and this is $\\rho~v_x$ where I am shifting definitions a bit on you: $\\rho$ now refers to the mass density field and $v_x$ still refers to the fluid velocity in the $x$-direction.\nNow a flow of momentum per unit time, which we said is what $\\mathbf J\\cdot d\\mathbf A$ is, is a force. Therefore $\\mathbf J$ naturally takes the form of a force per unit area in this context. Now we know that Newton's expression for viscous forces was in fact to write $F_x = \\mu~A~v_x/y$ where I am moving a surface of a fluid at speed $v_x$ at a perpendicular distance $y$ from a place where it is being held still; it will not surprise you at all to see that this is very similar to Fick's law and can be written as just $\\mathbf j_\\text{viscosity} = -\\mu~\\nabla v_x.$  To that we also need to add the effects of pressure, as a lowering in pressure also drives a fluid motion; this is a little bit harder to reason out but it takes the form that we can imagine a constant flow in the $x$-direction of $p~\\hat x$ and then deviations in this flow would produce the change in momentum per unit time $-\\partial p/\\partial x$ through this divergence term. (That's a little bit of a sloppy way to show that we are talking about a stress tensor and part of it is $p~\\mathbf 1$, the identity matrix multiplied by the pressure.) Combining these two components of $\\mathbf j$ we have \n$${\\partial \\over\\partial t}(\\rho~v_x) = -\\nabla\\cdot (\\rho~v_x~\\mathbf v - \\mu \\nabla (v_x)) - \\frac{\\partial p}{\\partial x} + \\Phi_x.$$The external contribution $\\Phi$ comes from forces influencing the fluid from outside, like gravity. \nIn the Navier-Stokes equations the Millenium Prize has restricted itself to a considerably simpler case where $\\nabla\\cdot\\mathbf v = 0$ and $\\rho$ and $\\mu$ are constant, which we call \"incompressible flow.\" This is generally a valid assumption when you're interacting with a fluid at speeds much lower than the speed of sound in that fluid; then the fluid would rather move away from you than be compressed into any one place. In this case we can commute $\\rho$ out of all of the spatial derivatives and then divide by it, so that the only impact is to rewrite $\\nu=\\mu/\\rho$ and $\\lambda=p/\\rho$ and $a_x=\\Phi_x/\\rho$, eliminating the unit of mass from the equation. For $v_x$ we have specifically,\n$${\\partial v_x\\over\\partial t} + \\mathbf v\\cdot\\nabla v_x - \\nu \\nabla^2 v_x = - \\frac{\\partial \\lambda}{\\partial x} + a_x,$$ and then we can extend the above analysis to the directions $y,z$ too to find,\n$$\\dot{\\mathbf v} + (\\mathbf v\\cdot\\nabla)\\mathbf v - \\nu \\nabla^2 \\mathbf v = - \\nabla \\lambda + \\mathbf a.$$This is the version of the Navier-Stokes equations written down in the Millenium Prize; we have a very straightforward explanation of this as \"The flow of momentum in a small box flowing downstream in an incompressible homogeneous Newtonian fluid is due entirely to Fick's-law diffusion of the momentum due to the viscosity of the fluid, plus a force due to pressure gradients inside the fluid, plus forces imposed by the external world.\" \nWhy this equation?\nThe understanding of the physics of how we got to this equation is not in question. What's at stake is the mathematics of this equation, in particular this $(\\mathbf v \\cdot \\nabla) \\mathbf v$ term which contains $\\mathbf v$ twice and thereby makes it a nonlinear partial differential equation: given two flow fields $\\mathbf v_{1,2}$ which are valid, in general $\\alpha \\mathbf v_1 + \\beta \\mathbf v_2$ will not solve this equation, removing our most powerful tool from our toolbox. \nNonlinearity turns out to be unbelievably hard to solve in general, and essentially the Clay Mathematics institute is giving the million-dollar prize for anyone who cracks nonlinear differential equation theory strongly enough that they can answer one of the more basic mathematical questions about these Navier-Stokes equations, as a \"most basic example\" for their new theoretical toolkit. \nThe idea of the Clay prizes is that they are specific problems (which is important for awarding a prize for their solution!) but that they seem to require powerful new general ideas which would allow our mathematics to go into places where it has historically been unable to go. You see this for example in $\\text{P} = \\text{NP}$, it's a very specific question but to answer it we would seem to need to have a better handle on \"here's a classification of set of stuff which computers can do, and here are some things which a computer can't efficiently do\" which nobody has yet been able to convincingly present. A new toolbox which could resolve this \"stupid little\" question would therefore profoundly improve our ability to work on a huge class of related problems in computation.", "meta": {"post_id": 362780, "input_score": 35, "output_score": 46, "post_title": "How were the Navier-Stokes equations found in the first place if we can't solve them?"}}
{"input": "Just recently, LIGO and Virgo successfully detected new signs of gravitational waves. This time, instead of colliding black holes, it is a pair of colliding neutron stars. This collision emits light and gravitational waves.\nI read in CNN: First-seen neutron star collision that this collision had a signal that lasted for 100 seconds. I read before that the first gravitational wave detection of two colliding black holes had a signal lasting for a split second, and this is also an indication of how long the merging takes place. Is this accurate?\nIf so, if the colliding neutron star has signal lasting for 100s, does that mean that the merging takes a longer time? In addition, if the merging of two black holes happen almost instantly (short time), then why does the merging of two neutron star take up more amount of time?", "output": "It is not that the merger of two neutron stars takes longer, the inspiral and merger of a pair of neutron stars just spends a longer time in the frequency range where LIGO is most sensitive. Let me try to explain in more detail.\nLIGO is sensitive only to gravitational waves with frequencies between approx. 10 Hz and 10 kHz. (See LIGO sensitivity curve). As has been much discussed in the press announcements, the gravitational waves from the merger of a compact binary follow a \"chirp\" pattern increasing both in amplitude and frequency until it cuts off at the merger. The maximum frequency reached is inversely proportional to the \"chirp mass\" a rather arcance combination of the masses of the two components of the binary. \nThe upshot of this, is that heavier binaries have a lower maximum frequency than lighter binaries. For the first event, GW150914, which was very heavy, this meant that LIGO was only sensitive to the very last part of the inspiral (only the last few cycles). The lightest BH binary merger to date, GW151226, already spent a lot more cycles of its inspiral in LIGO's sensitivity range.\nNow neutron stars are obviously even lighter, allowing LIGO to see even more of the cycles of the inspiral before the merger (around 3000). In fact, for the GW170817,  the final merger happens in a frequency range where LIGO is no longer that sensitive. The most accurate data is obtained from the inspiral phase.", "meta": {"post_id": 363306, "input_score": 31, "output_score": 53, "post_title": "Why did the neutron star merger signal last for so much longer than the black hole merger signals?"}}
{"input": "I've recently come across a strange result when comparing the Hamiltonian and Lagrangian formulations of classical mechanics.\nSuppose we are working in the regime where we can say the Hamiltonian $H$ is equal to the total energy $$H=T+V.\\tag{1}$$ That is, the constraints are holonomic and time-independent, and the potential is $V=V(q)$ where $q$ a the generalized position vector $q=(q_1,q_2,\\ldots,q_n)$. Let $$L=T-V\\tag{2}$$ be the Lagrangian.\nNow, the Euler-Lagrange equations tell us \n$$\\frac{d}{dt}\\frac{\\partial L}{\\partial \\dot{q_\\sigma}} - \\frac{\\partial L}{\\partial q_\\sigma} = 0,\\tag{3}$$\nfor the generalized coordinate $q_\\sigma,$ with $\\sigma\\in\\{1,\\ldots,n\\}$. \nWe also know that the conjugate momenta are defined by $p_\\sigma = \\frac{\\partial L}{\\partial \\dot{q_\\sigma}}$. So this equation tells us\n$$\\dot{p_\\sigma} - \\frac{\\partial L}{\\partial q_\\sigma} = 0.\\tag{4}$$\nIn the Hamiltonian formalism, we know that\n$$\\dot{p_\\sigma} = -\\frac{\\partial H}{\\partial q_\\sigma}.\\tag{5}$$\nCombining these gives\n$$\\frac{\\partial H}{\\partial q_\\sigma}=-\\frac{\\partial L}{\\partial q_\\sigma}.\\tag{6}$$\nNow, this seems very strange because in the regime we are considering, this implies that\n$$\\frac{\\partial (T+V)}{\\partial q_\\sigma}=-\\frac{\\partial (T-V)}{\\partial q_\\sigma}\\Rightarrow \\frac{\\partial T}{\\partial q_\\sigma}=0. \\tag{7}$$\nOf course, there are many examples where this is not true. I.e., simply consider the free particle analyzed using polar coordinates. Then we have\n$$H = L = T = \\frac{1}{2}m(\\dot{r}^2 + r^2\\dot{\\theta}^2),\\tag{8}$$\nand so\n$$\\frac{\\partial T}{\\partial r } \\neq 0.\\tag{9}$$\nWhat is the explanation for this strange discrepancy? Am I making a silly mistake somewhere?", "output": "The problem is that the Lagrangian and the Hamiltonian are functions of different variables, so you must be exceedingly careful when comparing their partial derivatives. \nConsider the differential changes in $L$ and $H$ as you shift their arguments:\n$$dL = \\left(\\frac{\\partial L}{\\partial q}\\right) dq + \\left(\\frac{\\partial L}{\\partial \\dot q}\\right) d\\dot q$$\n$$dH = \\left(\\frac{\\partial H}{\\partial q}\\right) dq + \\left( \\frac{\\partial H}{\\partial p}\\right) dp$$\nFinding $\\frac{\\partial L}{\\partial q}$ corresponds to wiggling $q$ while holding $\\dot q$ fixed.  On the other hand, finding $\\frac{\\partial H}{\\partial q}$ corresponds to wiggling $q$ while holding $p$ fixed.  If $p$ can be expressed a function of $\\dot q$ only, then these two situations coincide - however, if it also depends on $q$, then they do not, and the two partial derivatives are referring to two different things.\nExplicitly, write $p = p(q,\\dot q)$.  Then using the chain rule, we find that\n$$dH = \\left(\\frac{\\partial H}{\\partial q}\\right) dq + \\left(\\frac{\\partial H}{\\partial p}\\right)\\left[\\frac{\\partial p}{\\partial q} dq + \\frac{\\partial p}{\\partial \\dot q} d\\dot q\\right]$$\nSo, if we shift $q$ but hold $\\dot q$ fixed, we find that\n$$ dL = \\left(\\frac{\\partial L}{\\partial q} \\right)dq$$\nwhile\n$$ dH = \\left[\\left(\\frac{\\partial H}{\\partial q} \\right) + \\left(\\frac{\\partial H}{\\partial p}\\right)\\left(\\frac{\\partial p}{\\partial q} \\right)\\right]dq$$\nIf $L(q,\\dot q) = H(q,p(q,\\dot q))$ as in the case of a free particle, then we would find that\n$$dL = dH$$\nso\n$$\\left(\\frac{\\partial L}{\\partial q}\\right)= \\left(\\frac{\\partial H}{\\partial q} \\right) + \\left(\\frac{\\partial H}{\\partial p}\\right)\\left(\\frac{\\partial p}{\\partial q} \\right)$$\n\nWe can check this for the free particle in polar coordinates, where\n$$L = \\frac{1}{2}m(\\dot r^2 + r^2 \\dot \\theta^2)$$\n$$ H = \\frac{p_r^2}{2m} + \\frac{p_\\theta^2}{2mr^2}$$\n$$ p_r = m\\dot r \\hspace{1 cm} p_\\theta = mr^2 \\dot \\theta$$\nfor the left hand side,\n$$ \\frac{\\partial L}{\\partial r} = mr \\dot \\theta^2$$\nFor the right hand side,\n$$ \\frac{\\partial H}{\\partial r} = -\\frac{p_\\theta^2}{mr^3} = -mr\\dot\\theta^2$$\n$$ \\frac{\\partial H}{\\partial p_\\theta} = \\frac{p_\\theta}{mr^2} = \\dot \\theta$$\n$$ \\frac{\\partial p_\\theta}{\\partial r} = 2mr\\dot \\theta$$\nso\n$$ \\frac{\\partial H}{\\partial r} + \\frac{\\partial H}{\\partial p_\\theta} \\frac{\\partial p_\\theta}{\\partial r} = -mr\\dot \\theta^2 + (\\dot \\theta)(2mr\\dot \\theta) = mr\\dot \\theta^2$$\nas expected.\n\nYour mistake was subtle but common.  In thermodynamics, you will often find quantities written like this:\n$$ p = -\\left(\\frac{\\partial U}{\\partial V}\\right)_{S,N}$$\nwhich means\n\nThe pressure $p$ is equal to minus the partial derivative of the internal energy $U$ with respect to the volume $V$, holding the entropy $S$ and particle number $N$ constant\n\nThis reminds us precisely what variables are being held constant when we perform our differentiation, so we don't make mistakes.", "meta": {"post_id": 365390, "input_score": 21, "output_score": 40, "post_title": "Apparent paradox between Lagrangian and Hamiltonian formulations of classical mechanics"}}
{"input": "I have bought a handmade rug of size 1.5 $\\times$ 2m. About 1-2 weeks ago I noticed the rug was not in the center of my room and it had moved a bit. I thought maybe because I walked on it, it has moved. I put it in its place and it happened again and again.\nIt moves about 1 millimeter each day; I placed a marker on the floor so I can calculate the distance it moves. I avoid walking on it so my steps don't move it.\nWhat reason can be causing this rug to move? Can a magnetic field be the reason? It is a handmade rug made of animal fur, like wool. I used my smartphone to find if any magnetic field exists near the rug and I see $40\\text{-}50\\:\\mu\\mathrm{T}$ which is close to the Earth's magnetic field. I used an app with an orientation sensor and the floor is level, so that Earth's gravity can't be moving the rug.\nI have no pet, no maid, no room mate. Nobody can prank me or move this rug.", "output": "rugs woven by machine often exhibit a built-in anisotropy in the direction of the fiber \"lay\" within the rug's structure: rather than being perfectly perpendicular to the plane in which the rug lies, the fibers in the rug are all tilted slightly in one direction. This is manifestly apparent if you run a vacuum cleaner head back and forth across the surface of such a rug: the vacuum cleaner head will be deflected off a straight path and persistently skate sideways.\nIf that fiber lay is present on the backside of the rug, then vibrations from the floor or the action of walking across the rug will flex the fibers and urge the rug to creep in one direction. \ntoys have been designed to exploit this creep phenomenon: a little piece of stiff, rough cloth with a uniform tilt to the bristles in it will \"magically\" scoot across a smooth vibrating surface at a speed proportional to the strength of the vibrations.", "meta": {"post_id": 366769, "input_score": 67, "output_score": 46, "post_title": "What explanations are there for a rug steadily creeping at about a millimeter/day rate across a room?"}}
{"input": "In chapter 23.6, Schwartz's quantum field theory book defines renormalizability as follows, paraphrasing a bit for brevity:\n\nConsider a given subset $S$ of the operators and its complement $\\bar{S}$. Choose coefficients for the operators in $S$ to be fixed at a scale $\\Lambda_L \\ll \\Lambda_H$. If there is any way to choose the coefficients of the operators in $\\bar{S}$ as a function of $\\Lambda_H$ so that in the limit $\\Lambda_H \\to \\infty$ all operators have finite coefficients at $\\Lambda_L$, the theory restricted to the set $S$ is renormalizable. \n\nI'm very confused about what Schwartz is saying here. The RG flow equations are just differential equations that run backward just as well as they run forward. Thus you can choose any couplings at $\\Lambda_L$ whatsoever for all of the operators and simply run the RG flow backwards to see what the couplings at $\\Lambda_H$ should be. \nI also don't see how this is equivalent to the usual definition of 'no irrelevant operators in the Lagrangian'. Moreover, I'm not sure what 'the theory restricted to the set $S$' means. Does this mean we are supposed to forcibly set the coefficients for $\\bar{S}$ to zero at $\\Lambda_L$? \nCould somebody shine some light on this passage?", "output": "This is a very good question which, however, shows the extent of the reigning confusion about renormalization even four decades after Wilson's Nobel Prize winning theory on the matter. I essentially answered the OP's question, and much more, about constructing continuum QFTs in Wilson's framework in my expository article \"QFT, RG, and all that, for mathematicians, in eleven pages\" but in a very condensed fashion (one needs to do computations on the side to follow what is being said). So let me give more details pertaining to the OP's specific question. I should preface this by saying that what follows is a \"cartoon\" for renormalization. I will oversimplify things by ignoring anomalous dimensions, marginal operators, and nonlocal terms generated by the RG. You will not find technical details but hopefully the conceptual picture and logical structure of renormalization will become clearer.\nThe OP is right to point out that in the setting of ODEs and dynamical systems a first order equation can be run backwards in time.\nSo let me start by recalling some important terminology from that area.\nConsider a first order nonautonomous ODE of the form\n$$\n\\frac{dX}{dt}=f(t,X)\\ .\n$$\nIt generates a flow (groupoid morphism from time pairs to diffeomorphisms of phase space) I will denote by $U[t_2,t_1]$ which sends the initial value $X(t_1)$ to the value of the solution at time $t_2$. It trivially satisfies $\\forall t, U[t,t]={\\rm Id}$ and the semigroup property\n$$\n\\forall t_1,t_2,t_3,\\ \\ U[t_3,t_2]\\circ U[t_2,t_1]=U[t_3,t_1]\\ .\n$$\nThis time-dependent situation is to be distinguished from the autonomous ODE case\n$$\n\\frac{dX}{dt}=f(X)\n$$\nwhere $U[t_2,t_1]=U[t_2-t_1,0]=:U[t_2-t_1]$.\nIn Wilson's RG, time is scale or more precisely, $t=-\\log\\Lambda$ where the UV cutoff is implemented in momentum space by a condition like $|p|\\le\\Lambda$ or in position space by $\\Delta x\\ge \\Lambda^{-1}=e^t$. The high energy physics literature usually works in a nonautonomous setting while it is essential to translate the equation to autonomous form for a proper understanding of Wilson's RG. The latter imported tools and concepts from dynamical system theory like fixed points, stable and unstable manifolds etc. It is possible to do some contortions to try to make sense of these concepts in the nonautonomous setting, but these truly are notions that are congenial to autonomous dynamical systems.\nLet $\\mu=:\\mu_{-\\infty,\\infty}$ denote the probability measure corresponding to the free Euclidean theory.\nIts propagator is\n$$\n\\int \\phi(x)\\phi(y)\\ d\\mu_{-\\infty,\\infty}(\\phi)=\\langle \\phi(x)\\phi(y)\\rangle_{-\\infty,\\infty}=\n\\int\\frac{dp}{(2\\pi)^D} \\frac{e^{ip(x-y)}}{p^{D-2\\Delta}}\n$$\nwhere $\\Delta$ is the scaling dimension of the field $\\phi$. Normally, $\\Delta=\\frac{D-2}{2}$ but I will allow more general $\\Delta$'s\nin this discussion.\nNow let me introduce a mollifier, i.e., a smooth function of fast decay $\\rho(x)$ such that\n$\\int \\rho(x)\\ dx=\\widehat{\\rho}(0)=1$.\nFor any $t$, let me set $\\rho_t(x)=e^{-Dt}\\rho(e^{-t}x)$, so in particular $\\rho_0=\\rho$.\nLet $\\mu_{t,\\infty}$ be the law of the field $\\rho_t\\ast\\phi$ where $\\phi$ is sampled according to $\\mu_{-\\infty,\\infty}$ and we used a convolution with the rescaled mollifier. In other words, $\\mu_{t,\\infty}$ is the free cutoff measure at $\\Lambda_H=e^{-t}$ and propagator\n$$\n\\int \\phi(x)\\phi(y)\\ d\\mu_{t,\\infty}(\\phi)=\\langle \\phi(x)\\phi(y)\\rangle_{t,\\infty}=\n\\int\\frac{dp}{(2\\pi)^D} \\frac{|\\widehat{\\rho}_t(p)|^2\\ e^{ip(x-y)}}{p^{D-2\\Delta}}\\ .\n$$\nNote that $\\widehat{\\rho}_t(p)=\\widehat{\\rho}(e^t p)$ which we assume to have decreasing modulus with respect to $t$.\nWe have $\\widehat{\\rho}_{-\\infty}=1$ and $\\widehat{\\rho}_{\\infty}=0$ and $|\\widehat{\\rho}_{t_1}(p)|^2-|\\widehat{\\rho}_{t_2}(p)|^2\\ge 0$ whenever $t_1\\le t_2$. One can thus define a more general family of modified free/Gaussian theories $\\mu_{t_1,t_2}$ with $t_1\\le t_2$ by the propagator\n$$\n\\int \\phi(x)\\phi(y)\\ d\\mu_{t_1,t_2}(\\phi)=\\langle \\phi(x)\\phi(y)\\rangle_{t_1,t_2}=\n\\int\\frac{dp}{(2\\pi)^D} \\frac{\\left(|\\widehat{\\rho}_{t_1}(p)|^2-|\\widehat{\\rho}_{t_2}(p)|^2\\right)\\ e^{ip(x-y)}}{p^{D-2\\Delta}}\\ .\n$$\nOne has the semigroup property for convolution of (probability) measures\n$$\n\\mu_{t_1,t_2}\\ast\\mu_{t_2,t_3}=\\mu_{t_1,t_3}\n$$\nwhen $-\\infty\\le t_1\\le t_2\\le t_3\\le \\infty$. This means that for any functional $F(\\phi)$,\n$$\n\\int F(\\phi)\\ d\\mu_{t_1,t_3}=\\int\\int d\\mu_{t_1,t_2}(\\zeta)\\ d\\mu_{t_2,t_3}(\\psi)\\ F(\\zeta+\\psi)\\ .\n$$\nThe other key players are scale transformations $S_t$. Their action on fields is given by $(S_t \\phi)(x)=e^{-\\Delta t}\\phi(e^{-t}x)$\nand obviously satisfies $S_{t_1}\\circ S_{t_2}=S_{t_1+t_2}$.\nUsing the notion of push-forward/direct image of measures, one has $(S_t)_{\\ast}\\mu_{t_1,t_2}=\\mu_{t_1+t,t_2+t}$, i.e.,\n$$\n\\int d\\mu_{t_1,t_2}(\\phi)\\ F(S_t\\phi)=\\int d\\mu_{t_1+t,t_2+t}(\\phi)\\ F(\\phi)\\ .\n$$\nSince these are centered Gaussian measures, it is enough to check the last property on propagators, i.e., $F(\\phi)=\\phi(x)\\phi(y)$\nwhere this follows from a simple change of momentum integration variable from $p$ to $q=e^{-t}p$ in the above formula for the propagator.\nThis also covers the infinite endpoint case with the conventions $t+\\infty=\\infty$, $t-\\infty=-\\infty$ for finite $t$.\nThe high energy physics Wilsonian RG is the transformation of functionals $RG[t_2,t_1]$ for pairs $t_1\\le t_2$ obtained as follows.\nUsing the convolution semigroup property\n$$\n\\int e^{-V(\\phi)} d\\mu_{t_1,\\infty}(\\phi)=\\int e^{-V(\\zeta+\\psi)} d\\mu_{t_1,t_2}(\\zeta)\\ d\\mu_{t_2,\\infty}(\\psi)\n$$\n$$\n=\\int e^{-(RG[t_2,t_1](V))(\\phi)} d\\mu_{t_2,\\infty}(\\phi)\n$$\nafter renaming the dummy integration variable $\\psi\\rightarrow\\phi$ and introducing the definition\n$$\n(RG[t_2,t_1](V))(\\phi):=-\\log \\int e^{-V(\\zeta+\\phi)} d\\mu_{t_1,t_2}(\\zeta)\\ .\n$$\nIf $V$ is the functional of $\\phi$ corresponding to the bare action/potential with UV cutoff $\\Lambda_H=e^{-t_1}$, then\n$RG[t_2,t_1](V)$ is the effective potential at momentum/mass scale $\\Lambda_L=e^{-t_2}$.\nTrivially (Fubini plus associativity of convolution of probability measures) one has, for $t_1\\le t_2\\le t_3$,\n$$\nRG[t_3,t_2]\\circ RG[t_2,t_1]=RG[t_3,t_1]\n$$\nwhich is indicative of a nonautonomous dynamical system structure, to be remedied shortly.\nAt this point one can already state the main goal of renormalization/taking continuum limits of QFTs: finding a correct choice of cutoff-dependent potentials/actions/integrated Lagrangians, $(V_t^{\\rm bare})_{t\\in\\mathbb{R}}$\nsuch that\n$$\n\\forall t_2,\\  \\lim_{t_1\\rightarrow -\\infty} RG[t_2,t_1](V_{t_1}^{\\rm bare})\\ =:\\ V_{t_2}^{\\rm eff}\\ {\\rm exists}.\n$$\nThe OP's intuition is correct in seeing this as a backwards shooting problem: choosing the right initial condition at $\\Lambda_{H}$ to arrive where we want at $\\Lambda_{L}$.\nA difficulty here (related to scattering in classical dynamical systems) is this involves an IVP at $t=-\\infty$ instead of finite time.\nNote that the continuum QFT, its correlations, etc. should be completely determined by the collection of its effective theories indexed by scales $(V_{t}^{\\rm eff})_{t\\in\\mathbb{R}}$. This is most easily seen when considering correlations smeared with test functions with compact support in Fourier space and with a sharp cutoff $\\widehat{\\rho}(p)$ given by the indicator function of the condition $|p|\\le 1$ (or at least one which satisfies $\\widehat{\\rho}(p)=1$ in a neighborhood of zero momentum).\nSwitching to an autonomous setting involves some twisting by the scaling maps $S_t$. Given a potential V (bare or effective) which \"lives at\" scale $t_1$, one has\n$$\n\\int e^{-V(\\phi)}\\ d\\mu_{t_1,\\infty}(\\phi)=\\int e^{-V(S_{t_1}\\phi)}\\ d\\mu_{0,\\infty}(\\phi)=\n\\int e^{-(S_{-t_1}V)(\\phi)}\\ d\\mu_{0,\\infty}(\\phi)\n$$\nwhere we now define the action of rescaling maps on functionals by\n$$\n(S_t V)(\\phi):=V(S_{-t}\\phi)\\ .\n$$\nAs maps on functionals, one has the identity\n$$\nRG[t_2,t_1]=S_{t_1}\\circ RG[t_2-t_1,0]\\circ S_{-t_1}\\ .\n$$\nWilson's Wilsonian RG is $WRG[t]:=S_{-t}\\circ RG[t,0]$, for $t\\ge 0$. It acts on the space of \"unit lattice theories\" (I put quotes because I am using Fourier rather than lattice cutoffs). Thus the previous identity becomes\n$$\nRG[t_2,t_1]=S_{t_2}\\circ WRG[t_2-t_1]\\circ S_{-t_1}\\ .\n$$\nThe identity can be derived as follows (note the orgy of parentheses due to the increase of abstraction from functions to functionals, then to maps on functionals):\n$$\n[(RG[t_2-t_1,0]\\circ S_{-t_1})(V)](\\phi)=-\\log\\int d\\mu_{0,t_2-t_1}(\\zeta) \\exp[-(S_{-t_1}V)(\\phi+\\zeta)]\n$$\n$$\n=-\\log\\int d\\mu_{0,t_2-t_1}(\\zeta) \\exp[-V(S_{t_1}\\phi+S_{t_1}\\zeta)]\n$$\n$$\n=-\\log\\int d\\mu_{t_1,t_2}(\\xi) \\exp[-V(S_{t_1}\\phi+\\xi)]\n$$\nwhere we changed variables to $\\xi=S_{t_1}\\zeta$.\nFrom this one gets\n$$\n[(S_{t_1}\\circ RG[t_2-t_1,0]\\circ S_{-t_1})(V)](\\phi)=[(RG[t_2,t_1,]\\circ S_{-t_1})(V)](S_{t_1}\\phi)\n$$\nand the identity follows from the trivial fact $S_{t_1}(S_{-t_1}\\phi)=\\phi$.\nNote that $(V_t)_{t\\in\\mathbb{R}}$ is trajectory of $RG$, i.e.,\n$$\n\\forall t_1\\le t_2,\\ V_{t_2}=RG[t_2,t_1](V_{t_1})\n$$\nif and only if $W_t:=S_{-t}V_t$ is a trajectory of $WRG$, i.e.,\n$$\n\\forall t_1\\le t_2,\\ W_{t_2}=WRG[t_2-t_1](W_{t_1})\\ .\n$$\nThe semigroup property for $RG$ readily implies that for $WRG$, namely,\n$$\n\\forall t_1, t_2\\ge 0,\\ WRG[t_1+t_2]=WRG[t_1]\\circ WRG[t_2]\\ .\n$$\nNow define $W_{t}^{\\rm start}:=S_{-t} \\circ V_t^{\\rm bare}$. Then assuming continuity of all these RG maps one has\n$$\nV_{t_2}^{\\rm eff}=\\lim_{t_1\\rightarrow -\\infty} RG[t_2,t_1](V_{t_1}^{\\rm bare})=S_{t_2}(W_{t_2}^{\\rm eff})\n$$\nwhere\n$$\nW_{t_2}^{\\rm eff}:=\\lim_{t_1\\rightarrow -\\infty} WRG[t_2-t_1](W_{t_1}^{\\rm start})\\ .\n$$\nThe definiteness of the continuum QFT can also be rephrased as the existence of the potentials $W_{t}^{\\rm eff}$.\nA common source of confusion is the failure to see that while $(W_{t}^{\\rm eff})_{t\\in\\mathbb{R}}$ is (by definition, the semigroup property and continuity) a trajectory of $WRG$, the family of bare potentials $(W_{t}^{\\rm bare})_{t\\in\\mathbb{R}}$ is not.\nThe same statement is true, by undoing the \"moving frame change of coordinates\", when replacing $W$'s with $V$'s and $WRG$ with $RG$.\nFor concreteness, we need coordinates on the space where the RG acts. Assume the bare potential $V_t^{\\rm bare}$\nis determined by a collection of coordinates or couplings $(g_i)_{i\\in I}$ via\n$$\nV_{t}^{\\rm bare}(\\phi)=\\sum_{i\\in I} g_i^{\\rm bare}(t)\\ \\int \\mathcal{O}_i(x)\\ dx\n$$\nfor local operators of the form\n$$\n\\mathcal{O}_i(x)= :\\partial^{\\alpha_1}\\phi(x)\\cdots \\partial^{\\alpha_k}\\phi(x):_t\\ .\n$$\nThe Wick/normal ordering is with respect to the free cutoff measure $\\mu_{t,\\infty}$. More precisely, for every functional $F$,\n$$\n:F(\\phi):_t\\ \\ :=\\exp\\left[-\\frac{1}{2}\n\\int dxdy\\ \\frac{\\delta}{\\delta\\phi(x)}\\ C_{t,\\infty}(x,y)\\ \\frac{\\delta}{\\delta\\phi(y)}\n\\right]\\ F(\\phi)\n$$\nwhere we denoted the propagator by $C_{t,\\infty}(x,y):=\\langle\\phi(x)\\phi(y)\\rangle_{t,\\infty}$.\nNote that changing $-\\frac{1}{2}$ to $+\\frac{1}{2}$ followed by setting $\\phi=0$ is integration with respect to $\\mu_{t,\\infty}$.\nFor instance $:\\phi(x)^2:_t=\\phi(x)^2-C_{t,\\infty}(x,x)$ and $:\\phi(x)^4:_t=\\phi(x)^4-6C_{t,\\infty}(x,x)\\phi(x)^2+3C_{t,\\infty}(x,x)^2$.\nAn easy change of variables $y=e^{-t}x$ shows that\n$$\n(S_{-t}V_{t}^{\\rm bare})(\\phi)=\\sum_{i\\in I} g_i^{\\rm start}(t)\n\\int :\\partial^{\\alpha_1}\\phi(y)\\cdots \\partial^{\\alpha_k}\\phi(y):_0\\ dy\n$$\nwhere $g_i^{\\rm start}(t):=e^{(D-\\Delta_i)t}\\ g_i^{\\rm bare}(t)$\nand I used the notation $\\Delta_i=k\\Delta+|\\alpha_1|+\\cdots+|\\alpha_k|$ for the scaling dimension of the local operator\n$\\mathcal{O}_i$. The switch $g_i^{\\rm bare}\\rightarrow g_i^{\\rm start}$ corresponds to that from dimensionful to dimensionless coupling constants.\nThe indexing set splits as $I=I_{\\rm rel}\\cup I_{\\rm mar}\\cup I_{\\rm irr}$, respectively corresponding to the three\npossibilities for operators:\n$D-\\Delta_i>0$ or relevant, $D-\\Delta_i=0$ or marginal, $D-\\Delta_i<0$ or irrelevant.\n$W=0$ is a fixed point of the autonomous dynamical system $WRG$. The behavior near this (trivial/Gaussian/free) fixed point is governed by the linearization or differential at $W=0$, i.e., the maps $\\mathcal{D}WRG[t]$ given by\n$$\n[\\mathcal{D}WRG[t](W)](\\phi):=\\int W(S_t\\phi+\\zeta)\\ d\\mu_{0,t}(\\zeta)\n$$\nas follows from the definition\n$$\n[WRG[t](W)](\\phi)=-\\log \\int e^{-W(S_t\\phi+\\zeta)}\\ d\\mu_{0,t}(\\zeta)\n$$\nand the crude approximations $e^z\\simeq 1+z$ and $\\log(1+z)\\simeq z$.\nIf $W$ has coordinates $(g_i)_{i\\in I}$ (with $:\\bullet :_0$ Wick ordering), then one can show (good not so trivial exercise) that\n$\\mathcal{D}WRG[t](W)$ has coordinates given exactly by $(e^{(D-\\Delta_i)t}g_i)_{i\\in I}$, in the same frame, i.e., with the same $t=0$ Wick ordering.\nIf instead of flows one prefers talking in terms of the vector field $\\mathcal{V}$ generating the dynamics, then a trajectory\n$(W_t)_{t\\in\\mathbb{R}}$ of $WRG$ satisfies $\\frac{dW_t}{dt}=\\mathcal{V}(W_t)$ with $\\mathcal{V}:=\\left.\\frac{d}{dt} WRG[t]\\right|_{t=0}$\nadmitting a linear plus nonlinear splitting $\\mathcal{V}=\\mathcal{D}+\\mathcal{N}$. The linear part, in coordinates,\nis\n$$\n\\mathcal{D}(g_i)_{i\\in I}=((D-\\Delta_i) g_i)_{i\\in I}\\ .\n$$\nAssume the existence of $W_{\\rm UV}:=\\lim_{t\\rightarrow -\\infty} W_{t}^{\\rm eff}$, the UV fixed point, and\n$W_{\\rm IR}:=\\lim_{t\\rightarrow \\infty} W_{t}^{\\rm eff}$, the infrared fixed point (they have to be fixed points by continuity). The discussion of perturbative renormalizability\nalways refers to the situation where $W_{\\rm UV}=0$ corresponding to continuum QFTs\nobtained as perturbations of the free CFT $\\mu_{-\\infty,\\infty}$.\nBy definition, the QFT or the trajectory $(W_t)_{t\\in\\mathbb{R}}$ of its \"unit lattice\"-rescaled effective theories\nlies on the unstable manifold $\\mathcal{W}^{\\rm u}$ of the $W=0$ fixed point. In what follows I will assume for simplicity there are no\nmarginal operators so the fixed point is hyperbolic and there are no subtleties due to center manifolds.\nThe tangent space $T\\mathcal{W}^{\\rm u}$ is then spanned by functionals $\\phi\\longmapsto \\int \\mathcal{O}_i$, for $i$ in $I_{\\rm rel}$\nwhich is typically finite.\nNote that, in principle, knowing a QFT is the same as knowing a trajectory $(W_t^{\\rm eff})_{t\\in\\mathbb{R}}$ and thus the same as knowing just one point of that trajectory say $W_0^{\\rm eff}$ (if the $t=0$ IVP is well-posed forwards and backwards in time, which is another delicate issue as explained in Arnold's answer). The point $W_0^{\\rm eff}$ can be made to sweep the unstable manifold which can be identified with the space of continuum QFTs obtained by perturbing the $W=0$ fixed point. On the other hand our control parameter is the choice of cut-off dependent starting points $(W_t^{\\rm start})_{t\\in\\mathbb{R}}$. These belong to the bare surface $T\\mathcal{W}^{\\rm u}$. This is why when considering say the $\\phi^4$ model only a small finite number of terms are put in the bare Lagrangian, otherwise we would be talking about some other (family of) model(s) like $\\phi^6$, $\\phi^8$, etc.\nSo after all these explanations, it should be clear that renormalization in Wilson's framework can be seen as a parametrization of the nonlinear variety $\\mathcal{W}^{\\rm u}$ by the linear subspace $T\\mathcal{W}^{\\rm u}$.\nIf we denote the stable manifold by $\\mathcal{W}^{\\rm s}$ and its tangent space by $T\\mathcal{W}^{\\rm s}$ then, assuming hyperbolicity of the trivial fixed point, the full space where the RG acts should be $T\\mathcal{W}^{\\rm u}\\oplus T\\mathcal{W}^{\\rm s}$. The stable manifold theorem gives a representation of $\\mathcal{W}^{\\rm u}$ as the graph of a map from $T\\mathcal{W}^{\\rm u}$ into $T\\mathcal{W}^{\\rm s}$.\nThe main problem is to find $(W_t^{\\rm start})_{t\\in\\mathbb{R}}$ so that the limit\n$W_0^{\\rm eff}=\\lim_{t\\rightarrow -\\infty} WRG[-t](W_t^{\\rm start})$ exists. The stable manifold theorem is the $t=-\\infty$ case\nof a mixed boundary problem where on a trajectory one imposes conditions (on coordinates) of the form $g_i^{\\rm start}(t)=0$, $i\\in I_{\\rm irr}$, and $g_i^{\\rm eff}(0)=\\lambda_{i}^{\\rm R}$, $i\\in I_{\\rm rel}$. Irwin's proof is a nice way to solve this and it works even if the RG is not reversible. This method can be applied for finite negative $t$, and this should produce a collection $(W_t^{\\rm })_{t<0}$ (all that is needed in fact) dependent on the renormalized couplings $\\lambda_{i}^{\\rm R}$. Let us assume for instance that $I_{\\rm rel}=\\{1,2\\}$ and\n$I_{\\rm irr}=\\{3,4,\\ldots\\}$. Consider the map $P_t$ given by\n$$\n(\\lambda_{1}^{\\rm B},\\lambda_{2}^{\\rm B})\\longmapsto\n(g_i\\{WRG[-t](\\lambda_{1}^{\\rm B},\n\\lambda_{2}^{\\rm B},0,0,\\ldots)\\})_{i=1,2}\n$$\nwhere $g_i\\{W\\}$ denotes the $i$-th coordinate of $W$.\nA possible choice of starting points is thus\n$$\nW_t^{\\rm start}:=(P_t^{-1}(\\lambda_{1}^{\\rm R},\\lambda_{2}^{\\rm R}),0,0,\\ldots)\\ .\n$$\nThe above is more like a road map for what needs to be done but it does not quite provide a recipe for doing it. In the perturbative setting, one trades numbers in $\\mathbb{R}$ for formal power series in $\\mathbb{R}[[\\hbar]]$. The propagators of the $\\mu$ measures get multiplied by $\\hbar$ and there is now $\\frac{1}{\\hbar}$ in front of the $V$'s or $W$'s in the exponential. All the couplings $g_i$ now also become elements of $\\mathbb{R}[[\\hbar]]$. The invertibility of $P_t$ in this setting is easy and follows by analogues of the implicit/inverse function theorem for formal power series (e.g. in Bourbaki, Algebra II, Chapters 4-7, Berlin, Springer-Verlag, 1990).\nAll the work is in showing that for $i\\ge 3$, the quantities\n$$\nf_i(\\lambda_{1}^{\\rm R},\\lambda_{2}^{\\rm R}):=\\lim_{t\\rightarrow -\\infty}\ng_i\\{WRG[-t](P_t^{-1}(\\lambda_{1}^{\\rm R},\\lambda_{2}^{\\rm R}),0,0,\\ldots)\\}\n$$\nconverge to finite values. This gives the wanted parametrization $(\\lambda_{1}^{\\rm R},\\lambda_{2}^{\\rm R})\n\\mapsto(\\lambda_{1}^{\\rm R},\\lambda_{2}^{\\rm R},f_3(\\lambda_{1}^{\\rm R},\\lambda_{2}^{\\rm R}),f_4(\\lambda_{1}^{\\rm R},\\lambda_{2}^{\\rm R}),\\ldots)$ of $\\mathcal{W}^{\\rm u}$ by $T\\mathcal{W}^{\\rm u}$.\nThere are two ways of showing the above convergence statement. Underlying both ways is the fact (see Bourbaki above) the formal power series $P_t^{-1}(\\lambda_{1}^{\\rm R},\\lambda_{2}^{\\rm R})\\in \\mathbb{R}[[\\hbar]]^2$ exist and are unique.\nFans of combinatorics would prefer a two-step procedure consisting in 1) finding an explicit formula for  $WRG[-t](P_t^{-1}(\\lambda_{1}^{\\rm R},\\lambda_{2}^{\\rm R}),0,0,\\ldots)$ for finite $t$; then 2), with this formula in hand, analyze the limit\n$t\\rightarrow -\\infty$. The explicit formula in 1) is Zimmermann's forest formula.\nSee this article by Hairer for a recent take on the delicate  analytical estimates needed for step 2).\nFor those who abhor combinatorics, there is another method which avoids explicit formulas. Change the scale $0$ in the mixed boundary problem to an arbitrary scale $s>t$. Namely, impose $g_i(t)=0$ for $i\\ge 3$ and $g_i(s)=\\lambda_i^{\\rm R}$ for $i=1,2$ and study the variation of $s$ from $s=t$ to $s=0$ by ODE techniques. This is the Wilson-Polchinski approach. The best rigorous account that I know for this second approach is in the book \"Renormalization: An Introduction\" by Salmhofer.\nFinally, one could ask what would happen if one used $W_{s}^{\\rm eff}$, for some fixed $s\\neq 0$, to parametrize the QFTs instead of\n$W_{0}^{\\rm eff}$. The answer is obtained by noticing that the maps $W_s^{\\rm eff}\\mapsto {\\rm QFT}$  intertwine the action of $WRG$ on\n$\\mathcal{W}^{\\rm u}$ and that of the scaling maps $S_t$ on QFTs (simply rescale correlations, i.e., do $\\phi\\rightarrow S_t\\phi$ inside correlations).\nThis is the relation to the old Stueckelberg-Peterman-Gell-Mann-Low RG (i.e., change of scale can be absorbed in a change of renormalized coupling constants). In other words, the restriction of the nonreversible $WRG$ to the finite dimensional manifold $\\mathcal{W}^{\\rm u}$ should be reversible since $S_t$'s (on collections of correlations) are, or because of the remark I made about Irwin's proof even for noninvertible (discrete) dynamical systems.", "meta": {"post_id": 372306, "input_score": 31, "output_score": 43, "post_title": "What is the Wilsonian definition of renormalizability?"}}
{"input": "From my knowledge of magnetism, if a magnet is heated to a certain temperature, it loses its ability to generate a magnetic field. If this is indeed the case, then why does the Earth's core, which is at a whopping 6000 \u00b0C \u2014 as hot as the sun's surface, generate a strong magnetic field?", "output": "The crucial part is that earth's outer core is fluid, and that it's conductive. That the material happens to be iron which we know as ferromagnetic is actually rather unimportant, because the geomagnetic field is not created as a superposition of atomic spins like in a permanent magnet. Rather, it's generated via Amp\u00e8re's law from macroscopic currents, like in an electromagnet made from a wound copper coil with a current going though it. (It is an electromagnet, really.)\nThe reason there are such currents is that the liquid is in convective motion, probably fuelled by thermal transport from the radioactive decay in the inner core. When a conducting liquid moves, it \u201cpulls any magnetic field line with it\u201d. Starting from a small background field, if the flow is complex and rapid enough, this tends to amplify over time.\nThis dynamo effect can be described theoretically, numerically, or with laboratory-scale experiments using liquid sodium (sodium being nonmagnetic, but a good conductor and easy to melt). It is not hindered by high temperatures (rather, the high temperatures are often necessary to ensure flow and/or conductance). And it takes place not only on Earth, but also on many other objects:\n\nThe Sun's dynamo uses the plasma (hydrogen/helium), i.e. the fluid is not a metal at all, nor a liquid, but an ionised gas. This is again driven by convection.\nThe gas giants Jupiter and Saturn have dynamos that apparently consist of hydrogen too, but because of the comparatively low temperatures but still immense pressure it's likely in a metallic state.\nThe ice giants Neptune and Uranus have unusually tilted and irregular magnetic fields. It is assumed that this is due to a dynamo not in the core region like for earth, but in a shell rather higher up in the planet's structure. It probably consists of a mixture of hot, pressurised, liquid water, ammonia and methane, which has enough dissolved ions to be a good conductor.\nRocky planets and moons often have earth-like dynamos, most notably Mercury and Ganymede.\n\nRemanent magnetism, the kind that we know from permanent magnets and which only works below the Curie temperature, is only important on rocky planets which don't have a dynamo. The most prominent example is Mars, but this magnetic field is much weaker than the aforementioned dynamo-generated ones.", "meta": {"post_id": 373449, "input_score": 34, "output_score": 61, "post_title": "Why does the Earth even have a magnetic field?"}}
{"input": "There are three related questions here:\n\nGiven the current limits of technology how far away are we from probing Planck scale physics directly?\nIt's well known, at least in some circles, that atoms were thought of in Antiquity; given the limits of their technology how far were they away from probing atomic phenomena directly. I'm taking atom here to be atoms in the usual sense, ie an atom of hydrogen or of Iron, and not in the philosophical sense of being uncuttable or decomposable. \nAre we as far away from Planck scale physics, as they in Antiquity were from probing atoms? Or are we further away?", "output": "The highest energy reached so far by an accelerator is $13\\,\\text{TeV}$ in the LHC. The Planck scale is $\\sim 10^{16}\\,\\text{TeV}$, so we are $15$ orders of magnitude away. (Cosmic rays with a center-of-mass energy of about an order of magnitude above the scale of the LHC have been observed).\n\nIf by Antiquity we mean a period of history in which there were no measurement instruments for small distance scales, they would have to use the naked eye. Then the smallest distance they could resolve is $\\sim 10^{-1}\\,\\text{mm}$ (according to wikipedia). The hydrogen atom is $10^{-7}\\,\\text{mm}$ in size, so they were $6$ orders of magnitude away.\n\nThey were much closer to the atomic scale than we are now to the Planck scale.\n\n\n\nNotice also that the naked-eye scale corresponds to $10^{-15}\\,\\text{TeV}$ so we have improved this by $16$ orders of magnitude. This means that we\u2019re halfway to the Planck scale!", "meta": {"post_id": 374407, "input_score": 37, "output_score": 73, "post_title": "How far away are we from probing Planck scale physics directly?"}}
{"input": "Einstein's Special Relativity theory is based on the assumption that the laws of physics are invariant in all inertial frames, and from there - according to Maxwell's equations - it derives that the speed of light must be the same in all reference frames, thus the need for time dilation etc...\nBut how is the initial assumption justified? I have always been explained this assumption in an \"intuitive\" way, as a thought experiment, for example regarding the fact that sitting on a sofa feels no different than sitting in a plane. But I could have made the same thought experiment about the hypothesis that velocities always add together, so one could make light \"faster\" by shining a beam from the tip of a rocket...", "output": "Lefaroundabout's comment is important.  While we are typically taught that we use science to know things, that is not actually a correct statement.  Science is a very powerful tool for creating models that can be used to create educated predictions about how a system will behave, and it is founded on the idea of falsifiable hypotheses, but that doesn't mean we're never wrong.  It just means it's possible to disprove our hypotheses.\nYour example of making the velocities add is a great example.  It's terribly intuitive that velocities add together.  If I'm on a train, and I throw the baseball, an observe on the ground sees the baseball hurtling through the air at the train's speed plus the speed of my throw.  It would be very natural to assume that light behaves the same way.  In fact, I think most people believe this is how light works until they are told otherwise by a science teacher.\nNow let's bring in Maxwell's equations.  Maxwell's equations do a remarkably good job of predicting how electricity and magnetism behave.  You can try to falsify them by building oddly designed experiments to isolate magnetic monopoles and so forth, but we found his laws simply hold up well (at least all the way up to Quantum Mechanics, which is its own beast, and its own story).  After a lot of testing, the scientific community came to a consensus that Maxwell's equations are pretty darn reliable.  I can't say \"they knew his equations were true,\" because that would be an overstatement, but their confidence was very high.\nHowever, there's a quirk.  Maxwell's equations predict a \"speed of light.\"  But if you go back to our baseball example, we see that the baseball is going at different speeds in different inertial frames.  While I ride on the train at a constant velocity, I am viewing the world from an inertial frame, and I see the ball at one speed.  While you are on the ground, standing still, you are viewing the world from an inertial frame, and you see the ball at a different speed.   Maxwell's equations simply don't have any room for that.  They just say \"light has a fixed speed,\" leaving scientists to ponder what's up with that.\nOne intuitive approach is to assume the light is traveling through a medium, and the speed of light is with respect to that medium.  This is intuitive when you look at effects like drag on a baseball.  The drag forces on a baseball aren't dependent on how fast it's traveling with respect to me or you, it's how fast it's traveling with respect to the wind.  It was theorized that light might travel in a so called the \"luminiferous aether,\" just like our baseball travels through the air.  This solves the conundrum of Maxwell's equations: the \"speed of light\" is the speed of light with respect to the aether.\nSo this was a reasonable hypothesis.  Just like your \"velocities add\" hypothesis, it lead to natural ways of thinking about light.  Of course, this being a scientific hypothesis, it was designed to be falsifiable.  If one could demonstrate that light's movement did not act like there was some privileged reference frame (the frame of the aether), then one would be able to refute this hypothesis.  And they did.\nThe most famous experiment falsifying the aether theories was the Michaelson\u2013Morley experiment.  Through clever use of interferometry, they were able to compare the speeds of light going in the direction of the Earth's orbit around the sun versus going across it.  Their goal was to determine if the aether was stationary, or if it was somehow \"dragged\" along by massive objects like the Earth (like how air forms drafts behind a large vehicle).  They found, curiously enough, that there was no detectable difference in the speed of light in the two directions.  If indeed the aether existed (which they believed at the time), it was so tied to the movement of the earth that we couldn't discern it.  It's like you were drafting behind a large vehicle, and instead of feeling the wind pull you forward, it felt more like you were encased in concrete and being dragged forcefully along!\nMany other experiments also found results like this, which made aether theories start to seem very unreliable.  They just called for too much \"hand waving.\"  From this, we developed the Lorentz boosts, which were modifications to Maxwell's equations which were very effective at predicting the results of experiments like these, but made the equations terribly ugly.  The beauty of Maxwell's equations vanished under the Lorenz transformations.\nSo now enter Einstein, making his assumption that the speed of light must be the same in all reference frames.  I agree with your original opinion that it's a strange thing to just assume.  But it was brilliant.  When he was done with the math, the ugly Lorenz boosts that defiled Maxwell's equations were neatly tucked away into this assumption that the speed of light was the same in all reference frames.  It did a very good job of cleaning up a lot of ugliness in the theories.  People liked it.\nMore than being liked, it was scientific: it was falsifiable.  If we ever found two inertial frames which had different speeds of light, or if we found out that time dilation did not occur, it would have falsified Einstein's theories, and we probably wouldn't revere him as we do today.  However, in hundreds (if not thousands) of experiments, we have found that Einstein's theory is extraordinarily good at predicting some really awkward and unintuitive effects.\nSo thus, we justify his assumption that the speed of light is the same in all inertial frames after the fact.  We have found that the results of this assumption are tremendously useful and effective.  At the time, the justification was that it was an elegant solution to a very difficult problem, and it produced new falsifiable hypotheses to test (like any good scientific theory does).", "meta": {"post_id": 374839, "input_score": 19, "output_score": 45, "post_title": "How do we know that the laws of physics are invariant in all inertial frames?"}}
{"input": "This is probably a dumb question. I guess what I'm trying to ask is if radio waves travel the same speed as gamma rays, how do gamma photons carry more energy than radio photons? Do they spin faster? What other energy sources could they carry if they are moving the same speed through space?", "output": "Higher energy photons have shorter wavelengths.  This means they are higher frequency.  We can look at the equations, like E=h, and see directly that shorter wavelengths have more energy, but I think you're going to want a more intuitive example.  Let's haul out the ropes!\n\nBattle ropes are an exercise tool.  You try to set up waves that propagate down the ropes.  If we visualize ourselves pumping these ropes, we see that if we want to create higher frequencies and shorter wavelengths, we have to put more energy into the system.  We have to accelerate the ropes up and down at higher rates, and that requires more energy.  This is true even if we keep the amplitude of the ropes the same.\nPhotons don't move up and down like this, but they do create oscillating electric and magnetic fields (which are often visualized in a form similar to battle ropes).  Oscillating this field more rapidly involves more energy, in the same way as the higher frequency battle ropes did.\nLike with the battle ropes, the light waves travel at the same speed, regardless of whether they are high frequency (high energy) or low frequency (low energy).  The energy is seen in how rapidly the rope changes position (or the fields change strength).", "meta": {"post_id": 375010, "input_score": 14, "output_score": 40, "post_title": "What's the difference between low energy photons and high energy photons?"}}
{"input": "Today I saw the phenomenon in picture below. It was not raining (at least nearby me). What can that be? What is the technical explanation?\n\nEdit: Just seen today in Southern Brazil another circumhorizon arc, this time together with a halo. Really beautiful.", "output": "This is not a \"rainbow\". Quoting from the linked site, \"not all colored patches in the sky are rainbows\". It instead is a circumhorizon arc. Rainbows are caused by internal by refraction and reflection in water droplets. Halos such as the circumhorizon arc portrayed in the question are caused by internal refraction and reflection in ice crystals.", "meta": {"post_id": 376658, "input_score": 40, "output_score": 39, "post_title": "What is this sort of abstract rainbow?"}}
{"input": "In the 1860's Maxwell formulated what are now called Maxwell's equation, and he found that they lead to a remarkable conclusion: the existence of electromagnetic waves that propagate at a speed $c$, which turns out to be the speed of light, implying that light is an electromagnetic wave.  Now the fact that Maxwell's equations predict speed of light is $c$ suggested to Maxwell and others that Maxwell's equations are not actually true in all frames of reference.  Instead, they thought, Maxwell's equations only exactly true in one frame, the rest frame of the aether, and in all other frames they would have to be replaced by other equations, equations that were invariant under Galilean transformations in order to conform to the principle of relativity. These other equations implied that the speed of light in other frames was actually $c+v$ or $c-v$, where $v$ is the speed of the aether.  But then the Michelson-Morley experiment, which was intended to find the speed $v$ of the aether, ended up showing that the speed of light was $c$ in all frames, apparently contradicting the principle of relativity.  But Einstein showed that this doesn't contradict the principle of relativity at all, it's just that you need to rethink your notions of space and time.\nBut my question is, what are the equations that people thought were true in frames other than the aether frame? To put it another way, what are the equations you obtain if you apply a Galilean transformation to Maxwell's equations? (As opposed to a Lorentz transformation which leaves Maxwell's equations unchanged.)\nI've actually seen the equations obtained before.  They were formulated by some 19th century physicist, maybe Hertz or Heaviside, and they involve adding velocity-dependent terms to the Ampere-Maxwell law and Faraday's law. (Dependent on the velocity of aether, that is.) But I don't remember the details.", "output": "I'm no expert on the historical development of the subject, however I will offer a derivation.\nConsider two frames of reference $S$ and $S'$, and suppose that $S'$ moves with speed $\\textbf v$ with respect to $S$. Coordinates in $S$ and $S'$ are related by a Galileian transformation:\n$$\\begin{cases} t' = t \\\\ \\textbf x' = \\textbf x-\\textbf vt\\end{cases}$$\nTo find how the fields transform, we note that a Lorentz transformation reduces to a Galileian transformation in the limit $c \\to \\infty$. In fact, under a Lorentz transformation the fields transform like:\n$$ \\begin{cases}\n\\textbf E' = \\gamma (\\textbf E + \\textbf v \\times \\textbf B) - (\\gamma-1) (\\textbf E \\cdot \\hat{\\textbf{v}}) \\hat{\\textbf{v}}\\\\\n\\textbf B' = \\gamma \\left(\\textbf B - \\frac{1}{c^2}\\textbf v \\times \\textbf E \\right) - (\\gamma-1) (\\textbf B \\cdot \\hat{\\textbf{v}}) \\hat{\\textbf{v}}\\\\\n\\end{cases}$$\nTaking the limit $c\\to \\infty$ so that $\\gamma\\to 1$, we obtain the Galileian transformations of the fields:\n$$ \\begin{cases}\n\\textbf E' = \\textbf E + \\textbf v \\times \\textbf B\\\\\n\\textbf B' = \\textbf B\\\\\n\\end{cases}$$\nWe can then invert the transformation by sending $\\textbf v \\to -\\textbf v$:\n$$ \\begin{cases}\n\\textbf E = \\textbf E' - \\textbf v \\times \\textbf B'\\\\\n\\textbf B = \\textbf B'\\\\\n\\end{cases}$$\nBy the same reasoning, can obtain the Galileian transformation of the sources:\n$$ \\begin{cases}\n\\textbf J = \\textbf J' + \\rho' \\textbf v\\\\\n\\rho = \\rho'\\\\\n\\end{cases}$$\nWe know that the fields and sources satisfy Maxwell's equations in $S$:\n$$ \\begin{cases}\n\\nabla \\cdot \\textbf E = \\rho/\\epsilon_0\\\\\n\\nabla \\cdot \\textbf B = 0\\\\\n\\nabla \\times \\textbf E = -\\frac{\\partial \\textbf B}{\\partial t}\\\\\n\\nabla \\times \\textbf B = \\mu_0 \\left(\\textbf J +\\epsilon_0 \\frac{\\partial \\textbf E}{\\partial t} \\right)\\\\\n\\end{cases}$$\nReplacing the fields and sources in $S$ with those in $S'$ we obtain:\n$$ \\begin{cases}\n\\nabla \\cdot \\textbf (\\textbf E' - \\textbf v \\times \\textbf B') = \\rho'/\\epsilon_0\\\\\n\\nabla \\cdot \\textbf B' = 0\\\\\n\\nabla \\times \\textbf (\\textbf E' - \\textbf v \\times \\textbf B') = -\\frac{\\partial \\textbf B'}{\\partial t}\\\\\n\\nabla \\times \\textbf B' = \\mu_0 \\left(\\textbf J' + \\rho' \\textbf v +\\epsilon_0 \\frac{\\partial (\\textbf E' - \\textbf v \\times \\textbf B')}{\\partial t} \\right)\\\\\n\\end{cases}$$\nAs a last step, we need to replace derivatives in $S$ with derivatives in $S'$. We have:\n$$\\begin{cases} \\nabla = \\nabla' \\\\ \\frac{\\partial }{\\partial t} = \\frac{\\partial }{\\partial t'} - \\textbf v \\cdot \\nabla\\end{cases}$$\nSubstituting and removing the primes and using vector calculus, we obtain:\n$$ \\begin{cases}\n\\nabla \\cdot \\textbf E + \\textbf v \\cdot (\\nabla \\times \\textbf B) = \\rho/\\epsilon_0\\\\\n\\nabla \\cdot \\textbf B = 0\\\\\n\\nabla \\times \\textbf E = -\\frac{\\partial \\textbf B}{\\partial t}\\\\\n\\nabla \\times \\textbf B = \\mu_0 \\left(\\textbf J + \\rho \\textbf v +\\epsilon_0 \\frac{\\partial}{\\partial t}( \\textbf E - \\textbf v \\times \\textbf B) - \\epsilon_0 \\textbf v \\cdot \\nabla (\\textbf E - \\textbf v \\times \\textbf B) \\right)\\\\\n\\end{cases}$$\nIn a vacuum, we can take the curl of the fourth equation to obtain:\n$$c^2\\nabla^2 \\textbf B = \\frac{\\partial^2 \\textbf B}{\\partial t^2} + (\\textbf v \\cdot \\nabla)^2 \\textbf B - 2 \\textbf v \\cdot \\nabla \\left(\\frac{\\partial \\textbf B}{\\partial t}\\right)$$\nSubstituting a wave solution of the form $\\textbf B \\sim \\exp{i(\\textbf k \\cdot \\textbf x -\\omega t)}$\nWe obtain an equation for $\\omega$, which we can solve to obtain:\n$$\\omega = -\\textbf v \\cdot \\textbf k \\pm c |\\textbf k|$$\nTherefore the speed of propagation is the group velocity:\n$$\\frac{\\partial \\omega}{\\partial \\textbf k} = -\\textbf v \\pm c \\hat{\\textbf{ k}}$$\nwhich gives you the expected $c\\pm v$ with an appropriate choice of $\\textbf v$ and $\\textbf k$.", "meta": {"post_id": 378861, "input_score": 36, "output_score": 55, "post_title": "What does a Galilean transformation of Maxwell's equations look like?"}}
{"input": "So, soda is under pressure and has gas dissolved in it. But, when you open it, the gas is still dissolved in it. But, if we wait a few hours, the gas has escaped into the atmosphere.\nWhat factors determine the rate at which gas escapes the soda-gas solution?", "output": "When you open the bottle and reduce the pressure you now have a supersaturated solution of carbon dioxide in water so it is energetically favourable for the gas to come out of solution.\nHowever for the gas to come out of solution you have to form a bubble and the mechanism by which this happens is called nucleation. But there is an energy barrier that prevents tiny bubbles from forming, and as a result bubbles will only form when there is something to help them nucleate. For more on this see:\n\nWhy does soda fizz when it meets ice?\nWhy are coke bottles that much fizzier if you shake them?\n\nAnyhow, if you look carefully at the bubbles coming out of an opened bottle of soda you'll see they aren't forming randomly. Typically you'll see streams of bubbles coming from an area where there is some aid to nucleation e.g. a defect on the glass wall of the bottle.\nThis means the escape of the gas involves two steps:\n\nformation of bubbles at a nucleus\ndiffusion of the carbon dioxide through the water to the nucleus\n\nAnd it's step 2 that makes the escape of the carbon dioxide take a while. Where an aid to nucleation exists, e.g. at a defect on the glass wall, formation of a bubble will be very quick. However formation of the bubble will quickly use up the dissolved carbon dioxide in its vicinity and formation of further bubbles has to wait for more carbon dioxide to diffuse to the nucleation site. Diffusion of gases dissolved in water is surprisingly slow, and even though the gases typically only have to diffuse a few millimetres they still take a while to do it.\nIf you want to get the carbon dioxide out quickly the best way to do it is to increase the number of nucleation sites so you get many more nuclei and hence reduce the distance the dissolved gas has to diffuse. The traditional way to do this is to drop a mint into the bottle of soda, but stand well back when you do it.", "meta": {"post_id": 379120, "input_score": 44, "output_score": 45, "post_title": "Why doesn't soda go flat immediately after opening?"}}
{"input": "When I read JPL's mission status for Voyager 1 and Voyager 2 the distance between Earth and Voyager 1 is decreasing.\nIs it right?", "output": "Voyager $1$ is headed away from the Sun at around $17$ km per second at an angle to the ecliptic of around $35$\u00ba.\nThe orbital velocity of the Earth is $29.8$ km per second, and multiplying by $\\cos 35$\u00ba to get the component of the velocity in Voyager's direction gives a shade over $24$ km per second.\nSo at the point in its orbit where Earth is moving closest to the direction of Voyager's travel we are actually catching up with it at around $24 - 17 = 7$ km per second. Conversely at the point in Earth's orbit where it is moving opposite to Voyager it is moving away from us at $24 + 17 = 41$ km per second.\n\n(not to scale!)", "meta": {"post_id": 384605, "input_score": 25, "output_score": 82, "post_title": "Why is Voyager 1 approaching Earth?"}}
{"input": "This morning I found a really strange ice formation in my garden. I can't figure out how it appeared, because there was nothing above. The night was particularly cold (Belgium). \nTo give an idea, it has the size of a common mouse (5 cm of Height and 2 cm for the base of the inverted pyramid).", "output": "Congratulations, you found an inverted pyramid ice spike, sometimes called an ice vase!\nThe Bally-Dorsey model of how it happens is that first the surface of the water freezes, sealing off the water below except for a small opening. If the freezing rate is high enough the expansion of ice under the surface will increase pressure (since the ice is less dense than the water and displaces more volume), and this forces water up through the opening, where it will freeze around the rim. As the process goes on a spike emerges. \nIf the initial opening or the crystal planes near it are aligned in the right way the result is a pyramid rather than a cylinder/spike. \nThe process is affected by impurities, the water has to be fairly clean. It also requires fairly low temperatures so freezing is fast enough (but not too fast).", "meta": {"post_id": 387926, "input_score": 214, "output_score": 254, "post_title": "Strange ice found in my garden"}}
{"input": "There are so many times that something leaves you stumped. I was recently reading the paper \"Feynman's derivation of Maxwell's equations and extra dimensions\" and the derivation of the Maxwell's equations from just Newton's second law and the quantum mechanical commutation relations really intrigued me. They only derived the Bianchi set, yet with slight tweakings with relativity, the other two can be derived.\nAwesome as it is, does this even have a physical interpretation? How is it possible to mix together classical and quantum equations for a single particle, which aren't even compatible, and produce a description of the electromagnetic field?", "output": "Feynman's derivation is wonderful, and I want to sketch why we would expect it to work, and what implicit assumptions it's really making. The real issue is that by switching back and forth between quantum and classical notation, Feynman sneaks in physical assumptions that are sufficiently restrictive to determine Maxwell's equations uniquely.\nTo show this, I'll give a similar proof in fully classical, relativistic notation. By locality, we expect the force on a particle at position $x^\\mu$ with momentum $p^\\mu$ depends solely on $p^\\mu$ and $F(x^\\mu$). (This is Eq. 1 in the paper.) Then the most general possible expression for the relativistic four-force is \n$$\\frac{d p^\\mu}{d\\tau}= F_1^\\mu(x^\\mu) + F_2^{\\mu\\nu}(x^\\mu)\\, p_\\nu + F_3^{\\mu\\nu\\rho}(x^\\mu)\\, p_\\nu p_\\rho + \\ldots$$\nwhere we have an infinite series of $F_i$ tensors representing the field $F$. (Of course, we already implicitly used rotational invariance to get this.) I'll suppress the $x^\\mu$ argument to save space.\nIt's clear that we need more physical assumptions at this point since the $F_i$ are much too general. The next step is to assume that the Lagrangian $L(x^\\mu, \\dot{x}^\\mu, t)$ is quadratic in velocity. Differentiating, this implies that the force must be at most linear in momentum, so we have\n$$\\frac{d p^\\mu}{d\\tau}= F_1^\\mu + F_2^{\\mu\\nu}\\, p_\\nu.$$\nThis is a rather strong assumption, so how did Feynman slip it in? It's in equation 2, \n$$[x_i, v_j] = i \\frac{\\hbar}{m} \\delta_{ij}.$$\nNow, to go from classical Hamiltonian mechanics to quantum mechanics, we perform Dirac's prescription of replacing Poisson brackets with commutators, which yields the canonical commutation relations $[x_i, p_j] = i \\hbar \\delta_{ij}$ where $x_i$ and $p_i$ are classically canonically conjugate. Thus, Feynman's Eq. 2 implicitly uses the innocuous-looking equation\n$$\\mathbf{p} = m \\mathbf{v}.$$ \nHowever, since the momentum is defined as \n$$p \\equiv \\frac{\\partial L}{\\partial \\dot{x}}$$\nthis is really a statement that the Lagrangian is quadratic in velocity, so the force is at most linear in velocity. Thus we get a strong mathematical constraint by using a familiar, intuitive physical result.\nThe next physical assumption is that the force does not change the mass of the particle. Feynman does this implicitly when moving from Eq. 2 to Eq. 4 by not including a $dm/dt$ term. On the other hand, since $p^\\mu p_\\mu = m^2$, in our notation $dm/dt = 0$ is equivalent to the nontrivial constraint\n$$0 = p_\\mu \\frac{dp^\\mu}{d\\tau} = F_1^\\mu p_\\mu + F_2^{\\mu\\nu} p_\\mu p_\\nu.$$\nFor this to always hold, we need $F_1 = 0$ and $F_2$ (hereafter called $F$) to be an antisymmetric tensor and hence a rank two differential form. We've now recovered the Lorentz force law\n$$\\frac{d p^\\mu}{d\\tau} = F^{\\mu\\nu} p_\\nu.$$\nOur next task is to restore Maxwell's equations. That seems impossible because we don't know anything about the field's dynamics, but again the simplicity of the Hamiltonian helps. Since it is at most quadratic in momentum, the most general form is\n$$H = \\frac{p^2}{2m} + \\mathbf{A}_1 \\cdot \\mathbf{p} + A_2.$$\nCollecting $\\mathbf{A}_1$ and $A_2$ into a four-vector $A^\\mu$, Hamilton's equations are\n$$\\frac{dp^\\mu}{d\\tau} = (dA)^{\\mu\\nu} p_\\nu$$\nwhere $d$ is the exterior derivative. That is, the simplicity of the Hamiltonian forces the field $F$ to be described in terms of a potential, $F = dA$. Since $d^2 = 0$ we conclude\n$$dF = 0$$\nwhich contains two of Maxwell's equations, specifically Gauss's law for magnetism and Faraday's law. So far we haven't actually used relativity, just worked in relativistic notation, and indeed this is where our derivation and Feynman's run out of steam. To get the other two equations, we need relativity proper.\n\nThe basic conclusion is that Feynman's derivation is great, but not completely mysterious. In particular, it isn't really mixing classical and quantum mechanics at all -- the quantum equations that Feynman uses are equivalent to classical ones derived from Hamilton's equations, because he is using the Dirac quantization procedure, so the only real purpose of the quantum mechanics is to slip in $\\mathbf{p} = m \\mathbf{v}$, and by extension, the fact that the Hamiltonian is very simple, i.e. quadratic in $\\mathbf{p}$. The other assumptions are locality and mass conservation.\nIt's not surprising that electromagnetism pops out almost 'for free', because the space of possible theories really is quite constrained. In the more general framework of quantum field theory, we can get Maxwell's equations by assuming locality, parity symmetry, Lorentz invariance, and that there exists a long-range force mediated by a spin 1 particle, as explained elsewhere on this site. This has consequences for classical physics, because the only classical physics we can observe are those quantum fields which have a sensible classical limit.", "meta": {"post_id": 391744, "input_score": 77, "output_score": 72, "post_title": "Does Feynman's derivation of Maxwell's equations have a physical interpretation?"}}
{"input": "Reading through papers and online sources about radio galaxies, I kept stumbling across a term--a \"decade\" of the electromagnetic spectrum. Radio galaxy emission encompasses \"11 decades of the EM spectrum\". Or this quote from NASA:\n\nAstronomers have made observations of electromagnetic radiation from cosmic sources that cover a range of more than 21 decades in wavelength (or, equivalently in frequency or energy)! \n\nSource.\nWhat exactly does this term correspond to? \nNote: I used the electromagnetism tag because of the context, but I am not sure if the unit can be used outside of the field. Feel free to edit away!", "output": "While many units are available for physical measurables, there are only a few that identify unitless variables, like ratios.\nOne is 'octave', meaning a factor of two (usually in frequency); another is 'decade', meaning a factor of ten.   A third is bel, which grows\na suffix from time to time, and indicates (almost always) a factor\nof ten in power.   The tenth-of-a-bel, decibel, is denoted 'dB'.\nPercent, parts-per-million, pH, are also unitless.\nAny attempt to line-fit data on log/log or semilog plots will \ninvolve one or more axes being unitless, and give rise to\nphrases like 'dB per octave'.   When your data is spread\nover a 100:1 range, it might look best on two-decade semilog\npaper.", "meta": {"post_id": 392508, "input_score": 31, "output_score": 37, "post_title": "What is a \"decade\" as a unit of measure (ex. a decade of the EM spectrum)?"}}
{"input": "Consider a simple situation like this- an object is sitting on a table. In classical mechanics, we say that the net force on the object is zero because gravity (treated as a force) and normal reaction force are equal and opposite to each other, and hence, it's acceleration is zero. But according to Einstein's General Theory of Relativity, gravity isn't a force at all, but instead curvature created in spacetime by a massive object, and objects near it tend to move towards it because they are just moving along the geodesic paths in that curved spacetime.  So if an object kept on a table gets acted only by the normal reaction force (as gravity ain't a force), how is the net force on it zero?", "output": "So if an object kept on a table gets acted only by the normal reaction force (as gravity ain't a force), how is the net force on it zero?\n\nI've quoted what I think is the key part of your question, and it's key because the net force is not zero. The object on the table experiences a net force of $mg$ and as a result it is experiencing an upwards acceleration of $g$.\nThe way you can tell if no force is acting on you is by whether you are weightless or not. If you were floating in space far from any other objects then there would be no forces acting upon you and you'd be weightless. If we fixed a rocket to you and turned it on then you'd no longer be weightless because now the rocket is exerting a force on you. Technically you have a non-zero proper acceleration.\nIn general relativity your acceleration (your four-acceleration) has two components. We write it as:\n$$ a^{\\mu}= \\frac{\\mathrm du^\\mu}{\\mathrm d\\tau}+\\Gamma^\\mu_{\\alpha \\beta}u^{\\alpha}u^{\\beta} $$\nThe first term $\\mathrm du^\\mu/\\mathrm d\\tau$ is the rate of change of your (coordinate) velocity with time, so it is what Newton meant by acceleration, and the second term is the gravitational acceleration. The key thing about general relativity is that we don't distinguish between the two - they both contribute to your acceleration.\nIf you're falling freely then the two terms are equal and opposite so they cancel out and you''re left wit an acceleration of zero:\n$$ a^{\\mu}= 0 $$\nThis is when the net force on you is zero. For the object on the table the coordinate bit of the acceleration is zero but the second term is not and the acceleration is:\n$$ a^{\\mu}= \\Gamma^{\\mu}_{\\alpha \\beta}u^{\\alpha}u^{\\beta} $$\nSo the object sitting on the table has a non-zero acceleration and the net force on it is not zero.\nMaybe this sounds like I'm playing with words a bit, by defining what I do and don't mean by acceleration. But this is absolutely key to understanding how general relativity describes the motion of bodies. The key point is that gravitational and coordinate acceleration are treated on an equal footing, and if you are stationary in a gravitational field that means you are accelerating.\nIf you're interested in pursuing this further there is a fuller description in How can you accelerate without moving?. There is more on why spacetime curvature makes you accelerate in How does \"curved space\" explain gravitational attraction?\nA footnote\nGiven the attention this answer has received I think it is worth elaborating on exactly how relativists view this situation.\nThe question gives an example of an object sitting stationary on a table, but let's start with an object a few metres above the table and falling freely towards it.\n\nIt seems obvious that the apple is accelerating down towards the table. It seems obvious because we are used to taking the surface of the Earth as stationary because that's our rest frame (even though the surface of the Earth is most certainly not at rest :-).\nBut if you were the apple then it would seem natural to take your rest frame as stationary, and in that case the apple is not accelerating downwards - the table \nis accelerating upwards to meet it.\nSo which view is correct? The answer is that both are correct. Whether it's the apple or the table that is stationary is just a choice of rest frame, i.e. a choice of coordinates, and it is a fundamental principle in general relativity that all coordinates are equally good when it comes to describing physics.\nBut if we can randomly choose our coordinates it seems hard to say anything concrete. We could choose frames accelerating at any rate, or rotating, or expanding or all sorts of bizarre frames. Isn't there something concrete we can say about the situation? Well there is.\nIn relativity there are quantities called invariants that do not depend on the coordinates used. For example the speed of light is an invariant - all observers measuring the speed of light find it has the same value of $c$. And in our example of the apple and table there is an important invariant called the proper acceleration. While the apple and the table disagree about which of them is accelerating towards the other, if they compute their respective proper accelerations they will both agree what those values are.\nIn Newtonian mechanics acceleration is a vector $(a_x, a_y, a_z)$, but in relativity spacetime is four dimensional so vectors have four components. The four-acceleration is the relativistic equivalent of the three dimensional Newtonian acceleration that we are all used to. While it's a bit more complicated, the four acceleration is just a vector in 4D spacetime, and like all vectors it has a magnitude \u2013 in relativity we call this quantity the norm. And the norm of the four-acceleration is just the proper acceleration that I talk about above.\nThe proper acceleration can be complicated to calculate. There's a nice explanation of how to calculate it for an object like our table in What is the weight equation through general relativity? It turns out that the proper acceleration of the table is:\n$$ A = \\frac{GM}{r^2}\\frac{1}{\\sqrt{1-\\frac{2GM}{c^2r}}} $$\nwhere $M$ is the mass of the Earth and $r$ is the radius of the Earth.\nBut hang on \u2013 that tells me the proper acceleration of the table is non-zero. But ... but ... isn't the table stationary? Well, this takes us back to where we started. The table and the apple disagree about who is accelerating, but they both agree that the table has a non-zero proper acceleration. And in fact if we calculate the proper acceleration of the apple it turns out to be zero so both the apple and the table agree the apple has a proper acceleration of zero.\nThere is a simple physical interpretation of the proper acceleration. To measure your proper acceleration you just need to hold an accelerometer. Suppose you're floating around weightless in outer space, then your accelerometer will read zero, and that means your proper acceleration is zero. If you're standing on the surface of the Earth (alongside the table perhaps) then your accelerometer will read $9.81\\ \\mathrm{m/s^2}$, and indeed your proper acceleration is approximately $9.81\\ \\mathrm{m/s^2}$ not zero.\nTo summarise, a comment asks me:\n\nSo, let's just get this straight. The book sitting on the table in front of me is accelerating upwards all the time? But when I push it off the table and it falls down, then as it falls down it is not accelerating? Is that what you're saying?\n\nWhat I'm saying, and what all relativist would say, is that:\n\nthe book on the table has a non-zero proper acceleration\nthe falling book has a zero proper acceleration\n\nAnd this is all we can say. The question of which has a non-zero three-acceleration (Newtonian acceleration) is meaningless because that quantity is not frame invariant. The question of which has a non-zero proper acceleration is meaningful \u2013 even if the answer isn't what you expected.", "meta": {"post_id": 392863, "input_score": 22, "output_score": 40, "post_title": "If gravity isn't a force, then how are forces balanced in the real world?"}}
{"input": "Einstein's equivalence principle says that you cannot distinguish between an accelerating frame or a gravitational field. However, in an gravitational field, if I drop a tennis ball, it will bounce, but I don't think that it will in the accelerated rocket. Will it bounce? If so, how?", "output": "This is one of those things that should become clear once you see it, so I made an animation:\n\nAs you can see, the ball simply bounces off the back of the rocket once the rocket catches up with it, just like a tennis ball bouncing off the racket during a serve. In the comoving frame (i.e. if we are accelerating along with the rocket), this amounts to the ball bouncing off the floor.\nSince the rocket is still accelerating but the ball is not, the rocket will eventually catch up with the ball again and it will bounce a second time. Here is a bonus animation showing multiple bounces:\n\nIn this version the ball bounces elastically, and it starts at a lower height, so that several bounces can be observed before the rocket reaches the side of the image. It's a little hard for the eye to see, but in between collisions the ball moves at a constant speed, while the rocket accelerates to catch up with it.\nFinally, here's another bonus animation to show that if the ball doesn't bounce elastically then it will stop bouncing and start just moving along with the rocket:", "meta": {"post_id": 394171, "input_score": 43, "output_score": 164, "post_title": "If I drop a ball in an accelerating rocket, will it bounce? If so, how?"}}
{"input": "Pretend you have an indestructible tube that cannot leak, inside which is water. Imagine that in each side of the tube, you have very powerful pistons\nWhat would happen if you compress the water inside?\nWould it turn into heat and escape the tube?\nWould the water turn into solid because the water molecules are so close to each other?\nWould the water turn into a black hole?\nWhat would happen?", "output": "Short version\n\nAround ${10}^{5}\\mathrm{Pa}$, which is about normal atmospheric pressure, water's liquid.\nAround ${10}^{9}\\mathrm{Pa}$, water's compressed into ice.  Ice configuration varies as pressure increases.\nAround ${10}^{12}\\mathrm{Pa}$, the ice metallizes.  It's no longer a bunch of H2O molecules, but rather a soup of H and O atoms.\nAround ${10}^{16}\\mathrm{Pa}$, very roughly, nuclear reactions might start to become appreciable (though not exactly common).\nAround ${10}^{31}\\mathrm{Pa}$, pressures approach what's found in a neutron star.  It's no longer meaningful to speak of individual atoms.\nAt some point, it probably collapses into a black hole, or something.\nPast that, it'd be rampant speculation.\n\n\nLong version\nRoughly, works kinda like this:\n\nStart at a typical temperature/pressure; let's say $20{}^{\\circ}\\mathrm{C}$ and $1{\\cdot}{10}^{5}\\mathrm{Pa}~\\left(\\approx1~\\mathrm{atm}\\right)$.\nCompress, assuming that the cylinder is in a heat bath of constant temperature.\n\nAnother common option is to consider an adiabatic compression, in which heat is trapped too, such that temperature'll tend to increase as it's compressed.  Doing isothermal instead because it's lazier.\n\nAs pressure increases, a few minor effects will happen:\n\nWater'll lose some volume (though it's not too compressible).\nHeat'll get generated (though it'll be lost to the heat bath).\nThe chemical equilibrium will shift a bit.\n\nAround $P{\\approx}1{\\cdot}{10}^{9}\\mathrm{Pa}$, the liquid water will start to compress into ice.\n\nSpecifically, the water molecules will arrange themselves into an Ice VI pattern.\n\nAround $P{\\approx}2{\\cdot}{10}^{9}\\mathrm{Pa}$, the Ice VI pattern might start to lose way to Ice VII.\nAround $P{\\approx}6{\\cdot}{10}^{9}\\mathrm{Pa}$, the Ice VII pattern might start to lose way to Ice X.\nBeyond this point, things start to get speculative as we're outside the realm of experimental verification.\nThe plot in @BobJacobsen's answer shows a prediction of a variation of Ice XI, as does this slightly extended plot:\n\nAs pressures increase further, it stops being \"water\", but instead a metal composed of the atoms that used to be in the water.  The difference is that, pre-metallization, water is H2O; after metallization, it's no longer meaningful to speak of individual molecules of H2O, much like it's not meaningful to speak of \"molecules\" of typical metals.\nExactly when and how metallization happens is controversial.  There're competing claims for when hydrogen metallizes, and I found a claim that oxygen metallizes relatively soon too, and then another claim that water would metallize at another pressure:\n\n$P{\\approx}2.5{\\cdot}{10}^{10}\\mathrm{Pa}$: Early prediction of hydrogen's metallization.\n$P{\\approx}9.6{\\cdot}{10}^{10}\\mathrm{Pa}$:  Wikipedia cites oxygen going metallic.\n$P{\\approx}4.95{\\cdot}{10}^{11}\\mathrm{Pa}$:  There's a contested experimental claim to having observed metallic hydrogen.\n$P{\\approx}1.55{\\cdot}{10}^{12}\\mathrm{Pa}$:  Claim for water (so both hydrogen and oxygen together) going metallic:\n\nBased on density functional calculations we predict water ice to attain two new crystal structures with Pbca and Cmcm symmetry at 7.6 and 15.5 Mbar, respectively. The known high pressure ice phases VII, VIII, X, and Pbcm as well as the Pbca phase are all insulating and composed of two interpenetrating hydrogen bonded networks, but the Cmcm structure is metallic and consists of corrugated sheets of H and O atoms. The H atoms are squeezed into octahedral positions between next-nearest O atoms while they occupy tetrahedral positions between nearest O atoms in the ice X, Pbcm, and Pbca phases.\n-\"New Phases of Water Ice Predicted at Megabar Pressures\" [formatting omitted]\n\n\nAt some pretty ambiguous point, nuclear reactions'll probably start to become significant, likely with hydrogen's going to helium, etc..  Since nuclear reactions have started, we're outside the realm of chemistry.\nEventually, the matter'll probably become degenerate.  Naively, I kinda picture something like a neutron star, where increasing the pressure would be like digging deeper into a neutron star's layers:\n\nBut, obviously, we're deep into the realm of speculation at this point.\nEventually the degeneracy pressure is overcome, and it'll form a black hole, maybe.  Perhaps it'll look like a fuzzball, maybe.  Don't really know.\n\n\nDiscussion on high-pressure ice\nFor the extreme range of pressures in which water is still \"water\", this source seems to have a good discussion:\n\nVery high-pressure ices including superionic ice\nThe state of ice at the very high pressures above ice X has only recently been reached experimentally. Modeling gives a confusion of possibilities. As such modeling, but of lower pressure ices, does not give accurate results as compared with experimental structure information, it is expected that these results are, at best, indicative. Density functional calculations [1709] indicate a pressure-induced initial displacement of the ice-ten atomic layers to give an orthorhombic Pbcm structure. At higher pressure, this may be followed by the squeezing of the H-atoms from their midpoints to give a Pbca structure and then, at over a terapascal (TPa, 107 atm), to a metallic ice, consisting of corrugated sheets of H and O atoms with the H-atoms at the octahedral midpoints between next-nearest oxygen atoms [1709]. Alternative views have been given; one is that the orthorhombic Pbcm structure is superseded by a _Pmc_21 phase above 930 GPa, followed by a _P_21 crystal structure at about 1.3 TPa and finally the metallic C2\u2215m phase above about 4.8 TPa [1818]. Another study shows that trigonal P3121 and orthorhombic Pcca phases become stable in the ranges 0.77-1.44 TPa and 1.44-1.93 TPa [2114] respectively. Such ices are not molecular and may be considered as protons and oxygen dianions with mobile electrons [1666] and are expected at the core of giant planets such as Jupiter and Saturn A partially ionic phase consisting of alternate layers of OH- and H3O+ at low temperatures has been suggested [1810]. Several new phases may convert into one where the coordination number of oxygen increases from 4 to 5 with a significant increase of density [1818]. At pressures over about 5 TPa, it has been suggested that a phase splitting occurs with (the components of) H2O decomposing into a cubic Pa-3 H2O2 -formula phase and a hydrogen-rich phase, with metallization predicted at a higher pressure of just over 6 TPa [2114].\nA new superionic phase was proposed with an approximate triple point of about 1000 K, 40 GPa with liquid (supercritical and ionized) water and ice-seven at high temperatures (~1500K) [1572]. In this phase, the hydrogen ions (protons) were expected to be highly mobile, behaving like a liquid, and moving within the solid lattice of oxygen ions.The recent experimental discovery of superionic ice has reinforced this prediction [3199]. Using shock compression of ice-seven, it was shown that ice melts near 5000 K at 190 GPa.\n-\"Water Structure and Science\" [links omitted; formatting partially reproduced]", "meta": {"post_id": 394943, "input_score": 45, "output_score": 45, "post_title": "What happens when you put water under intense pressure?"}}
{"input": "Part of the reason that relativistic QFT is so hard to learn is that there are piles of 'no-go theorems' that rule out simple physical examples and physical intuition. A very common answer to the question \"why can't we do X simpler, or think about it this way\" is \"because of this no-go theorem\".\nTo give a few examples, we have:\n\nthe Reeh-Schlieder theorem, which I'm told forbids position operators in relativistic QFT\nthe Coleman-Mandula theorem, which forbids mixing internal and spacetime symmetries\nHaag's theorem, which states that naive interaction picture perturbation theory cannot work\nthe Weinberg-Witten theorem, which among other things rules out a conserved current for Yang-Mills\nthe spin-statistics theorem, which among other things rules out fermionic scalars\nthe CPT theorem, which rules out CPT violation\nthe Coleman-Gross theorem, which states the only asymptotically free theory is Yang-Mills\n\nOf course all these theorems have additional assumptions I'm leaving out for brevity, but the point is that Lorentz invariance is a crucial assumption for every one.\nOn the other hand, nonrelativistic QFT, as practiced in condensed matter physics, doesn't have nearly as many restrictions, resulting in much nicer examples. But the only difference appears to be that they work with a rotational symmetry group of $SO(d)$ while particle physicists use the Lorentz group $SO(d-1, 1)$, hardly a big change. Is there a fundamental, intuitive reason that relativistic QFT is so much more restricted?", "output": "One of the reasons relativistic theories are so restrictive is because of the rigidity of the the symmetry group. Indeed, the (homogeneous part) of the same is simple, as opposed to that of non-relativistic systems, which is not.\nThe isometry group of Minkowski spacetime is\n\\begin{equation}\n\\mathrm{Poincar\\acute{e}}=\\mathrm{ISO}(\\mathbb R^{1,d-1})=\\mathrm O(1,d-1)\\ltimes\\mathbb R^d\n\\end{equation}\nwhose homogeneous part is $\\mathrm O(1,d-1)$, the so-called Lorentz Group1. This group is simple.\nOn the other hand, the isometry group of Galilean space+time is2\n\\begin{equation}\n\\text{Bargmann}=\\mathrm{ISO}(\\mathbb R^1\\times\\mathbb R^{d-1})\\times\\mathrm U(1)=(\\mathrm O(d-1)\\ltimes\\mathbb R^{d-1})\\ltimes(\\mathrm U(1)\\times\\mathbb R^1\\times\\mathbb R^{d-1})\n\\end{equation}\nwhose homogeneous part is $\\mathrm O(d-1)\\ltimes\\mathbb R^{d-1}$, the so-called (homogeneous) Galilei Group. This group is not semi-simple (it contains a non-trivial normal subgroup, that of boosts).\nThere is in fact a classification of all physically admissible kinematical symmetry groups (due to L\u00e9vy-Leblond), which pretty much singles out Poincar\u00e9 as the only group with the above properties.  There is a single family of such groups, which contains two parameters: the AdS radius $\\ell$ and the speed of light $c$ (and all the rotation invariant \u0130n\u00f6n\u00fc-Wigner contractions thereof). As long as $\\ell$ is finite, the group is simple. If you take $\\ell\\to\\infty$ you get Poincar\u00e9 which has a non-trivial normal subgroup, the group of translations (and if you quotient out this group, you get a simple group, Lorentz). If you also take $c\\to\\infty$ you get Bargmann (or Galilei), which also has a non-trivial normal subgroup (and if you quotient out this group, you do not get a simple group; rather, you get Galilei, which has a non-trivial normal subgroup, that of boosts).\nAnother reason is that the postulate of causality is trivial in non-relativistic systems (because there is an absolute notion of time), but it imposes strong restrictions on relativistic systems (because there is no absolute notion of time). This postulate is translated into the quantum theory through the axiom of locality,\n$$\n[\\phi(x),\\phi(y)]=0\\quad\\forall x,y\\quad \\text{s.t.}\\quad (x-y)^2<0\n$$\nwhere $[\\cdot,\\cdot]$ denotes a supercommutator. In other words, any two operators whose support are casually disconnected must (super)commute. In non-relativistic systems this axiom is vacuous because all spacetime intervals are timelike, $(x-y)^2>0$, that is, all spacetime points are casually connected. In relativistic systems, this axiom is very strong.\nThese two remarks can be applied to the theorems you quote:\n\nReeh-Schlieder depends on the locality axiom, so it is no surprise it no longer applies to non-relativistic systems.\nColeman-Mandula (see here for a proof). The rotation group is compact and therefore it admits finite-dimensional unitary representations. On the other hand, the Lorentz group is non-compact and therefore the only finite-dimensional unitary representation is the trivial one. Note that this is used in the step 4 in the proof above; it is here where the proof breaks down.\nHaag also applies to non-relativistic systems, so it is not a good example of OP's point. See this PSE post for more details.\nWeinberg-Witten. To begin with, this theorem is about massless particles, so it is not clear what such particles even mean in non-relativistic systems. From the point of view of irreducible representations they may be meaningful, at least in principle. But they need not correspond to helicity representations (precisely because the little group of the reference momentum is not simple). Therefore, the theorem breaks down (as it depends crucially on helicity representations).\nSpin-statistics. As in Reeh-Schlieder, in non-relativistic systems the locality axiom is vacuous, so it implies no restriction on operators.\nCPT. Idem.\nColeman-Gross. I'm not familiar with this result so I cannot comment. I don't even know whether it is violated in non-relativistic systems.\n\n\n1: More generally, the indefinite orthogonal (or pseudo-orthogonal) group $\\mathrm O(p,q)$ is defined as the set of $(p+q)$-dimensional matrices, with real coefficients, that leave invariant the metric with signature $(p,q)$:\n$$\n\\mathrm O(p,q):=\\{M\\in \\mathrm{M}_{p+q}(\\mathbb R)\\ \\mid\\ M\\eta M^T\\equiv \\eta\\},\\qquad \\eta:=\\mathrm{diag}(\\overbrace{-1,\\dots,-1}^p,\\overbrace{+1,\\dots,+1}^q)\n$$\n\n\nThe special indefinite orthogonal group $\\mathrm{SO}(p,q)$ is the subset of $\\mathrm O(p,q)$ with unit determinant. If $pq\\neq0$, the group $\\mathrm{SO}(p,q)$ has two disconnected components. In this answer, \"Lorentz group\" may refer to the orthogonal group with signature $(1,d-1)$; to its $\\det(M)\\equiv+1$ component; or to its orthochronus subgroup $M^0{}_0\\ge+1$. Only the latter is simply-connected. The topology of the group is mostly irrelevant for this answer, so we shall make no distinction between the three different possible notions of \"Lorentz group\".\n\n2: One can prove that the inhomogeneous Galilei algebra, and unlike the Poincar\u00e9 algebra, has a non-trivial second co-homology group. In other words, it admits a non-trivial central extension. The Bargmann group is defined precisely as the centrally extended inhomogeneous Galilei group. Strictly speaking, all we know is that the central extension has the algebra $\\mathbb R$; at the group level, it could lead to a factor of $\\mathrm U(1)$ as above, or to a factor of $\\mathbb R$. In quantum mechanics the first option is more natural, because we may identify this phase with the $\\mathrm U(1)$ symmetry of the Schr\u00f6dinger equation (which has a larger symmetry group, the so-called Schr\u00f6dinger group). Again, the details of the topology of the group are mostly irrelevant for this answer.", "meta": {"post_id": 396818, "input_score": 55, "output_score": 37, "post_title": "Why are relativistic quantum field theories so much more restrictive than non-relativistic ones?"}}
{"input": "I've been reading/hearing that if the AMS satellite measures a significant flux of anti-helium in cosmic rays, that would be an irrefutable proof of dark matter. I was wondering:\n\nWhy is that? what is the dark matter decay/annihilation that produces the anti-helium.\nIsn't there any process involving standard model particles that produce anti-helium?\nIs there any relation with the search for anti-deuteron in dark matter detection experiments?", "output": "The original experiment was designed to find it as a proof of antimatter, not dark matter.\n\nthe AMS is finally delivering on the promise of its original name when \"AM\" stood for \"antimatter.\"\n\n\n\nWhen Ting sold NASA and DOE on the AMS, he said it might find runaway particles from oases of antimatter, helping solve a deep riddle. The big bang produced matter and antimatter in equal amounts. Soon after, they began colliding and annihilating each other in puffs of gamma rays. But somehow, matter came to dominate the observable universe. That could be because of some fundamental difference between the two\u2014or maybe it was just a coin flip, where certain regions of space came to be ruled by one or the other. Ting's idea to look for those regions galvanized his critics, who considered it outlandish because clumps of antimatter coexisting with normal galaxies would produce more gamma radiation than astronomers observe. Moreover, large antiparticles could not easily survive the journey to the AMS. But if antimatter were there, the AMS would sniff it out\u2014or so the original pitch went.\n\n\n\nBut each year has also brought one event or so that for all the world looks like it is curving with charge equal to minus two, Ting says\u2014the expected signature of antihelium. The events could just be heliums bouncing unusually off an atom inside the experiment, leading to a misidentification. But the team has used computers to model all the possible paths a particle could take in the detector. \"We still do not see any possible way this could come from any background,\" Ting says. \"Many people in the collaboration think we should publish it.\"\n\nAnd seem to be holding up for that, leftover antimatter from the big bang.\nYou ask:\n\nWhy is that? what is the dark matter decay/annihilation that produces that\n\nThis is a competing theoretical explanation, based on the theoretical model, example \n\nGalactic Dark Matter (DM) annihilations can produce cosmic-ray anti-nuclei via the nuclear coalescence of the anti-protons and anti-neutrons originated directly from the annihilation process. Since anti-deuterons have been shown to offer a distinctive DM signal, with potentially good prospects of detection in large portions of the DM-particle parameter space, we explore here the production of heavier anti-nuclei, specifically anti-helium\n\n\n\nIsn't there any process involving standard model particles that produce anti-helium?\n\nIt would be one with very small probabilities because It would have to be a complicated single interaction with 12 quarks and 12 antiquarks, if it were a pair production from a very high energy gamma-field pair production. The models where anti helium coalesces from lower antibaryon number have better probabilities.\n\nIs there any relation with the search for anti-deuteron in dark matter detection experiments?\n\nAnti-deuterons also may appear by coalescence but there  are proposals that  if dark matter is composed of supersymmetric particles :\n\nmeasurements of the antiproton cosmic-ray flux at the Earth will be a powerful way to indirectly probe for the existence of supersymmetric relics in the galactic halo. Unfortunately, it is still spoilt by considerable theoretical uncertainties. As shown in this work, searches for low-energy antideuterons appear in the meantime as a plausible alternative, worth being explored. Above a few GeV/n, a dozen spallation antideuterons should be collected by the future AMS experiment on board ISSA. For energies less than about 3 GeV/n, the antideuteron spallation component becomes negligible and may be supplanted by a potential supersymmetric signal. If a few low-energy antideuterons are discovered, this should be seriously taken as a clue for the existence of massive neutralinos in the Milky Way. \n\nIt is all very speculative and theoretical.", "meta": {"post_id": 404400, "input_score": 30, "output_score": 38, "post_title": "Why is Anti-helium so important in the search for dark matter?"}}
{"input": "What's wrong with the following diagram?\n\nImage source: Page 183, NCERT Physics Textbook for Class XII Part I\nThe reason stated in my textbook is as follows:\n\nMagnetic field lines between two pole pieces cannot be precisely straight at the ends. Some fringing of lines is inevitable. Otherwise, Ampere\u2019s law is violated. This is also true for electric field lines.\n\nI don't understand how is Ampere's law violated when fringe fields are absent.\nCan anyone please explain how Ampere's law is violated?", "output": "Consider the two paths $ABCDA$ and $EFGHE$.  \n \nPath $AB$ contributes a positive value to the $\\vec B\\cdot d\\vec l$ integral but the other parts of the loop contribute nothing, so overall there is a finite value for the $\\vec B\\cdot d\\vec l$ integral but no enclosed current which violates Ampere's law.  \nAgain path $EF$ contributes a positive value to the $\\vec B\\cdot d\\vec l$ integral but now all the other parts of the loop contribute a negative value to the $\\vec B\\cdot d\\vec l$ integral with the result that the total integral is zero as is the enclosed current.", "meta": {"post_id": 406837, "input_score": 30, "output_score": 44, "post_title": "Why is Amp\u00e8re's law violated if there are no fringe fields?"}}
{"input": "It's a well-known fact that when one soaks a thin piece of fabric, it will often become more transparent than it was before.\nWhat is the reason behind this? I can't put glass behind the fabric and increase its transparency.\n(Also, just in case this seems like a duplicate, I am not concerned necessarily with why the fabric become darker but just the transparency aspect, unless, of course, the causes of these two phenomena are not disjoint.)", "output": "The fabric is made of many thin fibers of fabric, with air in between. This structure causes light to bounce around many times inside, making it hard for light to get through. \nWhen you make the fabric wet, you replace the air with water, which has a closer index of refraction to the fibers. So the reflections inside are less important, and more light just goes straight through.\nSome people might interpret this as the clothing getting darker, especially if somebody is wearing the clothes, but that\u2019s just because no light is coming from the other side. If you hold the fabric up to the sun, it should be clear the effect is really just an increase in transparency.\nFor the same reason, paper becomes transparent when it gets oily, as anybody who has ever eaten pizza on a paper plate knows.", "meta": {"post_id": 408432, "input_score": 79, "output_score": 105, "post_title": "Why does soaking a fabric make it more transparent?"}}
{"input": "Suppose we took a photo of a rainbow, but in such a huge resolution and sharp focus as to be able to see each droplet in good detail. What would the droplets look like? Would they be nearly uniformly glowing, each with its color? Or would the rainbow colors come from some region (or regions?) of the droplets?", "output": "First let's zoom into a simulated primary rainbow from a grid of identical droplets, and then dim it to better see the source of color.\n\nWhat you may have noticed is that there're only several small regions of the droplet, where we can see images of the Sun. The main two are:\n\nWhite spot: the reflection from the surface,\nBright colored spot: the rainbow-forming internally-reflected (once in this case) ray.\n\nThe following image from Wikipedia article may make you wonder, why do only some parts of the sphere glow, in particular, why not the whole middle of it?\n\nThe answer to this is that outgoing rays exiting from different spots of the surface are all going in different directions, so that the camera/eye only sees some of them \u2013 those directed to it, so only some spots of the surface appear lit.\nOK, we've seen a yellow sphere above. But what about the other colors? How does the colored spot change when we move the Sun so that the sphere's dominant glow color changes from red to violet to white? Here's an animation of the spot forming primary rainbow \u2013 the one due to single internal reflection (sphere's azimuth is 0\u00b0, elevation 11.31\u00b0, Sun elevation is 5\u00b0, azimuth changes from 140.5\u00b0 to 142.2\u00b0):\n\nEnough simulations for now. You could actually see this for yourself with a real material object. For this you'll need a clear glass ball (such a ball can be found for less than 10 USD on Ebay or Amazon), and a point-like light source (e.g. Sun or a lamp). Here's how the ball in one of the configurations of light source, camera and the ball itself looked in my case (with varying exposure to make color details more visible):", "meta": {"post_id": 408618, "input_score": 28, "output_score": 46, "post_title": "What do individual rainbow-forming droplets look like?"}}
{"input": "I remember years ago in school my chemistry teacher showed us a tangled wire that untangled itself when a current is applied, can anyone suggest what the material may be?", "output": "You are almost certainly thinking of nitinol wire or \"memory wire\".\nHowever, it's not electricity that makes it untangle.  It's heat.  Running current through the wire is just a way to heat it.\nWhen at room temperature, nitinol wire can be easily bent.  When heated, it acts like a spring trying to go back to its unbent shape.  You can see the same effect by twisting some wire, then dropping it into boiling water.\nThere have been \"electric pistons\" built on this principle.  The piston is driven by a spring of memory wire.  When cold, the piston is easily compressed.  When the spring is heated by running electric current thru it, it pushes against the piston harder than what it took to push the piston in when cold.  This effect has niche uses but is mostly a curiosity.  The overall cycle is not very efficient.", "meta": {"post_id": 408771, "input_score": 32, "output_score": 49, "post_title": "Material that untangles itself when a current is applied?"}}
{"input": "The lens zooms and focuses something very far away, yet the reticle inside the lens assembly is in perfect focus just like the far objects. How?", "output": "The image of the distant object is formed in the plane of the graticule.\nThe eyepiece is then focused on the image of the distant object and the graticule which is in the same plane.  \n. \nThe objective forms an inverted image of the distant object in its focal plane.\nThe next lens combination forms an erect image in the plane of the graticule (reticle in North America).\nThat image of the distant object and the graticule are focussed by the eyepiece so that the eye sees the distant object and the graticule both in focus.", "meta": {"post_id": 414757, "input_score": 41, "output_score": 44, "post_title": "How is a (rifle scope) reticle in focus?"}}
{"input": "This was a humorous thought experiment that occurred while chatting about black holes.  The person that I was talking to assumed that a black hole required a specific density to be achieved. I pointed to the formula for the Schwarzschild radius.  This suggests that low density black holes are possible if they are large enough.  I'll assume simple spherical, non-rotating, uncharged black holes.  \n$$\nr = \\frac{2 G M}{c ^ 2}\n$$\nUsing $\\rho$ as the the average density.  \n$$\nM = \\frac{4}{3} \\pi r^3 \\rho\n$$\n$$\n\\rho = \\frac{3}{8 \\pi}\\frac{c^2}{G r^2}\n$$\nWhich can be as small as you like by having $r$ large enough. \nSo, assuming that the average density of a person is approximately that of water, I calculate that if I achieved a radius of approximately $4 \\times 10^8 km$ then I would become a black hole.  If I was centred at the Sun then I would extend into the asteroid belt.  Of course, people are not usually spherical though if you get this large then it is probably a good approximation.  There may also be some health issues and practical issues with obtaining sufficient food, oxygen, etc but they are off-topic in this group.  \nAm I right, is a black hole with the same average density as water possible?  \nApart from the biological and nutrient issues, what others might I face?  I guess that I will suffer severe problems long before I reach this size.  Would I collapse and become a star (quite literally)?\nAlternatively, if an extremely large number of people gathered in a huge group hug, could they become a black hole?\nUpdate\nThanks to the comments from kleingordon and dmitry-brant, my main question is answered.  This leaves:\n\nIs my calculation right?  (To 1 significant digit)\nWould I become a star or face some other calamity before becoming a black hole?", "output": "As you suggest, long before you got that large gravitation would become dominant.  One of the early what ifs is about what you get if you take a mole (ie $6\\times 10^{23}$) of moles (small animals) which results in something a little larger than the Moon, and the answer is not very pretty (at least not for the moles).\nThis is indeed why stars happen: if you get very large collections of matter, they collapse in on themselves gravitationally, fusion starts in their cores (you are mostly carbon, which would fuse I presume).  I don't know if anyone has done the sums describing the formation of stars whose precursors were very large humans: I suspect not.  But this would happen long before you got large enough to reach your Schwarzschild radius.\nIn fact, long before that you would hit another problem: surface to volume and temperature.  A grovel over the internet says that humans dissipate about $100\\,\\mathrm{W}$, so if the average human has a mass of $60\\,\\mathrm{kg}$, then this is about $1.6\\,\\mathrm{W/kg}$ or (assuming humans are about as dense as water) about $1.6\\,\\mathrm{kW/m^3}$.  If you assume humans are spherical then you get surface flux, I think, of about $550 r\\,\\mathrm{W/m^3}$, where $r$ is the radius of the human (the units are right here: r has the dimensions of length so the flux comes out as $\\mathrm{W/m^2}$).  And since humans are approximately black bodies, this corresponds to a surface temperature of\n$$\\left(\\frac{550r}{\\sigma}\\right)^{\\frac{1}{4}}$$\nSo this is going like $r^{1/4}$ which smells right to me.  Plugging in some numbers, a $100\\,\\mathrm{m}$ radius human is at around $1000\\,\\mathrm{K}$.  So you're dead well before you get that big.\nSo no, you can't eat yourself into a black hole: you die of heat exhaustion before gravity even becomes significant.", "meta": {"post_id": 415094, "input_score": 37, "output_score": 42, "post_title": "Can I eat myself into a black hole?"}}
{"input": "I'm not a physicist, but I was wondering:\nCan ants walk on dense liquid like mercury and why?", "output": "Needing any excuse to break away from the work I was doing, I immediately assumed the task of answering this question. \nYes, ants can walk on mercury with no trouble at all. I bet it was even kind of fun, but this little punk just split as soon as possible. I got a video, but had to settle for a screenshot for this post.", "meta": {"post_id": 416131, "input_score": 41, "output_score": 163, "post_title": "Can ants walk on liquid mercury?"}}
{"input": "Hydrogen is the most abundant element in nature. Does cosmological nucleosynthesis provide an explanation for why is this the case? Is the explanation quantitatively precise?", "output": "The short answers are that: (i) Protons (hydrogen nuclei) are produced abundantly in the early universe but only a small fraction of these are able to engage in nuclear reactions leading to heavier elements, either during primordial nucleosynthesis or later, inside stars. This means that hydrogen ends up being the most abundant element in the universe. (ii) Big Bang nucleosynthesis makes very precise predictions (to $<1$% precision) about the fraction of baryons that end up as protons vs other nuclei.\nFurther details\nIn the early phases of the big bang only the constituent parts of nucleons (quarks and anti-quarks) plus leptons (e.g. electrons, positrons, neutrinos) and light (photons) existed. As the universe expanded and cooled, quarks were able to combine and form the basic building blocks of nuclei - the neutrons and protons. A proton is of course a hydrogen nucleus; any heavier elements needed to be built by fusing together protons.\nProtons are positively charged and repel each other strongly. In order to fuse protons and make helium requires high energies/temperatures and the intermediate stage of forming deuterons - a proton plus a neutron in a bound pair.\nThe reason that most protons do not fuse with neutrons in this way during primordial nucleosynthesis is threefold. (Note that the fusion of two protons can take place inside stars, where there are no free neutrons, but the rate of that reaction in the early universe is quite negligible compared with direct proton-neutron fusion.)\n\nThe small excess mass of the neutron compared to the proton means that the equilibrium reactions that produce nucleons end up producing about six times as many protons as neutrons.\n\nFree neutrons then decay into protons on timescales of minutes, which increases this ratio further to about seven.\n\nThe deuteron is weakly bound, so there is only a limited window of time between when it is too hot to remain bound (prior to 10s after the Big Bang) and when it is too cool to get deuterons to fuse to become helium (beyond about 10 minutes after the Big Bang).\n\n\nOf these things, by far the most important factor is #1 and this is fundamentally the answer to your question. It is because the neutron is more massive than the proton. All heavier nuclei must contain neutrons because the Coulomb repulsion between two or more protons is too strong to form stable nuclei without them. By the end of Big Bang nucleosynthesis, essentially all of the available free neutrons end up in helium nuclei (with traces of deuterons and lithium nuclei) and thus the H/He ratio ends up at around 12 protons for every He nucleus (2 protons, 2 neutrons).\nIs this quantitatively precise? Well, my figure of 12 protons for every He nucleus, or 75% by mass, is a bit handwaving. A detailed model must take into account in a more accurate way the temperature evolution of the universe, the various (more minor) nucleosynthetic pathways, photodisintegration and so-on, but yes, the models do provide a very precise prediction of the H/He ratio (and that of more minor species) at the end of cosmological nucleosynthesis. There are small uncertainties in the neutron lifetime, the various reaction cross-sections and so-on, but the most important uncertainty is that there is an important \"free parameter\" - the baryon to photon ratio - that must be fixed. This can be constrained by demanding that one consistent value of this number can explain all the measured primordial abundance ratios (He/H, Li/H, D/H, $^3$He/H) or it can be found from other cosmological measurements (such as from the cosmic microwave background).\nThe He/H ratio is not very sensitive to this free parameter and hydrogen is always by far the most dominant nucleus for the reasons I explained above.\nCurrent levels of uncertainty on the mass fraction of hydrogen produced in the (standard) Big Bang are significantly smaller than 1% (e.g. Peimbert 2008). Coc et al. (2013) used the Planck cosmic microwave background constraints on the baryon-to-photon ratio and estimated a standard Big-Bang He/H mass ratio of $0.2463\\pm 0.0003$. One could consider additions to this standard model - e.g. change the number of neutrino families, have decaying dark matter particles in the early universe and so-on, but it seems hard to change the mass fraction of hydrogen by more than 1% without upsetting the concordance with other observations.\nA final point to make is that very little of this cosmological material has so far found its way into stars (perhaps 10%), and of that, much of it is still in the same (low-mass) stars that were formed. The amount of \"processed\" material made of heavier elements, fused from hydrogen in stars, that has enriched the cosmological material is therefore comparatively small - of order 1-2%. So the predominance of hydrogen has hardly decreased since the big bang.\nThis latter property can be used to test the whole model. By looking at the He/H ratio as we go \"back in time\" we can see if the primordial ratio matches that predicted by the Big-Bang. In practice this can be done by estimating the He/H ratio in the oldest stars or by estimating He/H in the interstellar medium of the most metal-poor galaxies. These measurements are more uncertain than the predictions above, but are in reasonable agreement with them. An example would be Izotov & Thuan (2010), who estimated a primordial He/H mass ratio of $0.2565 \\pm 0.005$ from metal-poor galaxies - about two (small) error bars higher than the prediction above.", "meta": {"post_id": 418550, "input_score": 56, "output_score": 83, "post_title": "Why is hydrogen the most abundant element in the Universe?"}}
{"input": "A beam of light is made of photons, which simply travel in a line from point $\\text{A}$ to point $\\text{B}$. But we can only see things when photons hit our retina, so doesn't this mean that the photons of the beam ought to travel to our eyes? How is it possible to see the beam?", "output": "You're not seeing the photons in the beam that are traveling from A to B (beam starting point to beam destination), you are seeing photons that are scattering off of dust particles that are in the path of the beam.\nThis is the reason why you see lasers in a night club more clearly when there is a smoke machine, and why cat burglars blow dust onto security beams, to expose them ;-)", "meta": {"post_id": 420622, "input_score": 17, "output_score": 56, "post_title": "How can we see a beam of light?"}}
{"input": "From Wikipedia:\n\nTo answer this question: \"What is the shape of a chain suspended at both ends?\" we can use the variational principle that the shape must minimize the gravitational potential energy.\n\nThe gravitational potential energy is highest at the ends. Then why isn't the chain shaped like a V?", "output": "Sorry to put in my contribution so late in the proceedings, but I don't think anyone has yet presented this simple argument based on forces\u2026\nSuppose the chain did hang in a V shape. Consider a small portion P of the chain. It is acted upon by a downward force, W, of gravity and by forces tangential to the chain from neighbouring parts of the chain. Now draw a line AB through P  at right angles to the chain at P, and in the plane of the chain as a whole. You'll see immediately that W has an unbalanced component along AB, so P can't be in equilibrium.", "meta": {"post_id": 421957, "input_score": 60, "output_score": 71, "post_title": "Why is the shape of a hanging chain not a \"V\"?"}}
{"input": "Fires have been burning here in Northern California. Today there was just a slight haze of smoke. The sun had a slight red hue to it. As expected the lower it got the redder it became. The blue light was filtered out by the earth\u2019s atmosphere and the smoke. Yet, I can look at distant stars and even a galaxy (with a telescope) millions of light years away, and there appears to be no loss of blue light. \nI wonder if it's really possible that there is more stuff in Earth\u2019s atmosphere than there is in all of the space between Earth and Andromeda. The galaxy is a fuzzy patch of whitish light indicating that all of the visible spectrum is making it through. Does that mean there is more \u201cstuff\u201d in our atmosphere than there is in the two million light years of space between Earth and Andromeda?", "output": "Sure, let's do the order of magnitude calculation! According to Wikipedia:\n\nIn cool, dense regions of the ISM, matter is primarily in molecular form  and reaches number densities of $10^6$ molecules per $\\text{cm}^3$. In hot, diffuse regions of the ISM, matter is primarily ionized, and the density is [$10^{\u22124}$ to $10^{-2}$] ions per $\\text{cm}^3$. Compare this with a number density of roughly $10^{19}$ molecules per $\\text{cm}^3$ for air at sea level.\n\nThe distance to Andromeda is $2.5 \\times 10^6$ light years while the thickness of the Earth's atmosphere is on the order of $20$ kilometers. (It technically extends much higher, but the thickness decreases rapidly.) Then the ratio of the distances is\n$$\\frac{\\text{Andromeda distance}}{\\text{atmosphere height}} \\sim 10^{18}.$$\nAt this point we would naively multiple this by the ratio of densities and call it a day, but it's crucial to account for the loss mechanism.\n\nThe atmosphere mostly consists of $N_2$ and $O_2$, which perform Rayleigh scattering. This is the kind that occurs way more for blue light than red, explaining why the sky is blue and sunsets are red.\nCool regions of the interstellar medium are mostly $H$ or $H_2$, and hydrogen just absorbs a few, discrete frequencies of visible light. These effects are important for astronomers, but not too important for the colors you see. That is, the cool regions don't matter, which is important for getting the right answer, because they're much denser than the hot regions!\nHot regions of the interstellar medium are mostly ionized hydrogen. The dominant effect should be Thomson scattering off the free electrons.\n\nSince only the hot regions matter, let's focus on those and suppose the whole line between the Earth and Andromeda is hot. Looking up standard numbers, for blue light we have\n$$N_2 \\text{ Rayleigh cross section} \\sim 2 \\times 10^{-26} \\, \\text{cm}^2$$\nand the Thomson cross section is wavelength independent,\n$$e^- \\text{ Thomson cross section} \\sim 7 \\times 10^{-25} \\, \\text{cm}^2.$$\nThese are close enough that we can just neglect the difference, so we just need to compare the total distance and density. The ratio of the densities is about $10^{19}/10^{-3} = 10^{22}$, so we have\n$$\\frac{\\text{ISM effect}}{\\text{atmosphere effect}} \\sim \\frac{10^{18}}{10^{22}} \\sim 10^{-4}.$$\nIt looks like all the space between us and Andromeda has less effect than the  atmosphere alone. \nEdit: as pointed out by Joshua (a real astrophysicist, unlike me, a regular physicist who just multiplied a bunch of powers of ten), the ISR is much sparser outside of galaxies, so I should have used the size of a galaxy rather than the full distance between galaxies. Also, a much larger effect comes from Rayleigh scattering off interstellar dust, which comes out to 20%. This is relatively close to the effect of the atmosphere.", "meta": {"post_id": 425041, "input_score": 33, "output_score": 63, "post_title": "Does more light from Andromeda get scattered in the atmosphere than in the entire trip to Earth?"}}
{"input": "Witnesses of nuclear explosions have described their hands becoming transparent, and that they could see the bones.  For example, see here.  How does that happen?", "output": "Have you never seen the bones of your hand when covering a flash light at night? Imo it was just   a very bright light over a large area and trying to shield the eyes the bones were seen.", "meta": {"post_id": 428127, "input_score": 37, "output_score": 76, "post_title": "In nuclear bomb explosions, witness describe their hands becoming transparent. How does that happen?"}}
{"input": "Traditionally for a free electron, we presume the expectation of its location (place of the center of mass) and the center of charge at the same place. Although this seemed to be reasonable for a classical approximation \n(see: Why isn't there a centre of charge? by Lagerbaer), I wasn't sure if it's appropriate for quantum models, and especially for some extreme cases, such as high energy and quark models.\nMy questions are:\n\nIs there any experimental evidence to support or suspect that the center of mass and charge of an electron must coincide?\nIs there any mathematical proof that says the center of mass and charge of an electron must coincide? Or are they permitted to be separated? (By electric field equation from EM, it didn't give enough evidence to separate $E$ field with $G$ field. But I don't think it's the same case in quantum or standard model, i.e. although electrons are leptons, consider $uud$ with $2/3,2/3,-1/3$ charges.)\nWhat's the implication for dynamics if the expectation of centers does not coincide?", "output": "Can the center of charge and center of mass of an electron differ in quantum mechanics?\n\nThey can. Particle physics does allow for electrons (and other point particles) to have their centers of mass and charge in different locations, which would give them an intrinsic electric dipole moment. For the electron, this is unsurprisingly known as the electron electric dipole moment (eEDM), and it is an important parameter in various theories.\nThe basic picture to keep in mind is something like this:\n\nImage source\nNow, because of complicated reasons caused by quantum mechanics, this dipole moment (the vector between the center of mass and the center of charge) needs to be aligned with the spin, though the question of which point the dipole moment uses as a reference isn't all that trivial. (Apologies for how technical that second answer is - I raised a bounty to attract more accessible responses but none came.) Still, complications aside, it is a perfectly standard concept.\nThat said, the presence of a nonzero electron electric dipole moment does have some important consequences, because this eEDM marks a violation of both parity and time-reversal symmetries. This is because the dipole moment $\\mathbf d_e$ must be parallel to the spin $\\mathbf S$, but the two behave differently under the two symmetries (i.e. $\\mathbf d_e$ is a vector while $\\mathbf S$ is a pseudovector; $\\mathbf d_e$ is time-even while $\\mathbf S$ is time-odd) which means that their projection $\\mathbf d_e\\cdot\\mathbf S$ changes sign under both $P$ and $T$ symmetries, and that is only possible if the theory contains those symmetry violations from the outset.\nAs luck would have it, the Standard Model of particle physics does contain violations of both of those symmetries, coming from the weak interaction, and this means that the SM does predict a nonzero value for the eEDM, which falls in at about $d_e \\sim 10^{-40} e\\cdot\\mathrm m$. For comparison, the proton sizes in at about $10^{-15}\\:\\mathrm m$, a full 25 orders of magnitude bigger than that separation, which should be a hint at just how small the SM's prediction for the eEDM is (i.e. it is absolutely tiny). Because of this small size, this SM prediction has yet to be measured.\nOn the other hand, there's multiple theories that extend the Standard Model in various directions, particularly to deal with things like baryogenesis where we observe the universe to have much more asymmetry (say, having much more matter than antimatter) than what the Standard Model predicts. And because things have consequences, those theories $-$ the various variants of supersymmetry, and their competitors $-$ generally predict much larger values for the eEDM than what the SM does: more on the order of $d_e \\sim 10^{-30} e\\cdot\\mathrm m$, which do fall within the range that we can measure.\nHow do you actually measure them? Basically, by forgetting about high-energy particle colliders (which would need much higher collision energies than they can currently achieve to detect those dipole moments), and turning instead to the precision spectroscopy of atoms and molecules, and how they respond to external electric fields. The main physics at play here is that an electric dipole $\\mathbf d$ in the presence of an external electric field $\\mathbf E$ acquires an energy\n$$\nU = -\\mathbf d\\cdot \\mathbf E, \n$$\nand this produces a (minuscule) shift in the energies of the various quantum states of the electrons in atoms and molecules, which can then be detected using spectroscopy. (For a basic introduction, see this video; for more technical material see e.g. this talk or this one.)\nThe bottom line, though, as regards this,\n\nIs there any experimental evidence to support or suspect the center of mass and charge of an electron must coincide?\n\nis that the current experimental results provide bounds for the eEDM, which has been demonstrated to be no larger than $|d_e|<8.7\\times 10^{\u221231}\\: e \\cdot\\mathrm{m}$ (i.e. the current experimental results are consistent with $d_e=0$), but the experimental search continues. We know that there must be some spatial separation between the electron's centers of mass and charge, and there are several huge experimental campaigns currently running to try and measure it, but (as is often the case) the only results so far are constraints on the values that it doesn't have.", "meta": {"post_id": 429390, "input_score": 29, "output_score": 36, "post_title": "Can the center of charge and center of mass of an electron differ in quantum mechanics?"}}
{"input": "I recently read this article which claims that last year\u2019s LIGO observation of gravitational waves is proof that, at least on massive scales, there cannot be more than three spatial dimensions. \nI don\u2019t understand the physics fully, so could someone please explain this to me? I know it\u2019s been theorized that gravity is relatively weak when compared to other forces because it leeches into other dimensions, and I think I understand how these observations disprove that, but how does this prove that there must be three and only three spatial dimensions?", "output": "It doesn't disprove all possibilities for higher dimensions - technically, you can't really disprove something so broad because there's always another way to phrase it that will put it out of reach of existing experimental data. This is a common theme with science, and thus why that scientific claims and hypotheses have to be specific and stated precisely.\nWhat it does do is, as you've surmised, disprove the idea, or at least the idea specifically tested, that gravity \"leaks\" into higher dimensions as a specific explanation for why it is so weak. This is in turn posited by some conceptions of string theory, but not all.\nI suspect the reason you are thinking that it somehow disproves higher dimensions generally and thus are confused when you see that it actually doesn't, is because of bad media. The media is not being anywhere close to as precise with these claims as a scientist would or should be, and is touting it as having \"disproved higher dimensions\", not \"disproved a particular gravitational theory that says gravity weakens through leakage into higher-dimensional spaces\".", "meta": {"post_id": 431010, "input_score": 92, "output_score": 36, "post_title": "Why does the LIGO observation disprove higher dimensions?"}}
{"input": "Does the question make sense? Velocity along time axis means $v_t=\\mathrm dt/\\mathrm dt$? If it doesn't, please explain where the flaw is. Taking time as measure like length? Or do we need to differentiate time with respect to some other quantity?\nExtension of the question is welcomed.", "output": "In non-relativistic mechanics, time $t$ is a (universal) parameter and a particle's coordinates (in some inertial coordinate system) can be expressed as three functions, $x(t),y(t),z(t)$ of this universal parameter $t$.  The velocity of the particle (in these coordinates) is then the derivative of the position with respect to the parameter $t$:\n$$\\mathbf{v} = \\frac{dx}{dt}\\hat{\\mathbf{x}} + \\frac{dy}{dt}\\hat{\\mathbf{y}} + \\frac{dz}{dt}\\hat{\\mathbf{z}}$$ \nHowever, in relativistic mechanics (SR for simplicity), time $t$ is a coordinate which is reference frame dependent.  Still, the world line of a particle can be parameterized with the proper time $\\tau$ which is essentially the time of an ideal clock fixed to the particle ('wristwatch time').\nThe coordinates of the particle (in some inertial coordinate system) can then be expressed as four functions, $t(\\tau),x(\\tau),y(\\tau),z(\\tau)$ of the particle's proper time $\\tau$.  The four-velocity of the particle is then the derivative of the four-position with respect to the parameter $\\tau$:\n$$\\vec{U} = c\\frac{dt}{d\\tau}\\hat{\\mathbf{t}} + \\frac{dx}{d\\tau}\\hat{\\mathbf{x}} + \\frac{dy}{d\\tau}\\hat{\\mathbf{y}} + \\frac{dz}{d\\tau}\\hat{\\mathbf{z}}$$\nSo, in this coordinate system, the component of the particle's four-velocity in the time direction is \n$$U^0 = c\\frac{dt}{d\\tau}$$\nNow, it can be shown that (time dilation)\n$$dt = \\gamma_v d\\tau$$\nwhere\n$$\\gamma_v \\equiv \\left(1 - \\frac{v^2}{c^2}\\right)^{-1/2}$$\nand\n$$ v = \\sqrt{\\left(\\frac{dx}{dt}\\right)^2 + \\left(\\frac{dy}{dt}\\right)^2 + \\left(\\frac{dz}{dt}\\right)^2}$$\nthus\n$$U^0 = c\\gamma_v$$\nThis is, I believe, a reasonable answer to the question \"With what velocity are we moving along the time dimension?\" if, by velocity, one means the the derivative of the coordinates with respect to a time parameter.\n(note:  as I was finishing typing this answer up, I noticed that Ben Crowell had posted essentially the same answer but I'll post this anyhow since it's already done.)", "meta": {"post_id": 438047, "input_score": 26, "output_score": 36, "post_title": "With what velocity are we moving along the time dimension?"}}
{"input": "If a person is sitting on a chair his momentum is zero and his uncertainty in position should be infinite. But we can obviously position him at most within few chair lengths. \nWhat am I missing? Do we have to invoke earth's motion, motion of the galaxy etc. to resolve the issue?", "output": "If a person is sitting on a chair his momentum is zero...\n\nHow close to zero?\nThe uncertainty principle says that if $\\Delta x$ is the uncertainty in position and $\\Delta p$ is the uncertainty in momentum, then $\\Delta x\\,\\Delta p\\sim \\hbar$. So, consider an object with the mass of a person, say $M = 70\\ \\mathrm{kg}$. Suppose the uncertainty in this object's position is roughly the size of a proton, say $\\Delta x = 10^{-15}\\ \\mathrm m$. The uncertainty principle says that the uncertainty in momentum must be \n$$\n  \\Delta p\\sim\\frac{\\hbar}{\\Delta x}\\approx\\frac{1 \\times 10^{-34}\\ \\mathrm m^2\\ \\mathrm{kg/s}}{10^{-15}\\ \\mathrm m}\\approx 1\\times 10^{-19}\\ \\mathrm{m\\ kg/s},\n$$\nso the uncertainty in the object's velocity is\n$$\n  \\Delta v=\\frac{\\Delta p}{M}\\approx \\frac{\\approx 1\\times 10^{-19}\\ \\mathrm{m\\ kg/s}}{70\\ \\mathrm{kg}}\\sim 1\\times 10^{-21}\\ \\mathrm{m/s}.\n$$\nIn other words, the uncertainty in the person's velocity would be roughly  one proton-radius per month. \nThis shows that the uncertainties in a person's position and momentum can both be zero as far as we can ever hope to tell, and this is not at all in conflict with the uncertainty principle.", "meta": {"post_id": 440399, "input_score": 19, "output_score": 107, "post_title": "Uncertainty principle for a sitting person"}}
{"input": "What if we take a cylindrical vessel with an inside surface completely reflecting and attach a piston such that it is also reflecting. What will happen to light if we compress it like this?", "output": "Suppose there is an amount of light (electromagnetic radiation) inside the cylinder. Note that electromagnetic radiation is composed of particles called photons, and if we consider that there is a very large number of photons inside the cylinder, we may use statistical mechanics to create a model of a photon gas. Yes, the system you describe will act like a gas, and its properties may be derived from statistics and from the properties of photons.\nIf a photon's frequency is $f$, its energy is $E_\u03b3 = hf$, where $h$ is Planck's constant. It is also important to remember that photons have linear momentum $$p = \\frac{E_\u03b3}{c} = \\frac{hf}{c}$$\nBut the fact that photons have nonzero linear momentum implies that they will exert pressure against the cylinder's walls. Once the photon reflects on the wall, its momentum will have changed direction, and this imples that the wall has exerted a force on the photon to make it change directions. Therefore, the photon gas exerts pressure against the walls. \nIt can be shown that if the total energy of the photon gas is $U$, then the relationship between the pressure $P$ and the volume $V$ of the gas is $U = 3PV$.\nIf you push the piston, you'll do positive work and therefore give energy to the system. It can also be shown that if you push the piston very slowly (reversible process) while keeping the system isolated (adiabatic transformation), the relationship between pressure and volume will be:\n$$PV^{4/3} = \\text{constant}$$\nIn other words, yes, light can be compressed and will act just like any other gas inside of a cylinder. Once you push the piston, you will feel an increase in pressure (the pressure of the photon gas increases)!\nThis photon gas can be used to make a simple model of stars, as is discussed in The Feynman Lectures on Physics, Vol. 1. The derivation of the other results presented before can also be found in this same book.\nAs pointed out in Yly's answer, the increase in energy as you push the piston will cause an increase in the frequency of the radiation, essentially causing a blueshift.", "meta": {"post_id": 444407, "input_score": 36, "output_score": 36, "post_title": "Can light be compressed?"}}
{"input": "I am reading Hawking's \"Brief answers\". He complained that black holes destroy information (and was trying to find a way to avoid this). What I don't understand: Isn't deleting information quite a normal process? Doesn't burning a written letter or deleting a hard disk accomplish the same?", "output": "(The answers by Mark H and B.fox were posted while this one was being written. This answer says the same thing in different words, but I went ahead and posted it anyway because sometimes saying the same thing in different words can be helpful.)\n\nThe key is to appreciate the difference between losing information in practice and losing information in principle.\nIf you write \"My password is 12345\" on a piece of paper and then burn it, the information might be lost for all practical purposes, but that doesn't mean that the information is lost in principle. To see the difference, compare these two scenarios:\n\nScenario 1: You write  \"My password is 12345\" on a piece of paper and then burn it.\nScenario 2: You write  \"My password is ABCDE\" on a piece of paper and then burn it.\n\nExactly what happens in either scenario depends on many details, like the specific arrangement of molecules in the piece of paper and the ink, the specific details of the flame that was used to ignite the paper, the specific arrangement of oxygen molecules in the atmosphere near the burning paper, etc, etc, etc. The variety of possible outcomes is equally vast, with possible outcomes differing from each other in the specific details of which parts of the paper ended up as which pieces of ash, which molecules ended up getting oxidized and drifting in such-and-such a direction, etc, etc, etc. This is why the information is lost in practice. \nHowever, according to the laws of physics as we understand them today, all of the physically possible outcomes in Scenario 1 are different than all of the physically possible outcomes in Scenario 2. There is no way to start with a piece of paper that says \"My password is 12345\" and end up with precisely the same final state (at the molecular level) as if the piece of paper had said \"My password is ABCDE.\" In this sense, the information is not lost in principle. \nIn other words, the laws of physics as we understand them today are reversible in principle, even though they are not reversible in practice. This is one of the key ideas behind how the second law of thermodynamics is derived from statistical mechanics. \nThe black hole information paradox says that our current understanding of physics is necessarily flawed. Either information really is lost in principle when a black hole evaporates, or else spacetime as we know it is only an approximately-valid concept that fails in this case, or else some other equally drastic thing. I think it's important to appreciate that the black hole information paradox is not obvious to most people (certainly not to me, and maybe not to anybody). As a testament to just how non-obvious it is, here are a few review papers mostly written for an audience who already understands both general relativity and quantum field theory:\n[1] Marolf (2017), \u201cThe Black Hole information problem: past, present, and future,\u201d http://arxiv.org/abs/1703.02143\n[2] Polchinski (2016), \u201cThe Black Hole Information Problem,\u201d http://arxiv.org/abs/1609.04036\n[3] Harlow (2014), \u201cJerusalem Lectures on Black Holes and Quantum Information,\u201d http://arxiv.org/abs/1409.1231\n[4] Mathur (2011), \u201cWhat the information paradox is not,\u201d http: //arxiv.org/abs/1108.0302\n[5] Mathur (2009), \u201cThe information paradox: A pedagogical intro- duction,\u201d http://arxiv.org/abs/0909.1038\nSection 2 in [1] says:\n\nconventional physics implies the Hawking effect to differ fundamentally from familiar thermal emission from hot objects like stars or burning wood. To explain this difference, ... [technical details]\n\nSection 4.2 in [2] says:\n\nThe burning scrambles any initial information, making it hard to decode, but it is reversible in principle. ... A common initial reaction to Hawking\u2019s claim is that a black hole should be like any other thermal system... But there is a difference: the coal has no horizon. The early photons from the coal are entangled with excitations inside, but the latter can imprint their quantum state onto later outgoing photons. With the black hole, the internal excitations are behind the horizon, and cannot influence the state of later photons.\n\nThe point of listing these references/excerpts is simply to say that the paradox is not obvious.\nThe point of this answer is mainly to say that burning a letter or deleting a hard disk are reversible in principle (no information loss in principle) even though they make the information practically inaccessible, because reconstructing the original message from its ashes (and infrared radiation that has escaped to space, and molecules that have dissipated into the atmosphere, etc, etc, etc) is prohibitively difficult, to say the least. \n\nNote added: A comment by the OP pointed out that the preceding answer neglects to consider the issue of measurement. This is an important issue to address, given that measurement of one observable prevents simultaneous measurement of a mutually non-commuting observable. When we say that the laws of physics as we currently know them are \"reversible\", we are ignoring the infamous measurement problem of quantum physics, or at least exploiting the freedom to indefinitely defer application of the \"projection postulate.\" Once the after-effects of a measurement event have begun to proliferate into the extended system, the extended system becomes entangled with the measured quantity in a practically irreversible way. (The impossibility of simultaneously measuring non-commuting observables with perfect precision is implicit in this.) It is still reversible in principle, though, in the sense that distinct initial states produce distinct final states \u2014 provided we retain the full entangled final state. This is what physicists have in mind when they say that the laws of physics as we currently know them are \"reversible.\" The black hole information paradox takes this into account. The paradox is not resolved by deferring the effects of measurement indefinitely in the black hole case, nor is it resolved by applying the \"projection postulate\" as soon as we can get away with it in the burning-piece-of-paper case. (Again, the BH info paradox is not obvious, but these things have all been carefully considered, and they don't resolve the paradox.) \nSince we don't know how to resolve the measurement problem, either, I suppose we should remain open to the possibility that the black hole information paradox and the measurement problem might be related in some yet-undiscovered way. Such a connection is not currently clear, and it seems unlikely in the light of the AdS/CFT correspondence [6][7], which appears to provide a well-defined theory of quantum gravity that is completely reversible in the sense defined above \u2014 but in a universe with a negative cosmological constant, unlike the real universe which has a positive cosmological constant [8]. Whether the two mysteries are connected or not, I think it's safe to say that we still have a lot to learn about both of them.\n[6] Introduction to AdS/CFT\n[7] Background for understanding the holographic principle?\n[8] How to define the boundary of an infinite space in the holographic principle?", "meta": {"post_id": 450326, "input_score": 48, "output_score": 48, "post_title": "Why is the information paradox restricted to black holes?"}}
{"input": "I recently read an old physics news about the Higgs boson where it was observed to decay into 2 photons and I was wondering why it wouldn't have decayed into a single photon with the combined energy of 2 photons?", "output": "No massive particle can decay into a single photon.\nIn its rest frame, a particle with mass $M$ has momentum $p=0$. If it decayed to a single photon, conservation of energy would require the photon energy to be $E=Mc^2$, while conservation of momentum would require the photon to maintain $p=0$.  However, photons obey $E=pc$ (which is the special case of $E^2 = (pc)^2 + (mc^2)^2$ for massless particles).  It's not possible to satisfy all these constraints at once.  Composite particles may emit single photons, but no massive particle may decay to a photon.", "meta": {"post_id": 453657, "input_score": 12, "output_score": 39, "post_title": "Why can a particle decay into two photons but not one?"}}
{"input": "I recently answered a question on the WorldBuilding forum about grenades and bullets.  One of the things that came up was that I argued smokeless powder in a rifle round could detonate, but was challenged on that.  Commenters said that smokeless powder only deflagrates during normal use.\nThis, however, leaves me with a question.  How can we accelerate a bullet to supersonic speeds using only a sonic speed pressure wave?  As the bullet approaches the speed of sound, shouldn't the pressure wave be pushing the bullet less effectively?  It strikes me that a bullet traveling at the speed of sound should not be able to be pushed by a pressure wave at the speed of sound.\nHow does this work?", "output": "Deflagration means that the combustion moves through the fuel slower than the speed of sound in the fuel. It doesn't say anything about the speed of the resulting gas, or how it compares to the speed of sound in that gas (and the speed of sound in solids is generally higher than that of gasses). The gas that is released from the combustion isn't at equilibrium, so properties such as \"pressure\", \"temperature\", and thus \"speed of sound\" aren't fully defined for it.", "meta": {"post_id": 458828, "input_score": 48, "output_score": 38, "post_title": "How do we get supersonic bullets?"}}
{"input": "For example, nucleons in nucleus are in motion with kinetic energies of 10 MeV. Their rest energies are about 1000 MeV. Kinetic energy of nucleons is small compared to rest energy. They are hence considered non-relativistic.", "output": "I would like to add something to the already great answers posted.\nObviously, non-relativistic is a qualitative term, you can translate it to \"relativistic effects are so small that they're negligible in this problem\".\nIn the particular case you're talking about, and as was pointed out by Roger JBarlow and John Rennie, you can calculate the Lorentz factor to be $\\gamma=1.01$. This means you are going to have measurement errors on the order of $10^{-2}$. In some fields this may be acceptable (it would be beyond amazing in fluid mechanics) , but I recall a great professor I had on relativity (he works in numerical relativity, and is one of the leading figures on the field, at least in my country) who said \"If the errors are on the order of $10^{-4}$, the results are basically useless\". This is further illustrated\n by the fact that accurate GPS measurements rely on accurate calculation of relativistic effects which are (if I recall correctly) on the order of $10^{-12}$, and would otherwise give errors of kilometers.\nThe bottom line is that the question \"is this particle non-relativistic?\" Is basically the same as asking \"is $\\gamma$ close enough to 1 so that I can just assume it's 1?\". This will change depending on the problem under consideration.", "meta": {"post_id": 459592, "input_score": 15, "output_score": 36, "post_title": "Why is a particle non-relativistic when its kinetic energy is small compared to its rest energy?"}}
{"input": "The no-hair theorem of black holes says they're completely categorised by their charge and angular momentum and mass.\nBut imagine two black holes colliding. At some point their event horizons would merge and I imagine the combined event horizon would not be spherical.\nYou could even imagine 50 black holes merging. Then the combined event horizon would be a very odd shape.\nWhy does this not disprove the no-hair theorem? Since the information about the shape of the event horizon is surely more than just charge, angular momentum and mass?", "output": "No. The no-hair conjecture applies to stable solutions of the Einstein-Maxwell equations. In the case of merging black holes, it applies to the end state of the merger into a single quiescent black hole, after the \u201cringdown\u201d has stopped.", "meta": {"post_id": 460041, "input_score": 39, "output_score": 58, "post_title": "Why don't merging black holes disprove the no-hair theorem?"}}
{"input": "Must a star belong to a galaxy, or could it be completely isolated?\nIn case it can be isolated (not belong to a galaxy), could it have a planet orbiting around it?", "output": "No, stars do not need to be inside a galaxy.  It is estimated that about 10% of stars do not belong to a galaxy [1].  While most intergalactic stars formed inside a galaxy and were ejected by gravitational interactions, stars can form outside of galaxies as well [2].\nWe assume that such stars could have planets, just like stars in a galaxy, although no specific examples have been detected yet.\n[1] \"Detection of intergalactic red-giant-branch stars in the Virgo cluster\", Ferguson et al.  Nature 391.6666 (1998): 461.\n[2] \"Polychromatic view of intergalactic star formation in NGC 5291\",\nM. Boquien et al.  A&A, 467 1 (2007) 93-106.", "meta": {"post_id": 461605, "input_score": 45, "output_score": 78, "post_title": "Does a star need to be inside a galaxy?"}}
{"input": "I read this somewhere:\n\nWhere are the protons and electrons in a neutron star? When the\u00a0neutron\u00a0star forms, most of the\u00a0protons and electrons combine\u00a0together to\u00a0form neutrons. \n\nBut on a true/false quiz, I saw the question\n\nA neutron is formed by an electron and a proton combining together and therefore it is neutral. \n\nbut the answer was false. Why are these not contradictory?", "output": "You're asking about two distinct phenomena.  The difference between them is subtle, and I think there is some context missing from the second question that you quote, which makes things more confusing than they need to be.\n\nWhen the neutron star forms, most of the protons and electrons combine together to form neutrons\n\nThis is mostly correct.  The process is known as \"electron capture,\" and the full reaction is\n$$\\rm p + e^- \\to n + \\nu_e$$\nThe other particle in the final state (represented by a nu) is a neutrino.  The neutrino is an uncharged, very low-mass electron-like particle, in the same way that neutrons and protons are different charge states of the same sort of particle.  So far as we know, in physics, the number of electron-like \"leptons\" and the number of proton-like \"baryons\" isn't changed in any physical process.  The neutrinos play an important role in the dynamics of the stellar collapses where neutron stars are formed, but in some authors who write very elementary explanations of neutron stars will leave the neutrinos out of their descriptions.  There are advantages and disadvantages to this approach; your confusion here is one of the disadvantages.\n\nA neutron is formed by an electron and a proton combining together, therefore it is neutral: true or false? Answer: false\n\nThis is a fundamentally flawed true-false question, because it makes several statements at the same time, some of which are correct.  The question I was expecting to find here, based on the title of your question, was more like\n\nThe neutron is an electron and a proton that are \"stuck together\" somehow.  (Answer: false)\n\nWe have another name for an electron and a proton that are semi-permanently \"stuck together,\" and the dynamics of that system are very different from the dynamics of the neutron.\nWhen you \"combine together\" macroscopic objects in ordinary life, the things that you combined are still somehow present in the combination.  But in particle physics, the situation is different.  The electron-capture process that we're talking about here fundamentally changes both the baryon and the lepton parts of the system.  To the extent that a neutron behaves like a composite particle, it behaves as if it is made out of quarks.", "meta": {"post_id": 462101, "input_score": 21, "output_score": 41, "post_title": "Why does this quiz question say that protons and electrons do not combine to form neutrons?"}}
{"input": "Place the beaker full of steel balls and submerge the table tennis ball under the steel balls. The table tennis ball does not float up. Why does it not float up? Do table tennis balls float when the diameter of steel balls is reduced? How to calculate the buoyancy of steel balls?\nWould it come up without friction?", "output": "The ball bearings are behaving as a solid because the forces between the steel balls (i.e. friction) are large enough to hold the balls in position relative to each other.\nIf you apply enough force to a solid you will cause it to fracture or to cause plastic flow. So for example if you attached a string to the ball and pulled upwards with enough force it would cause the steel balls to flow over each other and the table tennis ball would move up. The force required is related to the yield stress of the solid formed by the steel balls.\nYou can make the steel balls behave as a fluid by making a gas flow through them. This creates a fluidised bed. The gas pushes the steel balls apart so the friction between them is removed, and in this state the steel balls will behave like a fluid and the table tennis ball would float upwards.\nAlternatively just shake the beaker. This is equivalent to adding thermal energy i.e. heating the system until it melts. If you shake the beaker you'll find the table tennis ball floats upwards.", "meta": {"post_id": 469105, "input_score": 16, "output_score": 40, "post_title": "Why doesn't a table tennis ball float on a surface of steel balls? How do we calculate buoyancy here?"}}
{"input": "After the revelation of the first black hole images, it seems there is a bias towards the south side. Is it because of measuring it from earth or is it something more fundamental in the understanding of gravitation?", "output": "The reason is almost entirely due to Doppler beaming and boosting of radiation arising in matter travelling at relativistic speeds. This in turn is almost entirely controlled by the orientation of the black hole spin. The black hole sweeps up material and magnetic fields almost irrespective of the orientation of any accretion disk.\nThe pictures below from the fifth event horizon telescope paper makes things clear.\n\nThe black arrow indicates the direction of black hole spin. The blue arrow indicates the initial rotation of the accretion flow. The jet of M87 is more or less East-West (when projected onto the page - in fact I believe the projected jet axis position angle should be more like 72 degrees rather than 90 degrees), but the right hand side is pointing towards the Earth, with an angle of about 17 degrees between the jet and the line of sight. It is assumed that the spin vector of the black hole is aligned (or anti-aligned) with this.\nThe two left hand plots show agreement with the observations. What they have in common is that the black hole spin vector has a component into the page (anti-aligned with the jet), so that its projected spin vector is to the left. Gas is forced to rotate in the same way and results in projected relativistic motion towards us south of the black hole and away from us north of the black hole. Doppler boosting and beaming does the rest. \nAs the paper says: \"the location of the peak flux in the ring is controlled by the black hole spin: it always lies roughly 90 degrees counterclockwise from the projection of the spin vector on the sky.\"\nEDIT: Having read a bit more, there is a marginal (1.5 sigma) discrepancy between the large scale jet orientation, which should be at about a PA of 72 degrees (measuring to the right) from North in the observations and the deduced orientation of the black hole spin axis which is around $145 \\pm 55$ degrees measuring from the same datum line.", "meta": {"post_id": 471753, "input_score": 43, "output_score": 42, "post_title": "Why isn't the circumferential light around the M87 black hole's event horizon symmetric?"}}
{"input": "The first image of a black hole has been released today, April 10th, 2019. The team targeted the black hole at the center of the M87 galaxy.\nWhy didn't the team target Sagittarius A* at the center of our own galaxy? Intuitively, it would seem to be a better target as it is closer to us.", "output": "Of course they targeted Sgr A* as well.\nI think though that this is a more difficult target to get good images of.\nThe black hole is about 1500 times less massive than in M87, but is about 2000 times closer. So the angular scale of the event horizons should be similar. However Sgr A* is a fairly dormant black hole and may not be illuminated so well, and there is more scattering material between us and it than in M87.\nA bigger problem may be variability timescales$^{\\dagger}$. The black hole in M87 is light days across, so images can be combined across several days of observing. Sgr A* is light minutes across, so rapid variability could be a problem.\nThe penultimate paragraph of the initial Event Horizon Telescope paper says:\n\nAnother primary EHT source, Sgr A*, has a precisely measured mass three orders of magnitude smaller than that of M87*, with dynamical timescales of minutes instead of days. Observing the shadow of Sgr A* will require accounting for this variability and mitigation of scattering effects caused by the interstellar medium\n\n$\\dagger$ The accretion flow into a black hole is turbulent and variable. However, the shortest timescale upon which significant changes can take place across the source is the timescale for light (the fastest possible means of communication) to travel across or around it. Because the material close to the black hole is moving relativistically, we do expect things to vary on these kinds of timescales. The photon sphere of a black hole is approximately $6GM/c^2$ across, meaning a shortest timescale of variability is about $6GM/c^3$. In more obvious units:\n$$ \\tau \\sim 30 \\left(\\frac{M}{10^6 M_{\\odot}}\\right)\\ \\ {\\rm seconds}.$$\ni.e. We might expect variability in the image on timescales of 30 seconds multiplied by the black hole mass in units of millions of solar masses. This is 2 minutes for Sgr A* and a much longer 2.25 days for the M87 black hole.\nEDIT:  12th May. And here it is, an image reconstruction, published by the Event Horizon Telescope consortium (see here) for the black hole at the centre of the Milky Way. The image is a time-averaged composite reconstructed using a novel dynamical imaging process for about 10 hours of VLBI data.", "meta": {"post_id": 471792, "input_score": 34, "output_score": 49, "post_title": "Why was M87 targeted for the Event Horizon Telescope instead of Sagittarius A*?"}}
{"input": "Imagine we have paper book. If we put this into a pan and increase its temperature, this book would not catch on fire. If on the other hand the book interacts with this heat source directly, it does catch fire. What is the difference between these two situations?", "output": "Before answering your question, it is important to understand how ignition of a solid material occurs. For fuels that contain hydrogen and carbon like paper, Ignition is a gas phase phenomenon . It is not the solid itself that ignites. Before a solid material can be ignited, it must be partially converted into a volatile (combustible) gas. This generally requires heat. It is the combustible gases at the surface of the solid that actually ignites, not the solid itself. The process of decomposing a solid to generate combustible gas is called pyrolysis. The ignitable gaseous products of pyrolysis need to be mixed with oxygen (air) in the proper ratio in order to be in what is called the flammable range. \nIgnition of the gas/air mixture produced by heating the paper can occur in two ways. If you continue to increase the temperature of the mixture it may reach what is called its auto (self) ignition temperature and ignite. This would be the mechanism for the book on a heated pan. Alternatively, exposing it to a pilot ignition source, such as an external flame or arc, can also ignite the mixture. That would be your book surrounded by air and exposed to a flame. The temperature of the mixture at which this occurs is called the piloted ignition temperature, or flash ignition temperature.  Generally speaking, the piloted (flash) ignition temperature is less than the auto (self) ignition temperature.\nReturning to paper and your book, @StudyStudy mentioned Fahrenheit 451. That (233 C) happens to be the auto (self) ignition temperature of paper, made popular by the book of the same name. The original test used to determining that temperature comes from ASTM 1929 \u201cStandard Test Method for Determining Ignition Temperatures of Plastics\u201d, though the test is not restricted to plastics. The piloted (flash) ignition temperature using the ASTM test is about 177 C, which is less than the auto ignition temperature. \nNow let\u2019s consider your book on a pan. Since there is no flame or arc above the pan, any ignition that would occur would be auto (self) ignition.  All other things considered, as noted above, auto ignition requires the gas be at higher temperatures than ignition involving a pilot source (flame or arc). What\u2019s more, heating occurs on the bottom surface of book. Much of this heat is conducted away from the heated surface into the mass of the book by heat conduction as well as to the surrounding air by convection. Most of the gaseous products of pyrolysis that may be produced at the bottom are prevented from mixing with air, which is essential for ignition. The surrounding air above the pan dilutes those gaseous products that escape the bottom surface. What you are likely to get is a book with a charred bottom but no flaming ignition. \nIf the book is surrounded by air subjected to an external flame, the much higher flame temperature can quickly both cause pyrolysis (thermal decomposition) and ignition of the resulting vapors.\nHope this helps.", "meta": {"post_id": 478142, "input_score": 46, "output_score": 116, "post_title": "Why doesn't increasing the temperature of something like wood or paper set them on fire?"}}
{"input": "In the 2019 miniseries \"Chernobyl\", ordinary objects are depicted as being capable of becoming radioactive, such as clothes, water, stones.\nHow exactly does something composed of a non-radioactive mass, become radioactive?\nI'm aware of the differences between alpha, beta, and gamma radiation, and I know how ionizing radiation works.\nHowever, it isn't clear to me how any radiation, including ionizing radiation makes something radioactive in any long-lasting sense of the word.\nI can imagine that ionizing radiation excites the atoms in the object, which makes the atom emit a photon until it becomes relaxed again. However, this doesn't sound like something that has a very long lasting effect?\nI can also imagine that radioactive particles, such as those from U-235, may stick to clothes or contaminate water. However, this too seems not that plausible, is there really that much U-235 in a nuclear reactor for dust particles to be a considerable problem in this regard?\nI'm not arguing that this isn't true, it simply isn't clear to me how the mechanism behind it works. I'm pretty sure this isn't clear to most non-physicists either.", "output": "I ran a measurement lab in Surrey during the Chernobyl crisis and carried out whole-body measurements of many people, including bus-loads of school children returning from the general area.\nWhat I detected was primarily \"U235 fission fragments\" (Google the quotes) which are the unequal sized 'halves' of 235 - lots of mass numbers around 90-100, lots around 130-140. The people that were contaminated had been caught in the rain or walked in puddles. The rain took particles into their hair which lodged in the microtexture of the hairs themselves. These don't wash out easily and had to be cut out. The nature of the particles suggested that they were smoke from a very intense fire that was able to volatilise the normally refractory isotopes of Cerium and similar. When these cooled, they picked up other nuclides including I131 and Cs134 and Cs137. Whole body counts after showering and radioactive hair removal detected very low levels of thyroid uptake.\nLater I had the opportunity to count the levels on MSC filtration systems. This was interesting but I never got a satisfactory answer. The filters are 3 stage, prefilter that removes coarse dust from the air, a fine filter that takes out most of the rest and a HEPA (High Efficiency Particle Absorption). The main nuclides that I was looking at were Iodine and the Caesiums. I found that the ratios of Cs134 to Cs137 were different between the different filters, but consistent in different parts of the same filter and between filters of the same type. I could only conclude that the different particle sizes came from fires of different intensities in different parts of the reactor. These different parts may have had fuel rods of different ages explaining the different Cs ratios.\nI was also asked to count the contamination levels on samples of herbs and spices imported by a friend of my Professor from different countries that had different exposures to the radioactive clouds. Sage in particular was contaminated, presumably because the furry leaves collected particles in a similar way to human hair.\nThe Caesium issue was thought to be a biologically transient one. It was expected that any that was absorbed would be flushed out of the body along with potassium (sodium has a specific mechanism to reabsorb it if required). This was found not to be correct and Wales had a long-lasting crisis because the caesium was remaining in the soil, reappearing in the grass and being taken up in sheep. Some farms were not allowed to sell their sheep for years.\nGamma-neutron reactions require a gamma energy in excess of 6MeV - rare in reactors.\nFission continues in the reactor to this day. U235 is spontaneously fissile, and alpha particles from the fuel rods will generate neutrons if they interact with low-Z elements. These neutrons will stimulate fission in turn.\nNeutron activation is a problem. Gold jewellery or fillings are not permitted in staff in a nuclear facility because the cross-section fot gold is so high. Other substances are also easy to activate - steel invariably contains other transition metals, especially Cobalt. That becomes activated into Co60 in even a mild neutron flux. Fortunately not particularly fast.", "meta": {"post_id": 484026, "input_score": 76, "output_score": 91, "post_title": "How does an ordinary object become radioactive?"}}
{"input": "My physics teacher brought this up in a lecture and I am not exactly sure what he is saying.", "output": "Cracks and other flaws can be found in metal parts by scanning the surface of the part with a small electromagnetic coil, which induces a current flow in the metal part as if the coil and the part were two coils coupled together in a transformer. the presence of a flaw like a crack in the part perturbs the flow of induced current and in turn upsets the current flow in the coil, which can be detected with a sensitive electronic circuit which thereby signals the test operator that a flaw is present at that point. This is called an eddy current test. \nIf the metal part is ferromagnetic, surface cracks can be detected by temporarily magnetizing the part with a very strong external magnetic field and then rinsing the surface with a special fluid which contains a suspension of extremely finely-powdered iron in which the particles have been coated with a fluorescent dye. In the vicinity of a crack, the field lines in the magnetized part get bunched up and protrude slightly from the crack, attracting and entrapping the iron particles there. The test operator then rinses the excess fluid off the part and shines a UV light at it, which causes the dyed particles to visibly glow and trace out the crack. This test is called magnetic particle inspection (Magnaflux).\nCracks can also be detected in a flat metal part by attaching a piece of photographic film to it and then applying a brief high voltage pulse to the part. Electrons are ejected preferentially from the sharp edges of the crack and ionize the air nearby, causing it to glow faintly and expose the film. Once the film is developed and printed onto photographic paper, the cracks can be seen in it as bright lines. This is called corona discharge imaging.", "meta": {"post_id": 484165, "input_score": 15, "output_score": 40, "post_title": "How can electric fields be used to detect cracks in metals?"}}
{"input": "This problem is from Khan Academy. Specifically for the blue point circled in red, the answer is that at this blue point, the object is neither speeding up nor slowing down. When I think about the rule about the signs of velocity and acceleration and what this means for change in speed, this makes sense: if velocity and acceleration and have the same sign, the object is speeding up, and if velocity and acceleration have opposite signs, the object is slowing down. At the blue point, the instantaneous velocity is zero and because zero is neither positive nor negative, the object is neither speeding up nor slowing down. \nHowever, intuitively, this doesn't make sense. At the blue point circled in red, the velocity is zero so the speed must be zero. Also, the slope of the function at this blue point is negative so acceleration is negative, meaning that velocity is decreasing every second. If velocity is decreasing every second, then right after 6 seconds, the velocity will turn negative but the speed will have increased. So at the blue point, the object, even though it has zero speed, is in the process of speeding up. Why is this thinking wrong?", "output": "The tricky part of this question is that you are given a graph of velocity but asked a question about speed.\nSeveral others have said essentially the same thing, but what really makes this clear for me is a graph of speed:\n\nThe above is the graph of $$ y = \\left \\lvert 4 - \\left ( \\frac{x - 2}{2} \\right ) ^2 \\right \\rvert \\text{,}$$ which is just the absolute value of the velocity graph in your screenshot.\nThis represents the fact that speed is the absolute value of velocity.\nWe understand \"slowing down\" to mean that the slope of the speed is negative, and \"speeding up\" to mean that the slope of the speed is positive. What is the slope of point $(6, 0)$ on the graph (which corresponds to your circled dot)?\nThis point is a cusp. The notion of \"slope\" only exists for differentiable points, and as Wikipedia says, \n\na function with a bend, cusp, or vertical tangent may be continuous, but fails to be differentiable at the location of the anomaly.\n\nThus the slope of speed does not exist at this point, and so the object is neither speeding up nor slowing down in this instant.", "meta": {"post_id": 485816, "input_score": 19, "output_score": 38, "post_title": "The instant an accelerating object has zero speed, is it speeding up, slowing down, or neither?"}}
{"input": "I've been surfing the web for quite a while, finding the answers I would need, but couldn't find a convincing one. First of all I need to remind you that this a very long/continuous question, so please kindly take your time. I'll provide some illustrations to make things easier and more pleasant to read.\n\nAssume that I'm pushing a box against the table with a force of $80\\ \\mathrm N$, in accordance to Newton's 3rd Law, it'll exert a force equal but opposite to the box. This is fairly simple to understand.\n\nNow, here's the confusing part, assume, that somehow I could exert the $80\\ \\mathrm N$ just to that single upper most molecule of the box. {Neglect the possibilities that it'll penetrate to the box or any such.}\nIf that was the case, how does the box actually \"exert\" a force on the table or rather How does the force of my hand exert a force on the table via the box?\nHere are my assumed possibilities:\nPossibility 1A\n\nIn this case the force exerted on that molecule \"pushes\" the molecule below it and so on, until the very last molecule of the box \"pushes\" the table's molecule and thus exerting a force on it. The diagram above gives a pretty clear idea of my assumption.\nBut, if this was the case then this would happen:\n\nIf I'm going to push that object on that particular point, where that section of molecules of the box isn't \"directly\" in contact with the surface of the weighting scale, then it won't \"read\" my pushing force, which obviously doesn't make any sense, and I've tried this experiment a few days back and clearly the scale reads it. \nPossibility 1B\n\nMy next assumption would be that the pushed molecules somehow push the molecules next to it and so with the other side, and therefore the scale reads my \"push\". \nAt first this seems pretty logical, but after further thoughts, I then questioned my self, if the molecules could affect other molecules, don't they sum up? In other words, if that single molecule that was directly \"in contact\" with the source of the $80\\ \\mathrm N$ (let's say my hypothetical microscopic finger) could cause other molecules on that object to experience the same force, this means that every molecule on that object experiences $80\\ \\mathrm N$ of downward pushing force, and the weighting scale would read an astonishing force of $720\\ \\mathrm N (80\\times9)$, which is simply impossible as it'll break the fundamental laws of Physics.\nPossibility 2\nThe assumptions below are based on my logic which frankly, I doubt, which simply means a force is divided equally amongst each individual molecules, meaning that an object with less mass, let's say 5 molecules, would experience more \"individual\" force  then a \"10 molecule\" object as the main force is divided less and thus higher acceleration.\n\nNow moving to the 2nd possibility, which for me is slightly more sensible. Here, I assume that the force divides equally to each of the molecule, so even if it was in the weighting scale scenario, the sum exerted would always be equal to my push which is $80\\ \\mathrm N$.\nUnfortunately, this assumption has its weakness also, and this doesn't go along with my intuition. Here's my explanation.\n\nLet's change the situation a bit, imagine that my goal is to penetrate through the first layer of the molecules, using my hypothetical \"molecular\" nail, I exert a force of $45\\ \\mathrm N$ to that box, if my assumption holds true then the force, would divide equally with the number of molecules in that object, which is $5\\ \\mathrm N$ for each.\nThis is counter-intuitive because the force needed to penetrate/break that particular molecule varies as the number of molecules increase/decrease, if there were 15 molecules, then the force exerted on each molecule which includes the one I would want to break to be $3\\ \\mathrm N$, which basically means the more the molecules in an object the more the force needed to break the bond of that particular molecule only (not all of the bonds). Here's a scenario I visualized:\nImagine a driller drilling a hole of $5\\ \\mathrm{cm}$ in depth through the wall, it doesn't matter how thick or wide the wall is, the amount of force needed to drill a $5\\ \\mathrm{cm}$ hole stays the same, or simply, poking through a piece of an A4 paper is just as easy as a wider one (A3). \nNote that \"breaking\" in this case is not physically breaking the molecules into pieces but rather breaking its bonds. I jut wanted to make my explanation easy and concise to understand so I prefer less intricate phrases.\nMain Question\nI made some assumptions already but each of them seems to be quite contradictive. Am I missing something here? Or is there something new I need to learn? \n\nI'm currently sitting in highschool so there definitely is alot of things beyond my knowledge. I need to admit there are alot of my explanations that are doubtful, even to me personally, and I'll not be surprised if there are a few misconceptions here and there, but I'll be very glad to be corrected. Kindly take your time to answer. Any answer would be greatly appreciated!", "output": "All the answers here seem to be correct but excessively technical. I think there are more intuitive ways to think about it so I will give it a try.\nThe box is a solid. Solids are not only arrangements of atoms floating toghether, they are related by forces. These forces (which as explained by Hotlab are electromagnetic in nature) act just like the forces on a spring.\nIn our simplistic model, you should imagine each atom to be connected by springs to the neighbours (the details are much more complex). If one atom gets away from its neighbours then the spring pulls them back, if it gets too close then the spring pushes the atoms away to a more relaxed state.\nSo for the sake of clarity we are going to assume that our model consists of a rectangular grid of identical atoms connected by springs to their upper, lower, left and right atoms each and only. No atom is connected to the atom in the lower left for example and no atom is connected to more than those 4 atoms. Simply said, each atom is connected with springs to the atoms of its  von Neumann neighborhood, like in this image:\n\nLet's name the atom that you are going to push $C$ (for \"central\") and let's call its neighbour to the left $L$, the one to the right $R$ and the atom below it $D$ (for down). And let's ignore for a moment the rest of the ensamble.\n\nSo, think about it. Right now nothing is moving, everything is in equilibrium, all the springs are in their relaxed state (neither expanded nor contracted). Now you start to push $C$ downwards. As you push $C$ it starts to move downwards (because according to Newton's II Law of motion that force has to generate an acceleration). As $C$ moves down it starts to compress the $C-D$ string and thus a force on the spring starts to arise that wants to expand it, this force is resisting more and more of your downward initial force so that $C$ starts to slow down (as your force on it is counteracted more and more by the string's need to expand). Meanwhile as the $C$ atom was going down, the $C-L$ and $C-R$ are being expanded and thus a force arises also on them, the difference now is that those forces want to contract both the springs (since they are larger than their relaxed length). This string $C-L$ pulls on $C$ to the left and upwards and the string $C-R$ pulls to the right and upwards.\nSo we have 4 forces acting on $C$ right now: your push from above, the upwards reaction of the $C-D$ string, the left-upwards reaction of the $C-L$ string and the right-upwards reaction of the $C-R$ string. As $C$ continues to move, all these forces are going to change (except for your constant push from above), until it reaches a state of equilibrium where all the spring reactions are as strong as needed to stop you from continuing moving $C$; they reach a point where they exactly counteract your force pushing on $C$. You can tell that this makes sense if you watch this diagram:\n\nI've colored in black the arrows representing the forces acting on the atom $C$. As you can see the net force equals zero, at this moment $C$ stops moving and the system reaches equilibrium (your force is counteracted by the others). You can see that there is a component of the force of the $C-R$ string to the right and the one of the $C-L$ string to the left, since the system is horizontally mirror-symmetric with respect to $C$. This means that the net force has no horizontal components, and $C-R$ is pulling to the right exactly as hard as $C-L$ is pulling to the left. What about the vertical component of the net force? As you can see, all the three reactions of the springs go upwards, so they sum up to the same value you are pushing downwards. I'm not going to calculate exactly how they sum, but clearly (because of the same symmetry argument) the upward contribution of $C-L$ is the same as the upward contribution of $C-R$, together with the upward contribution of $C-D$ string they can oppose perfect resistance to your downward push.\nBut the system would not remain in this state for long. This would be the end if $R$, $L$ and $D$ were fixed (nailed to the background). But hey are free, thus they are going to move accordingly to the forces they also experience. These forces experienced by the neighbouring atoms I've color coded with yellow and are depicted as arrows inside their corresponding atom. Those forces are exerted by the springs as they want to expand (in the case of $C-D$) or contract (in the case of $C-L$ and $C-R$).\nThe thing is that these atoms are not fixed but they are free to move. So under these forces (the yellow arrows) they are going to start to move from their original positions. Now is not just $C$ that has moved and thus expanded or contracted 3 neighbouring springs, now we have 3 atoms moving and 9 springs exerting forces in response. I'm just not going to draw all of that. Also in the next step there are going to be 6 atoms relocating and 16 springs exerting different forces. As you can see the evolution of this system explodes in terms of complexity. This means that the task of calculating each force and the new positions on each step gets larger and larger, and it is just crazy to ask someone to accomplish it. These are only 20 atoms but real solids have trillions of them, they are not always so ordered as in this lattice either, they are 3D instead of 2D, the actual electromagnetic forces involved are not acting strictly like springs but a bit differently, there could be different types of atoms and molecules with different string strengths (the chemical bonds) across the solid, the von Neumann neighbourhood could be a simplistic approximation since atoms could be linked to their second most distant neighbours or diagonally, ... But in principle this model should be quite accurate in macroscopic terms.\nIn physics, when we reach a point where there's an explosion (a unchained increase) in the number of calculations needed to be accomplished to understand the phenomenon (when even simulating it in a computer would take billions of years for a real solid) we tend to avoid this kind of microscopic interactions view and start pondering what the overall behaviour looks like at the macroscopic scale. For these we either use statistical mechanics (which tells us about the average forces nature and the average reaction of each broad region of the grid) or continuum mechanics (where we start with the assumption that there are no atoms, no springs, but a continuous elastic infinitely divisible material, and use differential calculus to explain the entire system as a solid object without parts).\nLook at my crude simulation of the evolution of this system after several more steps using only the microscopic approach of calculating each force on each atom:\n\nThe force (introduced by yourself) is not multiplied across the lattice, it only gets more and more redistributed. You can think of it also as a Gothic cathedral. The entire mechanical system of a Gothic cathedral is made in such a way that a huge load on the top (force exerted by gravity) like the weight of the central tower, is redistributed over a larger area on the ground across these \"mechanical channels\" called flying buttresses. The force is the same but now it is spread so that the pressure doesn't collapse the ceiling of the cathedral. Our case is similar, only that when viewed in detail (microscopic detail), your solid redistributes the force to the entire lattice dynamically; it takes some time for that force to be redistributed because each spring has to communicate the interaction throughout moving parts across the solid until equilibrium between your force and all the reaction forces of the causal chain you have generated counteract each other.\nAgain, when this state of equilibrium between forces is reached there is no net force (the sum of all forces cancel out), and if there's no net force then there is no movement finally. The final state is that the solid would get compressed as if your force was more or less distributed between all the atoms of the top layer (even if you are pressing on one of them only), since the springs of the top layer will all have forces pulling downwards or at least some component of that would be transferred when you move $C$ downwards to all the atoms in that top layer. The solid would look like a bunch of horizontal layers that are vertically compressing vertical the springs between them. Like this:\n\nBut if the solid is not so solid (the springs are more elastic, less reactive to expansions and contractions, less rigid), you can see that the force will get distributed in such a way that the \"solid\" would deform. Your concentrated pressure would not be distributed fairly in the top layer (even if it will always be distributed in the entire lattice). The end result (when things stop moving) would look like this:\n\nIt all depends on the strength of the springs; the cohesive force of the solid. The absolutely rigid scenario is impossible, but since electromagnetic \"springs\" (chemical bonds) are extremely non-elastic (they react strongly to any attempt to compress or extend them), the solid looks a lot like that (it gets compressed uniformly from above). In the elastic case you have materials like jello that you can press on a point, and the entire thing will deform as in the previous image while you maintain that force. But jello is in the other end of the \"solidity\" spectrum.\nSo as you can see you can't push an atom independently of the others in a solid because it will push and pull its neighbours until the entire lattice has redistributed your initial force and every atom has been dragged by that single atom by means of its spring connections to the others.\nYou can even buy or build a toy model of this system (in 3D it is even more realistic) and play with it to grasp the idea of how solids behave under distributed or concentrated pressures.\n\nIt is great to play with this microscopic model of solid matter in your hands. You can understand all the aspects I mentioned of how this system works and get to strengthen this understanding deep inside your brain.\n\nSOUND WAVES: AN INTERESTING ASPECT\nI've mentioned the fact that analyzing the entire lattice microscopically, calculating each force and the relative movement of each atom is just madness and that there are models inside statistical mechanics and continuum mechanics that can explain this. But I haven't done any calculation nor approach in that sense.\nLet's do it now, at least vaguely. We can focus for a moment our attention on the column of atoms just below the $C$ atom, ignoring the rest of the system. This is also a solid: a vertical rod with only one atom of width. Let's see how your force propagates downwards using this animation I extracted from \"The Mechanical Universe\" series.\n\nWe could totally calculate each and every interaction for each instant in time by simply using Newton's Laws of Motion and Hooke's Law (which describes the specific nature of forces exerted by springs). But this is, as I said, impractical when the number of atoms and springs is large. But! Only watching a few of these atoms you can get the sensation that there is a macroscopic (a wide context understanding) behaviour for the system. It looks like the perturbation is been propagated; it looks like a wave!\n\nSo we can avoid calculating billions of interactions because the reality is that this is just a wave propagating downwards (more like a pulse but still a wave). We have equations that perfectly and simply describe how waves behave, so this has to be used. In particular this wave is a longitudinal wave.\nWhat about the other atoms in the lattice? Well, let's focus for a moment on the atoms of the same row of $C$ and only on the ones at right-hand side. We are moving $C$ downwards so the interactions would look like this animation:\n\nAgain this looks a lot like a wave propagating (since the force has actually to be distributed in a finite amount of time). But the difference is that in this case the wave is not longitudinal but transverse.\nBut there is something to note: in the previous animation atoms move up and down only (they might be fixed with a vertical rod, each of them, where they can slide). In our system this is not a limitation, and since $R$ is not only pushed downwards by the displaced $C$ but it is also pushed to the left, the actual wave is a combination of longitudinal and transverse oscillations. The same complex waves that we see in the oceans:\n\nLook at those atoms and how they oscillate in circles (nor only back and forth and not only up and down but with a combination of both motions). Also, your solid is not only this layer nor the previous column of atoms, it is both, and each part of the lattice will suffer the propagation of these complex waves in different forms depending on the distance from $C$ and the orientation.\nBecause of symmetry, this wave is not only propagating to the right of $C$ but also to the left of $C$. And also remember, yours is not a force applied with oscillating intensity but it is just a pulse, a single wave front. When the wave front has propagated to the entire solid, the situation ends (our springs damp any future oscillations, and we reach the equilibrium/static state).\nThese pressure waves propagating across the entire solid are in fact sound waves. Incredible, right? Sound waves are redistributing the forces of the solid after your action just like a Gothic cathedral. Sounds even poetic to me. So, if the springs are more rigid, then they transmit quickly the interaction (since they react strongly to any relative change between the atoms), while in the case of more elastic springs we have slower waves. This is actually the reason why sound waves propagate faster in stiffer objects. The elasticity of these springs is related to the chemical properties of the atoms of your solid.\nFor example, for lead the sound waves propagate at $v=1210 \\;\\mathrm m/\\mathrm s$, while for the stiffer aluminium block the sound waves reach $v=6320 \\;\\mathrm m/\\mathrm s$, more than 6 km each second! Obviously we are totally unable to notice this effect when we push a solid object, the dynamical evolution of the atomic grid is so extremely fast that we are actually always seeing the static result; we push objects, and they move as a coherent monolithic entity when in reality it we are applying the force to a single part of it.\nNot only extreme speeds make this an invisible phenomenon but also, since we are macroscopic creatures, we really never would see the displacement of the atoms as the wave passes. That's why we generally speak about rigid solids in terms of general mechanical laws of motion ignoring the fact that this behaviour emerges from trillions of minuscule Newtonian mechanical interactions.\n\nHEAT: ANOTHER INTERESTING ASPECT\nFinally I want to point to this simulation of a solid block of just a few atoms colliding with the floor.\n\nLook at how I lied a little on the fact that we reach a static final situation: after compression, all these springs keep interacting with each other (all the waves keep bouncing inside the solid, reflecting and interfering with themselves in a complex way). The solid never ceases to change shape (in minuscule amounts). These interactions become background noise vibrations, and these vibrations is what we perceive, as macroscopic beings, as the temperature of the object. There is no damping.\nWhat's interesting in the animation is that the atoms were not vibrating randomly before the impact of the object. With our atom-spring lattice model we can show that a solid object moving with certain kinetic energy will indeed heat up a little when colliding with another, part of the energy is kept as the overall kinetic energy of the block as it bounces upwards again, but a fair amount of the original energy is not stored as random movement of the molecules of the solid. This is the reason why objects don't reach the same altitude after bouncing on the floor. All of this is explained just by this simple model!\nJust as a bonus, this is the second bounce: you can see that now it is just one atom that suffers the force in the collision (instead of the entire bottom layer of atoms of the previous animation). This is similar to the experiment of your question.\n\nLook at how the wave propagates so quickly that it is almost invisible in both GIFs. It is just a few frames. In the first one it is more visible: the wave traverses the solid from bottom to the top in less than half a second.\n\nADDENDUM: EXAMPLE FOR A SIMPLE NETWORK CALCULATION\nSince you are so particularly interested in the actual force distribution and how does it work I'm going to expand here on the small details of how an actual calculation can be made for a network of interconnected masses attached by springs.\nFor that we first need to understand the nature of the forces involved. Since they are springs we can use Hooke's Law;\n$F=-k(L-L_0)$\nWhich tells us that the force excerted by a spring is proportional to the stretching or contraction of it. $L_0$ is the length of the spring when it is in the relaxed state, and $L$ is the length of the string in general. So $L-L_0$ is the change of length of the string from that relaxed state. $k$ is the stiffness coeficient of the string. And the minus (-) sign is there because for an expasion ($L-L_0>0$) the force has to go in the direction of contraction and for a contraction ($L-L_0<0$) the force has to point in the direction of expansion.\n\nNow let's immagine our simple model: four atoms, connected by springs in a configuration identical to that of our $C$, $R$, $L$ and $D$ atoms. The distance between adyacent atoms is 1 angstrom (a tenth of a nanometer). This distance will also be the relaxed length of each of our springs. Which means that on this configuration they are under no tension at all. So we have $L_0 = 1 \\;angstrom$ for all the springs.\n\nNow suppose that I fix the positions of the $R$, $L$ and $D$ atoms holding them while we change the position of the $C$ atom. All the springs then are going to change in size depending on where I put $C$, and thus all the strings are going to excert a force on $C$ (a force that wasn't there before in the relaxed situation).\nSo, to give some concrete numbers I will move $C$ in the downwards direction for 0.5 angstroms (half the way to the $D$'s position). Now the length of the $C-D$ spring has decreased to 0.5 angstroms, and thus a force should appear in the upwards direction (since the contraction happened in the downward direction and Hooke's law has that \"-\" sign in front of everything). So the force excerted by this string on $C$ is going to be $F_D=-k(L-L_0)=-k(0.5-1)=k/2$. But the lengths of the $C-R$ and $C-L$ springs has also changed. The new length can be calculated by using pythagoras theorem since the springs lengths can be regarded as the hypothenuses of a right triangle with base 1 angstrom and height 0.5 angstroms:\n\nAs you can see, the lengths of the $C-R$ and $C-L$ springs are now both equal to $L=\\sqrt{0.5^2+1^2}=1.118\\; angstroms$. From basic trigonometry we know that the angle at which these springs are inclined with respect to the horizontal is the inverse tangent of the slope and the slope is the ratio between height and base. So, the force of the $C-R$ spring is going to be $F_R=-k(L-L_0)=-k(1.118-1)=-0.118k$ which is negative because the force is pointing in the opposite direction of expansion (which is considered positive), and the force of the $C-L$ spring is going to be $F_L=-k(L-L_0)=-k(1.118-1)=-0.118k$ which again is the same (note how since the system is mirror symetric we could have avoided this calculation by just saying \"they have both to be the same because of symetry\"). The only difference between them is that the direction of expansion is defined positive differently on them, the $C-R$ spring expands to the left end and the $C-L$ spring expands to the right end, thus the forces are pointed one to the right and the other to the left, both inclined with respect to the horizontal at $\\alpha = 26.57^\\circ$.\nSo let's suppose one final parameter of our model. Let's say that $k = 132.106\\; N/angstrom$. This means that the strings in our model are able to react with $132.106\\; N$ of force for each angstrom we expand or contract them. Since we have contracted the $C-D$ spring by half an angstrom the intensity of the force (regardless of signs) is $|F_D|=k/2 = 66.05\\; N$. For the force of the $C-R$ and $C-L$ springs we have $|F_R|=|F_L|=0.118k=15.59 \\; N$ each.\n\nSince we now know the value of each force applied on $C$ when on this particular position by the three springs, and since we also know how those forces are oriented (one is pointed downwards, the other is pointed to the upper-left with an angle of $26.57^\\circ$ and the last one is pointed to the upper-right with the same inclination of $26.57^\\circ$), we can compute the net force applied on $C$. We only need to decompose the forces in their horizontal and vertical components. This can be done with simple trigonometry like so:\n\nFinally we can compute the horizontal component of the net force as the sum of the horizontal components of the all the forces and the same with the vertical component. Having both vertical and horizontal total contributions we can finally obtain the actual value for the net force and its direction:\n\nAll the horizontal contributions of the different forces cancel each other out perfectly in this configuration, and only the vertical contributions add up.\nSo the final answer here is that if $C$ moves to this particular position it will be subjected to a lifting force of $80\\; N$. Why $80\\;N$? Because I choosed the value of $k$ and the value of the displacement of $C$ such that this would be the result in our model.\nThis system is not in equilibrium since the net force on $C$ is not zero. That means that if I let $C$ go from this position it will start to move upwards. While it changes position the springs are going to change lengths and the net force might change. If the movement is attenuated (by some added up friction or heating of the springs) then ultimately after some oscillations the entire system will return to the initial T-shape configuration (since in that situation we saw there was no net force, thus no change).\nBut! if instead of letting $C$ go you were pushing it with $80\\;N$ downwards then the total net force would be balanced! because you will be canceling these spring forces with that of you pressing on this particular atom with that particular force.\nSo, your original question is actually this problem but in reverse. You push with $80\\;N$ of force downwards and with this reasoning it has been shown that after 0.5 angstroms (if and only if the stiffness of the springs is k$=132.106\\; N/angstrom$) the entire system would be at equilibrium and your applied force would be exactly balanced by the others so anything would move after that. The reality (as someone pointed out) is that, because of inertia, after passing the 0.5 angstroms tick your $C$ atom would keep moving towards $D$. But as it does that the total force on $C$ is going to change to an upwards force and thus the $C$ atom would in fact oscillate around the 0.5 angstrom position forever. If there is some damping then it will come at rest to that Y-shaped configuration.\nThis is the end result of you pushing the $C$ atom with a constant force in this 4 atom system. But What would happen if I released the other atoms of the system (instead of keeping them fixed)? Then the calculation turns much more tedius (not complicated since you would only have to apply the same reasoning and basic trigonometry but for many more forces). The result of this calculation is that everything would bend a little as you push it and the entire ensable would move downwards as you keep pushing it. So here you have an example of what I was telling you, the force applied to one atom can move the enitre object as it was one monolithic structure, the minuscule bendigs of the solid are imperceptible due to the extreme strenght of the atomic bonds (those springs are trully stiff). The dynamical evolution is also imperceptible since it happens with microscopic variations of the positions of single atoms and molecules, and because it happens at the speed of sound! So the end result is that there is no macroscopically noticiable real difference between you pushing a single atom of a solid or the entire solid.\nI should note also that if you pushed a single atom with $80\\;N$ of force you would probably break all the springs connected to it (the bonds are not binded by such strong forces), So in real life you would only be able to strip that atom from the solid. But been able to push that entire force into the surface of just one single atom is beyond any everyday experience. Also the atom in contact with that atom would be striped from your finger. In general you push with larger contact surfaces, the force is distributed evenly across that contact boundary so that the subsequent interaction can be reagrded as in our models (the springs never snap).\nThe qualitative result is the same for any network of atoms. But the specific calculations as I mentioned earlier are totally unfeasable if you want to know the actions and reactions on each atom and spring for each instant of a billion atoms ensamble. Don't ask me to do that because it would just be an unscientific approach to the problem.\n\nONE FINAL CLARIFICATION\nYou seem to be worried (at least in the chat) about how forces can be redistributed like this. I think you might have one missconception here.\nThere are conservation laws for energy and momentum in mechanics (and many other variables), but conservation of force is not a law of nature and has never been regarded as one. If a force dissapears somewhere it is not replaced by any other force. We can create forces and destroy them as nothing. Don't confuse that with Newton's III law, which in fact is a cryptic form of conservation of momentum not force.", "meta": {"post_id": 487583, "input_score": 78, "output_score": 153, "post_title": "How exactly is a normal force exerted, at the molecular level?"}}
{"input": "When I forget to water my plants, and their soil becomes very dry, during the next watering I can see that the soil becomes hydrophobic. I can even see pockets of air between the repelled blob of water and the soil.\nOn the contrary, when the soil is moist, it very quickly absorbs the water.\nThis goes against the intuition, that the diffusion , in order to equalize the concentration soil-water, would create the opposite effect.\nWhat is the physical explanation of this phenomenon?\nI tried to search on google, but the explanations are of low quality and very \"high level\" without real physics involved.", "output": "This effect appears like a paradox, as dry soil makes a very bad water conductor. Two effects prevent water from infiltrating:\n\nAir in the soil pores cannot escape: dry soil includes lots of air bubbles in small to large pores. If you expect water to get in, how do you think the air could get out? Often it gets stuck, and no water can infiltrate anymore. This effect also leads to dangerous flash-floods even during droughts, when strong rain events hit super-dry soil.\nSticky capillary forces: Water forms droplets and becomes sticky due to surface tension when in contact with lots of air. The effect is even stronger in smaller pores. So it is very hard for water to create a flowing stream.\n\nUnder these circumstances, water cannot simply diffuse, because random walk is hindered by air bubbles and capillary forces. As soon as the soil is saturated, water and solutes can actually diffuse. As a consequence, water flows faster in wet soil, since it can develop a continuous stream. \nThe dashed line in the graph below expresses this fact by showing the hydraulic conductivity (i.e. how fast water infiltrates) as a function of soil moisture (from dry to wet). \n\n--- EDIT: The actual behaviour of water infiltration is a superposition of the two effects described above. Very dry soil is often compacted and therefore exhibits small pores. Small pores cannot absorb huge amounts of water quickly enough, because (1) the only path for the air to escape is upwards, which is where the rainfall water influx is sustaining a surface cover, and (2) water is hesitant to fill the pores since capillary counterforces are inversally related to pore radius. One might argue that air bubbles can still rise in water, but in a small-pore domain, bubble formation and uprising is slow and inefficient. Eventually, this tragedy can lead to flash floods.", "meta": {"post_id": 491058, "input_score": 71, "output_score": 70, "post_title": "Why is dry soil hydrophobic? Bad gardener paradox"}}
{"input": "Instantaneous velocity is defined as the limit of average velocity as the time interval \u2206t becomes infinitesimally small. Average velocity is defined as the change in position divided by the time interval during which the displacement occurs.\nWhen the time interval is infinitesimally small, there shouldn't be any considerable change in position. Thus the instantaneous velocity should be 0.", "output": "$$v_\\text{average}=\\frac{\\Delta s}{\\Delta t}$$\n$$v_\\text{instantaneous}=\\lim_{\\Delta t\\to0}\\frac{\\Delta s}{\\Delta t}$$\n\nIf the time interval gets infinitesimally small $\\Delta t\\to 0$, then you are dividing with something very, very tiny - so the number should become very big: $$\\frac{\\cdots}{\\Delta t}\\to \\infty \\quad\\text{ when } \\quad\\Delta t\\to0$$\nIf the change in position gets infinitesimally small $\\Delta s\\to 0$, then you are multiplying with something very, very tiny - so the number should become very small: $$\\frac{\\Delta s}{\\cdots}\\to 0 \\quad\\text{ when } \\quad\\Delta s\\to0$$\n\nNow, what if both happen at the same time, $\\frac{\\Delta s}{\\Delta t}$? What if, as in your case, the $\\Delta s$ is tied to $\\Delta t$ so that when one becomes very small, the other one does as well? Then how do you know, which of them that affects the number the most?  The denominator or the numerator? Does the number become very large or very tiny?\n$$\\frac{\\Delta s}{\\Delta t}\\to\\text{ ?}\\quad\\text{ when } \\quad\\Delta t\\to0$$\nYou seem to be assuming that the tiny change in position $\\Delta s$ is the one that dominates, so the result should go towards $0$ - but why wouldn't you assume the tiny time interval $\\Delta t$ to dominate instead, so the result goes towards infinity $\\infty$?\nThe answer is that anything can happen, depending on the values. It depends on the exact relationship between them. If the result goes towards an infinitely large number, we say that it is diverging. If it stabilises at some number, we say that it is converging. In work with physics you will often see it converging, since you will often deal with values that are interdependent and that \"balance off\" at some resulting number. In the case of velocity, the result does indeed converge towards some value, which we then choose to call the instantaneous velocity.\nThis is what calculus is all about: the mathematical discipline of going towards - converging towards - a limit and then figuring out what that limit is.", "meta": {"post_id": 500901, "input_score": 5, "output_score": 38, "post_title": "How does instantaneous velocity or acceleration have any other numerical value than 0?"}}
{"input": "When electrons transition from a higher energy state to a lower energy state (energy difference $E$), they produce massless photon with frequency $\\nu$ where \n$ \\Delta E= h \\nu$\n(h is Planck constant). We know energy-mas relation $ E=mc^2$. Why not create  some kind particle, in this case a particle that has mass m that we could calculate from the energy difference of the two states of the electron? Is there any kind critical energy difference $\\Delta E_c$ such that lower than $\\Delta E_c$ always  is creating photon and higher than $\\Delta E_c$ its  value create particle with mass?", "output": "There are a few reasons why the particle produced needs to be a photon. Aside from conserving energy, we also need to conserve momentum, charge and spin, for example. So you would need to ask what other particle, instead of a photon, could be emitted while satisfying all those conservation requirements. \nIf you just consider energy and spin conservation, the total amount of energy available in electron transitions in an atom is small, and not enough to make any of the other massive Bosons. To use your terminology, the maximum energy difference in electron transitions, \u0394, is way below the energy \u0394 you would need to create any of the other known massive particles that satisfy the other conservation requirements.", "meta": {"post_id": 505593, "input_score": 9, "output_score": 38, "post_title": "Why does transition from one electron shell to another shell always produce massless photon?"}}
{"input": "I am having an argument with my friend about how a nearly-full soda bottle should be stored in the fridge, with the goal of keeping the soda from going flat (i.e. keeping as much of the gas dissolved in the liquid as possible). Assume the bottle is a standard 2L bottle and its walls are impermeable so this is a purely static problem.\nHe thinks it doesn't make a difference whether the bottle is standing up vertically or lying flat horizontally. I think that standing up is better. My vague reasoning is that in either case, the plastic surface will feel the same amount of pressure $P$ from the contents; but when the bottle is lying horizontally, the shape of the air has a larger surface area and needs more stuff in it to attain the same pressure (since pressure if force over area).\nMy statement about the shape of the air is likely true by the isoperimetric inequality (or at least some heuristic which says that among shapes with the same volume, the ones \"closer\" to a sphere have less surface area), since the air-shape at the top of the bottle in the vertical case is closer to a sphere, than the shape when it is lying horizontally (in this case the air is like a long prism). However I'm not sure it's true that the pressure felt by the plastic is the same in both cases.\nWho is right and why?\nEDIT: thank you for your explanations.  I understand how to answer this in terms of constant volumes now, although it isn't very intuitive to me.  I wonder if there is an explanation involving the sum of the forces acting on the surface of the liquid being zero, for both the horizontal and vertical configurations.", "output": "In an unopened 2L polyethylene terephathalate (PETE) bottle of soda the primary loss of CO2 is by diffusion of the CO2 through the walls of the plastic bottle.  If you left a full bottle at room temperature, the half life of this process is about six months, meaning that a six-month old room temperature bottle of soda will be ~50% flat, even if you never open it.  After a year, it will be 75% flat.\nKeeping the bottle in the fridge naturally slows this process, so a chilled bottle of soda will retain its CO2 for much longer.  And, in real life, you're not just watching a full bottle day after day - you're drinking out of it.  The vast majority of the CO2 will be lost when you open the bottle.  There is likely some differential between the diffusion rates at the liquid/PETE interface vs the gas/PETE interface, but in either case this is a process that takes months to years.  \nEach time you open the bottle, however, you lose a significant amount of CO2.  The partition coefficient for CO2 in water is about 4, so the gas above the liquid will have about 1/5 of the CO2 concentration as compared to the liquid, which will have a concentration four times higher.  So your bottle becomes about 20% flatter each time you open the bottle (this is a gross approximation! ***), assuming you leave enough time for it to return to equilibrium after closing the bottle.  \nSo, if you want to worry about keeping your soda from going flat, forget about which way you store it in the fridge - it doesn't matter.  What you want to avoid is opening the bottle more frequently than necessary.  How flat is your soda?  How many times have you opened the bottle?  Let's assume you remove 300mL from the bottle each time you open it :\n  Openings   Fullness   Cumulative CO2 lost\n  -----------------------------------------\n  One          85%         4.2% \n  Two          70%         13.5% \n  Three        55%         28.2%\n  Four         40%         47.8%\n  Five         25%         70.2%\n  Six          10%         90.8%\n\n\n*** If we assume, at least, that a serving of soda is removed each time the bottle opens then there will be a ~15-85% fraction of gas/liquid at each opening.  When the bottle is more full there will be a lower loss of CO2 as the volume required to be repressurized to equilibrium will be lower - as the bottle empties the CO2 loss per 'opening' likewise increases. A 20% loss of CO2 happens only when the volumes of liquid and gas are equal (ie: half empty bottle).  A 75% full bottle would lose only 7.7% of its CO2, for example, but a 25% full bottle would lose a full 43% of its remaining CO2.", "meta": {"post_id": 517159, "input_score": 39, "output_score": 42, "post_title": "Should a soda bottle be stored horizontally or vertically?"}}
{"input": "I've read in an answer to this question, of which I think that it was a very good, but somewhat long one, (I include the context in which it was written):\n\nLet me expand this point. When this happens, not necessarily for a light wave but for whichever sort of wave, we say that the medium is non-dispersive. This is what your teacher meant with his \"principle of wave constancy\". It is a property of the medium and does not generally hold true, for elastic waves, for sound waves (a kind of elastic waves), etc. It may hold approximately - this happens for sound waves in air - or not hold at all: think of gravity waves we see at sea surface or on a lake, on a pond... \n\nI'm a bit confused about what it's meant by that. Normally one would think that gravity waves are propagating distortions of space, though they are actually called gravitational waves. I can imagine that the pull of gravity causes the water waves, or is this exactly what is meant by calling these water waves gravity waves? Or is it that the waves are called gravity waves instead of gravitational waves so these waves have to be interpreted in a different way? But again, in what way? I have a gut feeling about what is meant but can't find the words for it. \nI could have looked it up, I guess, but in this way also other users can benefit to improve their knowledge.\nWho knows?", "output": "Gravity waves are a term of art used by people who study wave behavior in liquids or gases in which gravity and a free surface or a density difference are present. Gravity waves in the surface of water are the large, fast-moving ones stirred up by strong winds, that surfers ride on and that can crash over and capsize large ships at sea. In this special context, they have nothing to do with waves in the fabric of spacetime. \n(The other type of surface waves in water are capillary waves, in which the restoring force that strives to smooth them out is not gravity but surface tension. These are tiny waves that move slowly, and are produced by things like wiggling insects floating on the surface of the water.)", "meta": {"post_id": 519867, "input_score": 18, "output_score": 62, "post_title": "What is meant by \"gravity waves we see at sea surface\"?"}}
{"input": "As far as I understand it, dark matter direct detection experiments are based on the idea that dark matter interacts with ordinary matter, it just has a very small cross-section. So far, there's been no confirmed detection.\nIs there any evidence at all that dark matter interacts non-gravitationally with ordinary matter at all? That is, is it possible that dark matter exists, but can literally never be detected because every non-gravity interaction cross-section is exactly zero? \nIf there is evidence, what is it? If there is no evidence, why does this hypothesis seem never to be taken seriously?\nRelated: Is there any evidence for dark matter besides gravitational effects? and Why do physicists assume that dark matter is weakly interacting? However, neither question deals explicitly with the hypothesis that dark matter doesn't interact non-gravitationally.", "output": "There are some standing anomalies that could be explained by non-gravitational dark matter interactions. For example, Fermi-LAT is an indirect detection experiment (i.e. an experiment that looks for the debris of a dark matter decay that occurred far from Earth), and it currently reports an excess of gamma rays. There are occasional claims that nontrivial dark matter interactions make galaxy simulations work better. Excess cooling of astrophysical objects, such as white dwarfs, also \"hints\" at dark matter which could carry extra energy away. Finally, there are even some direct detection experiments like DAMA which claims to see dark matter interactions. \nHowever, these anomalies generally don't point in any coherent direction, and often fade away. Most of the time, all they reflect is an incomplete understanding of astrophysics. So you're completely right: the default hypothesis, if you're an astrophysicist, is that dark matter has no non-gravitational interactions.\nBut particle physicists are investigating a different problem: they're trying to explain what dark matter is made of and how it got here. This always takes place within specific models. No direct detection experiment just looks for \"dark matter\" per se; instead they look for specific dark matter candidates. \nThe longest-running direct detection experiments look for particles whose mass is about a hundred times the proton's, and whose interactions are primarily electroweak. This specific guess is because such dark matter candidates exist in many supersymmetric extensions of the Standard Model, which were favored for other reasons. In such models you automatically get dark matter interactions; you can't get rid of them unless you purposefully tune the interaction to zero. Moreover, when you run the numbers you find that such models automatically produce the right amount of dark matter in the early universe, a result known as the WIMP miracle. (Production is another reason you want interactions; you could just postulate you get the right amount by tweaking the initial conditions, but it would be nicer to explain why.)\nThese days, a wider range of dark matter candidates are getting attention, leading to a great variety of cheap direct detection experiments, which target each candidate's particular interactions. Everybody working in this field (which comprises less than 1% of physics at large) is perfectly aware that all these candidates could be nonexistent, and that the whole enterprise might have been completely doomed from the start. But that is true for any scientific endeavour; that risk is what makes it exciting in the first place!", "meta": {"post_id": 522778, "input_score": 38, "output_score": 57, "post_title": "Is there any evidence that dark matter interacts with ordinary matter non-gravitationally?"}}
{"input": "As we all know, force applied to a spring is directly proportional to the extension of spring as shown below:\n\nHowever, my experimental results for a simple spring from a school laboratory don't match this behaviour:\n\nWhy is this happening? I don't think systematic error is the reason that is causing the experimental graph to move away from the origin.", "output": "The coils of the spring are touching one another and the spring is initially under self-compression so it takes a finite force to move all the coils away from one another and for the spring to behave as you expected.\nThat initial part of the source vs stretch curve is real (you had obtained data whilst undertaking an experiment)  and hence should not be ignored.", "meta": {"post_id": 525645, "input_score": 28, "output_score": 43, "post_title": "Why do my experimental data for Hooke\u2019s law not match the expected data?"}}
{"input": "In his book Gravitation and Cosmology, Steven Weinberg says that the Cosmic Microwave Background (CMB) makes it \"difficult to doubt that the universe has evolved from a hotter, denser early stage\".\nIn my understanding, CMB is just a peculiar isotropic radiation representing a black body at ~ 2.7K.\nHow and why does the CMB point to the early Universe being hotter and denser?", "output": "Beyond the fact that the cosmic microwave background (CMB) is a direct prediction of the big bang model, there is the question of how you would produce it in any other way. It is remarkably close to being isotropic and remarkably close to being a blackbody spectrum - i.e. it is almost a perfect blackbody radiation field.\nA blackbody radiation field is emitted by material in complete thermodynamic equilibrium (CTE). An example would be the interior of a star. A requirement for (CTE) is that the matter and radiation field are characterised by the same temperature and that the material is \"optically thick\" - meaning that it is opaque to that radiation at basically all wavelengths.\nGiven that the universe is mainly made up of hydrogen, helium and (presently) traces of heavier elements, we can ask how is it possible to produce a perfect blackbody radiation field? Cold hydrogen and helium are transparent to microwaves. To make them opaque they need to be ionised, so that the free electrons can be a source of opacity at all wavelengths via Thomson scattering. But this requires much higher temperatures - about 3000 K.\nHow do we uniformly raise the temperature of a gas (adiabatically)? By squeezing it. A smaller, denser universe would be hot enough to have ionised hydrogen and would be opaque to the radiation within it. As it expanded and cooled, the electrons combined with protons to form atoms and the universe becomes transparent, but filled with a perfect blackbody radiation spectrum. The light, originally at a temperature of 3000 K and mainly in the visible and infrared, has had its wavelengths stretched by a factor of 1100 by expansion of the universe, meaning we now see it mainly as microwaves.\nAdditional evidence for this model is that the radiation field is not absolutely isotropic. These small ripples encode information such as the expansion rate of the universe at the time of (re)combination and the density of matter. When inferred from measurements, these parameters agree very closely with other determinations that are independent of the CMB, such as  the Hubble redshift distance relationship and estimates of the primordial abundance of Deuterium and Helium.\nThere is now direct evidence that the CMB was hotter in the past and by exactly the amount predicted by an adiabatic expansion. The source of this evidence is measurements of the frequency-independence of the Sunyaev-Zel'dovich effect towards galaxy clusters (e.g. Luzzi et al. 2009); or more precisely by probing the excitation conditions in gas clouds at high redshift using even more distant quasars as probes (e.g. Srianand et al. 2008. New results have been published by Li et al. (2021). They describe measurements of the Sunyaev-Zel'dovich effect to hundreds of galaxy clusters in the redshift range $0.07<z<1.4$ and show that, the temperature of the CMB goes as $T_0(1 + z)^{0.983^{+0.032}_{-0.029}}$, consistent with an adiabatic expansion to 3%.", "meta": {"post_id": 530411, "input_score": 29, "output_score": 61, "post_title": "Why is the Cosmic Microwave Background evidence of a hotter, denser early universe?"}}
{"input": "A laser is built on quantum mechanics to create a beam of photons with the same frequency and phase. Someone told me a free electron laser is a based on classical electrodynamics. Is that true?", "output": "is classical laser possible?\n\nIMO, the question doesn't make sense. \"Classical\" and \"quantum\" are not different options for how a thing can work. They are different options for us to try to understand how it works. LASERs aren't \"built on\" quantum mechanics, but rather, quantum mechanics is an appropriate tool for understanding stimulated emission. A free electron laser isn't built on classical electrodynamics, but classical electrodynamics offers a sufficient explanation for why it emits light.", "meta": {"post_id": 533051, "input_score": 16, "output_score": 50, "post_title": "Is a classical laser possible?"}}
{"input": "I understand that a binary orbiting around one another will circularize due to the emission of GWs due to Peters equations and that highly eccentric binaries evolve faster. \nBut GW emission also removes energy and angular momentum (wouldn\u2019t the latter increase the eccentricity from the relation between the eccentricity and the angular momentum?).\nWhat is the physical picture behind this?", "output": "The other answers have given good \u201crigorous mathematical\u201d arguments for why this happens, but I'd like to add a simpler hand-waving one.\nGravitational waves are emitted when massive bodies accelerate. The acceleration is strongest at periapsis (i.e. when the bodies are closest). The GW emission removes energy. As a result, the orbiting body has less kinetic energy left to rise out of the periapsis, i.e. the next apoapsis will be lower.\nBy comparison, at the apoapsis there's not so much acceleration, thus the height of the periapsis doesn't change very much. But of course the next time you are at that periapsis, more energy is lost. Repeat, until eventually the apoapsis isn't really higher than the periapsis anymore: you have a circular orbit.", "meta": {"post_id": 534036, "input_score": 26, "output_score": 39, "post_title": "Why do gravitational waves circularize a binary?"}}
{"input": "When a merchant vessel drops an anchor, the anchor chain is initially stretched. The captain is waiting until the chain unstretches and after that he is assured that the anchor keeps the vessel in position.\nThe opposite seems reasonable to me: that only a stretched chain can keep anything in position. Does anybody know something more on this?", "output": "There are many different kind of anchors with different working principles (see wiki). Most of them, however, rely on the chain lying on the ground for the anchor to have its effect.\nTo understand this, let us look at a stockless anchor and how it holds onto the ground (picture from the wikipedia article):\n\nFrom the picture it is clear that the anchor has its main strength when the chain pulls parallel to the ground. In fact, the way the anchor is liftet is by pulling it upwards (pciture also from the wikipedia article):\n\nSo what about the chain stretching/slackness? Let's look at the following picture (from this quora question):\n\nSo essentially what happens is that most of the chain lies on the ground. The rest is fairly loose, which gives the ship some swaying room, but when pulled by wind in one direction it will stretch sufficiently to balance the wind force on the boat. The weight of the anchor chain therefore also plays a crucial role, since the chain should not be stretched fully by the wind force.\nIn summary, if we stretch the chain too much, the anchor cannot operate. Instead, a large part of the chain has to lie on the ground, such that the force on the anchor is rougly parallel to the ground. The weight of the anchor chain ensures that forces on the boat such as waves and wind do not fully stretch the anchor chain.\n\nAaron Stevens pointed out that the question also asks about the equilibration phase after anchoring, which I missed initially in my answer. Specifically, why one waits until the anchor relaxes again.\nLet us look at what happens after throwing the anchor.\n\nAnchor hits ground.\nShip still moves. Anchor is dragged along.\nThe anchor gets a grip. Remaining movement of the ship stretches the chain, drags the anchor further.\nEventually, the anchor gets stuck in its final position, with the chain most likely stretched due to the ship movement.\nThe ship is stopped and dragged into an equilibrium position by the stretched chains weight.", "meta": {"post_id": 536560, "input_score": 30, "output_score": 47, "post_title": "Why must the anchor of a merchant ship be slack to keep her in position?"}}
{"input": "I know there are solutions to Einstein's field equations that give a wormhole geometry. But they are time independent. They are static. Is there a process where empty flat spacetime can evolve into a wormhole by an appropriate flow of matter and energy and negative energy? \nIf so, it would change the topology of spacetime. Does General Relativity permit this? How would a hole in spacetime form? What determines where the other mouth of the wormhole would be located?", "output": "The current state of knowledge is basically that we don't know. \nThe topology change is contentious - it is unclear if it is permitted, but there are also disagreements about why and how. The standard approach is to shout \"quantum gravity!\" and escape in the confusion.\nOne classical argument for why making a wormhole would be problematic is the topology censorship theorem. It states:\n\nEvery causal curve extending from past null infinity to future null infinity\n  can be continuously deformed to a  curve near \n  infinity.\nRoughly speaking, this says that an observer, whose trip begins and ends near\n  infinity,  and who thus remains outside all black holes, is unable to probe \n  any nontrivial topological structures.\n\nNow, there are issues with the theorem (since it assumes the null energy condition that wormholes and quantum fields often break, and some topological assumptions). But it seems to be a good reason to suspect wormhole formation or existence is not allowed unless it gets hidden by a topologically spherical event horizon. Except that general relativity on its own seems to be too much of a local theory to be really good defence against non-trivial topology.\nThere are quantum gravity papers arguing that a cosmic string breaking by tunnelling can produce traversable wormholes and gleefully break the (classical) topological censorship. Here the wormholes show up at the ends of the string, initially next to each other.", "meta": {"post_id": 537994, "input_score": 36, "output_score": 44, "post_title": "Can a wormhole be created if it has not always existed?"}}
{"input": "Why do you need 13.8 MJ/kg (9% of energy content) to compress hydrogen to 200 bar, but only 1.4 MJ/kg (2.5% of energy content) for methane?\nI looked into compressibility factors and the compressibility factor for methane is way lower than for hydrogen (up until high pressures). Does this determine how much work is required?", "output": "The essential reason is that a kilogram of hydrogen contains 8 times as many molecules as a kilogram of methane (because the mass of a hydrogen molecule is about 1/8  of the mass of a methane molecule).\nIf we assume, for the sake of argument, that the compression is isothermal (constant temperature, $T$) the work needed to compress a sample of $N$ molecules of an ideal gas from pressure $p_1$ to pressure $p_2$ is\n$$\\text{Work}=Nk_BT \\ln \\left(\\frac{p_2}{p_1}\\right)\\ \\ \\ \\ [k_B= \\text{Boltzmann's constant}]$$\nSo if the gases were ideal, 8 times more work would be needed per kilogram for the hydrogen, but at such high pressures the gases are far from ideal. Intermolecular forces and the finite volumes occupied by the molecules are significant and different for different gases. That would account for why the ratio of work needed is not exactly 8:1", "meta": {"post_id": 548857, "input_score": 25, "output_score": 36, "post_title": "Why is it so much more energy intensive to compress hydrogen than methane?"}}
{"input": "Suppose there are $N$ radioactive atoms and the half life of decay is $t$. Then after one half life the number of remaining atoms will be $\\frac{N}{2}$. And so after each half life the number will be halved.\nWhich means,\n$1/2$ of the atoms will have a life of $t$\nHalf of the the remaining half or $1/4$ of the atoms will have a life of $2t$ and so on.\nThen if the mean time for decay is $\\tau$, then it should be:\n$\\tau = \\frac{(\\frac{N}{2}t+\\frac{N}{4}2t+\\frac{N}{8}3t+...)}{N}$\nor $\\tau = t(\\frac{1}{2}+\\frac{2}{4}+\\frac{3}{8}+...)$\nBut this infinite series doesn't equal to $\\frac{1}{ln2}$.\nAnd we know that, $\\tau =\\frac{t}{ln2}$\nSo obviously my calculation is wrong. Why is this way of calculating the mean time for decay wrong?", "output": "Your mistake is here:\n\nWhich means, 1/2 of the atoms will have a life of t\nHalf of the the remaining half or 1/4\nof the atoms will have a life of 2t and so on.\n\nThe corrected statement is:\n\nWhich means, 1/2 of the atoms will have a life $\\le t$\nHalf of the the remaining half or 1/4\nof the atoms will have a life between $t$ and $2t$ and so on.", "meta": {"post_id": 551336, "input_score": 16, "output_score": 46, "post_title": "Why is this way of calculating mean life of radioactive atoms incorrect?"}}
{"input": "This is a thought experiment where I have made a \"C\" shaped hole inside diamond. The refractive index $(\\mu)$ of diamond is 2.45. Say we shine a laser from top of the \"C\" as shown.\nMy calculations show that light reaching A can reach B in the least possible time if gone through the \"C\". but I'm pretty sure the perpendicular laser beam travels undeflected and straight down. Though I don't have experimental evidence, I see something wrong either with my intuition or with the theory.\nIt would be great if someone could clarify.\n*       'a' in the diagram is the thickness of the cutout and all comparable distances can be taken 'a'.", "output": "As others have said, Fermat's principle says that the path which light follows is stationary rather than a minimum of optical path length (though in fact it typically is a bona fide local minimum).  The more important point, however, is that this is a necessary but not sufficient condition for a given path to be that followed by light.  This is a mathy way of saying that there might be several paths which are local extrema of path length, but light need not follow all of them.\nThis is a typical issue with variational arguments.  The same thing can happen with a massive particle which has the option of following either of two paths to an endpoint.  Feynman considered such scenarios in developing his path integral approach to quantum mechanics, but even for classical mechanics it is an interesting case study.  If you solve the Euler-Lagrange equation for such a system, you'll find that there are two paths which make the action stationary, i.e. two paths which the particle can follow to get from its starting point to its ending point.  But we know that a classical particle will only follow one path, so which will it take?\n\nMathematically, the issue here is that variational problems are typically posed as boundary value problems\u2060\u2014we specify where the particle needs to start and where it needs to end up.  Unlike initial value problems, boundary value problems need not have unique solutions.  But in real life, we don't actually control where the particle ends up.  What we really control is the particle's initial position and velocity\u2060\u2014i.e. we set up an initial value problem, a differential equation for which there is a unique mathematical solution.  After we send off the particle and see where it ends up, we can then use its ending location and the Euler-Lagrange equation to see which path it took to arrive at the endpoint, but there can be multiple solutions.\nThe same thing happens in optical systems.  When you shoot a laser, you specify the initial conditions of the laser beam by the position of the laser and the direction it points.  This sets up an initial value problem which has a unique solution.  After you find out where the beam goes, you can then use the starting and ending points of the beam together with Fermat's principle to figure out the path it took to get there.  But you may find that there are multiple solutions to Fermat's principle, and you need to use either common sense or some discrete data about the orientation of the laser to figure out which one is the right one.\n\nSome final remarks about the particular case you are considering.  The actual shortest path in the system drawn in the OP would be that going straight from point A to the inside corner of the \"C\", then down the boundary between air and diamond to the other corner, then straight to point B.  A curious feature of this path is that infinitesimal perturbations to the segment of the path along the boundary of air and diamond would result in discontinuous changes in the path length, because if you push the path from the air side to the diamond side the length gets 2.45 times longer.  This means that usual variational calculus arguments (like those used in deriving the Euler-Lagrange equation) don't work, as they assume smooth variation of the action (i.e. optical path length) with small perturbations to the path.  So you have to be more careful in this case.  In fact, physically no light will typically ever follow this path (at least at the level of geometric optics), because there is nothing to \"bend the light around the corner\".\nAnother interesting feature of this system is that there might (depending on exact positions of A and B) be another locally extremal path from A to B, namely that which enters the diamond at an angle, undergoes total internal reflection at the air-diamond interface, and then bounces back to B.  So if you have a light bulb (which sends light in all directions) at point A and someone sitting at point B, the person at B would see two lights, one from the line straight to A and another coming at an angle from the left.  This is another illustration of the caveats on Fermat's principle\u2060\u2014if the light does not have a well defined initial direction, it may follow multiple stationary paths!", "meta": {"post_id": 567920, "input_score": 44, "output_score": 41, "post_title": "How does Fermat's principle make light choose a straight path over a short path?"}}
{"input": "Let's assume there is an astronaut with a very long rope trailing behind him. As he approaches a very large black hole, he can look back and see the rope behind him trailing off into the distance.\nWhat would he see after he crosses the event horizon and looks back along the rope while a portion of the rope is still outside the event horizon?", "output": "Dale's answer is correct, but I want to further emphasize that nothing special happens in the vicinity of an event horizon. It's just like any other region of spacetime.\nHere's an analogy. Suppose you're in a building that's rigged to explode at a certain time. If you're in the building and too far from an exit at a late enough time, you won't be able to escape before the explosion even at your top speed. If it's a single-story, square building and you can exit at any point on the edge, then the region from which you won't be able to escape at a given time is square. It starts in the center of the building and expands outward at your maximum running speed. The boundary of that region is the \"escape horizon\".\nIf you don't escape and die in the explosion, then the escape horizon will necessarily sweep over you at some point before your death. When it passes you, nothing special happens. You don't notice it passing. You can't detect it in any way. It isn't really there. It's just an abstract concept that we defined based on our foreknowledge of the future.\nThe event horizon of a black hole is defined in the same way, with a singularity in place of the explosion and the speed of light in place of your running speed. If your worldline ends at the singularity, then the event horizon will sweep over you, at the speed of light, at some earlier time. But you won't notice. You can't detect it in any way. It isn't really there.\nPeople get confused about this because there's phenomenology associated with black hole horizons: the closer you get to them, the faster you have to accelerate to avoid falling through, the slower your clock runs, the hotter you get from the Hawking radiation, and so on. They also behave like electrical conductors for some purposes, though it's not mentioned as often.\nThe thing is, if you mispredict where the singularity is going to be, and try to escape from what you think is the horizon but actually isn't, all of those same things happen. Any event horizon defined by any future spacetime points, whether singular or not, has these properties, even in special relativity. (See Rindler coordinates and Unruh effect for more about the special-relativistic case.)\nSo the answer to any question about what you'd see while falling through an event horizon is always the same as if the event horizon was somewhere else.", "meta": {"post_id": 576396, "input_score": 23, "output_score": 51, "post_title": "What happens to an astronaut (with a long rope trailing behind him), when he crosses the event horizon of a black hole?"}}
{"input": "If a uranium atomic bomb directly hit a stockpile of weapons grade uranium, would the chain reaction also detonate the stockpile?\nwhat about a stockpile of nuclear reactor fuel rods?\nwhat about a stockpile of various nuclear weapons?\nwhat about a plutonium bomb or a hydrogen bomb?\nwhat about all possible permutations of these?", "output": "To supplement niels's answer, the hardest part about a nuclear bomb is to prevent it from blowing itself apart before it has completed fission (or fusion). If a nuclear bomb does detonate, any nearby potential fission/fusion fuel will simply be blown away and not fizz. To understand why we need to understand how nuclear bombs work.\n\nAn explosion is a rapid increase in volume and energy causing high pressure, usually due to gas rapidly expanding. A bomb is basically a device which uses extreme heat to vaporize material turning it into a rapidly expanding gas. If this expansion causes a supersonic shock wave we call it a detonation. High explosives are explosives which detonate.\nNormal explosives happen via combustion, the technical term for burning. Once sufficient energy is applied the chemicals in the explosive combine with oxygen. This reaction is exothermic meaning it gives off energy. That energy then starts the nearby material reacting with oxygen. Once one bit starts burning it can provide energy to the next bit and the next bit and so on to make a chain reaction. This is why a burning fuse works; so long as there is combustible material, oxygen, and energy to start the reaction, any amount of material will burn.\nNuclear fission works very differently. When fissile material is bombarded with neutrons, some of them will smack into a nucleus and break it apart. This reaction is very exothermic, and it also produces more neutrons which then fly off and break apart more nuclei producing more energy. However, the density of neutrons required to sustain a reaction is very high, so the fissile material must be kept packed together. The point at which the reaction is producing enough energy and neutrons to sustain itself is the critical mass.\nNuclear reactors must sit between too dense and not dense enough while using the waste heat to produce electricity. Various safety mechanisms manage this. Not dense enough and the reaction cannot sustain itself and it fizzles out. Too dense and the reaction runs away, it goes supercritical, and you get a nuclear meltdown... or a bomb.\nA nuclear fission bomb is, basically, a deliberate nuclear meltdown. It's a way to very precisely smash hunks of sub-critical fissile material together to make a critical mass; a prompt criticality. This must happen very precisely because as soon as some fission starts energy will be produced which will vaporize material raising pressure rapidly. This can shove the fissile pieces apart shutting down the reaction before much fission has happened.\nThe most basic fission bomb is a gun-type which literally shoots a sub-critical pellet of uranium into a sub-critical cylinder of uranium making a critical mass. But it's also very inefficient since as soon as fission starts the uranium blows itself apart stopping the fission. Most of the uranium is never used. Little Boy was a gun-type bomb.\nA more efficient, and much more complex, fission bomb is the implosion type. This uses very, very, very precise conventional explosives arranged around many pieces of sub-critical material to simultaneously crush them into a sphere. The force and precision of the conventional explosion holds the fissile material together in a super-critical state for as long as possible to fizz as much material as possible making them very efficient. Fat Man was an implosion-type bomb.\n\nFusion bombs work on basically the same principle: you need to squeeze the material together very quickly and very precisely before it blows itself apart. They do this with a fission bomb. A fusion (\"hydrogen\") bomb is basically a conventional bomb that sets off a fission bomb which sets off a fusion bomb.\n\nNow we can see why a nuclear bomb will not set off a nearby stockpile of nuclear material or bombs. An insignificant fraction will fizz because of the particle bombardment, but the blast will simply blow the extra material away before it can achieve critical mass.\nIf you were to take two pieces of sub-critical fissile and smack them together with your hands to make a critical mass, it would be very bad for you and everyone nearby, but it would not cause a nuclear blast. As Wikipedia dryly puts it...\n\nThe prompt-critical excursion is characterized by a power history with an initial prompt-critical spike as previously noted, which either self-terminates or continues with a tail region that decreases over an extended period of time.\n\nIn layman's terms: the two halves would blow themselves apart.\nThis is known as a \"criticality accident\" or \"critical power excursion\". This happened at Los Alamos twice when experimenting with the \"Demon Core\" in terrifyingly unsafe manners; though in both cases the scientists shut down the reactions before they blew themselves apart.\n\nAnd this is why nuclear weapons are considered \"safe\". Unlike conventional explosives which can be detonated by a simple fire, a nuclear bomb must work perfectly to go off. This is why they are often referred to as a \"device\". Any damage to the bomb makes it safer. Safety mechanisms effectively remove critical parts of the device; like how one can ensure a car will not start by pulling out the carburetor or the fuel pump. Arming a nuclear bomb basically finishes putting the device together.\nThe worst that is likely to happen to an unarmed nuclear device is the conventional explosives will detonate scattering fissile material into the environment. While that's indeed very bad it's much better than a nuclear explosion. We're very sure of this because it has happened a very distressing number of times.", "meta": {"post_id": 578282, "input_score": 21, "output_score": 52, "post_title": "Would an atomic bomb detonate a uranium stockpile?"}}
{"input": "Or is there a bias toward a specific angle in regards to the direction of the current?", "output": "These types of questions are tempting to ask in a yes-no way, and you currently have an answer that says \"yes\" and and answer that says \"no.\"\nThe physicist's approach is to ask how big the biggest effect might be; let's try that.\nThe current answer which proposes an aligning effect suggests an interaction between the electric dipole moment of the water molecule, $p \\approx 6\\times10^{-30}\\,\\mathrm{C\\,m} \\approx 0.4\\,e\\,\u00c5$, and the Earths' magnetic field, via the Lorentz force, $\\vec F = q \\vec v \\times \\vec B$.  The energy associated with this interaction is what you get if the force interacts over the length scale of the molecule, which has a bond length of about $1\\,\u00c5$.  The typical thermal velocities obey $kT \\approx mv^2$, or\n\\begin{align}\nv^2 \\sim \\frac{kT}{m} = \\frac{25\\rm\\,meV}{18\\,\\mathrm{GeV}/c^2}\n&\\approx \\frac 43\\times10^{-12}\\ c^2\n\\\\\nv &\\sim 10^{-6}\\ c \\approx 300 \\rm\\,m/s\n\\end{align}\nSo a typical Lorentz-force polarization energy would be\n\\begin{align}\nU &\\approx | p v B |\n%\\\\ &= 6\\times10^{-30} \\mathrm{C\\,m}\\cdot 3\\times10^2\\mathrm{m/s} \\cdot \\frac12\\times10^{-4}\\mathrm T\n%\\\\ &\\approx 9\\times10^{-32}\\,\\mathrm J\n%\\times\\frac{1\\rm\\,eV}{1.6\\times10^{-19}\\rm\\,J}\n\\\\ &\\approx \\frac 58\\times10^{-13} \\rm\\,eV\n\\approx 60 \\rm\\,feV\n\\end{align}\nThose are femto-eV.\nBut the water molecule's rotational degree of freedom also has milli-eV energy sloshing around.  The ratio of the aligned and un-aligned populations will go like the Boltzmann factor for this energy difference,\n$$\ne^{\\Delta E/kT} = e^{\\text{femto/milli}} = 1 + 10^{-12},\n$$\nthat is, a part-per-trillion difference.  I've been involved in several experiments looking for part-per-billion asymmetries; each one took ten years.  A few parts per trillion is a small effect, even if you go back through my arithmetic and futz around with some missing factors of two.\nWhat's more, the preferred direction $\\vec v \\times \\vec B$ is only well-defined if most of the water molecules are moving in generally the same direction.  That only happens if the rate of flow is much faster than the typical thermal velocity --- which doesn't really happen unless the flow approaches the speed of sound in water.\nIf you tried to enhance the effect --- by, say, shooting a hypersonic jet of water through the bore of ten-tesla magnet, to bring the asymmetry up to the part-per-million range --- you'd probably just learn something sneaky about hydrogen bonding.", "meta": {"post_id": 578819, "input_score": 19, "output_score": 45, "post_title": "Are water molecules orientation absolutely independent of the flow direction?"}}
{"input": "When reading about Astra satellites on Wikipedia (https://en.wikipedia.org/wiki/Astra_1KR), I saw that the period of the Astra 1KR satellite, positioned at 19.2\u00b0 E, is 1,436.1 minutes (source: NORAD data).\nThat is 3.9 minutes short of a day (1440 minutes), how is that possible with the satellite still being geostationary?", "output": "A day, i.e. 24 hours, isn't how long the Earth takes to rotate. It's the time between the Sun being in the same place in the sky, but that isn't the same as the time it take the Earth to rotate 360\u00b0 because the Earth moves around the Sun at the same time as rotating on its axis. Strictly speaking what we call a day is a solar day.\nThe time the Earth takes to rotate by 360\u00b0 is called a sidereal day, and it's 23 hours, 56 minutes and 4.1 seconds i.e. about 3.9 minutes less than a solar day. The period of a geostationary satellite is a sidereal day not a solar day, and that's why it too is 3.9 minutes shorter than a solar day.\nIf you are interested in reading more about this you'll find lots of articles about sidereal time on the web. I found a good introductory article on the Astronomy Essentials web site.", "meta": {"post_id": 580267, "input_score": 41, "output_score": 110, "post_title": "Why is the period of a geostationary satellite not exactly 1440 minutes?"}}
{"input": "I know that there are Noether theorems in classical mechanics, electrodynamics, quantum mechanics and even quantum field theory and since this are theories with different underlying formalisms, if was wondering it is possible to find a repeating mathematical pattern. I know that a common \"intuitive\" explanation is that each symmetry has a corresponding constant quantity - but can we express this in a mathematical way?\nIn other words: Can all Noether theorems be regarded as special cases of one recipe (in mathematical terms) that works for all formalisms?", "output": "The core of the Noether theorem in all contexts where it arises is surprisingly elementary!\nFrom a very general point of view, one considers the following structure.\n(i) A set of \"states\" $x\\in \\Omega$,\n(ii) A one-parameter group of transformations of the states   $\\phi_u : \\Omega\\to \\Omega$, where $u\\in \\mathbb{R}$.\nThese transformations are requested to satisfy by definition $$\\phi_t\\circ \\phi_u = \\phi_{t+u}\\:, \\quad \\phi_{-u}= (\\phi_u)^{-1}\\:, \\quad \\phi_0 = \\text{id}\\tag{0}\\:.$$\n(iii) A preferred special one-parameter group of transformations\n$$E_t : \\Omega \\to \\Omega $$\nrepresenting the time evolution (the dynamics) of the physical system whose states are in $\\Omega$.\nThe general physical interpretation is clear. $\\phi_u$ represents a continuous transformation of the states $x\\in \\Omega$ which is additive in the parameter $u$ and is always reversible.  Think of the group of rotations of an angle $u$ around a given axis or the set of translations of a length along a given direction.\nA continuous dynamical symmetry is a one-parameter group of transformations that commutes with the time evolution,\n$$E_t \\circ \\phi_u = \\phi_u \\circ E_t \\quad \\forall u,t \\in \\mathbb{R}\\:.\\tag{1}$$\nThe meaning of $(1)$ is that if I consider the evolution of a state\n$$x_t = E_t(x)$$\nand I perform a symmetry transformation at each time\n$$ \\phi_u(x_t)\\:,$$\nthen\nthe resulting time-parametrized curve of states is still a possible evolution with respect the said dynamics\n$$\\phi_u(x_t) = E_t(\\phi_u(x))\\:.$$\nThese features are shared by the theory of dynamical systems,  Lagrangian mechanics, Hamiltonian mechanics, Quantum Mechanics, general Quantum Theory  including QFT.\nThe difference is the mathematical nature of the space $\\Omega$ and some  continuity/differentiability properties of the map $\\mathbb{R} \\ni u \\mapsto \\phi_u$, whose specific nature depends on the context.\nThe crucial observation is that, once assumed these quite natural properties,\nthe one-parameter group structure $(0)$ provides a precise meaning of\n$$X := \\frac{d}{du}|_{u=0} \\phi_u$$\nand, exactly as for the standard exponential maps which satisfies $(0)$, one has (for us it is just a pictorical notation)\n$$\\phi_u = e^{uX}\\:.$$\n$X$ is the generator of the continuous symmetry.\n\nIn quantum theory, $X$ (more precisely $iX$) is a self adjoint operator and hence a quantum observable,\n\nin dynamical system theory and Lagrangian mechanics $X$ is a vector field,\n\nin Hamiltonian mechanics $X$ --written as $X_f$ -- is an Hamiltonian vector field associated to some function $f$.\n\n\n$X$ (or $iX$, or $f$) has another meaning, the one of  observable.\nHowever, it is worth stressing that this interpretation is delicate and strictly depends on the used formalism and on  the mathematical nature of the space $\\Omega$ (for instance, in real quantum mechanics the said interpretation of $X$ in terms of an associated quantum observable is not possible in general).\nNow notice that, for a fixed $t\\in \\mathbb{R}$,\n$$u \\mapsto E_t\\circ  e^{uX} \\circ E^{-1}_t =: \\phi^{(t)}_u$$\nstill satisfies $(0)$ as it immediately follows per direct inspection. Therefore it can be written as\n$$E_t\\circ e^{uX} \\circ E^{-1}_t  = e^{uX_t}\\tag{3}$$\nfor some time-depending generator $X_t$.\nWe therefore have a time-parametrized curve of generators\n$$\\mathbb{R} \\ni t \\mapsto X_t\\:.$$\nThe physical meaning of $X_t$ is the observable (associated to) $X$ temporally translated to the time $t$.\nThat interpretation can be grasped from the equivalent form of $(3)$\n$$E_t \\circ e^{uX}  = e^{uX_t} \\circ E_t  \\tag{4}.$$\nThe similar curve\n$$\\mathbb{R} \\ni t \\mapsto X_{-t}$$\nhas the meaning of the time evolution of the observable (associated to) $X$.\nOne can check that this is in fact the meaning of that curve in the various areas of mathematical physics I introduced above. In quantum mechanics $X_t$ is nothing but the Heisenberg evolution of $X$.\nNoether Theorem.\n$\\{e^{uX}\\}_{u\\in \\mathbb R}$ is a dynamical symmetry for $\\{E_t\\}_{t\\in \\mathbb R}$ if and only if $X=X_t$ for all $t\\in \\mathbb R$.\nPROOF.\nThe symmetry condition $(1)$ for $\\phi_t = e^{tX}$ can be equivalently rewritten as\n$E_t \\circ e^{uX}  \\circ E^{-1}_t = e^{uX}$. That is, according to $(3)$:\n$e^{uX_t} = e^{uX}$. Taking the $u$-derivative at $u=0$ we have $X_t=X$ for all $t\\in \\mathbb R$. Proceeding backwardly $X_t=X$ for all $t\\in \\mathbb R$ implies\n$(1)$ for $\\phi_t = e^{tX}$.   QED\nSince $E_t$ commutes with itself, we have an immediate corollary.\nCorollary. The generator $H$ of the dynamical evolution\n$$E_t = e^{tH}$$\nis a constant of motion.\nThat is mathematics. Existence of specific groups of symmetries is matter of physics.\nIt is usually assumed that the dynamics of an isolated physical system is invariant under a Lie group of transformations.\nIn classical mechanics (in its various formulations) that group is Galileo's one. In special relativity that group is Poincar\u00e9's one. The same happens in the corresponding quantum formulations.\nEvery Lie group of dimension $n$ admits $n$ one-parameter subgroups. Associated to each of them there is a corresponding conserved quantity when these subgroups act on a physical system according to the above discussion. Time evolution is one of these subgroups.\nThe two afore-mentioned groups have dimension $10$ and thus there are $10$ (scalar) conserved quantities. Actually $3$ quantities (associated to Galilean boosts and Lorentzian boosts) have a more complex nature and require a bit more sophisticated approach which I will not discuss here; the remaining ones are well known: energy (time evolution), three components of the total momentum (translations along the three axes), three components of the angular momentum (rotations around the three axes).", "meta": {"post_id": 597734, "input_score": 42, "output_score": 61, "post_title": "Do all Noether theorems have a common mathematical structure?"}}
{"input": "Today my wife gave me a little box of solar-powered Christmas tree lights.  She bought them last year 2019 but had forgotten she had them so it was only today (a year later) that I took them out of the box.  These lights consist of a small solar panel wired to a rechargeable solar battery and an alkaline battery plus wiring which connects the circuitry to a string of 100 little LED lights.  There are no moving parts that I can see.\nI took everything out of the cardboard box and placed the components onto a white melamine table in our living room and screwed the connector for the wire from the LED lights string into the back of the solar panel box.  Then I turned the solar panel itself up to the light within the room - which wasn't particularly bright as I was indoors.  None of the LEDs glowed at all, so I assumed that I would need to place the solar panel outside in bright sunlight for some time to gain enough 'light energy' to power the LEDs.  But then .. I accidentally knocked the solar panel box face down onto the white melamine table and the LEDs lit up.  Every time I picked the box off the table and turned it to face the room, the LEDs went off, and every time I turned the solar panel to be back face down on the melamine table - the LEDs lit up again.  I have left the solar panel box lying face down and the LEDs have now been lit for 3 hours and are fairly bright.\nSo my question is this: the solar panel is face down on the table so no room light or natural light or solar light can strike its face, and I think that even if I was to black tape around the box (i.e. stick it to the table) that wouldn't make any difference ... so from where is the solar panel deriving the energy it needs to light the LEDs?\nI have removed the alkaline battery and the LEDs still light; if I remove the solar battery then they go off because that surely breaks the circuit between the solar panel and the LEDs.  If the solar battery had had charge after 1 year in the box, then surely the LEDs would light up when I turn the solar panel away from the table wouldn't they?  What am I missing here, please?", "output": "Here's what I think:\n\nIt doesn't take a lot of charge to light LEDs for a few hours. Your \"Solar Battery\" probably still has enough charge from the factory to power the lights for a while. I imagine if you keep the solar panel out of the sunlight, eventually you will run down the solar battery and it will stop working.\nYour solar panel likely also has an ambient light sensor on its front. That way, the lights will never turn on when it's light outside (when you probably don't want them anyways) and they will automatically switch on when it gets dark. When you dropped the panel on the ground, you covered up the ambient light sensor, and the lights switched on. (The idea being that if the solar panel is placed outside, the lights only turn on at night)", "meta": {"post_id": 598940, "input_score": 9, "output_score": 48, "post_title": "Where is the energy coming from to light my Christmas tree lights?"}}
{"input": "In my life I hear/read this statement a lot:\n\nA non-linear equation or theory leads to self-interactions.\n\nFor example in GR, we say that gravity can interact with itself because it is non-linear.\nFor some reason I always assumed it was correct. However now I think about it, I can not see a clear reason in the maths for why this statement holds. Can someone help me out? :D\nEdit$_1$: As Vadim pointed out. The statement should be the other way around.\n\nA self interacting physical system leads to non-linear equations.\n\nEdit$_2$: The questions is beautifully answered by @gandalf61 for 2 variable system. However, still do not really understand what is going on for 1 variable system, e.g. in general relativity. Could someone maybe also give an example there? Thank you in advance. :D\nIn the comments on the answer of @gandalf61, you will also find the answer of edit$_2$.", "output": "If I go to a shop and buy $5$ apples and $10$ bananas then I can usually take the price of one apple $a$ and the price of one banana $b$ and add these together to get a total cost of $5a+10b$. And I pay the same total amount if I buy apples and bananas at the same time or I buy apples, then go back to the shop later and buy bananas - my purchases do not interact with one another. This is a linear system.\nBut if there is an offer of \"$5$ apples for the price of $3$\" or \"one free banana with every $5$ apples\" or \"$10\\%$ off if you spend more than $\\$5$\" then the cost of $5$ apples and $10$ bananas will no longer be $5a+10b$. This is a non-linear system, and there is an interaction between my different purchases.", "meta": {"post_id": 600790, "input_score": 18, "output_score": 40, "post_title": "How do non-linear equations lead to self-interaction?"}}
{"input": "Last time I was watching a candle die. After its wick was finished, there remained just a drop of molten wax that was still slowly burning, with a flame that became smaller and smaller, down to a millimeter high, until it disappeared.\nIt made me wonder how small can a flame get. With controlled conditions, is it possible to make a micrometric flame for instance ? Is there a lower limit ?", "output": "Combustion is... complicated. Essentially what is going on in flame is that you have molecules of fuel and oxidizer that mix and start to bounce off each other. If the molecules are moving fast enough (meaning they have enough energy, which we measure as temperature), then when they collide with each other, they start to make the fuel and oxidizer fall apart into other molecules.\nDepending on which molecules collide and the energies involved, when things start to fall apart they are moving to lower energy states and the energy that was stored in the chemical bonds gets released as heat (and radiation in the form of light, which may be invisible). If it is happening often enough, the heat raises the temperature (adds energy) of the molecules around it and the process starts to run away. This is how you get a stable flame.\nSo this means there's at least a fundamental limit to the thickness of a flame -- you couldn't have a flame at lengths smaller than the distance molecules travel before they collide. This distance is called the mean free path, but frankly it's not a useful limit because flames cannot exist on the scale of the mean free path for other reasons.\nFor a flame to exist and be stable (i.e. not just a spark or something that goes away quickly), the rate of heat release has to be in balance with the rate of heat losses. If heat release exceeds heat losses, the flame will get bigger. If heat release is less than heat losses, the flame will run out of energy.\nAll of this means it is difficult, if not impossible, to put a general limit on the smallest possible flame. It will depend on the fuel source and how much oxidizer is present (different fuel+oxidizer combinations need different energies to start releasing heat), what the flow around the flame is like (how fast heat is carried away), how much energy the mixture has (higher temperature means more collisions that can break things apart), and how far the molecules need to move before they collide (how dense the mixture is).\nThe only definitive thing we can say is that the flame needs to be thicker than the mean free path, but anything more precise would require getting specific about the setup.\n\nFor a candle flame, we're looking at what is called a diffusion flame. The fuel (wax) is on one side and it has to vaporize and diffuse/mix with the oxygen in the air before it can properly burn. This is pretty hard. An overview lecture on diffusion flames is available, but it's actually not that easy to define a thickness for diffusion flames.\nSuffice to say that the flames can be arbitrarily small, at least for sizes greater than several times the mean free path, provided the heat release is in balance with the heat losses. To be more specific would require a lot more details of the setup.", "meta": {"post_id": 603114, "input_score": 52, "output_score": 39, "post_title": "How small can a flame get?"}}
{"input": "If we fold a paper and then apply pressure on the newly formed crease, it seems that the paper's surface gets a permanent deformation but what exactly has happened to the paper at a molecular scale?", "output": "Basically, a fold or crease in paper will remain because the structure of the fibers in the paper have become irreversibly damaged. This happens because the paper is bent/compressed beyond its elastic limit.\nChemically, paper is mainly composed of cellulose  from plant fibers. Cellulose is an organic polymer, which has D-glucose units connected through hydrogen bonds. These bonds form between the oxygen atom of the one-hydroxyl group belonging to the glucose and the hydrogen atom of the next glucose unit. These are microscopic properties of paper, but to understand what happens when we fold paper or do Origami, it is sufficient to learn what is happening macroscopically.\nAll materials have what is called an elastic limit and a plastic region. The elastic limit is the point at which a material will bend but still return to its original position without any permanent change or damage to its structure. Further deforming the material beyond this limit takes it to its plastic region. At this point any structural or physical changes become permanent and the paper will not return to its original form.\nEvery material has a different elastic limit or yield, and plastic region. Imagine holding a piece of paper slightly bent but not folding or creasing it. The plant fibers that make up the paper will not have exceeded their elastic limit. So as soon as you let go of the paper sheet it will quickly return to its noncreased original flat state. However, if you were to roll that piece of paper into a cylinder and hold it for a few minutes, some of these fibers will be pushed beyond the elastic limit which is evident since it will not lie flat anymore since slight deformations have occurred in this sheet.\nNow, when you properly fold a piece of paper as you would during Origami, the plant fibers along the crease are pushed into the plastic region of the paper, causing a fracture point at the actual line of the fold. A practical example of this is if you were to fold a piece of paper, you will note that if you stretch the paper evenly on both sides of the fold, the paper will tear right on the fold (a quick way to \"cut\" paper if you have no scissors). The fold then becomes an irreversible structural failure and the fibers in the paper will never regain their original state.\nBecause of this damage to its structure, the paper will from then on have this fold. And no matter how hard you try to flatten out the fold it will never return to its original state. This is why Origami models continually retain their shape.", "meta": {"post_id": 607329, "input_score": 75, "output_score": 94, "post_title": "What is the physics behind origami?"}}
{"input": "Unfortunately I broke my specs today which I used in this question.\nBut I observed that the edges are completely different then the entire part of the lens. The middle portion of the lens was completely transparent but the edges appeared opaque (and I can't see through the edges). This image shows the same in case of a shattered glass.\n\nThe edges in the above picture are green and not transparent as other portions appear.\nSo why are the edges not transparent (in both the case of specs and the shattered glass)?\nEdit : I would like to add that the edges of my specs were not green. They were just silvery opaque. I couldn't take a pic of it during asking the question but take a look at it now.", "output": "Because you're looking through more of glass\nI'd like to just add to the other answers with some diagrams. We have an intuition that light beams travel in straight lines, so we tend to assume that the beam paths looking through glass might be as follows:\n\nHowever, the actual paths of the beam due to refraction and total internal reflection look more like this:\n\nNote that the beams that enter the face of the glass aren't significantly deflected, and exit the glass pretty quickly. However beams that enter the edge of the glass spend a lot more distance within the glass. As the beam spends more time within the glass, it has more of a path to be affected by impurities.", "meta": {"post_id": 607574, "input_score": 36, "output_score": 41, "post_title": "Why are the edges of a broken glass almost opaque?"}}
{"input": "I bought 5.6 gr of uranium ore.\nThe measured gamma radiation is 1\u00b5Sv/h, we didn't have the instruments to measure alpha/beta radiation.\nEDIT:\nThe gamma radiation was measured at 1cm distance. I also updated the unit of measurement as I had only written 1\u00b5Sv instead of 1\u00b5Sv/h.", "output": "Assuming the measurement is 1\u00b5Sv per hour, looking at XKCD's handy radiation chart suggests that it is equivalent to eating 10 bananas or having an arm X-ray. If you were staying around the ore it would be equivalent to living in a place like the Colorado plateau with higher than normal background radiation. So that is not much of a problem.\nWhat would worry me more is the alpha and beta radiation. Alpha is short-range, so as long as you don't eat, inject or inhale the ore things are fine. The beta radiation might be more damaging, but as this answer shows, the risk is pretty minuscule even for more active samples than yours. Finally, there is the issue of radon production. This again seems to be a microscopic factor, although sleeping in the same room as the ore might be unnecessary. See also this page for way more information than you need.\nOverall, the ore is as safe as any other heavy metal ore.", "meta": {"post_id": 608581, "input_score": 27, "output_score": 36, "post_title": "Is it safe to keep uranium ore in my house?"}}
{"input": "Whenever I wash my thermos, I put hot water and then some soap in; then I seal the one end with my hand or use the lid.  After shaking it up, if I slowly remove the lid or my hand, it expels a little air.  Why is that?  Does it have something to do with increased surface area of soapy water?  Or is it the fact that the air is heated by the water, even though the water must surely cool slightly?", "output": "There is another effect here which is significant, as follows.\nWarm water wants to evaporate, but in a flask-shaped container, the evaporation can take place only at the free surface of the water in the flask. Furthermore, as soon as the boundary layer of air right next to the warm water becomes saturated with vapor, the diffusion of water vapor into the air slows down greatly.\nIf you close the container and shake it vigorously with soap added, tiny air bubbles get mixed into the warm water, producing a huge surface area available for evaporation to occur across. The bubbles expand as they get loaded with vapor and the pressure inside the container jumps up suddenly.", "meta": {"post_id": 617113, "input_score": 59, "output_score": 53, "post_title": "Why does pressure in a thermos increase after shaking up hot water and soap?"}}
{"input": "Imagine a system of two objects: a supermassive black hole mass of approximately $10^{36}$ kg and another $1$ kg object revolving around the black hole with an average mean distance of about $1.5\u00d710^{8}$ m. The angular velocity of the smaller object is $2$ rad/s and correspondingly the linear velocity is equal to the speed of light. But how could this be? I know this might be wrong, but where?", "output": "A black hole of mass $10^{36}$ kg would have a Schwarzschild radius (the distance from the center to the event horizon) of about $1.5\\times 10^{9}$ m.\nSo your choice of \"orbital\" distance is inside the black hole, and it won't orbit, it will just fall inward.  Outside the event horizon there is a minimum distance for a stable circular orbit which is three times the Schwarzschild radius.\nYou cannot use Newtonian physics for these calculations; you need full blown general relativity.  If you try mixing these two systems together you get nonsense.  It is only at distances where the gravitational field is weak that you can apply Newtonian physics with good accuracy.\nRegarding why we are so confident that we know what happens inside a black hole (like everything falling inward) when we can never test that directly it comes down to the way the theory is designed.  The theory for what happens outside the event horizon and inside the event horizon are the same theory and as we have verified that theory for outside the event horizon to a very, very high level of confidence so there is a very high level of confidence in it's predictions for inside the event horizon.  The basic core the theory of general relativity is that physics must work the same way everywhere.  The event horizon doesn't make any difference in this sense.", "meta": {"post_id": 619987, "input_score": 10, "output_score": 62, "post_title": "Indirectly breaking the speed of light"}}
{"input": "This question about the speed of light prompted my own question. In the linked question it is asked if there is experimental proof that the speed of gravity equals the speed of light. I was surprised not to see the LIGO measurements mentioned.\nThe experiment uncovered the arrival of a spacetime distortion coming from fast-spinning binary systems of black holes or neutron stars. Due to LIGO's extensive Nature (there is one observatory in Livingston and one in Hanford) it seems that upon arrival the gravitational wave (if it hits the Earth at a sharp angle) will hit one of both observatories first (which one depends obviously from the origin of the wave). So it should be possible to measure the speed of gravity. Or, at least, to measure if the speed is finite (or not).\nHas this been done?", "output": "Yes. In principle, the speed of gravitational waves can be measured using the data of LIGO. In fact, using a Bayesian approach, the first measurement of the speed of gravitational waves using time delay among the GW detectors was suggested/performed by Cornish, Blas and Nardini. By applying the Bayesian method, they found that the speed of gravitational waves is constrained to 90% confidence interval between $0.55c$ and $1.42c$ by use of the data of binary black hole mergers GW150914, GW151226, and GW170104.\nAfter that, a more precise measurement of the speed of gravitational waves was\nperformed by the measurement of the time delay between GW and electromagnetic observations of the same astrophysical source, as @Andrew nicely mentioned, by use of a binary neutron star inspiral GW170817. They found the speed of gravitational wave signal is the same as the speed of the gamma rays to approximately one part in $10^{15}$. Note that this study is primarily based on the difference between the speed of gravity and the speed of light.\nRecently, a new method has been introduced using a geographically separated network of detectors. As the authors mentioned, while this method is far less\nprecise, it provides an independent measurement of the speed of gravitational waves by combining ten binary black hole events and the binary neutron star event from the first and second observing runs of Advanced LIGO and Advanced Virgo. By combining the measurements of LIGO and Virgo, and assuming isotropic propagation, the authors have constrained the speed of gravitational waves to ($0.97c$, $1.01c$) which is within 3% of the speed of light in a vacuum.\nIn my opinion, the best study is the second one (that @Andrew nicely mentioned), in which multiple measurements can be measured to produce a more accurate result, but the later (the third study) has its scientific significance. This is because the later method is an independent method of directly measuring the speed of gravity which is based solely on GW observations and so not reliant on multi-messenger observations, as the authors mentioned.\nBesides these achievements, there are other interesting results that one can extract from LIGO's data. For example, observations of LIGO have constrained a lower bound on the graviton Compton wavelength as\n$${{\\lambda _{{\\rm{graviton}}}} > 1.6 \\times {{10}^{13}}{\\rm{km}}},$$\nwhich is really interesting. In fact, assuming that gravitons are dispersed in vacuum like massive particles, i.e. ${\\lambda _{graviton}} = \\frac{h}{{{m_{graviton}}\\,c}}$, one can find an upper bound for graviton's mass as ${{m_{{\\rm{graviton}}}} \\le 7.7 \\times {{10}^{ - 23}}eV/{c^2} \\sim {{10}^{ - 38}}g}$, which is extremely small, beyond the technology of our detectors.", "meta": {"post_id": 622729, "input_score": 38, "output_score": 49, "post_title": "Did LIGO measurements prove that the speed of gravity equals the speed of light?"}}
{"input": "Today it was announced that the Fermilab measurements of the muon's gyromagnetic ratio are in disagreement with the Standard Model with a statistical certainty reported at 4.2 sigma [1, 2], raising the distinct possibility that the discrepancy measured originally at Brookhaven two decades ago is real. On the other hand, a paper published today in Nature claims that through state of the art lattice calculations, they have obtained a new theoretical estimate of the muon's $g$-factor which, to my understanding, they claim reduce the discrepancy between theory and previous experiments.\nFrom what I have read and understood, it seems to me that (1) the new Fermilab sigma figure is presumably being compared to older theoretical calculations and (2) the new theoretical calculation is presumably being compared to older experimental measurements. This seems rather incredible that these two seemingly conflicting announcements come on the same day.\nSo my question is, what gives? Do the new theoretical calculations (assuming they can be verified) lower the new Fermilab sigma figure?", "output": "This seems rather incredible that these two seemingly conflicting\nannouncements come on the same day.\n\nThe pre-print for the Nature paper by the BMW group was placed on arXiv in 2020 around the same time as the muon g-2 Theory Initiative paper (submitted on 8 Jun 2020 and last revised 13 Nov 2020, published here) that the Fermilab collaboration referenced in its announcement. The BMW pre-print was posted February 27, 2020, and last revised on August 18, 2020. (The 14-person BMW team is named after Budapest, Marseille and Wuppertal, the three European cities where most team members were originally based.) So, insiders weren't surprised.\nFermilab announced when its experimental results would be shared. Nature intentionally and strategically released the paper that had been in their offices awaiting publication for about eight months on the same day to maximize its impact. The theory presentation on Zoom this morning from Fermilab actually mentioned the BMW paper in passing although it didn't emphasize the point.\nThe BMW paper and the Theory Initiative paper use quite different methodologies to calculate the leading order Hadronic Vacuum Polarization (LO-HVP) contribution to the Standard Model muon g-2 calculation, which is the dominant source of theoretical uncertainty in the calculation. The BMW paper makes some refinements in the calculation that are very computation intensive (it took several hundred million \"core hours\" on seven sets of supercomputers to calculate) and is a straight up theory calculation (Quanta Magazine has a nice discussion of what this involved with a bit more depth). The Theory Initiative paper uses data on electron-positron annihilation products experimentally as a substitute for doing some key calculations that BMW does \"on paper\" (with BMW criticizing the Theory Initiative and others using similar methods for not transitioning the experimental data into the theoretical calculation in the manner that they think is correct).\nThe new Fermilab experimental results largely confirmed the previous Brookhaven measurement of muon g-2; the two experimental results were consistent at the 0.6 sigma level. The new Fermilab results moved slightly from the previous measurement in favor of the theoretically predicted values. The results were (all multiplied by a factor of 10-11):\n\n\n\n\nsource\nresult\n\n\n\n\nBrookhaven's E821 (2006)\n116,592,089(63)\n\n\nCombined Experimental Measurement\n116,592,061(41)\n\n\nFermilab (2021)\n116,592,040(54)\n\n\nBMW Standard Model Prediction\n116,591,954(55)\n\n\nTheory Initiative Standard Model Prediction\n116,591,810(43)\n\n\nBMW - Theory Initiative\n144\n\n\n\n\n(It is also worth noting that all of the experimental results and all of the theoretical predictions are all identical when rounded to the first six significant digits, i.e. at a parts per million level.)\nCompared to the combined results used for the 4.2 sigma compared to the Theory Initiative paper, the BMW number is consistent with the combined experimental result at the 1.6 sigma level. The BMW paper claims 27% more uncertainty in its theoretical result than the Theory Initiative paper and the Theory Initiative result has been replicated (something much more difficult to do in the case of the much more computation resource intensive BMW calculation), which is part of the reasons that Fermilab decided to go with the Theory Initiative benchmark (another is that the Fermilab theory director is part of the Theory Initiative collaboration, while the BMW collaborators aren't affiliated with Fermilab).\nA new pre-print making a more precise calculation of the hadronic light by light contribution to muon g-2 (reducing the relative error in that component of the calculation from 20% to 14%) was also strategically released on arXiv today. It adds 14.8 * 10-11 to the BMW prediction. Combined with the BMW prediction this is 158.8 * 10-11 more than the Theory Initiative Standard Model Prediction. So, including this result as well as the BMW prediction would further reduce the experiment-SM prediction discrepancy to 1.3 sigma (the two innovations do not overlap).\nIt will be interesting to see if the Lattice QCD/SM prediction theorists will be able to reach a consensus on this issue, which was a simmering behind the scenes controversy for months before this announcement. Multiple conferences on the muon g-2 calculation are planned for the next year (as the theory presentation from Fermilab this morning mentioned) and this disparity will be at the top of the agenda at all of them.\nThe stakes are pretty high. If the Theory Initiative is right, new physics beyond the Standard Model almost certainly exist and are right around the corner. If the BMW collaboration is correct, the prospect for new beyond the Standard Model High Energy Physics discoveries at experiments that are possible to conduct in our lifetimes is dismal.\nAn intermediate possibility is that neither calculation secures consensus support, but that the QCD community concludes, based upon the disparity between the legitimately calculated Theory Initiative result and the legitimately calculated BMW collaboration result, that both papers have grossly underestimated the amount of theoretical uncertainty present in their SM prediction calculations. This would leave us in the same limbo we've been in on muon g-2 for the last two decades.\nIf you are a visual leaner, you can read the comic strip explanation.", "meta": {"post_id": 627849, "input_score": 46, "output_score": 67, "post_title": "Resolving Conflicting Reports on Fermilab $g-2$ Results"}}
{"input": "I have been learning about the solar system from popular science shows.  In these shows they suggest that, after having seeing around 2500 other solar systems, astronomers have concluded that our solar system is not the normal one.  They see sun hugging hot jupiters and super earths close to their star.  They find most systems have most of their matter closer to their star.  They draw conclusions about our system, namely that our system is a freak.\nWe know that the first exoplanets found were hot jupiters.  And they found super earths close to their star.  We also know that telescope technology is always improving.  With increasing telescope quality, we can find dimmer objects.  These would naturally be smaller planets orbiting distant stars at further distances from their stars.\nMy question is this: how do we know that the apparent rare quality of our system is not an artifact of limited observing power that selects for larger objects close to their star?", "output": "The solar system cannot be said (yet) to be \"rare\" because we lack the ability to examine the planetary systems around other stars in detail. In particular, the census of low-mass planets and planets that are more than an astronomical unit from their star is very incomplete.\nNevertheless, enough is known to say that the solar system is unusual in some respects. The main oddity about the solar system is that it doesn't contain any \"super-Earths\" or \"sub-Neptunes\" at all (i.e. planets intermediate in size between Earth and Neptune), despite them being common in other systems, and the close-in planets are all small and rocky. Most ($\\sim 70$%) solar-type stars have at least one exoplanet larger than the Earth orbiting with a period of 100 days or less (e.g. Kunimoto & Matthews 2020). Most of these close-in planets are 2-5 times the size of the Earth.\nThe presence of a Jupiter-sized planet at 3-7 au is also somewhat unusual - occurring in $<10$% of solar-type stars Wittenmyer 2016).\nThe lack of a hot Jupiter in the solar system is not unusual, since the occurrence rate of these is only of order 1%.\nThese frequencies are corrected for the known and well-understood biases in detection sensitivity associated with system geometry, signal-to-noise ratio and observing cadence. These factors can easily be accounted for in a forward modelling approach. This is where you simulate your exoplanet population, then \"observe\" it, in software, including all the observation biases and detection thresholds, and then adjust the characteristics of the simulated population until the simulated observations match the real observations.\nNote for those wanting to discuss the anthropic principle. It seems to me that whether the planetary system around our Sun has an unusual architecture has nothing to do with our presence. What the anthropic principle may have a bearing on is explaining why we live in an unusual solar system or why we might expect the solar system to be unusual.", "meta": {"post_id": 633661, "input_score": 43, "output_score": 51, "post_title": "Is our solar system really that odd?"}}
{"input": "I just captured the following two pictures. Straight above me, almost directly above, was a rainbow, about 120 degrees of it were visible.\nThe thing is, the sun was completely out, low on the horizon and not centred. What explains this? My understanding was that the refraction at specific angles was what made the colour separate in a specific pattern. The angles didn't match, here.\nLocation: Montreal, ~15 minutes ago, unseasonably warm.\n\nIn the portrait picture, the sun is in the very bottom, on the left side:", "output": "As pointed out in the comment by @Rob, this is called a Circumzenithal Arc or colloquially, an \"upside-down rainbow\". Different to usual rainbows (which appear on the opposite side of the sky from the sun), a circumzenithal arc is centered around the zenith of the sky (directly above), and can only appear if the sun's angle is less than $\\approx 30\u00b0$ to the horizontal.\nIn order for a circumzenithal arc to form, small ice crystals need to be positioned high in the sky in order to create a field of tiny prisms. Then the sun's rays will enter these ice crystals and refract through them therefore projecting an arc in the sky. If this projection was complete (a full $360\u00b0$), it would  completely encircle the sky's zenith - hence the term circumzenithal.\nCompletely circular circumzenithal arcs do occur but are very rare, and so most of them only take up a section of the sky. The circumzenithal arc  remains until the sun's angle exceeds $\\approx 30\u00b0$ to the horizontal.\nIn most cases, a circumzenithal arc will last about 30 minutes to an hour (sometimes more). They are most common in colder climates (I assume in Montreal - where you took these images - it is fairly cool), where ice crystals abundantly tend to collect in the sky  (they can be sometimes be seen in mild temperature zones as well during winter, or periods of cooler weather).\nThe above link (which explains the phenomena in detail) has more technical details:\n\nThe circumzenithal arc, also called the circumzenith arc (CZA),\nupside-down rainbow, and the Bravais arc,is an optical phenomenon\nsimilar in appearance to a rainbow, but belonging to the family of\nhalos arising from refraction of sunlight through ice crystals,\ngenerally in cirrus or cirrostratus clouds, rather than from\nraindrops. The arc is located at a considerable distance\n(approximately $46\u00b0$) above the observed Sun and at most forms a quarter\nof a circle centered on the zenith. It has been called 'a smile in the\nsky', its first impression being that of an upside-down rainbow. The\nCZA is one of the brightest and most colorful members of the halo\nfamily. Its colors, ranging from violet on top to red at the bottom,\nare purer than those of a rainbow because there is much less overlap\nin their formation.\nThe intensity distribution along the circumzenithal arc requires\nconsideration of several effects: Fresnel's reflection and\ntransmission amplitudes, atmospheric attenuation, chromatic dispersion\n(i.e. the width of the arc), azimuthal angular dispersion (ray\nbundling), and geometrical constraints. In effect, the CZA is\nbrightest when the Sun is observed at about $20\u00b0$.", "meta": {"post_id": 644286, "input_score": 25, "output_score": 36, "post_title": "What did I just photograph? (rainbow way out of place)"}}
{"input": "I've read that higher energy means higher mass, and in atomic systems, the kinetic energy and potential energy actually contributes more mass than the actual particles themselves (or so I've read). So, how much of Earth's mass is created by the energy in the molten core? What would be the difference in mass between an almost identical Earth with no molten core and the Earth that we actually have?", "output": "According to Table 2.17 from page 109 of Chemistry of the Climate System by Detlev M\u00f6ller, the heat content of the inner core of the Earth is $\\sim 3.6\\times 10^{30}$ J, and the outer core is $\\sim 1.5\\times 10^{31}$ J. The total heat content of the Earth is $\\sim 2\\times 10^{31}$ J. The author stresses that these are only crude estimates based on theories that give mean temperature and composition for the various layers.\nUsing $E=mc^2$, the mass equivalence of the inner core heat is $\\sim 4\\times 10^{13}$ kg, the outer core is $\\sim 1.67\\times 10^{14}$ kg, so the total for the core is around $2.1\\times 10^{14}$ kg.\nFor comparison, the Earth's mass is $\\sim 5.9722\\times 10^{24}$ kg. So the core heat contributes around 1 part per 29 billion of the total mass.\n\nHere's the contents of M\u00f6ller's table.\n\n\n\n\nregion\ndistance\nmean T\ndensity\nmatter\nheat\n\n\n\n\n\n(km)\n\u00b0C\n$g/cm^3$\n\n(J)\n\n\ncrust\n0-30*\n350\n3.5\nrocks\n$2\u00d710^{22}$\n\n\nouter mantle\n30-300\n2000\n4\nrocks\n$5.6\u00d710^{28}$\n\n\ninner mantle\n300-2890\n3000\n5\nrocks\n$2.2\u00d710^{30}$\n\n\nouter core\n2890-5150\n5000\n8\nFe-Ni\n$1.5\u00d710^{31}$\n\n\ninner core\n5150-6371\n6000\n8.5\nFe\n$3.6\u00d710^{30}$\n\n\n\n\n\nContinental crust, oceanic crust is 5-10 km depth.\n\nIt's surprisingly difficult to find this geothermal energy data. Wikipedia gives a figure of $10^{31}$ J for the internal heat content of the Earth, linking to a report which quotes a figure of $12.6\u00d710^{24}$ MJ from What is Geothermal Energy by Dickson & Fanelli (2004), but that article gives no details for the calculation.", "meta": {"post_id": 652536, "input_score": 21, "output_score": 43, "post_title": "How much of Earth's mass is created by the energy of the core?"}}
{"input": "I'm trying to understand Manishearth's experiment  in the answer here,\n\nTo try this out, close one eye. Now hold your arms straight out, nearly stretched, but not completely stretched. Now extend your index fingers (there should be about one inch between them). Now try touching them together. Try this a few times, then repeat with both eyes open. You'll realise how necessary the second eye is for judging depth.\n\nI tried the experiment a few times but I am really not sure what I am supposed to see/ how the experiment works.\nThe one part I do understand is the reason they have said not to completely stretch the arms. If one does that, then by the sensation of arm being stretched will give a sense of depth, so it is necessary to not extend till to total arm length.\n\nP.S: I completely understand the mathematics and fact we need two rays, but I think I am not getting the correct result for the experiment. Ideally an answer with pictures would be best.", "output": "The problem with the two finger experiment is that your body\u2019s sense of proprioception is so accurate and so instinctive that you don\u2019t need binocular vision to touch your finger tips together. In fact, you don\u2019t need vision at all. Try the experiment with your eyes closed. You will find that you can still touch your finger tips together quite accurately without even seeing them.\nTo get a better sense of the power of binocular vision, use a pen or pencil held in each hand instead of finger tips, to reduce the effect of proprioception. Wave the pens/pencils around to randomise the starting positions, and then try to make the ends of the pens/pencils meet. With both eyes open this task is very easy. With only one eye open you will find it is surprisingly difficult.", "meta": {"post_id": 659624, "input_score": 28, "output_score": 78, "post_title": "Experiment to show that we need two eyes to determine depth"}}
{"input": "Suppose I have a bottle of pills and I throw the bottle in the air vertically. I wonder if the pills inside the box also fly up, or do they remain stable at the bottom of the bottle?\nI tried this experiment several times and I think the pills remain stable. I took the top of the bottle off and moved the bottle quickly vertically and observed the pills don't go up. But what if I throw it to the air very quickly? Do they still remain stable?\nI don't know if my guess is correct and what physics rule is behind that?", "output": "In a vacuum, the moment the bottle leaves your hand it will be in free-fall, and both the pills and the bottle will be subject to exactly the same acceleration - namely, $9.8\\ \\text{m/s}^2$ toward the floor.  As a result, they will move together.\nOn the other hand, in real life there will be a small amount of air resistance which acts on the bottle (because the air in the room is stationary) but not the pills (because the air trapped in the bottle is moving with the same speed as the pills/bottle are when they leave your hand).  As a result, at the moment the bottle leaves your hand the downward acceleration of the bottle will be slightly more than it would be in vacuum, and therefore slightly more than the pills, so the pills will begin to rise very slightly.\nOnce the pill bottle reaches its apex and begins to fall back down toward the floor, the situation is reversed - the bottle will accelerate toward the floor at slightly less than $9.8\\ \\text{m/s}^2$ - and the pills will gently fall back down to the bottom.\nFinally, depending on the properties of the pills and bottle, this effect might be swamped by friction or adhesion which would act to keep the pills stationary. Experiments would be required to work out what actually happens on a case-by-case basis.", "meta": {"post_id": 667819, "input_score": 12, "output_score": 44, "post_title": "Throwing a bottle containing pills to the air vertically"}}
{"input": "I recently bought steel ice cubes. A better name is probably \"steel cubes with unidentified liquid\" which I presume is water. When I opened the package I was quite surprised that they contained some liquid. I thought it was going to be a solid cube of steel. This made me think how do steel cubes compare to plastic cubes filled with water (or regular ice cubes)?\nVolume of cube: $V=(2\\ \\mathrm{cm})^3=8\\cdot10^{-6}\\mathrm{m^3}$\nSpecific heat capacity of ice $C_i=2090\\left[\\mathrm{\\frac{J}{kg ^\\circ C}}\\right]$\nSpecific heat capacity of steel $C_s=466\\left[\\mathrm{\\frac{J}{kg ^\\circ C}}\\right]$\nDensity of ice $\\rho_i=917 \\left[\\mathrm{\\frac{kg}{m^3}}\\right]$\nDensity of steel $\\rho_s=7750 \\left[\\mathrm{\\frac{kg}{m^3}}\\right]$\nI used the lower boundary for density of steel (from source).\nIce cubes:\nHeat capacity $C=\\rho_i\\cdot V \\cdot C_i \\approx 15.33\\left[\\mathrm{\\frac{J}{^\\circ C}}\\right]$\nSteel cubes:\nHeat capacity $C=\\rho_s\\cdot V \\cdot C_s \\approx  28.89\\left[\\mathrm{\\frac{J}{^\\circ C}}\\right]$\nEven though I used the lower boundary for the density of steel it still has more heat capacity than ice. From this it seems to make most sense to produce cubes of solid steel since it would cool your drink more.\nWhy do my steel cubes (used for cooling drinks) contain (presumably) water?\nCould it be that solid steel cubes transfer their heat too quickly? Hence manufacturers add water inside which does lower the heat capacity but make the cubes cool for a longer time period? Or am I interpreting the results from my calculations wrongly? Or maybe my calculations are wrong?\nSources where I get values:\nhttps://en.wikipedia.org/wiki/Steel\nhttps://www.cs.mcgill.ca/~rwest/wikispeedia/wpcd/wp/i/Ice.htm\nhttps://gchem.cm.utexas.edu/data/section2.php?target=heat-capacities.php", "output": "Water thaws at 0\u00b0C.  The latent heat of fusion of water is $L_i = 344000$ J/kg, which means that to thaw the frozen water inside your cubes requires much, much more energy than you're accounting for.  Steel, on the other hand, undergoes no such phase transformation (edit: at comfortable drinking temperatures), and so it cannot invoke the magic of phase transformations to cool your drinks.\nTo put some numbers on it:  how cold would a cube of solid steel have to be to absorb as much heat as the same volume of melting ice?  We want\n$$\n\\rho_s C_s V \\Delta T = \\rho_i L_i V \\quad \\Rightarrow \\Delta T = \\frac{\\rho_i L_i}{\\rho_s C_s} = 87.3 {}^\\circ \\mathrm{C}.\n$$\nSo to match the performance of a melting ice cube at 0\u00b0C, your steel cube would have to start out at -87\u00b0C or so, which is clearly out of the range of household freezers.", "meta": {"post_id": 672309, "input_score": 16, "output_score": 46, "post_title": "Why do my \"steel ice cubes\" have water in them?"}}
{"input": "There are multiple questions on here about QFT textbook recommendations, but I am looking for mathematically precise texts on QFT.\nRecommendations of introductory and advanced texts are welcome, but please at the level of rigor of pure mathematics texts.", "output": "This question cannot be aswered as it is asked. There is no general mathematical rigorous definition of QFT in general, but rather different approaches with different goals and applications.\n\nFirst of all, there is what is called Axiomatic Quantum Field Theory, which are attempts to formulate quantum field theories in an mathematical axiomatic way. Note that physical speaking, such approaches start already at the quantum level and do not discuss the process of quantization. Examples of books discussing the famous \"G\u00e5rding\u2013Wightman axioms\" are for example:\n\nR. F. Streater and A. S. Wightman: PCT, Spin and Statistics and all that. volume of Princeton Landmarks in Physics. Princeton University Press, Princeton, New Jersey, 1964.\nE. de Faria, W. de Melo: Mathematical Aspects of Quantum Field Theory. volume 128 of Cambridge studies in advanced mathematics. Cambridge University Press, Cambridge 2010.\nM. Reed, B. Simon: Methods of Modern Mathematical Physics. II: Fourier Analysis, Self-Adjointness. Academic Press, 1975.\nM. Schottenloher: Chapter 8: Axioms of Relativistic Quantum Field Theory in A Mathematical Introduction to Conformal Field Theory. volume 759 in Lecture Notes in Physics. Springer, Berlin, Heidelberg, 2008.\n\nThere are also some good lecture notes, which you can find online (just google them):\n\nW. Dybalski: Lectures on mathematical foundations of QFT.\nM. Keyl: Mathematical Aspects of Quantum Field Theory.\n\nA great success of these axioms is for example the \"Haag-Ruelle scattering theory\". Parts of this is discussed in the references cited above.\nThere are also axioms for Euclidean QFT (called \"Osterwalder-Schrader axioms\"). These axioms can either be formulated in terms of Schwinger functions or in terms of path integrals (using measures on the space of tempered distributions; using the \"Bochner-Minlos Theorem\"). A standard reference for this is\n\nA. Jaffe, J. Glimm: Quantum Physics: A Functional Integral Point of View. Springer, New York, 1987.\n\nRelated to axiomatic QFT is \"Constructive Quantum Field Theory\", which is the area of mathematics trying to find examples of non-perturbative and interactive QFTs satisfying these axioms. The book by A. Jaffe and J. Glimm is also a nice starting point for this point of view.\nAs pointed out in the comments, up to now, one was only able to construct such theories in low dimensions (see for example this physics SE post). Furthermore, note that finding similar axiomatic approaches for quantum gauge theories is still an open question. In the end, this is one of the \"Millennium Prize Problems\".\nAnother nice book discussing both the Wightman axioms and Osterwalder Schrader axioms and some general aspects of non-perturbative QFT is\n\nF. Strocchi: An Introduction to Non-Perturbative Foundations of Quantum Field Theory. Oxford Science Publications, 2013.\n\n\nAnother mathematical topic in QFT is \"Causal Perturbation Theory\" (sometimes also called \"Finite Quantum Field Theory\"), which is a mathematically rigorous construction of perturbative quantum field theory, based on the \"Epstein-Glaser approach\" of renormalization. Standard references include\n\nG. Scharf: Finite Quantum Electrodynamics. The Causal Approach (3. edition). Dover, Mineola, New York, 2014.\nG. Scharf: Gauge Field Theories: Spin One and Spin Two: 100 Years After General Relativity. Dover, Mineola, New York, 2016.\n\n(Note that the name of the second volume was changed in later editions. The first edition was called Quantum Gauge Theories \u2013 A True Ghost Story. As the name suggest, in the later edition, the author added some discussion of spin 2 particles and gravity as an effective quantum field theory (\"perturbative quantum gravity\").)\n\nA modern approach to quantum field theory, which axiomatizes the assignment of algebras of observables, is \"Algebraic Quantum Field Theory\", based on the \"Haag-Kastler-Axioms\". There are also many good books about that approach. Examples are\n\nH. Araki: Mathematical Theory of Quantum Fields, Oxford Science Publications, 1999.\nR. Haag: Local Quantum Physics. Fields, Particles, Algebras. Springer, Berlin, Heidelberg, 1996.\nR. Brunetti, C. Dappiaggi, K. Fredenhagen and J. Yngvasson (editors): Advances in Algebraic Quantum Field Theory. volume of Mathematica Physics Studies. Springer International Publishing, 2015.\n\nA book about perturbative aspects of algebraic quantum field theory and locally covariant quantum field theory (including curved spacetime) is\n\nK. Rejzner: Perturbative Algebraic Quantum Field Theory. An\nintroduction for Mathematicians. volume of Mathematical Physics\nStudies. Springer International Publishing,\n2016.\n\nHowever, this is a very active research area and there are much more books out there. Check for example this nlab page or this website.\n\nAnother modern approach to QFT is so-called \"Functorial Quantum Field Theory\", which is based on the discussion of topological QFT in terms of the \"Atiyah-Segal Axioms\", which in turn are based on previous axiomatic formulations of conformal field theory by G. Segal. I am not an expert on this. Check for example this nlab page.\n\nIf you are interested in the process of Quantization, there are also some mathematical approaches like \"Geometric Quantization\" and \"Deformation Quantization\". You can find many books about this topic.\n\nSome books covering various different mathematical aspects and tools of QFT are the books by E. Zeidler:\n\nE. Zeidler: Quantum Field Theory I: Basics in Mathematics and\nPhysics. A Bridge between Mathematicians and Physicists. Springer,\nBerlin, Heidelberg, 2006.\nE. Zeidler: Quantum Field Theory II: Quantum Electrodynamics. A\nBridge between Mathematicians and Physicists. Springer, Berlin,\nHeidelberg, 2009.\nE. Zeidler: Quantum Field Theory III: Gauge Theory. A Bridge between\nMathematicians and Physicists. Springer, Berlin, Heidelberg, 2011.\n\nThese books contain many different topics, but are more on mathematical tools than on QFT itself. In my personal opinion, they cover some really interesting stuff, however, they are written in a rather chaotic style (some things are discussed several times, etc.).\nQuite famous are also the two books\n\nP. Deligne, P. Etingof, D. Freed, L. Jeffrey, D. Kazhdan, J. Morgan, D. Morrison and E. Witten, (editors): Quantum Fields and Strings, A course for mathematicians. Volume 1. American Mathematical Society, Providence, Rhode Island 1999.\nP. Deligne, P. Etingof, D. Freed, L. Jeffrey, D. Kazhdan, J. Morgan, D. Morrison and E. Witten, (editors): Quantum Fields and Strings, A course for mathematicians. Volume 2. American Mathematical Society, Providence, Rhode Island 1999.\n\nThese books also cover many interesting aspects of QFT (the first volume also includes a discussion of the Wightman axioms). However, note that thes books are not really textbooks, but rather collections of various lecture notes. Furthermore, they do not only cover QFT, but also other topics like string theory (especially the second volume).\nAt this point, I should probably also add the book\n\nG. B. Folland: Quantum Field Theory: A Tourist Guide for Mathematicians. volume 149 of Mathematical Surveys and Monographs. American Mathematical Society, Providence, Rhode Island, 2008.\n\nThis books is basically a \"bottom-up\" approach, where the author translates QFT from physics to a mathematical language.\n\nNot directly related to QFT, but if you are interested in Mathematical Gauge Theory, there are also some nice mathematical books, like:\n\nM. J. D. Hamilton: Mathematical Gauge Theory. volume of Universitext.\nSpringer International Publishing, 2017.\nG. L. Naber: Topology, Geometry and Gauge fields. volume 25 of Texts\nin Applied Mathematics (2. edition). Springer, New York, 2011.\nG. Rudolph and M. Schmidt: Differential Geometry and Mathematical\nPhysics. Part II. Fibre Bundles, Topology and Gauge Fields. volume of\nTheoretical and Mathematical Physics. Springer Netherlands, 2017.\n\nThis is of course for classical gauge theory, but is for example of interest when you would like to understand the Lagrangian of the standard model in mathematical terms.\n\n\nLast but not least, let me mention that my list is of course by no means complete. There are also many other topics in mathematical QFT. For example, there is also some literature for mathematical QFT in condensed matter physics, or literature on some more specialized stuff, like on CFTs or supersymmetry. Furthermore, there is also what is called \"non-commutative QFT\", which is a approach of QFT based on non-commutative geometry (e.g. \"non-commutative standard model\"). I do not add more references on this more advanced and/or specialized things.", "meta": {"post_id": 673224, "input_score": 17, "output_score": 43, "post_title": "Mathematically rigorous QFT text"}}
{"input": "A question that popped into my head: if I see a picture of the sun close to the horizon, in an unknown place, can I know if it was taken at sunset or sunrise?\nDo sunrises and sunsets look the same in a still image? Can one tell them apart?", "output": "If you have a sufficiently advanced camera, then you can distinguish a sunrise from a sunset from a still frame. I will assume that the Sun and the horizon are visible.\nThe Sun is rotating at roughly 2 km/s at the equator.\nThis rotation imparts Doppler shifts in the light from the Sun, even in a still frame. So with a sufficiently advanced camera which can detect those Doppler shifts (for example, an IFU).\nThen you can measure the rotation axis of the Sun. Now, depending on where on Earth you are (latitude and whether this is sunrise or sunset) the rotation axis of the Sun will appear at a different angle relative to the horizon.\nSo, not only could you theoretically you figure out whether it is sunrise or sunset, but you could also measure the rotation speed of the Sun and your present latitude.\nThe Sun and the Earth rotate in the same direction (counterclockwise when viewed from above the North Pole). Thus, the top of the Sun relative to the horizon will rotate in the same direction as the observer.\nI will use this fact to describe what you would see due to the Sun's rotation:\nDuring sunset, you must be on the side of the Earth moving away from the Sun. From this angle, the top of the Sun (relative to the horizon, not necessarily North!) will appear blueshifted relative to the bottom of the Sun, since the apparent top of the Sun has a velocity towards Earth (same direction as your side of the Earth).\nDuring sunrise, you must be on the side of the Earth moving towards the Sun. From this angle, the top of the Sun will appear redshifted instead.\nSide note: I think in a statistical sense you could distinguish between sunrises and sunsets based on effects mentioned in other answers/comments: temperature of the air, stillness of the air, presence of particulates. Statistical meaning you could theoretically do better than a 50/50 guess with a single image, and better if you allow multiple images taken at the same place or with other variables controlled for. So although those answers/comments do not provide a sure way to distinguish sunrise from sunset, I think they suffice to show that the two phenomena are different on some level.", "meta": {"post_id": 675824, "input_score": 65, "output_score": 40, "post_title": "Do sunrises and sunsets look the same in a still image?"}}
{"input": "The no hair theorem says that a black hole can have only three properties: mass, charge and angular momentum. But why don't we say that linear momentum is one of its properties? If we throw an object into it at a certain velocity, it's clear the linear momentum will increase. So why isn't it a fundamental property? Is it because its velocity and hence linear momentum depends on the reference frame? But then doesn't its angular momentum as well if the frame is non-inertial?", "output": "In relativity the covariant properties are tensors. The linear momentum you are referring to is a 3-vector and therefore is not covariant. In particular its magnitude is not a scalar invariant and therefore cannot be a fundamental property of a black hole.\nIn plainer terms the value of the momentum depends on the frame of reference of the observer. Observers moving at different velocities would observe the black hole to have different values of momentum. A fundamental property needs to have the same value for all observers.\nThe relativistic version of momentum is the four-momentum, and a black hole can have this property. However the associated invariant, i.e. the magnitude of the four-momentum, is just the rest mass of the black hole, and as you say the rest mass is one of the three fundamental properties a black hole can have.", "meta": {"post_id": 677983, "input_score": 26, "output_score": 54, "post_title": "Why doesn't a black hole have linear momentum?"}}
{"input": "Whenever I see a 2D drawing of dispersion occurring when light travels through a solid prism, I see the rays get bent downwards on entry and downwards on exit again. For example here: https://www.wikiwand.com/en/Dispersion_(optics) \nTo my understanding of optics when entering a medium with a higher optical density,  the ray should get bent towards the normal of the surface, rotated CW and CCW when entering one with a lower IOR. However, the drawings suggest that it gets bent in the same direction upon entry and exit.", "output": "The normals in consideration for the incident and emergent rays are different.\nFor simplicity, take a monochromatic beam of light incident on a prism, as shown in this figure:\n\n\nWhen light is incident on a medium with a higher index of refraction ($n$), it bends towards the normal.\nWhen light is incident on a medium with a lower $n$ it bends away from the normal.\n\nIn reference to this figure, the incident ray should bend towards the normal, which would mean a clockwise rotation ($\\phi_1 < \\theta_1$)\nAnd the ray within the prism would bend away from the new normal at the new interface, corresponding to another clockwise rotation. ($\\phi_2 < \\theta_2$)\nFor a beam of light, dispersion will cause different wavelengths of light to bend in different angles, but they will all bend in the same sense.\nHope this helps.\n\nImage source.", "meta": {"post_id": 684631, "input_score": 20, "output_score": 48, "post_title": "Why does the light passing through a prism get bent in the same direction twice?"}}
{"input": "The first gravitational wave ever observed, GW150914, was calculated to be caused by a merger of two black holes of 36 and 29 solar masses. The resulting black hole had a mass of 62 solar masses, and 3 solar masses were said to have been radiated in the form of gravitational waves. But what about the kinetic energy of the orbiting objects just before the merger? When I substitute the Schwartzschild radii of the two black holes ($2GM/c^2$) into the formula for kinetic energy ($GM_1M_2/2(r_1+r_2)$), I find a kinetic energy of 4 solar masses. Should I add this up to the $29 + 36$? If so, the question should not be where the 3, but where the 7 solar masses went. Or do the given masses (29 and 36) already include the kinetic energy? In that case still 1 solar mass of orbital energy is missing. Did it go into the spin of the merger black hole? And is it included in the given mass of 62 solar masses? How will kinetic energy be divided between spin and radiation?", "output": "The masses used in the gravitational wave analysis are those that the black holes would have had in their own frames in isolation.  The best way to think about this is that the given masses of 36 & 29 solar masses would be the mass-energy of the black holes when they were very far apart, and had relatively negligible kinetic energy (i.e., they were moving at a speed of much less than $c$ relative to each other).  At that time, the total mass-energy of the system was well-approximated by the sums of their masses, i.e., about 65 solar masses.\nThe black holes then spiraled in towards each other over a period of millions of years.  During this inspiral phase, we can think of the motion in Newtonian terms;  the individual black holes decreased their gravitational potential energy (since they slowly got closer to each other) and increased their kinetic energy (since objects that are closer together will orbit their common barycenter faster.)  In this process, they were very slowly emitting gravitational wave energy, meaning that the total mass-energy of the system was very slowly decreasing.  Finally, the two black holes coalesced.  This last phase can really only be modeled using full numerical general relativity simulations, and I won't try to describe it here.\nIn this whole process (inspiral and coalescence), about 3 solar masses worth of energy was emitted in form of gravitational waves, leaving a final black hole of 62 solar masses behind.  The total energy radiated as gravitational waves turns out to have been divided very roughly evenly between the initial long in-spiral and the final brief coalescence.  The best estimate of the peak gravitational wave luminosity (power radiated per time) was about 200 solar masses per second, and this phase of \"maximum brightness\" lasted about 5\u201310 milliseconds.  So something like 1\u20132 solar masses of energy were radiated as gravitational waves during the long slow initial inspiral, and the other 1\u20132 solar masses were radiated during the quick final coalescence.\nSee Phys. Rev. Lett. 116, 241102 (2016) for the gory details.  (The definition of the black hole masses is in the introduction;  the comparison between energy radiated in the inspiral and the coalescence is on page 8.)", "meta": {"post_id": 693271, "input_score": 27, "output_score": 49, "post_title": "Where does the kinetic energy of the orbiting black holes go after the merger?"}}
{"input": "I am studying the inkjet printer in detail. I have come across thermal inkjet printing technology (bubble inkjet technology) and this short discussion below.\nWe create a water vapour bubble by heating a resistance, which displaces ink and forms a drop but after that.\nWhy does the bubble collapse in 10 to 20 microseconds?\n\nBubble Lifetime\nThe bubble lifetime can be determined from the reflectance measurements. If the bubble collapse is considered complete when the reflectance recovers to 0.75 of its initial value, then the typical lifetime for this printhead is about 11 \u03bcs, depending on the voltage applied to the heater. A higher voltage tends to length the bubble lifetime as seen in Figure 3b. The reflectance does not assume its initial value quickly until the heater cools to its steady state temperature.\n\n(screenshot of original)", "output": "Here is why.\nThe exploding vapor bubble launches up off the surface of the heater resistor at an initial speed of about 5 meters/second and reaches a maximum thickness (top to bottom) of between 25 to 100 microns, depending on which HP printhead design you are studying. That vapor bubble acts as a piston to push a droplet of ink out of the nearby nozzle.\n(BTW as soon as the resistor surface has been covered by a thin layer of vapor, heat transfer between the hot resistor surface and the liquid is essentially shut off and the bubble expands ballistically.)\nBecause that bubble is expanding ballistically upwards, the inertia of the liquid next to it causes the bubble to overexpand. Its internal temperature falls due to the expansion and also due to heat loss to the cold ink immediately surrounding it. By the time its expansion stops, its internal temperature is ~ambient and its internal pressure has already fallen to subatmospheric, and the bubble begins a very rapid contraction as the vapor inside it quickly condenses back to liquid.\nThe shape of the bubble as it expands and collapses is that of a cushion or pillow with an almost flat top and rounded sides. It has a scale length of order ~1/2(heater length) and for HP's earliest inkjet heaters this varied from 30 to 55 microns. This means that for almost all times during bubble collapse except for the very end stages (where the advancing liquid front is  ~1 micron off the heater surface) the effects of surface tension can be safely ignored in comparison to the magnitude of the inertial effects.\nAlso note that the momentum of the inrushing liquid creates a huge overpressure or water-hammer effect at the instant the bubble vanishes, and will swiftly pound holes in the protective layer atop the heater, causing it to fail. The walls enclosing the sides of the heater must be carefully shaped to urge the bubble collapse impingement point off the active surface of the heater to avoid this cavitation damage.\nI spent 28 years in the business of designing and building thermal inkjet printheads for HP and have lots more information on inkjet device physics to share if you need it.", "meta": {"post_id": 698471, "input_score": 22, "output_score": 51, "post_title": "Why does the vapour bubble in an inkjet printhead collapse so fast?"}}
{"input": "I was flying over the Atlantic at night in near complete darkness. There was a white, bright full moon. It\u2019s moonglade (the light reflected off the waters surface) was a orange-red color and not white. Is there any explanation for this?\nI\u2019ve attached an image.", "output": "You would probably be about 9 to 12 km high, above the bulk of the atmosphere.  The blue part of the light from the moon is more diffused travelling through the atmosphere and back, leaving the red part to be reflected, whereas the white light directly from the moon to the plane passes through less of the atmosphere and was not diffused, hence did not become reddish.\nThe particular phenomenon that results in reddening of transmitted light is known as Rayleigh scattering. There is more information in this video.\nRed sunlight in the evening is due to the blue part of the light having been diffused out.\nIf the sun is fairly high in the sky, you should see something similar with sunlight reflected in the ocean. From a Google image search, it appears that the sun's reflection appears yellowish.", "meta": {"post_id": 718135, "input_score": 27, "output_score": 36, "post_title": "White full moon reflected orange-red light off of Atlantic Ocean surface. Why is this?"}}
{"input": "I would expect two deuterium nuclei to fuse straight into a single helium-4 nucleus, because that's by far the most stable way to arrange 2 protons and 2 neutrons. But instead, any two fusing deuterons have a 50-50 chance of producing either a tritium nucleus and a neutron or a helium-3 nucleus and a proton. Why is this?", "output": "The deuterium fusion reaction is extremely exothermic. It releases about a million times more energy than a typical chemical reaction, and that energy has to go somewhere. If we had two deuterium nuclei fusing to form a helium-4 nucleus there is nowhere for the energy to go and the helium nucleus would just split up again.\nSo the newly formed helium nucleus has to get rid of all that energy, and there are three ways to do this:\n\nthe helium nucleus could release the energy as a gamma ray and form ${}^4\\mathrm{He}$ directly\n\nthe helium nucleus could release a proton to form ${}^3\\mathrm{H}$. Then the energy is carried away as the kinetic energy of the proton and the ${}^3\\mathrm{H}$ nucleus.\n\nthe helium nucleus could release a neutron to form ${}^3\\mathrm{He}$. Then the energy is carried away as the kinetic energy of the neutron and the ${}^3\\mathrm{He}$ nucleus.\n\n\nBut these three branches have very different probabilities. About 55% of the time reaction (3) occurs and we end up with helium-3. About 45% of the time reaction (2) occurs and we end up with tritium. Reaction (1) happens only about 0.0001% of the time so it's very rare for the fusion to form helium-4 in one step.\nNow the next question is why emitting a photon is so much less probable than emitting a proton or neutron, and as Chris commented below we can answer this in a handwaving way. Creating a photon involves an electromagnetic interaction, while ejecting a proton or neutron requires only a strong force interaction. The EM force is much, much weaker than the strong force so in general any process involving the EM force is much slower than interactions involving the strong force.", "meta": {"post_id": 724694, "input_score": 25, "output_score": 42, "post_title": "Why don't deuterons produce a helium-4 nucleus when they fuse?"}}
{"input": "In quantum field theory electrons are conceptualized as quantized excitations of the quantum electron field. Generically the electron field can be in a superposition of number states. This is related to the fact that under QFT Hamiltonian/Lagrangian energy can be exchanged between electrons and other quantum fields reducing the number of electrons while increasing the number of quantum in other fields.\nHowever, in low energy situations like atomic physics, it is overwhelmingly likely to find the electron field to have a fixed integer number of electron quanta. For example the hydrogen atom always has 1 (and not 1.2 or 1.5) electron quanta and likewise the carbon atom has 12 (and not 12.3 or 11.7) electron quanta.\nNote that this in contrast to the photon field which is regularly found in photon coherent states which are superpositions of photon number states.\nWhy are fixed integer  states with little or no number uncertainty likely for massive quantum fields like the electron field in low energy situations?\nIt may be related to the fact that nuclei are found to have fixed proton numbers so charge neutrality for bound states leads to fixed electron numbers.\nBut this kicks the can down the road. Why don\u2019t we see, for example, a superposition state of multiple proton and electron numbers. Or maybe out differently, why don\u2019t we see stable bound atomic states that are superpositions of H and He atoms?\nDoes this have to do with the fact the electrons and protons are massive?", "output": "This is a good question. It turns out to be several different questions.\n\nFor example the hydrogen atom always has 1 (and not 1.2 or 1.5) electron quanta\n\nThis is not actually true. The hydrogen atom is by definition a charge eigenstate, but an energy eigenstate of hydrogen is only approximately an electron number eigenstate. The approximation is a good one because the atomic energy scale is small compared to the mass-energy of an electron-positron pair. For heavy enough atoms (hand-wavingly, those with $Z\\gtrsim 1/\\alpha$), you can \"spark the vacuum,\" and the uncertainty in particle number is of order unity. My knowledge of QCD is not great, but I believe that, for example, a hydrogen atom does have an uncertainty in quark number that is of order unity.\n\nNote that this in contrast to the photon field which is regularly found in photon coherent states which are superpositions of photon number states.\n\nThere is a number-phase uncertainty relation. Because of this, you can't get a classical field (one whose phase can be measured) made out of fermions. To get coherence, you need to have the density of particles (per unit volume $\\lambda^3$) to be $\\gg 1$, but this is impossible for fermions.\nFor massive neutral bosons, it's possible in principle to have a coherent wave, but because of the number-phase uncertainty relation, it will have to have a large uncertainty in particle number. This means that it has a large uncertainty in energy.\n\nBut this kicks the can down the road. Why don\u2019t we see, for example, a superposition state of multiple proton and electron numbers.\n\nYou can have this, for example, in beta decay. If you prepare the parent nucleus in its ground state, and then wait, the Schr\u00f6dinger equation says that the wave function becomes a mixture of the decayed and undecayed states. (The decayed state includes the emitted beta particle and neutrino.) These states aren't uncommon in any definable objective sense, but normally when we do nuclear physics experiments, we measure the emitted beta particle as our way of detecting that something has happened. Then we get decoherence between the state of the detector that has seen a beta particle and the one that hasn't.\n\nOr maybe out differently, why don\u2019t we see stable bound atomic states that are superpositions of H and He atoms?\n\nThese systems have different baryon numbers. Baryon number is not only conserved, but we also don't have any observables $A$ such that $\\langle \\text{H} | A | \\text{He} \\rangle\\ne0$. Therefore they inhabit different superselection sectors, and we can't make coherent superpositions of them. So there is nothing in quantum mechanics that prohibits the superposition, but the superposition doesn't have any observable consequences, e.g., you can't observe interference effects.", "meta": {"post_id": 730386, "input_score": 23, "output_score": 37, "post_title": "Why, in low energy situations like atomic physics, are massive particles found to be in integer number states?"}}
{"input": "I\u2019m not very good at math but I frequently watch PBS Spacetime on YouTube to try to satisfy my curiosity about physics despite that.\nIn a recent video by Dr Ben Miles titled \u201cHow Physicists Proved the Universe Isn\u2019t Real\u201d, the discussion is of course about quantum entanglement and whether when we don\u2019t measure things, if they really occur in our universe. I have a \u201clayperson\u2019s\u201d interpretation on this topic which I\u2019d like to have validated or corrected:\nMeasurement of course has nothing to do with consciousness - when particles interact, that\u2019s measurement. And systems of interacting particles \u201cresolve\u201d (let\u2019s use that term for wave function collapse, though that \u201ccollapse\u201d notion in itself is I think somewhat disputed) each-other\u2019s position so as to exist as particles rather than probabilities. But not entirely (precisely), as described by HUP.\nSo \u201creal\u201d in this case is really a question of whether systems of interacting particles are \u201cresolved\u201d, which entirely depends on the perspective of the observer. If the observer is in that group of interacting particles (for after-all, what are we but systems of interacting particles, which are, in theory, themselves made up excitations in various fields), from its perspective the interacting particles will be \u201cresolved\u201d, or \u201creal\u201d.\nIs that more or less accurate? At least not egregiously wrong, for a layperson trying to understand the world around them without knowing how to read the equations that describe it more precisely?\nBonus curiosity, admittedly not a well defined question:\nBut what gets confusing to me here, is the definition of \u201cinteracting\u201d. Because entanglement seems as if it must, at least on a larger scale, act as a gradient based on the significance of the interaction. Because how else, in this universe of particles, would some things interact and others not? Even if gravity between two atoms at a large distance is practically zero, the interaction is not truly, absolutely zero, is it? So some immeasurably tiny interaction must occur between all particles. Yet, we can conduct the double slit experiment, so there is some threshold at which the interaction is so small that two distinct behaviors occur.", "output": "First, it's important to clarify two definitions.\n\nThe principle of locality loosely says that interactions occur at individual points in space. If you say that one charged particle at a point $\\mathbf x$ exerts a force on a second charged particle at a point $\\mathbf y$, then that would be a non-local interaction. On the other hand, if you say that one charged particle at $\\mathbf x$ creates a distortion in the electromagnetic field which permeates all of space and that a particle at $\\mathbf y$ feels a force due to that electric field, then you are describing a local interaction.  If a theory obeys the principle of locality, it is called local.\nRealism is the idea that the observable quantities of a system take definite values at each moment in time.  Classical (non-statistical) physics is unambiguously real, insofar as the observables of a system (position, energy, momentum, angular momentum, etc) all have definite values at all times. Most formulations of quantum mechanics (with exceptions like de Broglie-Bohm) dispense with this principle and in a generic state of the system, the observables exist in superposition and do not take definite values.\n\nWith those two definitions out of the way, one may ask whether it is possible that nature can be described by a theory which features both of these properties - such theories are called locally real. Classical mechanics is an example of a locally real theory, but it is known to disagree with experiment. The standard formulation of quantum mechanics is not locally real, but perhaps there is a locally real theory which underlies it, or at least produces the same predictions.\nThe Bell theorem(s) answer this question in the negative. Given some fairly reasonable assumptions, it tells us that if a theory is locally real, then there exist experiments in which they must produce predictions which unambiguously disagree with the predictions made by quantum theory. If such an experiment were performed and the results agree with the predictions of quantum theory, then it follows that whatever theory ultimately describes nature cannot be locally real.\nThe 2022 Nobel prize in Physics was awarded to Clauser, Aspect, and Zeilinger for respectively performing the first practical Bell-type experiment, improving the experiment by closing a potential loophole, and developing more sophisticated experiments which utilize and illustrate the properties of the so-called entangled states which are the origin of the disagreement with any locally real predictions.\n\nIs that more or less accurate?\n\nI would say that your definition of \"real\" isn't quite right. One way to think about it is that realism means that when you make a measurement of a system, you are simply revealing the definite values of observable quantities which already existed before the measurement. If you measure the energy of a particle to be $10\\ \\mathrm{eV}$, then its energy of the particle was $10\\ \\mathrm{eV}$ before you measured it, and your measurement simply revealed that fact.\nOn the other hand, the standard formulation of quantum mechanics would say that the energy of the particle was (generally) indefinite before your measurement, and only assumed a definite value when the measurement was performed. Whether this is due to some kind of wavefunction collapse, entanglement between the system and the measurement device, or something else is not important; the point is that the energy of the particle did not exist as a definite value before the measurement took place.\n\nSo some immeasurably tiny interaction must occur between all particles. Yet, we can conduct the double slit experiment, so there is some threshold at which the interaction is so small that two distinct behaviors occur.\n\nYes, that's true. Entanglement is not binary; the degree of entanglement of a system is quantified by the entanglement entropy, and can take a continuous range of values between totally unentangled and maximally entangled. Tiny interactions between particles produce correspondingly small degrees of entanglement, which may be able to be safely ignored. On the other hand, ostensibly small interactions may cause entangled states to decohere, so they can be very important in understanding how a particular system behaves.\n\n\nSo, since the wave function collapse occurs from the perspective of each respective observer (observer not being a human, but rather an individual particle), and the entanglement can occur as some non-binary gradient space of \"degrees\", to use your term, could we then carry out a double-slit experiment wherein the result is equally non-binary?\n\nIn a sense, yes. Let's imagine that we perform a double slit experiment with electrons as per Feynman's thought experiment (sec. 1-6, \"Watching the Electrons\"). We can label the slits $A$ and $B$, and we can imagine directing a laser toward slit $B$ in such a way that an electron going through slit $B$ will scatter a photon into a detector, thus confirming which route it took to the screen.\nIf the photon energy is high, then the wavelength of the photon will be short. You can imagine that the photon itself is correspondingly small, like a bullet.  In this case, a scattered photon almost certainly means an electron going through slit $B$.\nOn the other hand, if the photon energy is low, then the wavelength of the photon will be large and you can imagine the photon to resemble a big, fuzzy ball. In this case, the photon can't resolve the difference between an electron going through slit $B$ and one going through slit $A$; either one is just as likely to scatter.\nOne loose way to think about entanglement between an electron and the measuring device is that it quantifies how much information the state of the detector gives you about the state of the photon. If the interaction between the two is such that knowing the state of the detector is enough to completely specify the state of the electron, then they are maximally entangled and have high entanglement entropy. On the other hand, if knowing the state of the detector tells you nothing whatsoever about the state of the electron, then they are completely unentangled.\nIn a general case, our double slit experiment will be somewhere in between these two extremes, so we will not see a perfectly pure interference pattern (as we'd expect with no electron/detector entanglement) nor will we see two broad bright spots and no interference pattern (as we'd expect with complete electron/detector entanglement). Feynman's thought experiment is very well explained in the link above, so I would encourage you to read it thoroughly to get more information and intuition than I am providing here (though he does not frame the issue precisely in terms of entanglement).", "meta": {"post_id": 733500, "input_score": 18, "output_score": 36, "post_title": "Is my interpretation of the underlying idea behind this 2022 Nobel Prize story \u201cHow physicists proved the universe isn\u2019t real\u201d more or less accurate?"}}
{"input": "In a racing video game series named Trackmania, there is a game mechanic where when you hit a jump and the car is in mid-air, you can stop the car from pitching downward by tapping on the brakes.\nI am curious if this mechanic has some basis in real physics. What would happen if a car were pitching nose down while in the air, and you hit the brakes thus stopping the rotating wheels. Would that affect the car's pitch, and if so, how?", "output": "It will affect pitch, but not the way it works in the game. In the game, braking while in the air stops your pitch axis rotation. In real life, it does something completely different.\nThe wheels have angular momentum. When the wheels are slowed, this angular momentum must be conserved. This results in a transfer of angular momentum from the wheel to the vehicle.\nSince the wheels are moving clockwise in relation to a vehicle travelling left-to-right (i.e. the top of the wheel is moving toward the front of the car, and the bottom of the wheel is moving toward the rear) the car will also start to rotate clockwise, pitching the nose down. For a car already starting to pitch down after a jump, this will cause it to pitch down even faster, the opposite of what it does in-game.\nWe can even calculate a rough magnitude of the effect!\nFor simplicity, let's state some assumptions:\n\nthis is a rear-wheel drive vehicle with stationary front wheels\nboth rear wheels are moving at the same angular velocity (no slip diff)\nboth rear wheels are the same size and have the same mass\nthe rear axle is a rigid balanced cylinder (i.e. its center of mass is the center of the axle)\nthe brakes bring the wheels to a complete stop\nwe ignore the motion of the driveshaft, flywheel, clutch, gearbox, and other parts of the drivetrain\nwe ignore air resistance, lift, and all other aerodynamics\n\nEach of the two rear wheels can be approximated as a cylindrical mass whose center of mass is the axle joint. The same can be said for the rear driveshaft - it's a long cylinder. As such, the momentum of each of these bodies can be described by spin angular momentum, which is angular momentum about the center of mass. This is in contrast to orbital angular momentum, which is angular momentum about an arbitrary point.\nAngular momentum is expressed as $L=I\\omega$, where $I$ is the angular moment of inertia and $\\omega$ is the angular velocity in radians per second. You can think of the angular moment of inertia as a way to describe the mass distribution of an object about its axis (or axes) of rotation. A cube, a cylinder, and a sphere all have different moments of inertia, and those moments also change depending on where you put the axis of rotation (through the center, on an edge, etc.)\nA cylinder with mass $m$ and radius $r$ rotating about its $z$ axis has an angular moment of inertia described by $I = \\frac 1 2 mr^2$.\n\nAs such, the moment of inertia for each wheel can be approximated by $I = \\frac 1 2 mr^2$, where $m$ is the mass of the wheel and $r$ is the radius of the wheel. The moment of inertia for the axle can be described similarly, since we can model that as a cylinder too.\nGiven that we have two wheels rotating about the same axis, we can think of them as a combined cylinder of the same radius but with twice the mass, which cancels out the $\\frac 1 2$ term. We can then add the moment of inertia for the axle to get the total moment of inertia:\n$$I_T = m_W {r_W}^2 + \\frac 1 2 m_A {r_A}^2$$\n(with $T$ meaning total, $W$ meaning wheels, and $A$ meaning axle)\nThis can then be plugged into the angular momentum equation, $L=I\\omega$, where $\\omega$ is the angular velocity in radians per second.\n$$L = \\omega \\left(m_W {r_W}^2 + \\frac 1 2 m_A {r_A}^2\\right)$$\nIf we assume that the vehicle's wheels have remained at a constant angular velocity since leaving the ground, we can estimate $\\omega$ from the vehicle's land speed at the time of take-off and the radius of the wheel including the tyre.\nOne revolution of the wheel moves the vehicle forward by the circumference of that wheel, and the circumference is $2\\pi r$. If we take the car's velocity in meters per second (1mph \u2248 0.447m/s) and divide it by the wheel circumference, that tells us how many times the wheel was rotating per second. One rotation is 360\u00b0, or $2\\pi$ radians. As such:\n$$\\omega \\approx \\frac {v_C} {2\\pi {r_W}} \\times 2\\pi = \\frac {v_C} {r_W}$$\nWhere $v_C$ is the car's velocity at the point of take-off, and $r_W$ is the wheel radius.\nSubstituting this into our previous equation, we get:\n$$L = \\frac {v_C} {r_W} \\left(m_W {r_W}^2 + \\frac 1 2 m_A {r_A}^2\\right)$$\nWhere $L$ is the angular momentum, $v_C$ is the velocity of the car at take-off (for the purposes of angular velocity estimation), $r_W$ is the radius of the rear wheels including the tyre, $m_W$ is the mass of each of the two rear wheels including the tyre, $m_A$ is the mass of the rear axle, and $r_A$ is the radius of the rear axle.\nFor the sake of simplicity in this worked example, we'll assume that the front wheels aren't spinning, even though in practice it would make sense for the front wheels to be rotating at the same angular velocity as the rear wheels. While it is entirely possible to calculate the resultant angular velocity of the car as a result of both the front and rear wheels, including the case where the front wheels are not facing straight forward, the calculations are much easier to follow in a system with angular momentum being transferred between two bodies in a single axis.\nLet's try a quick test-case:\n\nEach wheel weighs 25 kg including the tyre.\nThe rear wheels have a radius of 25 cm (approximating a 16\" diameter alloy with 2\" thick tyres).\nThe rear axle is 6 cm in diameter and weighs 50 kg.\nThe car was travelling at 40 m/s (roughly 90 mph) when it left the ground.\n\nPlugging these numbers in, we get:\n$$L = \\frac {40~\\mathrm{m~s}^{-1}} {0.25~\\mathrm{m}} \\left(25~\\mathrm{kg} \\times (0.25~\\mathrm{m})^2 + \\frac 1 2 50~\\mathrm{kg} \\times (0.06~\\mathrm{m})^2\\right) = 265.4~\\mathrm{kg}\u22c5\\mathrm{m}^2\u22c5\\mathrm{s}^{-1}$$\nNote that kg\u22c5m2\u22c5s\u22121 are the units for momentum.\nThis is all well and good, but what does this mean in terms of the movement of the car?\nSince angular momentum must be conserved, the change in momentum in the wheels is passed on to the body of the car. The equations we used above can be used in reverse - we can start with angular momentum and a moment of inertia and use it to find the resulting angular velocity!\nHowever, there's a bit of a hitch: the angular momentum isn't being applied at the center of mass of the car, but instead at the location of the rear axle. This means that the car's movement is described by orbital angular momentum, not spin angular momentum. The car also isn't a cylinder, so we need a different equation.\nTo keep things simple, let's imagine the car is a cuboid of uniform mass with the real axle running along one of the bottom edges:\n\nThe moment of inertia for such a cuboid is described by:\n$$I = \\frac {m(a^2 + b^2)} {12}$$\nwhere $m$ is the mass, $a$ is the side of length a in meters, and $b$ is the side of length b in meters.\nWe can now derive the equation for estimating the angular momentum of the car, using $L=I\\omega$:\n$$L_C \\approx \\omega \\times \\frac {m_C(l^2 + h^2)} {12}$$\nwhere $L_C$ is the angular momentum of the car, $\\omega$ is the angular velocity of the car, $m_C$ is the mass of the car, and $l$ and $h$ are the length and height of the car respectively in meters.\nThe equation above is written in terms of $L_C$, so to find the resulting angular velocity of the car we need to rearrange it in terms of $\\omega$:\n$$\\omega \\approx \\frac {L_C} {\\left(\\frac {m_C(l^2 + h^2)} {12}\\right)} = \\frac {12L_C} {m_C(l^2 + h^2)}$$\nLet's continue with our test case by defining the last few parameters:\n\nThe car is approximately 1.25 m tall and 4.75 m long.\nThe car weighs 1600 kg. After subtracting the mass of the wheels and rear axle, that's 1500 kg. (edit: thanks to nitsua60 for pointing out that since the wheels and axle move as part of the car, their mass counts as part of the overall moment of inertia and should not be subtracted)\n\nSince we know that the angular momentum being transferred from the wheels and axle to the car is 265.4 kg\u22c5m2\u22c5s-1, we can now plug everything in:\n$$\\omega \\approx \\frac {12 \\times 265.4~\\mathrm{kg}\u22c5\\mathrm{m}^2\u22c5\\mathrm{s}^{-1}} {1600~\\mathrm{kg} \\times (4.75^2 + 1.25^2)~\\mathrm{m}^2} = 0.0825~\\mathrm{rad/s}$$\nThis is equivalent to 4.73\u00b0/s of nose-down rotation - small, but fairly noticeable!\nThe approximations here are crude, but they give you a good idea of how the conservation of angular momentum results in the downward pitch when the brakes slow down the spinning wheels.\nIt is possible to calculate the system's behaviour more accurately by considering the three-dimensional moment of inertia around the rear axle, angular momentum transfer of the flywheel and drivetrain (the car will tend to tilt slightly to one side as the drivetrain slows), non-uniform mass distribution of the car, air resistance, lift, and other aerodynamic effects, but the calculations are significantly more complicated and beyond the scope of this answer.\n\nAs a final wrap-up point, if you express the conservation of angular momentum between two objects ($a$ and $b$) as a single equation, you can gain some intuition for the behaviour of the objects as a function of their mass, size, and velocity.\n$$I_a\\omega_a = I_b\\omega_b$$\nIf we rearrange for $\\omega_b$ we can see how a change in angular velocity on object $a$ affects the angular velocity of object $b$:\n$$\\omega_b = \\frac {I_a} {I_b} \\omega_a$$\nWhen angular momentum is transferred, the change in angular velocity in object $b$ is a function of the ratio between the two angular moments of inertia. Since the moment of inertia of an object is proportional to its mass and size, a smaller lighter object imparts less angular velocity to a larger heavier object.", "meta": {"post_id": 734513, "input_score": 39, "output_score": 59, "post_title": "Could pressing the brakes on a car in mid-air affect its pitch rotation?"}}
{"input": "Typing my question directly so people know what I am asking, afterwards providing background and context.\nQ: What does it mean when space is falling, faster than light?\n(I am  specifically wondering about just that \"space falling\"  which is what is confusing me the most).\nI mean it does this after it falls inside the horizon of a black hole. (A Schwarzschild black hole to be specific, so a \"static\",\nno electric charge & no spin)\nthis is stated in both the documentary, and in the book(both provided below).\nCiting the book\n\nspace is falling into the black hole. Outside\nthe horizon, space is falling less than the speed of light; at the horizon space is falling at the speed of light;\nand inside the horizon, space is falling faster than light, carrying everything with it. This is why light cannot\nescape from a black hole: inside the horizon, space falls inward faster than light, carrying light inward even if that light is pointed radially outward.\n\n\nGeneral Relativity, Black Holes, and Cosmology by Andrew J. S. Hamilton 4 December 2021 Available here at chapter 7. \"Schwarzschild Black Hole\" section '7.6 Horizon' - page 137\n\n\nAnd, I include a screenshot of this Wikipedia link about the Event horizon of a black hole, which also illustrates this:\n\n\n\nBackground and what I have tried\nBackground\n\nI have no university level education in Physics yet, but I know some terms and have read some articles and books(such as Wikipedia and *edu sites, like jila.colorado.edu).\nAnd I am reading books(like Sean Carroll's \"spacetime and geometry\" intro to general relativity, and Taylor/Wheeler's book as well, and many others). And so I am not completely \"new\" to Physics but, not at all an expert.\nWhat I have tried\n\nBefore asking this question I thoroughly tried to find my question in various, numerous sites(including this one), and books. But didn't find anything that would explain the stating that \"space\" would fall. (excluding the one I typed above)\nBefore this question was asked\nI read other questions and answers on this site, and specifically this question really inspired me how I should write my question, as well as of course first of all I read the following:\n\ndon't-ask\nhow to ask\n\nI want to be very clear that I \"Keep an open mind\", and I try to be on-topic and specific.\nWhich is why I typed the question directly above, and, to be sure it doesn't become a vague or more discussion kind of question, I try to keep things short. Since this is also, my first question.\nCiting the Documentary\nThis documentary about black holes - at timestamp 33:13 Hamilton, Andrew J S  says the following:\n\nspace is falling faster than light\n\nMy question is about just that, and I do know this is from YouTube, which is why I provided the link to the book and checked the topic discussed about in here.\nResources I have tried\n\nIf spacetime can expand faster than the speed of light, then can a black hole do that too?\n\nwhy didn't that article help?\nthe question is about \"spacetime\", whereas my question is about \"space\" itself.\n\n\n\n\nRelated and External links\n\nAndrew Hamilton's Homepage - jila.colorado.edu\nAndrew's book - jila.colorado.edu\nblack_holes - math.ucdr\nCan space expand with unlimited speed? - Physics.stackexchange and sub-links\nFrame-dragging - Wikipedia\nThirring_effect - Wikipedia\nSchwarzschild_metric - Wikipedia\nBlack_hole - Wikipedia", "output": "This is the \"river\" picture of black holes, as Dale said, but I disagree strongly with his statement that it is a \"nice heuristic\".\nRivers flow at a certain speed. If you fall into a river, friction with the water will accelerate you until you're moving at the same speed as the water.\nGravity doesn't work like that at all. Gravity doesn't give you a certain velocity, but a certain acceleration. The time reversal of a river is a river flowing in the opposite direction, but the time reversal of a gravitational field is a gravitational field in the same direction. If you film a ball being tossed in the air and play the film backward, the ball is still attracted toward the earth in the reversed film. Gravity is a conservative, not a dissipative, force. The river picture fails to capture any of those properties.\nThe river picture leads people to wonder why black holes don't just suck up everything around them, and how the space that flows into them is replenished. Those would be reasonable questions if the river picture made sense, but it just doesn't.\nThe river picture is inconsistently used only for black holes when it could equally be applied to any other gravitating body. Black holes are unique in that time symmetry is broken at the event horizon and inside it, but that's irrelevant to the observable behavior of astronomical black holes, which depends only on the physics outside the horizon. The physics outside is time-symmetric, and doesn't fundamentally differ from that of other gravitating bodies. The river picture tries to explain the broken time symmetry by breaking it everywhere, even outside the horizon. But it isn't broken outside the horizon. The explanation is wrong.", "meta": {"post_id": 735441, "input_score": 17, "output_score": 41, "post_title": "Space falling faster than light after it falls inside the event horizon of a black hole?"}}
{"input": "Sunlight reaches the surface of the ocean and refracts. So it is still there. And its speed is about $225000$ km/s in water which is still incredibly fast. Light is a massless electromagnetic wave. So why does it fade away to a complete darkness at very deep parts of the ocean?", "output": "Light is an electromagnetic wave and when it passes through (cold) matter it can be absorbed via reaction with the electrons in the atoms that make up the matter. Typically, the absorption is an all-or-nothing process: an individual photon will interact with an electron (either one in an atom or molecule or, in the case of a metal, a 'free' conduction electron) and will be completely absorbed. To explain the process in detail would require a venture into solid state and quantum physics.\nFor most materials, this happens within a distance in the range of nanometres to millimetres, but even for materials that we typically think of as transparent -- such as air, glass, and water -- the absorption still occurs. Water is relatively transparent in the visible spectrum, particularly for blue light - see the graph below. But even in the purest water, a photon only has about a 50% chance of passing through 50 m of water without being absorbed.\nSo, for example, less than 1/4 of the light that enters water at sea level will reach 100 m depth, less than 1 millionth of it will reach a depth of 1 km, and by the time you reach the deep ocean at several kilometres, the chance of even a single photon arriving from the surface is vanishingly small.\nAbsorption spectrum of liquid water (source):", "meta": {"post_id": 773369, "input_score": 24, "output_score": 53, "post_title": "Why can't sunlight reach the very deep parts of an ocean?"}}
{"input": "I was studying the phenomena of the formation of a rainbow. In my book, the following diagram is given:\n\nSo, the rays at the red end of the spectrum make a larger angle with the incident ray than the rays at the violet end of the spectrum. However, whenever we see a primary rainbow, the red is always on the top.\nWhy is it so? I know there is an obvious explanation and I am surely going wrong somewhere in my understanding. Please help me understand my mistake.", "output": "Yes. It is precisely the larger angle that makes this happen. Because the red is angled \"down\" more the red droplets are the ones located higher in your field of view.", "meta": {"post_id": 774776, "input_score": 31, "output_score": 80, "post_title": "A Rainbow Paradox"}}
{"input": "The 2023 Nobel Prize in Physics was announced today, and it was awarded to Pierre Agostini, Ferenc Krausz and Anne L\u2019Huillier, for\n\n\u201cexperimental methods that generate attosecond pulses of light for the study of electron dynamics in matter\u201d.\n\nThe documents released by the Nobel Foundation along with the announcement (the popular science background  and the more detailed scientific background do a good job of explaining the basics, but:\nwhy are attosecond pulses exciting, and what can you do with them that you cannot do in any other way?", "output": "What's the big deal?\nWhen quantum mechanics was being discovered and formalized, in the 1920s and 1930s, our view of physics was deeply rooted in the macroscopic world. We understood that microscopic entities like atoms and molecules existed, and we arrived reasonably quickly at a good understanding of their basic structure, but for a very long time they were very remote objects, whose behaviour was so abstract and disconnected from our everyday experience that it was even kind of pointless to really interrogate it.\nSo, as an example, if you heated up a vial with sodium, then the gas sample in the vial might emit or absorb light at a particular wavelength, and if you worked out the quantum-mechanical maths then you could predict what those wavelengths should be, in terms of quantum jumps between energy levels $-$ but, could you really say what each individual atom in the gas was doing? How could you be sure that those \"quantum jumps\" were even real, if you only ever had access to the macroscopic gas sample, and never to any individual atom?\nMoreover, that same quantum-mechanical maths predicts that the dynamics in an atom will be blazingly fast, and indeed many orders of magnitude faster than any experimental techniques available at the time. So, could you really talk about the electrons \"moving\"? This was aggravated by the fact that the particular choices of quantum-mechanical maths that made sense for this type of experiment talked much more about \"orbitals\" and \"energy levels\", with those mysterious quantum jumps to link them $-$ so maybe it makes more sense to treat those orbitals and energy levels as the \"real\" objects, and disregard the notion that there is any movement in the micro-world?\nHowever, we live in a very different world now. Not only do we have tools like scanning electron microscopy that allow us to observe the atoms that make up a metal surface, we are also now able to hold and control a single atom with delicate electrical \"tweezers\", which then allows us to interrogate it directly. And when we look, much to our chagrin, that individual atom is indeed performing the fabled quantum jumps. More generally, since the turn of the millenium the name of the game (and indeed the routine) has been the observation and control of individual quantum systems.\nA similar story holds for the dynamics of microscopic systems, and for our ability to observe them directly. The discoveries of the laser, and then Q-switching and mode locking allowed laser pulses to get pretty fast, first faster than a microsecond ($10^{-6}\\:\\rm s$) and then faster than a nanosecond ($10^{-9}\\:\\rm s$), respectively, and work in the 1970s and 1980s allowed us to create pulses as short as a picosecond ($10^{-12}\\:\\rm s$) and shorter. If you really push a laser system, using technology known as Chirped Pulse Amplification (which I wrote about previously here when it won its Nobel Prize), you can get down to a few femtoseconds ($10^{-15}\\:\\rm s$). This is very fast for a pulse of light, and it is actually so fast that the pulse of light is no longer a periodic electric-field oscillation, and instead it lasts only for a few cycles. But it is still not fast enough.\nWhy? Because atoms are even faster.\nTo understand how fast atoms are, it is enough to do some basic dimensional analysis. The dynamics of the electrons inside an atom are governed by the Schr\u00f6dinger equation,\n$$\ni\\hbar \\frac{\\partial \\psi}{\\partial t} = -\\frac{\\hbar^2}{2m_e}\\nabla^2\\psi -\\frac{e^2}{r}\\psi,\n$$\nand this has only three core constants involved: the reduced Planck constant, $\\hbar$, the electron's mass, $m_e$, and the electron charge $e$. (Or, if you work in SI units, the Coulomb constant $e^2/4\\pi\\epsilon_0$.) And, as it turns out, those constants can be combined into a unique timescale, known as the atomic unit of time,\n$$\nt_\\mathrm{a.u.} = \\frac{\\hbar^3}{m_ee^4} = 24\\:\\rm as,\n$$\nwhich is measured in attoseconds: $1\\:\\rm as = 10^{-18}\\:\\rm s$. As a rule of thumb, the dynamics might be somewhat faster, or somewhat slower, depending on the atom and the conditions, but it will generally stick to that rough order of magnitude.\nAnd that means, in turn, that those dynamics might seem completely out of reach, because the period of oscillation of optical light is still rather slower than this. (For light of wavelength $550\\:\\rm nm$, the period is of about $2\\:\\rm fs$.) So that might make you think that a direct observation of something as fast as atomic dynamics must be out of reach.\nSo how do you make an attosecond pulse?\nThis is the real breakthrough that is being rewarded with today's announcement. Our workhorse is a process known as high-harmonic generation, which uses a highly nonlinear interaction between a gas and a pulse of laser light to generate sharp bursts of radiation $-$ the famed attosecond pulses $-$ which can be much shorter than the period of the pulse that drives the process, and can be as short as a few dozen attoseconds.\nFrom an experimental perspective, what you have to do is simply start with a laser pulse with a fairly long wavelength and slow period (usually in the near-infrared), shine it into a gas cell, and make sure that the pulse is intense. How intense? very intense. Intense enough to directly yank electrons out of the gas atoms and shake them about once they're free. (And, indeed, intense enough that the pulse will burn out the laser amplifier if you let it, as explained in the thread about Chirped Pulse Amplification.)\nThis was done in 1987 by a team led by Anne L'Huillier, and the surprising observation was that the gas emitted harmonics, i.e., additional wavelengths of light at sub-multiples of the original driving wavelength. This was known to occur (second-harmonic generation is almost as old as the laser itself), but L'Huillier and colleagues discovered that if the driving pulse is intense enough, it can generate all sorts of harmonics at crazy high orders, with a very slow decline in emission as the order increases. (Up until the signal reaches a cutoff and decays exponentially, of course.)\nWhat's going on? the basic physics was worked out by Paul Corkum (who was very high in the shortlist for getting the Nobel Prize if it ever did get awarded to attosecond science), and it is known as the three-step model.\n\nImage taken from D. Villeneuve, Contemp. Phys. 59, 47 (2018)\nIn essence, the laser can be thought of as a constant force (and therefore a linear ramp in potential energy) which slowly oscillates and tilts around the potential well that the atomic electron sits in. At the maximum of field intensity, this is enough to yank the electron away (though more on this later), at which point the electron will freely oscillate in the field, gaining energy from the electric field of the light ... up until it crashes into the potential well that it just left, at which point it can recombine back with the ion it left behind, and emit its (now considerable) kinetic energy as a sharp burst of radiation.\nThe coolest things about this collision are that it is very energetic (so the burst of radiation has a high photon energy, and therefore very high frequencies), and that it is very short (it is over in a flash), and it is this short duration that means that the pulses of radiation emitted will be extremely short.\nThe other parts of the Nobel Prize are being awarded for the explicit creation and detection of these sharp bursts of light.\n\nOne thing that happens quite often is that (because the driving pulse is long, and has many periods where the three-step model can happen), the emission is often in the shape of an attosecond-pulse train, sometimes with several dozen sharp bursts following each other in quick succession. Pierre Agostini was the first to directly observe the duration of the bursts within such a train, using a technique known as RABBITT (attoscience has since acquired an \"animal theme\" for our acronyms), and his group was able to show that they were indeed very short, down to as little as $250\\:\\rm as$.\n\nAlternatively, you might want to invest some (considerable) time and energy into finding a way to \"gate\" the emission, so that there is only one burst in the train. (For a fresh-off-the-press review of different ways to \"gate\" the emission see e.g. this preprint.) This gating was achieved by Ferenc Krausz's group, who were able to isolate a single pulse with a duration of $650\\:\\rm as$.\n\n\nOf course, the field has continued to innovate, making things more reliable and robust, but also pushing down the shortest duration achievable. If I understand correctly, the current record is $43\\:\\rm as$, which is very, very short.\n(Another cool record is how high you can push the order of nonlinearity in the process, for which, if I understand correctly, a 2012 classic still holds the prize with a minimal order of nonlinearity of 4,500.)\nWhat can you use these pulses for?\nWe're now down to the most interesting part. Say that you have made one of these attosecond pulses. What can you do with it?\nDirectly observing the wave oscillations of light\nFor me, the most exciting application from the \"classic\" experiments in attoscience is a setup known as \"attosecond streaking\".\nThe basic idea is to take a short attosecond pulse, and overlap it, inside a gas sample, with a slower pulse of infrared light.\n\nThe short pulse has enough photon energy to ionize the gas, and we know that this must happen within the duration of the short pulse. After this ionization, the slower infrared pulse has an electric field which oscillates, and this will impact the final energy and momentum of the electron, but the extent of this effect will depend on when the electron is released, so by changing the time delay between the two, we can scan against this electric field.\n$\\qquad$\n\nThe end result, shown above, is a direct observation of the oscillations of the electric field (raw data on the left, and reconstructed electric field on the right), which is a task that was considered somewhere between impossible and unthinkable for many, many decades after we understood that light was a wave (but only had indirect ways to prove it).\nI've discussed this experiment previously here. For more details (and the source of the figures), see the landmark publication:\n\nDirect measurement of light waves. E. Goulielmakis et al. Science 305, 1267 (2004); author eprint.\n\nDirectly observing electron motion in real time\nSimilarly to observing the motion of the electric field of light, we can also observe the motion of electrons inside an atom. I have discussed this in detail in Is there oscillating charge in a hydrogen atom?, but the short story is that if you prepare an electron in a quantum superposition of two different energy levels, such as the combination\n$$\n\\psi = \\psi_{1s} + \\psi_{2p}\n$$\nof the hydrogen $1s$ and $2p$ levels, the charge density in the atom will oscillate over time:\n\nMathematica source through Import[\"http://halirutan.github.io/Mathematica-SE-Tools/decode.m\"][\"https://i.stack.imgur.com/KAbFl.png\"]\nThis is not a hypothetical or purely theoretical construct, and we can directly observe it in experiment. The first landmark test, reported in\n\nReal-time observation of valence electron motion. E. Goulielmakis et al. Nature 466, 739 (2010).\n\nwas able to show a clear oscillation in how much a short pulse was absorbed by an oscillating charge distribution caused by spin-orbit interactions (where different parts of the oscillations correspond to different orientations of the charge density, and therefore to different absorption profiles), showing a clear corresponding oscillation in the absorbance:\n\n\n\nSimilarly, a much-beloved example is the observation of charge oscillation dynamics in a bio-relevant molecule, phenylalanine, which was reported in\n\nUltrafast electron dynamics in phenylalanine initiated by attosecond pulses. F. Calegari et al., Science 346, 336 (2014),\n\nand where the ionization of the molecule by a (relatively) short laser pulse (in the near-infrared) is then probed by a (very) short attosecond burst. The resulting dynamics inside the molecule are fairly complicated,\n\nbut they lead to clear oscillations in the signal (with the graph below showing the overall decay, and the oscillations on top of an exponential background) at a very short timescale that is only observable thanks to the availability of attosecond pulses.\n\nWatching quantum interference build up in real time\nI will do one more direct-timing-of-observation, because I think they're really cool. This one is again about a quantum superposition, but one that happens with a free electron. When you ionize an atom, the electron gets released, and one photon gets absorbed. And, more importantly, the details of the energy states that the electron gets released into will be imprinted into the absorbance spectrum of the light.\nIn particular, it is possible to tune things so that you are ionizing close to a resonance: the electron can either ionize directly, or it can spend some time in a highly-excited autoionizing state (also explained here and here) that will fall apart after some time. The end result is that the electron will go into a superposition of both pathways, which will interfere in its spectrum and cause a wonky, nontrivial shape in the absorption spectrum.\nHowever, if we have short pulses of radiation, we are able to control how long we let the electron to sit in that autoionizing state, before we come in with a second pulse of light to disrupt it, and kill the interference:\n\nAnd indeed, when we do this, the build-up of the line and the development of the interference features (and particularly that sharp dip on the right-hand side of the line) is very clearly seen in experiment:\n\nAnd, just to add some more pretty pictures, here it is all stacked together, on the left-hand figure, and on the right a similar experiment showing very clearly the destructive interference building up over time:\n\n\nFor more details, and the sources of the figures, see\n\nObserving the ultrafast buildup of a Fano resonance in the time domain. A. Kaldun et al. Science 354, 738 (2016)\n\nand\n\nAttosecond dynamics through a Fano resonance: Monitoring the birth of a photoelectron. V Gruson et al. Science 354, 734 (2016)\n\nMoreover, it is also possible to use these types of resonances to enhance high-harmonic generation itself, in a process known as resonant HHG. For a nice review written by a colleague (in a paper I coauthored) see Eur. Phys. J D 75, 209 (2021) (arXiv:2101.09335).\nFurther reading\nLong as this post is, I have only just scratched the surface. Here are some additional places to read more about the field:\n\nAttosecond science. D. Villeneuve, Contemp. Phys. 59, 47 (2018) (author eprint)\n\nAttosecond science. P.B. Corkum & F. Krausz. Nature Physics 3, 381 (2007) (author eprint)\n\nThe physics of attosecond light pulses. P. Agostini & L.F. DiMauro. Reports on Progress in Physics 67, 813 (2004) (author eprint)\n\nAttosecond electromagnetic pulses: generation, measurement, and application. Attosecond metrology and spectroscopy. M.Yu. Ryabikin et al. *Physics-Uspekhi 66, 360 (2023)\n\nShining the shortest flashes of light on the secret life of electrons. M. Khokhlova, E. Pisanty & A. Zair. Advanced Photonics 5, 060501 (2023)", "meta": {"post_id": 782972, "input_score": 154, "output_score": 226, "post_title": "What is an \"attosecond pulse\", and what can you use it for?"}}
{"input": "I'm currently taking a third-year electromagnetism course (we use Griffiths), and we have begun covering approximations of our potential function, $\\text{V} =\\int\\frac{k \\text{dQ}}{\\textbf{||r||}}$, where dQ is the charge distribution that can depend on r. Mainly, we've used both the Taylor Series and the Multipole Expansion to help approximate our potential function at large distances.\nHowever, I'm still very confused about the purpose of using these approximations. What do they tell us that our regular potential function doesn't? Is there something revealing if we use an approximation rather than the potential function? Is it \"easier\" to find the value of the potential using, for example, the Multipole Expansion, rather than just using our regular potential function? Why is the regular potential function not sufficient?\nI haven't had a clear answer to this yet, and I've been told that it's because \"we want something to tell us more than the fact that the potential is 0 when r is very large.\" However, I'm confused why that just isn't the answer? It makes sense that the potential is 0 at a large distance away from a charge distribution, why would it be anything different and how would the approximations give that? For example, in this passage in Griffiths:\n\nHow does an approximation (Taylor or Multipole) give us something \"more informative?\" As far as I'm aware, they will result in 0 anyways at a large distance. For example, Multipole expansion results in terms that depend on and go from $$\\frac{1}{r}, \\frac{1}{r^2}, \\frac{1}{r^3}...$$\nThis, of course, will be 0 at large r, which is what our potential function also shows.\nMoreover, for the Taylor Series, my professor did an example here:\n\n\nFor when z very large and also greater than R, I can see that the potential function goes to 0. Moreover, even after the Taylor Series expansion and the subsequent expression, it still goes to 0 at large z. However, I do admit that the Taylor Series expression does look like a point charge, which is interesting!", "output": "What does the electric potential of a water molecule look like?\n\nImagine a cartoon picture of a water molecule, in which the oxygen atom has charge $-2q$ and sits at the origin and the hydrogen atoms each have charge $q$ and sit at $x=\\pm d\\cos(\\theta), y=0, z=-d\\sin(\\theta)$ with $d\\approx 94$ pm and $\\theta \\approx 52.2^\\circ$.  What does the electric potential look like at distances very large compared to $d$?\nYour question suggests that your response would be \"the potential is basically zero.\" That is extremely unhelpful, however, if I asked my question with the intent of understanding how water molecules interact with one another. Those interactions may or may not be particularly strong, but if I want to understand the nature of them then I need something to work with.\n\"Aha!\" You say, \"I can simply write down the answer:\"\n$$ V(x,y,z) = -\\frac{2q}{4\\pi \\epsilon_0 \\sqrt{x^2+y^2+z^2}}+ \\frac{q}{4\\pi\\epsilon_0\\sqrt{(x-d\\cos(\\theta))^2+y^2+(z+d\\sin(\\theta))^2}}+ \\frac{q}{4\\pi\\epsilon_0\\sqrt{(x+d\\cos(\\theta))^2+y^2+(z+d\\sin(\\theta))^2}}\\tag{$\\star$}$$\nOkay, fair enough. So now, can you tell me how one water molecule interacts with another? Can you compute, for example, the torque that this water molecule applies to another which is located at some other position in a different orientation? In principle, sure. But it's going to be messy, and tedious, and not particularly illuminating.\nIs there a better solution? From your time sitting in calculus classes, you may realize that you could approximate these results assuming that $d$ is small. This might provide a nearly equivalent answer which is far simpler to write down, and gives you vastly more insight into the behavior of water molecules.\nIn particular, notice that\n$$(x\\pm d\\cos(\\theta)^2+y^2+(z+d\\sin(\\theta))^2 = x^2+y^2+z^2 \\pm 2xd\\cos(\\theta)+2zd\\sin(\\theta) + d^2$$\n$$\\equiv r^2\\left(1 \\pm \\frac{2xd}{r^2}\\cos(\\theta) + \\frac{2zd}{r^2}\\sin(\\theta) + \\frac{d^2}{r^2}\\right)$$\nTaking the square root and computing the reciprocal yields\n$$\\frac{1}{r}\\left(1 \\mp \\frac{xd}{r^2}\\cos(\\theta) - \\frac{zd}{r^2}\\sin(\\theta)\\right)$$\nwhere we have approximated $(1+ \\ldots)^{-1/2}$ and neglected $d^2/r^2$, which we take to be far smaller than the terms we have kept. Applying this approximation to each term in the nightmare above yields the following:\n$$V(x,y,z) \\approx -\\frac{2q}{4\\pi\\epsilon_0 r} + \\frac{q}{4\\pi\\epsilon_0 r}\\left(1- \\frac{xd}{r^2}\\cos(\\theta) - \\frac{zd}{r^2}\\sin(\\theta)\\right)$$\n$$+\\frac{q}{4\\pi\\epsilon_0 r}\\left(1 + \\frac{xd}{r^2}\\cos(\\theta) - \\frac{zd}{r^2}\\sin(\\theta)\\right)$$\n$$= \\frac{(-2q + q + q)}{4\\pi \\epsilon_0 r} - \\frac{2qzd\\sin(\\theta)}{4\\pi \\epsilon_0 r^3}$$\nHopefully you agree that this is a vast improvement in clarity. Things are improved further by noting that the first term cancels out because the total charge of the molecule is $-2q+q+q=0$, leaving\n$$V(x,y,z)\\approx \\frac{\\mathbf p \\cdot \\mathbf r}{4\\pi \\epsilon_0 r^3}\\tag{$\\star\\star$}$$\nwhere $\\mathbf p \\equiv -(2q)d\\sin(\\theta) \\hat z$ is the molecule's dipole moment. I'm sure you will agree that $(\\star\\star)$ is vastly preferable to $(\\star)$ both in conceptual clarity and computational efficiency - and for $d\\ll r$, the difference between them is a small fraction of a percent.\nWhat we've actually done is compute the first two terms of the multipole expansion, which formalizes what we did by hand and makes it very efficient. The monopole contribution vanishes because the net charge is zero, but the dipole moment is nonzero and so the second term in the expansion survives (as do others, but they are much smaller at large distances). We can now use it to answer my questions from before:\n\nCan you compute, for example, the torque that this water molecule applies to another which is located at some other position in a different orientation?\n\nSure. The electric field due to the dipole is\n$$\\mathbf E = -\\nabla V = -\\frac{\\mathbf p}{4\\pi\\epsilon_0r^3} + \\frac{3(\\mathbf p \\cdot \\mathbf r)\\mathbf r}{4\\pi \\epsilon_0 r^5}$$\n(have fun calculating that for $(\\star)$). An elementary result tells us that the torque on a second dipole $\\mathbf p'$ is\n$$\\boldsymbol{\\tau} = \\mathbf p' \\times \\mathbf E = -\\frac{\\mathbf p'\\times \\mathbf p}{4\\pi \\epsilon_0 r^3} + \\frac{3(\\mathbf p\\cdot \\mathbf r)(\\mathbf p' \\times \\mathbf r)}{4\\pi \\epsilon_0 r^5}$$\n\ncan you tell me how one water molecule interacts with another?\n\nEach water molecule creates an approximate dipole field, and other molecules feel a torque which encourages them to align with that dipole field. Two isolated water molecules will therefore seek to align with one another (this is part of hydrogen bonding), and networks of water molecules will assume a configuration which most effectively aligns them with one another (which results in the crystalline structure of ice).", "meta": {"post_id": 786488, "input_score": 20, "output_score": 39, "post_title": "Purpose of Using Taylor Series and Multipole Expansion to Approximate Potential"}}
