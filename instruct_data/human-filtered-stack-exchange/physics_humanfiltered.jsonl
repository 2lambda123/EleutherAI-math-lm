{"input": "I have been studying scattering theory in Sakurai's quantum mechanics.  The phase shift in scattering theory has been a major conceptual and computational stumbling block for me.\nHow (if at all) does the phase shift relate to the scattering amplitude?\nWhat does it help you calculate?\nAlso, any literature or book references that might be more accessible than Sakurai would be greatly appreciated.", "output": "Suppose you treat scattering of a particle in a central potential. This means that the Hamiltonian $H$ commutes with the angular momentum operators $L^2$ and $L_z$. Hence, you can find simultaneous eigenfunctions $\\psi_{k,l,m}$. \nYou might know, for example from the solution of the hydrogen atom, that these functions can be expressed in terms of the spherical harmonics:\n$$\\psi_{k,l,m}(x) = R_{k,l}(r) \\Psi_m^l(\\theta, \\varphi)$$\nwhere the radial part satisfies\n$$\\frac{1}{r^2} \\frac{d}{dr} \\left( r^2 \\frac{dR_{k,l}}{dr}\\right)\n+\\left(n^2 - U(r) - \\frac{l(l+1)}{r^2}\\right) R_{k,l} = 0$$\nwith $U(r) = 2m/\\hbar^2 V(r)$, your central potential, and $k$ is the particle's wavenumber, i.e., $E = \\frac{\\hbar^2 k^2}{2m}.$\nThe first step is to look for a special case with simple solutions. This would be the free particle, with $U(r) = 0$. Then, the radial equation is a special case of Bessel's equation. The solutions are the spherical Bessel functions $j_l(kr)$ and $n_l(kr)$, where the $j_l$ are regular at the origin whereas the $n_l$ are singular at the origin. Hence, for a free particle, the solutions are superpositions of the $j_l$:\n$$\\psi(x) = \\sum_{l,m} a_{l,m} j_l(kr) Y^l_m(\\theta, \\varphi)$$\nIf we also have axial symmetry, only $m = 0$ is relevant. Then we can rewrite the spherical harmonics using Legendre polynomials. This will lead to\n$$\\psi(x) = \\sum_{l,m} A_{l} j_l(kr) P_l(\\cos \\theta)$$\nOne important special case of such an expansion is the Rayleigh plane wave expansion\n$$e^{ikz} = \\sum_l (2l+1) i^l j_l(kr) P_l(\\cos\\theta)$$\nwhich we will need in the next step.\nWe move away from free particles and consider scattering from a potential with a finite range (this excludes Coulomb scattering!). So, $U(r) = 0$ for $r > a$ where $a$ is the range of the potential. For simplicity, we assume axial symmetry. Then, outside the range, the solution must be again that of a free particle. But this time, the origin is not included in the range, so we can (and, in fact, must) include the $n_l(kr)$ solutions to the Bessel equations:\n$$\\psi(r) = \\sum_l (a_l j_l(kr) + b_l n_l(kr)) P_l(\\cos \\theta)$$\nNote how the solution for a given $l$ has two parameters $a_l$ and $b_l$. We can think of another parametrization: $a_l = A_l \\cos\\delta_l$ and $b_l = -A_l \\sin \\delta_l$. The reason for doing this becomes apparent in the next step:\nThe spherical Bessel functions have long range approximations:\n$$j_l(kr) \\sim \\frac{\\sin(kr - l\\pi/2)}{kr}$$\n$$n_l(kr) \\sim \\frac{\\cos(kr - l\\pi/2)}{kr}$$\nwhich we can insert into the wavefunction to get a long range approximation. After some trigonometry, we get\n$$\\psi(r) \\sim \\sum_l \\frac{A_l}{kr} \\sin(kr - l\\pi/2 + \\delta_l) P_l(\\cos \\theta)'$$\nSo, this is what our wavefunction looks like for large $r$. But we already know how it should look: if the incoming scattered particle is described as a plane wave in $z$-direction, it is related to the scattering amplitude $f$ via\n$$\\psi(\\vec{x}) \\sim e^{ikz} + f(\\theta) \\frac{e^{ikr}}{r}.$$\nObviously, both forms for writing down a long-range approximation for $\\psi$ should give the same, so we use the Rayleigh plane wave expansion to rewrite the latter form. We also rewrite the $\\sin$ function using complex exponentials. The ensuing calculations are a bit tedious, but not complicated in itself. You just insert the expansions. What we can do afterwards is comparing the coefficients in both expressions for the same terms, e.g. equation the coefficients for $e^{-ikr}P_l(\\cos\\theta)$ will give you\n$$A_l = (2l+1)i^l e^{i\\delta_l}$$\nwhereas equating coefficients for $e^{ikr}$ gives you\n$$f(\\theta) = \\frac{1}{2ik} \\sum_l (2l+1) \\left( e^{2i\\delta_l} - 1 \\right) P_l(\\cos \\theta).$$\nInterpretation of the Phase Shift: Remember the long range limit of the wavefunction. It led to an expression for the $l$-th radial wavefunction in the long-range of\n$$u_l(r) = kr\\psi_l(r) \\sim A_l \\sin(kr - l\\pi/2 +\\delta_l).$$\nFor a free particle, the phase shift $\\delta_l$ would be $0$. One could therefore say that the phase shift measures how far the asymptotic solution of your scattering problem is displaced at the origin from the asymptotic free solution.\nInterpretation of the Partial Wave Expansion: In the literature, you will often come across terms such as $s$-wave scattering. The partial wave expansion decomposes the scattering process into the scattering of incoming waves with definite angular momentum quantum number. It explains in which way $s$-, $p$-, $d$-waves etc. are affected by the potential. For low energy scattering, only the first few $l$-quantum numbers are affected. If all but the first term are discarded, only the $s$-waves take part in the scattering process. This is an approximation that is, for example, made in the scattering of the atoms in a Bose-Einstein condensate.", "meta": {"post_id": 8132, "input_score": 39, "output_score": 53, "post_title": "Phase shifts in scattering theory"}}
{"input": "What is the difference between implicit, explicit, and total time dependence, e.g. $\\frac{\\partial \\rho}{\\partial t}$ and $\\frac{d \\rho} {dt}$?\nI know one is a partial derivative and the other is a total derivative. But physically I cannot distinguish between them. I have a clue that my doubt really might be understanding the difference between implicit, explicit and  total time dependence.", "output": "I usually explain it this way:\n$$\\rho = \\rho(t,x(t),p(t))$$\n$$\\frac{\\partial\\rho}{\\partial t} = \\lim_{\\Delta t \\to 0} \\frac{\\rho(t+\\Delta t,x(t),p(t))-\\rho(t,x(t),p(t))}{\\Delta t}$$\n$$\\frac{d\\rho}{d t} = \\lim_{\\Delta t \\to 0} \\frac{\\rho(t+\\Delta t,x(t+\\Delta t),p(t+\\Delta t))-\\rho(t,x(t),p(t))}{\\Delta t}$$", "meta": {"post_id": 9122, "input_score": 60, "output_score": 66, "post_title": "What is the difference between implicit, explicit, and total time dependence, e.g. $\\frac{\\partial \\rho}{\\partial t}$ and $\\frac{d \\rho} {dt}$?"}}
{"input": "A similar question was asked here, but the answer didn't address the following, at least not in a way that I could understand.\nElectric charge is simple - it's just a real scalar quantity. Ignoring units and possible quantization, you could write $q \\in \\mathbb{R}$. Combination of electric charges is just arithmetic addition: $ q_{net} = q_1 + q_2 $.\nNow to color charge. Because there are three \"components\", I am tempted to conclude that color charges are members of $\\mathbb{R}^3$. However, I've read that \"red plus green plus blue equals colorless\", which seems to rule out this idea. I can only think that either:\n\nred, green and blue are not orthogonal, or\n\"colorless\" doesn't mean zero color charge (unlikely), or\ncolor charges don't combine in a simple way like vector addition\n\nIn formulating an answer, please consider that I know some mathematics (vectors, matrices, complex numbers, calculus) but almost nothing about symmetry groups or Lie algebras.", "output": "Color charge is the representation of the SU(3) gauge group. The representation theory of SU(3) is described below:\nThe basic representation is called the \"3\" or the fundamental, or defining, representation. It is a triplet of complex numbers $V^i$, which transform under a 3 by 3 SU(3) matrix by getting multiplied by the matrix. The value of \"i\" is sometimes called \"red\",\"green\",\"blue\", so that a quark which is all in the $V^1$ direction is red, etc. This is reasonable, because every fundamental representation vector is a linear combination with complex coefficient of red-green-blue.\nHermann Weyl proved that every other representation occurs somewhere among the tensors: $V^{i_1,i_2 .. i_n}_{j_1,j_2,...,j_m}$ where the upper indices transform by multiplying the index by the SU(3) matrix, and lower indices by multiplying by the conjugate matrix, which is also the inverse. Addition of representations is just like addition of angular momentum in quantum mechanics, by taking tensor products.\nWarm-up: Quick Representations SU(2)\nFor SU(2), the invariant tensors are $\\delta^i_j$, $\\epsilon_{ij}$, and $\\epsilon^{ij}$, which are trace and two-dimensional volume. You can raise and lower indices using $\\epsilon$ tensors, so every tensor representation is equivalent to one with all the indices down. Any three antisymmetric indices are necessarily zero, and any two antisymmetric indices can be deleted by contracting them with the appropriate epsilon tensor. So there are only clumps of symmetric indices in a representation.\nThe irreducible representations are exhausted by the fully symmetric tensors with all indices down:\n$$ T_{i_1, i_2 , .... i_n}$$\nBecause when you multiply two of these, you get a tensor\n$$ T_{i_1, i_2,....,i_n;j_1, j_2, ... j_n'}$$\nwith symmetry on permuting the first n indices and the last n' indices. I will write this as (n,n'). By contracting the $\\epsilon$ tensor on one of the i's and one of the j's (they all give the same result because they are symmetric), you extract an (n-1,n'-1) representation from this. The remainder is fully symmetric on n+n' indices, because you have removed the antisymmetric part. The result is the decomposition\n$$(n,n') = (n+n') + (n-1,n'-1)$$\nSo that, recursively, the tensor product of (n) and (n') decomposes into\n$$(n+n'), (n+n'-2), (n+n'-4), ... (1) or (0)$$\nwhere the last term is 1 if n+n' is odd, or 1 if n+n' is even. If you recognize that the n-index totally symmetric tensor with two possible values for each index has exactly n+1 different components, you realize that the (n) representation is just the spin (n/2) representation, and the decomposition above is the familiar Clebsch-Gordon series for addition of quantum angular momentum.\nThe tensorial method is never taught for some reason, but it is the quickest way to do Clebsch-Gordon decompositions in real life.\nBack to SU(3)\nSU(3) transformations preserve inner products, and 3-dimensional complex volumes, so there are three basic invariant tensors, $\\delta^i_j$, $\\epsilon_{ijk}$, and $\\epsilon^{ijk}$. The $\\epsilon$ tensors allow you to take the antisymmetric part on any two upper indices and turn it into a lower index, or the anyisymmetric part of two lower indices and turn it into an upper index.\nThe irreducible representations of SU(3) are all tensors\n$$ T^{i_1,i_2,....,i_n}_{j_1,j_2,...,j_m}$$\nwhich are fully symmetric on the upper indices, and fully symmetric on the lower indices. To see this, call this representation (n;m), and tensor two such representations to produce\n$$(n,n';m,m')$$\nWhich means n totally symmetric upper indices followed by n' totally symmetric upper indices, and m totally symmetric lower indices followed by m' totally symmetric lower indices.\nThen, acting the epsilon tensor between the n and n' clump produces\n$$(n,n'; 1,m,m')$$\nleaving behind $(n+n';m,m')$, since it takes away the antisymmetric part. The recursive rule is as ollows\n$$(n_1,...,n_k; m_1,,...,m_k) \\rightarrow $$\n$$ (n_1+n_2,n_3,...,n_k;m_1,...,m_k) \r\n \\oplus (n_1-1,n_2-1,n_3,...n_k; 1, m_1, ...,m_k)$$\n$$(n_1,...,n_k; m_1,....,m_k) \\rightarrow$$\n$$ (n1,...,n_k; m_1+m_2,m_3,...,m_k)\r\n\\oplus (1,n_1,...,n_k;m_1-1,m_2-1,...,m_k)$$\nThese rules correspond to acting with the two epsilon tensors, and they terminate on terms of the form (n;m) in a finite number of steps, because either thing on the right hand side either has a smaller number of clumps, or a smaller sum of indices. Decomposing the traces out of (n;m) gives all the irreducible representations.\nRemoving the traces\nAfter you reduce the tensors to (n;m), you get rid of all the trace parts, by subtracting $\\delta^i_j$ times an (n;m) tensor. This turns every (n,m) of the previous section into a series of trace-reduced (n-k;m-k) parts which go from k=0 to k=min(m,n). These tensors are the true irreducible representations.\nThe color charge is defined as the representation of SU(3) of the colored object. The representation is indexed by (n,m). The color-charge of an instance of the actual object is an n-list of rgb-rgb-..rgb values, where the order doesn't matter, and an m-list of cmy-cmy...-cmy colors, where the order doesn't matter. These are the basic colors, and you superpose them with arbitrary complex numbers, but imposing the trace condition, which is a little hard to state in RGB language--- it says that the sum of (r,LIST;c,LIST) + (g,LIST;m,LIST') + (b,LIST;y,LIST') is zero for any colors in LIST and LIST'.\nTo add two color charges, you use the procedure above for tensor products. The sum of two color charges is a complicated mixture of color-charges, given by decomposing the tensor representation.\nThese rules are relatively complicated, so be thankful that the only fundamental color representations in the world are quark fundamental triplets, and gluon one-up-index, one-down-index traceless tensors, and that all hadrons are singlets.", "meta": {"post_id": 10403, "input_score": 29, "output_score": 39, "post_title": "Mathematically, what is color charge?"}}
{"input": "I am following the first volume of the course of theoretical physics by Landau. So, whatever I say below mainly talks regarding the first 2 chapters of Landau and the approach of deriving Newton's laws from Lagrangian principle supposing Hamilton's principle of extremum action. Please keep this view in mind while reading and answering my queries and kindly neglect the systems to which Action Principle is not applicable:\nIf we use homogeneity of space in Euler-Lagrange equations, we obtain a remarkable result i.e. the conservation of momentum for a closed system.\nNow, this result, using the form of Lagrange for a closed system of particles, transforms into $ \\Sigma F = 0 $ . Now, how from this can we conclude that the internal forces that particles exert come in equal and opposite pairs?\nIs it because for 2 particles this comes out as $ F_{1} + F_{2} = 0 $ and we take the forces exerted by particles on one other to be independent of other particles (i.e. Superposition Principle) as an experimental fact?\nI doubt it as whole of Newtonian Mechanics is derivable from Lagrangian Mechanics and supposed Symmetries. So, according to me, a fact like Newton's Third Law should be derivable from it without using an additional experimental fact.\nI have an idea to prove it rigorously. Consider two particles $i$ and $j$. Let the force on $i$ by $j$ be $F_{ij}$ and on $j$ by $i$ be $k_{ij}F_{ij}$. Now the condition becomes $\\Sigma (1+k_{ij})F_{ij}=0$ where the terms to be included and rejected in summation understood. As this must be true for any value of $F_{ij}$, we get $k_{ij}=-1$. I don't know if this argument or refinement of such an argument holds or not. I can see many questions arising in this argument and it's not very convincing to me.\nI would like to hear from you people as to if it is an experimental result used or not? If not, then is the method given above right or wrong? If wrong, how can we prove it?\nAddendum\nMy method of proof uses the fact of superposition of forces itself, so it is flawed. I have assumed that the coefficients $k_{ij}$ are constants and don't change in the influence of all other particles which is exactly what superposition principle says.\nAs the superposition of Forces can be derived by superposition of potential energies at a point in space and potential energy being more fundamental in Lagrangian Mechanics, I restate my question as follows:\nIs the principle of superposition of potential energies by different sources at a point in space derivable from the inside of Lagrangian Mechanics or is it an experimental fact used in Lagrangian Mechanics?\nI, now, doubt this to be derivable as the fundamental assumption about potential energy is only that it is a function of coordinates of particles and this function may or may not respect superposition.", "output": "The derivation in Landau and Lifschitz is making some additional implicit assumptions. They assume that all forces come from pair-interactions, and that the pair forces are rotationally invariant. With these two assumptions, the potential function in the Lagrangian is\n$$V(x_1,\\ldots,x_n) = \\sum_{\\langle i,j\\rangle} V(|x_i - x_j|)$$\nAnd then it is easy to prove Newton's third law, because the derivative of the distance function is equal and opposite for each pair of particles.\nThis type of derivation is reasonable from a physical point of view for macroscopic objects, but it is not mathematically ok, because it omits important examples.\nNo rotational invariance, no third law\nDropping the assumption of rotational invariance, but keeping the assumption of pair-wise interaction, one gets the following counterexample in 2 dimensions, with two particles (A,B) with position vectors $(A_x,A_y)$ $(B_x,B_y)$ respectively:\n$$V(A_x,A_y,B_x,B_y) = f(A_x-B_x) + f(A_y - B_y) $$\nwhere $f$ is any function other than $f(x)=x^2$. This pair potential leads to equal and opposite forces, but not collinear ones. Linear momentum and energy are conserved, but angular momentum is not, except when both particles are on the lines $y=\\pm x$ relative to each other. The potential is un-physical of course, in the absence of a medium like a lattice that breaks rotational invariance.\nMany-body direct interactions, no reflection symmetry, no third law\nThere is another class of counterexamples which is much more interesting, because they do not break angular momentum or center of mass conservation laws, and so they are physically possible interactions in vacuum, but they do break Newton's third law. This is the chiral three-body interaction.\nConsider 3 particles A,B,C in two dimensions whose potential function is equal to the signed area of the triangle formed by the points A,B,C.\n$$V(A,B,C) = B_x C_y - A_x C_y -B_x A_y - C_x B_y + C_x A_y + A_x B_y$$\nIf all 3 particles are collinear, the forces for this 3-body potential are perpendicular to the common line they lie on. The derivative of the area is maximum by moving the points away from the common line. So you obviously cannot write the force as any sum of pairwise interactions along the line of separation, equal and opposite or not. The forces and torques still add up to zero, since this potential is translationally and rotationally invariant.\nMany body direct interaction, spatial reflection symmetry, crappy third law\nIf the force on k particles is reflection invariant, it never gets out of the subspace spanned by their mutual separation. This is because if they lie in a lower dimensional subspace, the system is invariant with respect to reflections perpendicular to that subspace, so the forces must be as well.\nThis means that you can always cook up equal and opposite forces between the particles that add up to the total force, and pretend that these forces are physically meaningful. This allows you to salvage Newton's third law, in a way. But it gives nonsense forces.\nTo see that this is nonsense, consider the three-particle triangle area potential from before, but this time take the absolute value. The result is reflection invariant, but contains a discontinuity in the derivative when the particles become collinear. Near collinearity, the forces perpendicular have a finite limit. But in order to write these finite forces as a sum of equal and opposite contributions from the three-particles, you need the forces between the particles to diverge at collinearity.\nThree body interactions are natural\nThere is natural physics that gives such a three-body interaction. You can imagine the three bodies are connected by rigid frictionless struts that are free to expand and contract like collapsible antennas, and a very high-quality massless soap bubble is stretched between the struts. The soap bubble prefers to have less area according to its nonzero surface tension. If the dynamics of the soap bubble and the struts are fast compared to the particles, you can integrate out the soap bubble degrees of freedom and you will get just such a three-body interaction.\nThen the reason the bodies snap together near collinearity with a finite transverse force is clear--- the soap bubble wants to collapse to zero area, so it pulls them in. It is then obvious that there is no sense in which they have any diverging pairwise forces, or any pairwise forces at all.\nOther cases where you get three body interactions directly is when you have a non-linear field between the three objects, and the field dynamics are fast. Consider a cubically self-interacting massive scalar field (with cubic coupling $\\lambda$) sourced by classical stationary delta-function sources of strength g. The leading non-linear contribution to the classical potential is a tree-level, classical, three-body interaction of the form\n$$V(x,y,z) \\propto g^3 \\lambda \\int \\,\\mathrm d^3k_1\\mathrm  d^3k_2 { e^{i(k_1\\cdot (x-z) + k_2\\cdot(y-z))} \\over (k_1^2 + m^2) (k_2^2 + m^2)((k_1+k_2)^2 + m^2)}$$\nwhich heuristically goes something like ${e^{-mr_{123}}r_{123}\\over r_{12}r_{23}r_{13}}$ where the r's are the side lengths of the triangle and $r_{123}$ is the perimeter (this is just a scaling estimate). For nucleons, many body potentials are significant.\nThe forces from the crappy third law are not integrable\nIf you still insist on a Newton's third law description of three-body interactions like the soap bubble particles, and you give a pairwise force for each pair of particles which adds up to the full many-body interaction, these pairwise forces cannot be thought of as coming from a potential function. They are not integrable.\nThe example of the soap-bubble force makes it clear--- if A,B,C are nearly collinear with B between A and C, closer to A, you can slide B away from A towards C very very close to collinearity, and bring it back less close to collinear. The A-B force is along the line of separation, and it diverges at collinearity, so the integral of the force along this loop cannot be zero.\nThe force is still conservative of course, it comes from a three-body potential after all. This means that the two-body A-B force plus the two-body B-C force is integrable. It's just that the A-C two body force is not. So the separation is completely silly.\nAbsence of multi-body interactions for macroscopic objects in empty space\nThe interactions of macroscopic objects are through contact forces, which are necessarily pairwise since all other contacts are far away, and electromagnetic and gravitational fields, which are very close to linear at these scales. The electromagnetic and gravitational forces end up being linearly additive between pairs, and the result is a potential of the form Landau and Lifschitz consider--- pairwise interactions which are individually rotationally invariant.\nBut for close packed atoms in a crystal, there is no reason to ignore 3-body potentials. It is certainly true that in the nucleus three-body and four-body potentials are necessary, but in both cases you are dealing with quantum systems.\nSo I don't think the third law is particularly fundamental. As a philosophical thing, that nothing can act without being acted upon, it's as valid as any other general principle. But as a mathematical statement of the nature of interactions between particles, it is completely dated. The fundamental things are the conservation of linear momentum, angular momentum, and center of mass, which are independent laws, derived from translation invariance, rotational invariance, and Galilean invariance respectively. The pair-wise forces acting along the separation direction are just an accident.", "meta": {"post_id": 12122, "input_score": 25, "output_score": 41, "post_title": "Deriving Newton's Third Law from homogeneity of Space"}}
{"input": "I have very little background in physics, so I apologize if this question is painfully naive.\nConsider the following thought experiment: an observer is in a closed room whose walls, floor, and ceiling are made entirely of mirrors, with a single light source in the middle of the room. When the light is on, the observer can see many copies of his reflection all over the place.\nSuddenly, the light source turns itself off. Intuitively, I would expect the observer to \"instantly\" see darkness. However, I can't figure out why that is the case under the \"particle\" interpretation of light. There are obviously lots of photons already in the room from before. Furthermore, we know that they don't get \"consumed\" when they hit a wall, because otherwise the observer wouldn't see so many reflections of himself. Basically, when the light goes off, what happens to the photons already in the room?\nI suspect the answer goes something like this: the photons in the room lose a little bit of energy every time they bounce off a mirror, but it's so minuscule that we can still see more reflections than our eye can resolve anyway. When the light goes off, however, it takes them a very small fraction of a second to bounce around the room enough times to diffuse completely, which our eye cannot detect.\nIs that about right? If we had a theoretical \"perfect reflector\", would the light remain trapped in the room forever? If we had instruments that could measure such things very finely, would it take (slightly) longer for the light to go out in a room made of mirrors as opposed to a room made of, say, black cloth?", "output": "When being reflected by a mirror, the photons do not lose \"a tiny bit\" of energy. Either they are reflected unchanged, or they are completely absorbed. A good mirror will reflect most of the photons, but will absorb a small fraction of them as well, say $0.1\\%$ of them. \nThat is: Your photons don't lose energy over time; what happens is that the room loses photons over time: For each time a photon hits a wall, there is some probability $p$ that it will get absorbed (\"consumed\"). The chance that it doesn't get consumed after $N$ hits is $(1-p)^N$. Since the photons are very fast, they'll bounce off the walls very often in a short amount of time, so $N$ becomes really large really quick, and then $(1-p)^N$ becomes really small pretty fast, so after a short amount of time, all photons have been consumed with very high probability. \nAn important property of photons, that might not be entirely intuitive when coming from a \"wave\" background: The energy of an individual photon is determined entirely by the frequency of the light. Blue photons have higher energy than red photons. The intensity of light is determined not by the energy of your photons, but by their number. \nIf the photons would lose energy each time they bounce off a mirror, the reflections would change their color gradually, so that eventually blue light becomes red, then infrared etc. That doesn't happen: The mirrors don't change the color of the light. They only swallow some of the photons, i.e. they reduce the intensity.\nWith perfect mirrors, you could indeed expect to never lose any photons. But since anyone looking at the photons also absorbs then, the room would still get dark eventually. Unless there's nobody in there. \nTo be overly pedantic: Unless you keep the walls at zero temperature, you will always have some photons in the room as blackbody radiation. At \"normal\" temperatures, these photons are mostly in the infrared range, but if you make it really hot, the walls will start glowing.", "meta": {"post_id": 13500, "input_score": 29, "output_score": 42, "post_title": "How are photons \"consumed\"?"}}
{"input": "I've read many times, including here on this very site that the commonly known explanation of flight is wrong, and that airplanes can fly because the shape of their wings deflects air down. This makes sense, but as far as I can tell it doesn't explain upside down flight or symmetric wings.\nThe images I've seen show an inclined wing, which forces the air to go downwards. But how can planes fly upside down then?", "output": "Upside-down or right side up, flight works the same way. As you stated, the wing deflects air downward. When inverted, the pilot simply controls the the pitch of the aircraft to keep the nose up, thus giving the wings sufficient angle of attack to deflect air downwards.\nMost airplanes are designed with some positive angle of attack \"built-in,\" meaning that there is some angle between the wings and the fuselage so that the wings have a small positive angle of attack while the fuselage is level. This is why the floor isn't tilted tailwards when you're in an airliner in level flight. So when upside down the nose has to be held a bit higher than usual, and the other flight systems (including the pilot!) must be designed to handle it, but there is nothing really special about upside-down flight.", "meta": {"post_id": 15981, "input_score": 47, "output_score": 42, "post_title": "How can airplanes fly upside down?"}}
{"input": "The sun is made of fire but fire needs oxygen right? So.. \n\nWhy can there be flames in space, while there's no oxygen? \nSame idea as with the rocket engines of the spaceship, which also produce fire while there's no oxygen?", "output": "The Sun isn't \"made of fire\".  It's made mostly of hydrogen and helium.  Its heat and light come from nuclear fusion, a very different process that doesn't require oxygen.  Ordinary fire is a chemical reaction; fusion merges hydrogen nuclei into helium, and produces much more energy.  (Other nuclear reactions are possible.)\nAs for rockets, they carry both fuel and oxygen (or another oxidizer) with them (at least chemical rockets do; there are other kinds).  That's the difference between a rocket engine and a jet engine; jets carry fuel, but get oxygen from the air.", "meta": {"post_id": 26628, "input_score": 17, "output_score": 39, "post_title": "Why can there be fire in space while there is no oxygen?"}}
{"input": "The purpose of this question is to ask about the role of mathematical rigor in physics. In order to formulate a question that can be answered, and not just discussed, I divided this large issue into five specific questions.\nUpdate February, 12, 2018: Since the question was put yesterday on hold as too board, I ask future to refer only to questions one and two listed below. I will ask a separate questions on item 3 and 4. Any information on question 5 can be added as a remark. \n\n\nWhat are the most important and the oldest insights (notions, results) from physics that are still lacking rigorous mathematical\n  formulation/proofs.\nThe endeavor of rigorous mathematical explanations, formulations, and proofs for notions and results from physics is mainly taken by\n  mathematicians. What are examples that this endeavor was beneficial to\n  physics itself.\n\n\n\nWhat are examples that insisting on rigour delayed progress in physics.\nWhat are examples that solid mathematical understanding of certain issues from physics came from further developments in physics itself. (In particular, I am interested in cases where mathematical rigorous understanding of issues from classical mechanics required quantum mechanics, and also in cases where progress in physics was crucial to rigorous mathematical solutions of questions in mathematics not originated in physics.)\nThe role of rigor is intensely discussed in popular books and blogs. Please supply references (or better annotated references) to academic studies of the role of mathematical rigour in modern physics.\n\n(Of course, I will be also thankful to answers which elaborate on a single item related to a single question out of these five questions. See update)\nRelated Math Overflow questions: \n\nExamples-of-non-rigorous-but-efficient-mathematical-methods-in-physics (related to question 1); \nExamples-of-using-physical-intuition-to-solve-math-problems; \nDemonstrating-that-rigour-is-important.", "output": "Rigorous arguments are very similar to computer programming--- you need to write a proof which can (in principle) ultimately be carried out in a formal system. This is not easy, and requires defining many data-structures (definitions), and writing many subroutines (lemmas), which you use again and again. Then you prove many results along the way, only some of which are of general usefulness.\nThis activity is extremely illuminating, but it is time consuming, and tedious, and requires a great deal of time and care. Rigorous arguments also introduce a lot of pedantic distinctions which are extremely important for the mathematics, but not so important in the cases one deals with in physics.\nIn physics, you never have enough time, and we must always have a only just precise enough understanding of the mathematics that can be transmitted maximally quickly to the next generation. Often this means that you forsake full rigor, and introduce notational short-cuts and imprecise terminology that makes turning the argument rigorous difficult.\nSome of the arguments in physics though are pure magic. For me, the replica trick is the best example. If this ever gets a rigorous version, I will be flabbergasted.\n\n1) What are the most important and the oldest insights (notions, results) from physics that are still lacking rigorous mathematical formulation/proofs.\n\nHere are old problems which could benefit from rigorous analysis:\n\nMandelstam's double-dispersion relations: The scattering amplitude for 2 particle to 2 particle scattering can be analytically expanded as an integral over the imaginary discontinuity $\\rho(s)$ in the s parameter, and then this discontinuity $\\rho(s)$ can be written as an integral over the t parameter, giving a double-discontinuity $\\rho(s,t)$ If you go the other way, expand the discontinuity in t first then in s, you get the same function. Why is that? It was argued from perturbation theory by Mandelstam, and there was some work in the 1960s and early 1970s, but it was never solved as far as I know.\nThe oldest, dating back centuries: Is the (Newtonian, comet and asteroid free) solar system stable for all time? This is a famous one. Rigorous bounds on where integrability fails will help. The KAM theorem might be the best answer possible, but it doesn't answer the question really, since you don't know whether the planetary perturbations are big enough to lead to instability for 8 planets some big moons, plus sun.\ncontinuum statistical mechanics: What is a thermodynamic ensemble for a continum field? What is the continuum limit of a statistical distribution? What are the continuous statistical field theories here?\nWhat are the generic topological solitonic solutions to classical nonlinear field equations? Given a classical equation, how do you find the possible topological solitons? Can they all be generated continuously from given initial data? For a specific example, consider the solar-plasma--- are there localized magneto-hydrodynamic solitons?\n\nThere are a bazillion problems here, but my imagination fails.\n\n2) The endeavor of rigorous mathematical explanations, formulations, and proofs for notions and results from physics is mainly taken by mathematicians. What are examples that this endeavor was beneficial to physics itself.\n\nThere are a few examples, but I think they are rare:\n\nPenrose's rigorous proof of the existence of singularities in a closed trapped surface is the canonical example: it was a rigorous argument, derived from Riemannian geometry ideas, and it was extremely important for clarifying what's going on in black holes.\nQuasi-periodic tilings, also associated with Penrose, first arose in Hao and Wang's work in pure logic, where they were able to demonstrate that an appropriate tiling with complicated matching edges could do full computation. The number of tiles were reduced until Penrose gave only 2, and finally physicists discovered quasicrystals. This is spectacular, because here you start in the most esoteric non-physics part of pure mathematics, and you end up at the most hands-on of experimental systems.\nKac-Moody algebras: These came up in half-mathematics, half early string theory. The results became physical in the 1980s when people started getting interested in group manifold models.\nThe ADE classificiation from Lie group theory (and all of Lie group theory) in mathematics is essential in modern physics. Looking back further, Gell-Mann got SU(3) quark symmetry by generalizing isospin in pure mathematics.\nObstruction theory was essential in understanding how to formulate 3d topological field theories (this was the subject of a recent very interesting question), which have application in the fractional quantum hall effect. This is very abstract mathematics connected to laboratory physics, but only certain simpler parts of the general mathematical machinery are used.\n\n\n3) What are examples that insisting on rigour delayed progress in physics.\n\nThis has happened several times, unfortunately.\n\nStatistical mechanics: The lack of rigorous proof of Boltzmann ergodicity delayed the acceptance of the idea of statistical equilibrium. The rigorous arguments were faulty--- for example, it is easy to prove that there are no phase transitions in finite volume (since the Boltzmann distribution is analytic), so this was considered a strike against Boltzmann theory, since we see phase transitions. You could also prove all sorts of nonsense about mixing entropy (which was fixed by correctly dealing with classical indistinguishability). Since there was no proof that fields would come to thermal equilibrium, some people believed that blackbody light was not thermal. This delayed acceptance of Planck's theory, and Einstein's. Statistical mechanics was not fully accepted until Onsager's Ising model solution in 1941.\nPath integrals: This is the most notorious example. These were accepted by some physicists immediately in the 1950s, although =the formalism wasn't at all close to complete until Candlin formulated Grassman variables in 1956. Past this point, they could have become standard, but they didn't. The formalism had a bad reputation for giving wrong results, mostly because people were uncomfortable with the lack of rigor, so that they couldn't trust the method. I heard a notable physicist complain in the 1990s that the phase-space path integral (with p and q) couldn't possibly be correct because p and q don't commute, and in the path integral they do because they are classical numbers (no, actually, they don't--- their value in an insertion depends discontinuously on their time order in the proper way). It wasn't until the early 1970s that physicists became completely comfortable with the method, and it took a lot of selling to overcome the resistance.\nQuantum field theory construction: The rigorous methods of the 1960s built up a toolbox of complicated distributional methods and perturbation series resummation which turns out to be the least useful way of looking at the thing. It's now C* algebras and operator valued distributions. The correct path is through the path integral the Wilsonian way, and this is closer to the original point of view of Feynman and Schwinger. But a school of rigorous physicists in the 1960s erected large barriers to entry in field theory work, and progress in field theory was halted for a decade, until rigor was thrown out again in the 1970s. But a proper rigorous formulation of quantum fields is still missing.\n\nIn addition to this, there are countless no-go theorems that delayed the discovery of interesting things:\n\nTime cannot be an operator (Pauli): this delayed the emergence of the path integral particle formulation due to Feynman and Schwinger. Here, the time variable on the particle-path is path-integrated just like anything else.\nVon-Neumann's proof of no-hidden variables: This has a modern descendent in the Kochen Sprecher theorem about entangled sets of qubits. This delayed the Bohm theory, which faced massive resistance at first.\nNo charges which transform nontrivially under the Lorentz group(Coleman-Mandula): This theorem had both positive and negative implications. It killed SU(6) theories (good), but it made people miss supersymmetry (bad).\nQuasicrystal order is impossible: This \"no go\" theorem is the standard proof that periodic order (the general definition of crystals) is restricted to the standard space-groups. This made quasicrystals bunk. The assumption that is violated is the assumption of strict periodicity.\nNo supergravity compactifications with chiral fermions (Witten): this theorem assumed manifold compactification, and missed orbifolds of 11d SUGRA, which give rise to the heterotic strings (also Witten, with Horava, so Witten solved the problem).\n\n\n4) What are examples that solid mathematical understanding of certain issues from physics came from further developements in physics itself. (In particular, I am interested in cases where mathematical rigorous understanding of issues from classical mechanics required quantum mechenics, and also in cases where progress in physics was crucial to rigorous mathematical solutions of questions in mathematics not originated in physics.)\n\nThere are several examples here:\n\nUnderstanding the adiabatic theorem in classical mechanics (that the action is an adiabatic invariant) came from quantum mechanics, since it was clear that it was the action that needed to be quantized, and this wouldn't make sense without it being adiabatic invariant. I am not sure who proved the adiabatic theorem, but this is exactly what you were asking for--- an insightful classical theorem that came from quantum mechanics (although some decades before modern quantum mechanics)\nThe understanding of quantum anomalies came directly from a physical observation (the high rate of neutral pion decay to two photons). Clarifying how this happens through Feynman diagrams, even though a naive argument says it is forbidden led to complete understanding of all anomalous terms in terms of topology. This in turn led to the development of Chern-Simons theory, and the connection with Knot polynomials, discovered by Witten, and earning him a Fields medal.\nDistribution theory originated in Dirac's work to try to give a good foundation for quantum mechanics. The distributional nature of quantum fields was understood by Bohr and Rosenfeld in the 1930s, and the mathematics theory was essentially taken from physics into mathematics. Dirac already defined distributions using test functions, although I don't think he was pedantic about the test-function space properties.\n\n\n5) The role of rigor is intensly discussed in popular books and blogs. Please supply references (or better annotated references) to academic studies of the role of mathematical rigour in modern physics.\n\nI can't do this, because I don't know any. But for what it's worth, I think it's a bad idea to try to do too much rigor in physics (or even in some parts of mathematics). The basic reason is that rigorous formulations have to be completely standardized in order for the proofs of different authors to fit-together without seams, and this is only possible in very long hindsight, when the best definitions become apparent. In the present, we're always muddling through fog. So there is always a period where different people have slightly different definitions of what they mean, and the proofs don't quite work, and mistakes can happen. This isn't so terrible, so long as the methods are insightful.\nThe real problem is the massive barrier to entry presented by rigorous definitions. The actual arguments are always much less daunting than the superficial impression you get from reading the proof, because most of the proof is setting up machinery to make the main idea go through. Emphasizing the rigor can put undue emphasis on the machinery rather than the idea.\nIn physics, you are trying to describe what a natural system is doing, and there is no time to waste in studying sociology. So you can't learn all the machinery the mathematicians standardize on at any one time, you just learn the ideas. The ideas are sufficient for getting on, but they aren't sufficient to convince mathematicians you know what you're talking about (since you have a hard time following the conventions). This is improved by the internet, since the barriers to entry have fallen down dramatically, and there might be a way to merge rigorous and nonrigorous thinking today in ways that were not possible in earlier times.", "meta": {"post_id": 27665, "input_score": 122, "output_score": 86, "post_title": "The Role of Rigor"}}
{"input": "I have been told that $$[\\hat x^2,\\hat p^2]=2i\\hbar (\\hat x\\hat p+\\hat p\\hat x)$$ illustrates operator ordering ambiguity.\nWhat does that mean?\nI tried googling but to no avail.", "output": "The ordering ambiguity is the statement \u2013 or the \"problem\" \u2013 that for a classical function $f(x,p)$, or a function of analogous phase space variables, there may exist multiple operators $\\hat f(\\hat x,\\hat p)$ that represent it. In particular, the quantum Hamiltonian isn't uniquely determined by the classical limit.\nThis ambiguity appears even if we require the quantum operator corresponding to a real function to be Hermitian and $x^2 p^2$ is the simplest demonstration of this \"more serious\" problem. On one hand, the Hermitian part of $\\hat x^2 \\hat p^2$ is \n$$ \\hat x^2 \\hat p^2 - [\\hat x^2,\\hat p^2]/2 = \\hat x^2\\hat p^2 -i\\hbar (\\hat x\\hat p+\\hat p\\hat x)$$\nwhere I used your commutator.\nOn the other hand, we may also classically write the product and add the hats as $\\hat x \\hat p^2\\hat x$ which is already Hermitian. But\n$$ \\hat x \\hat p^2\\hat x = \\hat x^2 \\hat p^2+\\hat x[\\hat p^2,\\hat x] = \\hat x^2\\hat p^2-2i\\hbar\\hat x\\hat p $$\nwhere you see that the correction is different because $\\hat x\\hat p+\\hat p\\hat x$ isn't quite equal to $2\\hat x\\hat p$ (there's another, $c$-valued commutator by which they differ). So even when you consider the Hermitian parts of the operators \"corresponding\" to classical functions, there will be several possible operators that may be the answer. The $x^2p^2$ is the simplest example and the two answers we got differed by a $c$-number. For higher powers or more general functions, the possible quantum operators may differ by $q$-numbers, nontrivial operators, too.\nThis is viewed as a deep problem (perhaps too excessive a description) by the physicists who study various effective quantum mechanical models such as those with a position-dependent mass \u2013 where we need $p^2/2m(x)$ in the kinetic energy and by an expansion of $m(x)$ around a minimum or a maximum, we may get the $x^2p^2$ problem suggested above.\nBut the ambiguity shouldn't really be surprising because it's the quantum mechanics, and not the classical physics, that is fundamental. The quantum Hamiltonian contains all the information, including all the behavior in the classical limit. On the other hand, one can't \"reconstruct\" the full quantum answer out of its classical limit. If you know the limit $\\lim_{\\hbar\\to 0} g(\\hbar)$ of one variable $g(\\hbar)$, it clearly doesn't mean that you know the whole function $g(\\hbar)$ for any $\\hbar$.\nMany people don't get this fundamental point because they think of classical physics as the fundamental theory and they consider quantum mechanics just a confusing cherry on a pie that may nevertheless obtained by quantization, a procedure they consider canonical and unique (just hat addition). It's the other way around, quantum mechanics is fundamental, classical physics is just a derivable approximation valid in a limit, and the process of quantization isn't producing unique results for a sufficiently general classical limit.\nThe ordering ambiguity also arises in field theory. In that case, all the ambiguous corrections are actually divergent, due to short-distance singularities, and the proper definition of the quantum theory requires one to understand renormalization. At the end, what we should really be interested in is the space of relevant/consistent quantum theories, not \"the right quantum counterpart\" of a classical theory (the latter isn't fundamental so it shouldn't stand at the beginning or base of our derivations).\nIn the path-integral approach, one effectively deals with classical fields and their classical functions so the ordering ambiguities seem to be absent; in reality, all the consequences of these ambiguities reappear anyway due to the UV divergences that must be regularized and renormalized. The process of regularization and renormalization depends on the subtraction of various divergent counterterms, to get the finite answer, which isn't quite unique, either (the finite leftover coupling may be anything).\nThat's why the renormalization ambiguities are just the ordering ambiguities in a different language. Whether we study those things as ordering ambiguities or renormalization ambiguities, the lesson is clear: the space of possible classical theories isn't the same thing as the space of possible quantum theories and we shouldn't think about the classical answers when we actually want to do something else \u2013 to solve the problems in quantum mechanics.", "meta": {"post_id": 46988, "input_score": 28, "output_score": 42, "post_title": "Operator Ordering Ambiguities"}}
{"input": "The gravitational force on your body, called your weight, pushes you down onto the floor.\n$$W=mg$$\nSo, what is the weight equation through general relativity?", "output": "Start with the Schwarzschild metric $$ds^2 = (1-\\frac{r_S}{r})c^2dt^2-(1-\\frac{r_S}{r})^{-1}dr^2-r^2d\\Omega^2 $$  where $$r_S=\\frac{2GM}{c^2} $$  A particle at rest at radius $r$ and angular parameters zero from the centre of mass has worldline $$ x^{\\mu}=(t, r, 0, 0)$$  Its four velocity is thus $$ u^{\\mu}=\\frac{dx^{\\mu}}{d\\tau}=((1-\\frac{r_S}{r})^{-\\frac{1}{2}}, 0, 0, 0)$$  Its four-acceleration is $$a^{\\mu}= \\frac{du^{\\mu}}{d\\tau}+\\Gamma^{\\mu}_{\\alpha \\beta}u^{\\alpha}u^{\\beta} $$  After looking up the Christoffel symbols, because I'm lazy, I get $$ a^{\\mu} = (0, \\frac{c^2r_S}{2r^2}, 0, 0)$$  So the Lorentz norm squared of the four-acceleration is $$g_{\\mu \\nu}a^{\\mu}a^{\\nu}= \\frac{c^4r_S^2}{4r^4(1-\\frac{r_S}{r})}=\\frac{G^2M^2}{r^4(1-\\frac{2GM}{c^2r})}$$        Now the proper acceleration of an object at time t is the acceleration relative to an observer in free fall, who is momentarily at rest w.r.to the object at time t.  The free fall guy is the one who is not accelerating - the object held at rest at radius r is the one who is accelerating.  As we've shown, his acceleration is $$\\frac{GM}{r^2}\\frac{1}{\\sqrt{1-\\frac{2GM}{c^2r}}} $$  So if you want to define a force, it would be $$F=ma=\\frac{GMm}{r^2}\\frac{1}{\\sqrt{1-\\frac{2GM}{c^2r}}} $$ As $c\\rightarrow \\infty$ we recover the Newtonian definition, but nobody bothers phrasing it in these terms.", "meta": {"post_id": 47379, "input_score": 48, "output_score": 64, "post_title": "What is the weight equation through general relativity?"}}
{"input": "In Griffiths' Intro to QM [1] he gives the eigenfunctions of the Hermitian operator $\\hat{x}=x$ as being \n$$g_{\\lambda}\\left(x\\right)~=~B_{\\lambda}\\delta\\left(x-\\lambda\\right)$$\n(cf. last formula on p. 101). He then says that these eigenfunctions are not square integrable because \n$$\\int_{-\\infty}^{\\infty}g_{\\lambda}\\left(x\\right)^{*}g_{\\lambda}\\left(x\\right)dx\n~=~\\left|B_{\\lambda}\\right|^{2}\\int_{-\\infty}^{\\infty}\\delta\\left(x-\\lambda\\right)\\delta\\left(x-\\lambda\\right)dx\n~=~\\left|B_{\\lambda}\\right|^{2}\\delta\\left(\\lambda-\\lambda\\right)\n~\\rightarrow~\\infty$$\n(cf. second formula on p. 102). My question is, how does he arrive at the final term, more specifically, where does the $\\delta\\left(\\lambda-\\lambda\\right)$ bit come from? \nMy total knowledge of the Dirac delta function was gleaned earlier on in Griffiths and extends to just about understanding \n$$\\tag{2.95}\\int_{-\\infty}^{\\infty}f\\left(x\\right)\\delta\\left(x-a\\right)dx~=~f\\left(a\\right)$$\n(cf. second formula on p. 53).\nReferences:\n\nD.J. Griffiths, Introduction to Quantum Mechanics, (1995) p. 101-102.", "output": "You need nothing more than your understanding of \n$$\n\\int_{-\\infty}^\\infty f(x)\\delta(x-a)dx=f(a)\n$$\nJust treat one of the delta functions as $f(x)\\equiv\\delta(x-\\lambda)$ in your problem. So it would be something like this:\n$$\n\\int\\delta(x-\\lambda)\\delta(x-\\lambda)dx=\\int f(x)\\delta(x-\\lambda)dx=f(\\lambda)=\\delta(\\lambda-\\lambda)\n$$\nSo there you go.", "meta": {"post_id": 47934, "input_score": 40, "output_score": 42, "post_title": "Don't understand the integral over the square of the Dirac delta function"}}
{"input": "It is often quoted that the number of atoms in the universe is 10$^{70}$ or 10$^{80}$.\nHow do scientists determine this number? \nAnd how accurate is it (how strong is the supporting evidences for it)?\nIs it more likely (logically >50% chance) that the numbers are right, or is it more likely that the numbers are wrong?", "output": "The cosmological estimation of the number of atoms in the observable universe works as follows: one of the Friedmann equations can be written as\n$$\n\\dot{a}^2 -\\frac{8\\pi G}{3}\\rho a^2= -kc^2, \n$$\nwhere the scale factor $a(t)$ describes the expansion of the universe, $\\rho$ is the total mass density (radiation, baryonic matter, dark matter, and dark energy) and the integer $k$ is the intrinsic curvature of the universe ($k$ can be 1, 0 or -1). Observations of the Cosmic Microwave Background (CMB) indicate that the spacial curvature $k/a^2$ of the universe is practically zero, so we can set $k=0$. In this case the total density is equal to the so-called critical density\n$$\n\\rho_\\text{c}(t) = \\frac{3H^2(t)}{8\\pi G},\n$$\nwhere \n$$\nH(t) = \\frac{\\dot{a}}{a}\n$$\nis the Hubble parameter. The present-day density is then\n$$\n\\rho_\\text{c,0} = \\rho_\\text{c}(t_0) = \\frac{3H_0^2}{8\\pi G},\n$$\nwith $H_0=H(t_0)$ the Hubble constant. We can write $H_0$ in the following form\n$$\nH_0 = 100\\,h\\;\\text{km}\\,\\text{s}^{-1}\\,\\text{Mpc}^{-1},\n$$\nwith $h$ a dimensionless parameter and $1\\;\\text{Mpc}=3.0857\\times 10^{19}\\;\\text{km}$ (called a megaparsec). So\n$$\n\\rho_\\text{c,0} = 1.8785\\,h^2\\times 10^{-26}\\;\\text{kg}\\,\\text{m}^{-3}.\n$$\nA detailed analysis of the Cosmic Microwave Background reveals what the density of ordinary matter (baryons) is: according to the latest CMB data, the present-day baryon fraction is\n$$\n\\Omega_\\text{b,0}h^2 = \\frac{\\rho_\\text{b,0}}{\\rho_\\text{c,0}}h^2 =\n0.02205 \\pm 0.00028.\n$$\nNotice how accurately this quantity is known. The same data also yield a value of the Hubble constant:\n$$\nH_0 = 67.3 \\pm 1.2\\;\\text{km}\\,\\text{s}^{-1}\\,\\text{Mpc}^{-1},\n$$\nin other words, $h = 0.673\\pm0.012$ so that\n$$\n\\Omega_\\text{b,0} = 0.0487,\n$$\nwhich means that ordinary matter makes up 4.87% of the content of the universe. We don't actually need the value of $h$ to calculate the baryon density $\\rho_\\text{b,0}$, because the factor $h^2$ cancels out: we get\n$$\n\\rho_\\text{b,0} = \\Omega_\\text{b,0}\\rho_\\text{c,0} = 0.4142\\times 10^{-27}\\;\\text{kg}\\,\\text{m}^{-3}.\n$$\nAbout 75% of the baryon density is in the form of hydrogen, and nearly 25% is helium; all other elements make up about 1%, so I'll ignore those. The masses of hydrogen and helium atoms are\n$$\n\\begin{align}\nm_\\text{H} &= 1.674\\times 10^{-27}\\;\\text{kg},\\\\\nm_\\text{He} &= 6.646\\times 10^{-27}\\;\\text{kg},\n\\end{align}\n$$\nso the number density of hydrogen and helium atoms is\n$$\n\\begin{align}\nn_\\text{H} &= 0.75\\rho_\\text{b,0}/m_\\text{H} = 0.1856\\;\\text{m}^{-3},\\\\\nn_\\text{He} &= 0.25\\rho_\\text{b,0}/m_\\text{He} = 0.0156\\;\\text{m}^{-3},\n\\end{align}\n$$\nand the total number density of atoms is\n$$\nn_\\text{A} = n_\\text{H}+n_\\text{He} = 0.2012\\;\\text{m}^{-3}.\n$$\nNow, the radius of the observable universe is calculated to be $D_\\text{ph} = 46.2$ billion lightyears, which is $4.37\\times 10^{26}\\,\\text{m}$ (the subscript 'ph' stands for particle horizon; see this post for a detailed explanation). This is a derived value, which depends on all cosmological parameters; nonetheless, it is accurate to about 1%. The volume of the observable universe is thus\n$$\nV = \\frac{4\\pi}{3}\\!D_\\text{ph}^3 = 3.50\\times 10^{80}\\;\\text{m}^3.\n$$\nSo finally, there are about\n$$\nN_\\text{A} = n_\\text{A}V = 7.1\\times 10^{79}\n$$\natoms in the observable universe.", "meta": {"post_id": 47941, "input_score": 47, "output_score": 37, "post_title": "Dumbed-down explanation how scientists know the number of atoms in the universe?"}}
{"input": "My knowledge on this particular field of physics is very sketchy, but I frequently hear of a theoretical \"graviton\", the quantum of the gravitational field.  So I guess most physicists' assumption is that gravity can be described by a QFT?\nBut I find this weird, because gravity seems so incredibly different from the other forces (yes, I know \"weirdness\" isn't any sort of scientific deduction principle).\nFor relative strengths:\n\nStrong force: $10^{38}$\nElectromagnetic force: $10^{36}$\nWeak force: $10^{25}$\nGravity: $1$\n\nNot only does gravity have a vastly weaker magnitude, it also has a very strange interaction with everything else.  Consider the Standard Model interactions:\n\nNo particle (or field) interacts directly with all other fields.  Heck, gluons only barely interact with the rest of them.  So why is it then that anything that has energy (e.g. everything that exists) also has a gravitational interaction?  Gravity seems unique in that all particles interact through it.\nThen there's the whole issue of affecting spacetime.  As far as I'm aware, properties such as charge, spin, color, etc. don't affect spacetime (only the energy related to these properties).", "output": "The short answer for why gravity is unique is that it is the theory of a massless, spin-2 field.  To contrast with the other forces, the strong, weak and electromagnetic forces are all theories of spin-1 particles.  \nAlthough it's not immediately obvious, this property alone basically fixes all of the essential features of gravity.  To begin with, the fact that gravity is mediated by massless particles means that it can give rise to long-range forces.  \"Long-range\" here means that gravitational potential between distant masses goes like $\\dfrac{1}{r}$, whereas local interactions most commonly fall of exponentially, something like $\\dfrac{e^{-mr}}{r}$, where $m$ is the mass of the force particle (this is known as a Yukawa potential).  \nAnother important feature of massless particles is they must have a gauge symmetry associated with them.  Gauge symmetry is important because it leads to conserved quantities.  In the case of electromagnetism (a theory of a massless, spin-1 particle), there is also gauge symmetry, and it is known that the conservation of electric charge is a consequence of this symmetry.  \nFor gravity, the gauge symmetry puts even stronger constraints on the way gravity interacts: not only does it lead to a conserved \"charge\" (the stress energy tensor of matter), it actually requires that the gravitational field couple in the same way to all types of matter.  So, as you correctly noted, gravity is very unique in that it is required to couple to all other particles and fields.  Not only that, but gravity also doesn't care about the electric charge, color charge, spin, or any other property of the things it is interacting with, it only couples to the stress-energy of the field.  For people who are familiar with general relativity, this universal coupling of gravity to the stress energy of matter, independent of internal structure, is known as the equivalence principle.  A more technical discussion of the fact that massless, spin-2 implies the equivalence principle (which was first derived by Weinberg) is given in the lecture notes found at the bottom of this page.\nAnother consequence of this universal coupling of gravity is that there can only by one type of graviton, i.e. only one massless, spin-2 field that interacts with matter.  This is much different from the spin-1 particles, for example the strong force has eight different types of gluons.  So since gravity is described by massless, spin-2 particles, it is necessarily the unique force containing massless spin-2 particles.  \nIn regards to the geometric viewpoint of gravity, i.e. how gravity can be seen as causing curvature in spacetime, that property also follows directly (although not obviously) from the massless spin-2 nature of the gravitons.  One of the standard books treating this idea is Feynman's Lectures on Gravitation (I think at least the first couple of chapters are available on google books).  The viewpoint that Feynman takes is that gravity must couple universally to the stress tensor of all matter, including the stress tensor of the gravitons themselves. This sort of self-interaction basically gives rise to the nonlinearities that one finds in general relativity.  Also, the gauge symmetry that was mentioned before gets modified by the self-interactions, and turns into diffeomorphism symmetry found in general relativity (also known as general covariance).  \nAll of this analysis comes from assuming that there is a quantum field theoretic description of gravity.  It may be concerning that people generally say we don't have a consistent quantum theory of gravity.  This is true, however, it can more accurately be stated that we don't have an ultraviolet complete theory of quantum gravity (string theory, loop quantum gravity, asymptotically safe gravity are all proposed candidates for a full theory, among many others).  That means that we don't believe that this theory of massless spin-2 particles is valid at very high energies.  The cutoff where we think it should break down is around the Planck mass, $M_p \\approx 10^{19}$ GeV.  These energies would be reached, for example, at the singularity of a black hole, or near the big bang.  But in most regions of the universe where such high energies are not present, perturbative quantum general relativity, described in terms of gravitons, is perfectly valid as a low energy effective field theory.  \nFinally, you noted that the extremely weak coupling of gravity compared to the other forces also sets it apart.  This is known as the hierarchy problem, and to the best of my knowledge it is a major open problem in physics.  \nRegardless, I hope this shows that even hierarchy problem aside, gravity plays a very special role among the forces of nature.", "meta": {"post_id": 57228, "input_score": 62, "output_score": 55, "post_title": "Why is gravity such a unique force?"}}
{"input": "I have read the thread regarding 'the difference between the operators $\\delta$ and $d$', but it does not answer my question.\nI am confused about the notation for change in Physics. In Mathematics, $\\delta$ and $\\Delta$ essentially refer to the same thing, i.e., change. This means that $\\Delta x = x_1 - x_2 = \\delta x$. The difference between $\\delta$ and $d$ is also clear and distinct in differential calculus. We know that $\\frac{dy}{dx}$ is always an operator and not a fraction, whereas $\\frac{\\delta y}{\\delta x}$ is an infinitesimal change. \nIn Physics, however, the distinction is not as clear. Can anyone offer a clearer picture?", "output": "The symbol $\\Delta$ refers to a finite variation or change of a quantity \u2013 by finite, I mean one that is not infinitely small.\nThe symbols $d,\\delta$ refer to infinitesimal variations or numerators and denominators of derivatives.\nThe difference between $d$ and $\\delta$ is that $dX$ is only used if $X$ without the $d$ is an actual quantity that may be measured (i.e. as a function of time) without any ambiguity about the \"additive shift\" (i.e. about the question which level is declared to be $X=0$). On the other hand, we sometimes talk about small contributions to laws that can't be extracted from a well-defined quantity that depends on time.\nAn example, the first law of thermodynamics.\n$$dU = \\delta Q - \\delta W$$\nThe left hand side has $dU$, the change of the total energy $U$ of the system that is actually a well-defined function of time. The law says that it is equal to the infinitesimal heat $\\delta Q$ supplied to the system during the change minus the infinitesimal work $\\delta W$ done by the system. All three terms are equally infinitesimal but there is nothing such as \"overall heat\" $Q$ or \"overall work\" $W$ that could be traced \u2013 we only determine the changes (flows, doing work) of these things.\nAlso, one must understand the symbol $\\partial$ for partial derivatives \u2013 derivatives of functions of many variables for which the remaining variables are kept fixed, e.g. $\\partial f(x,y)/\\partial x$ and similarly $y$ in the denominator.\nIndependently of that, $\\delta$ is sometimes used in the functional calculus for functionals \u2013 functions that depend on whole functions (i.e. infinitely many variables). In this context, $\\delta$ generalizes $d$ and has a different meaning, closer to $d$, than $\\delta$ in the example of $\\delta W$ and $\\delta Q$ above. Just like we have $dy=f'(x)dx$ for ordinary derivatives in the case of one variable, we may have $\\delta S = \\int_a^b dt\\,C(t)\\delta x(t)$ where the integral is there because $S$ depends on uncountably many variables $x(t)$, one variable for each value of $t$.\nIn physics, one must be ready that $d,\\delta,\\Delta$ may be used for many other things. For example, there is a $\\delta$-function (a distribution that is only non-vanishing for $x=0$) and its infinite-dimensional, functional generalization is called $\\Delta[f(x)]$. That's a functional that is only nonzero for $f(x)=0$ for every $x$ and the integral $\\int {\\mathcal D}f(x) \\,\\Delta[f(x)]=1$. Note that for functional integrals (over the infinite-dimensional spaces of functions), the integration measure is denoted ${\\mathcal D}$ and not $d$.", "meta": {"post_id": 65724, "input_score": 60, "output_score": 53, "post_title": "Difference between $\\Delta$, $d$ and $\\delta$"}}
{"input": "The operator-state correspondence in CFT gives a 1-1 mapping between operators $\\phi(z,\\bar{z})$ and states $|\\phi\\rangle$,\n$$\n|\\phi\\rangle=\\lim_{z,\\bar{z}\\mapsto 0} \\phi(z,\\bar{z}) |0\\rangle\n$$\nwhere $|0\\rangle$ is the $SL(2,\\mathbb{Z})$ invariant vacuum. \nWhy can't we have a similar operator-state correspondence in non-CFT QFTs? Can't we just map operators to states by acting with the operator on the vacuum state?", "output": "The operator-state correspondence says that all states in the theory can be created by operators which act locally in a small neighborhood of the origin. That is to say that the entire Hilbert space of a CFT can be thought of as living at a single point. The key here is that for CFTs we have radial quantization, and states evolve radially outwards unitarily from the origin. This corresponds to the limit $z, \\bar z \\rightarrow 0$. \nIf you wanted to do the same for an ordinary QFT, the analagous thing would be associating a Heisenberg picture operator $\\Phi$ with the state $\\displaystyle \\lim_{t \\rightarrow -\\infty} \\Phi(t) | 0 \\rangle$. The biggest problem here is that now one can't think of these as local operators acting at a single point if you want to get the full Hilbert space of the theory. Obviously one always has a map from operators to states just by acting the operators on the vacuum as above, but only for CFTs does the map go the other way that every state corresponds uniquely to a single local operator.", "meta": {"post_id": 88773, "input_score": 43, "output_score": 45, "post_title": "Operator-state correspondence in QFT"}}
{"input": "This question is a consequence of another question of mine which is about spin.\nHere is my spin question.\nWhat is the difference between these two fields? How do they occur? Am I right if I say that a magnetic field is about photons (because they occur between N and S poles of a magnet) and an electric field is about electrons? How they are related?\nFinally; when and why do we use the word \"electromagnetism\"?", "output": "Electric forces are attractive or repulsive forces between \"charged objects\", e.g. comb and dry hair after some friction. Charged objects are those that carry some nonzero electric charge $Q$. The lightest \u2013 and therefore easiest to move \u2013 charged particle is the electron so the surplus or deficit of electrons is the most typical reason why some objects are charged.\nMagnetic forces are attractive or repulsive forces between magnets, like magnetized pieces of iron. The amount of \"magnetic dipole\" carried by a magnet is completely independent of its electric charge. They're as independent as the gravitational and electrostatic forces i.e. as independent as the mass and the charge of an object.\nFor centuries, these two forces were thought of as independent. Only a few centuries ago, due to Faraday and others, relationships between the electric and magnetic forces began to be uncovered. Magnets may be produced by coils \u2013 by electric charges moving in loops. They become indistinguishable from bar magnets. Similarly, moving magnets produce electric fields.\nIn the middle of the 19th century, because of these \"mutual influences\" between electricity and magnetism, a unified theory was gradually found. Because electricity and magnetism influence each other, we need to talk about a whole \u2013 electromagnetism or, to point out that magnetism is related to moving electric charges, electrodynamics (dynamics sort of means \"motion\" or \"reasons for motion\"). \nJames Clerk Maxwell wrote the unified equations for electricity and magnetism which exhibited a near perfect symmetry between electricity and magnetism. They are two independent \"siblings\" but they affect one another and the inner mechanisms in them are analogous. Maxwell's theory also implied that there are electromagnetic waves \u2013 disturbances in space where the electric field goes up and down and so does the magnetic field which is excited by the electric one and vice versa. Moreover, he proved that light was a special example of the electromagnetic wave.\nIn the 20th century, it was realized that the existence of the other force follows from one force (e.g. magnetism followed from electricity) due to a symmetry between inertial observers who are moving relatively to each other, i.e. due to the Lorentz symmetry which underlies Einstein's special relativity. It was also found out that the electromagnetic waves may be thought of as collections of photons and that the exchange of the photon is the \"reason\" behind electric as well as magnetic forces.\nSo the photons are the messengers of electromagnetism \u2013 both electricity and magnetism. Electrons are the most important carriers of the electric charge which means that they're the most important particles that produce the electric and magnetic (when electrons are moving or spinning) fields. These fields arise and affect other pieces of matter (especially electrons) due to the \"messenger role\" of the photons. Photons are \"units\" of the electromagnetic waves.", "meta": {"post_id": 95815, "input_score": 17, "output_score": 38, "post_title": "What is the difference between an electric and a magnetic field?"}}
{"input": "We have seen birds sitting on uninsulated electric wires of high voltage transmission lines overhead without getting harmed, because sitting on only one wire doesn't complete any circuit. \nBut what about the potential difference between their legs? Is this not a small complete circuit? Because the wire has a potential gradient, there should be a potential difference between the bird's feet. Is this potential difference so very small that we can say the bird is sitting at a single point on the wire? If a bird of a sufficiently large size, with a wide gap between its feet, sits on a single wire, shouldn't the bird receive a shock if the potential difference is sufficient?", "output": "Here is a circuit representing the system. $R_{wire}$ is the resistance of the section of wire between the bird's legs. $R_{bird}$ is the resistance of the bird (which you can measure by sticking the two probes of the multimeter to the bird's two feet - if the cable is insulated, you will have to add the resistance of the insulation as well).\nWhen the bird lands, do everyone's lights dim? (does the bird affect how much electricity goes through)\nWhen the bird lands, the resistance between the two points (where its feet touch the wire) changes, so first we must determine whether the current coming from the transformer at the beginning of the power line changes. The resistance would go from $R_{wire}$ to: \n$$R_T = \\frac{1}{\\frac{1}{R_{wire}}+\\frac{1}{R_{bird}}}=\\frac{R_{wire} \\cdot R_{bird}}{R_{wire} + R_{bird}}$$\nAs evidenced by the fact that we use metal cables, and not birds, to transmit electricity, $R_{wire} << R_{bird}$:\n$$ R_{wire} + R_{bird} \\approx R_{bird} \\Rightarrow R_T \\approx \\frac{R_{wire} \\cdot R_{bird}}{R_{bird}}=R_{wire} $$\nTherefore, the resistance does not change much, and the current should also stay about the same because $I=V / R$. (Actually, the current will increase very slightly, because the bird's resistance will be in parallel with the wire's resistance, and this will decrease the overall resistance of the power line very slightly - thanks Nate Eldredge and Max)\nDoes the bird experience extreme voltage?\nThe potential difference between two points is $V_0 = I \\cdot R$. $I$ here is the total current passing through the wire, which we have already established does not differ much with the bird or without. So:\n\nWithout the bird we have $V_0=I \\cdot R_{wire}$. \nWith the bird we have $V_{bird}=I \\cdot R_T \\approx I \\cdot R_{wire}$ (see previous section). \n\nTherefore the voltage experienced by the bird can be approximated with $I \\cdot R_{wire}$. Once again, the wire is very conductive, so $R_{wire}$ will be small; $I$ may be large but not very large. $V_0$ will probably be a volt or less, likewise for $V_{bird}$.\nAlternatively, we can observe that resistance is proportional to length, and therefore so is voltage: $$\\frac{R_{wire}}{R_{line}} = \\frac{L_{wire}}{L_{line}} = \\frac{V_{wire}}{V_{line}} $$ \nHere:\n\n$R_{line}$ is the resistance between the two endpoints of the whole line\n$V_{line}$ is the potential between the two endpoints of the whole line (typically tens of kV)\n$L_{line}$ is the length of the entire power line (typically several kilometers)\n$L_{wire}$ is the length of wire spanned by the bird's legs (typically a few centimeters)\n\nTherefore you can appreciate that the right side of the equation is a very small number, so likewise, $V_{wire}$ must be less than a volt - and the bird experiences approximately $V_{wire}$ potential difference as well.\nDoes the bird experience extreme current?\nDespite low voltage, high current may still be dangerous to animals. As pointed out before, the amount of current passing through the bird-wire block is $I_T=V/R_T \\approx V/R_{wire}$.\nAt one of the bird feet, the current will split into $I_{wire}$ (which goes through the wire) and $I_{bird}$ (which goes through the bird), and then combine at the other foot. Because $V_T = V_{bird} = V_{wire}$, we can conclude that $I_{bird} = V_T/R_{bird}$ and $I_{wire} = V_T/R_{wire}$, therefore current and resistance of either component is inversely proportional:\n$$ \\frac{I_{bird}}{I_{wire}} = \\frac{V_T/R_{bird}}{V_T/R_{wire}} = \\frac{R_{wire}}{R_{bird}}$$\nWe previously established that $R_{wire} << R_{bird}$, so $I_{wire} >> I_{bird}$. Current must be conserved (otherwise the bird must be stealing electrons) so $I_{wire} + I_{bird} = I_T > I_{wire} >> I_{bird}$.\n$I_T$ can be pretty large for the higher capacity lines, but it's not that large - it's on the order of hundreds of amperes. Even though even 0.1 A is considered lethal to humans, the bird will experience a current $I_{bird}$ which is much smaller than this.\nRecall the inverse proportion between current and resistance: Typically, animal bodies have a resistance of a few $M \\Omega$ or a few hundred $k \\Omega$ (original research), while good metal wires a few centimeters long will have less (often much less) resistance than 1 $\\Omega$. So the current passing through the bird will be a few $\\mu A$ at most - harmless.\nIs it dangerous for the bird to open its legs wide?\nA critical factor is the ratio of the resistance of the bird's body $R_{bird}$ to the resistance of the section of wire between its 2 legs $R_{wire}$. First let's consider the the effect of opening legs on total current.\n\nWith legs closed, we get total resistance of the power line $R_{closed} = R_{line} + R_1 + \\frac{1}{\\frac{1}{R_2} + \\frac{1}{R_{bird}}}$. With legs open, $R_{open} = R_{line} + \\frac{1}{\\frac{1}{R_1 + R_2} + \\frac{1}{R_{bird}}}$. $R_{closed} > R_{open}$ (intuitively, you are replacing more of the wire with a more conductive bird/wire composite module). Accordingly, the total current through the whole power line will be higher when legs are open $I_{closed} < I_{open}$.\nFurthermore, as Ilmari Karonen pointed out, increasing $R_{wire}$ increases both the potential experienced by the bird and how much of the (now higher) total current \"splits\" off into the bird part of the circuit.\nIf the bird increases the distance between its legs hundredfold, the increase in total current on the line will be negligible. $V_{wire} = V_{bird}$ will go up hundredfold, and correspondingly, the bird will experience hundredfold-stronger current. However, for a normal bird, if we repeat our original analysis we will find that even 100 cm of cable still has negligible resistance compared to a bird, so I doubt real birds would notice a difference.\n\nWhat if you stretched a bird's legs so much that they could span the whole power line? Besides looking ridiculous, the bird would now experience tremendous potential difference. But in stretching the bird, you would also make it very thin (which increases resistance) and make it very long (which also increases resistance). So $R_{bird}$ would also be much larger and the current would still be very small. The bird would probably experience some form of discomfort, but not due to electrical phenomena.\n\nWhat if you had a giant bird that is so big, its two legs could span the whole power line, even without stretching? Resistance is proportional to length, but inversely proportional to thickness. So if the bird was well-proportioned, it would have the same resistance as a small bird. However, now the resistance of $R_{wire}$ is non-trivial - many kilometers of even very conductive wire can have significant resistance. As said earlier, if 100 A passes through the power line, the bird need only get 0.1% of that to be at risk of death, so if the bird is long enough to span enough kilometers of power line that the resistance of the line is at least a few $k\\Omega$, it will experience a very dangerous shock. Although a bird that big would also have other problems, such as the square-cube law, or current going through its head to make lightning in the upper layers of the atmosphere.", "meta": {"post_id": 109142, "input_score": 38, "output_score": 74, "post_title": "Birds sitting on electric wires: potential difference between the legs"}}
{"input": "When you run or ride bike at night if you observe the moon you feel like he moves along with you as the same speed you are going. Why?", "output": "Suppose you're walking past a nearby tree:\n\nAs you pass the tree the angle of the line joining you and the tree changes. From your perspective it looks as if you are standing still and the tree has moved backwards.\nHowever the Moon is so far away that, as you walk, the angle of the line joining you to the Moon doesn't change by any significant amount:\n\nSo, from your perspective it looks as if the moon is keeping up with you i.e. it's traveling at the same speed as you are.\nThis effect is particularly marked if there are any nearby landmarks. For example, nearby trees seem to move backwards as you pass them, and this enhances the feeling that the Moon is moving forwards to keep up with you.", "meta": {"post_id": 114748, "input_score": 19, "output_score": 40, "post_title": "Why does one get an illusion as moon following him?"}}
{"input": "While I was walking my dog this morning, I passed over a canal filled with boats, barges, and kayaks all of different masses and moving at different speeds. I noticed that all of these vessels left behind wakes, and the waves of these wakes moved through the water at different rates, though my ability to make good observations was limited. This made me wonder: what determines the velocity of these waves?\nI know that sound travels through water at 1,480 m/s or so, but surface waves travel at different rates (tsunamis travel faster than the ripples I make in my bowl of soup when I blow on it). In particular, how is the velocity of wake waves determined?", "output": "The complete answer to that question is an open problem in fluid mechanics, as exact closed form solutions to the irrotational surface gravity water wave equations are unknown. However, under certain asymptotic approximations, we can estimate the speed of these waves. \nIrrotational inviscid surface waves are governed by Laplace's equation, i.e. \n$$\\nabla^2 \\phi = 0$$\nwhere $\\phi$ is the velocity potential. This governing equation, together with the boundary conditions \n$$\\phi_t+\\frac{1}{2}(\\nabla \\phi)^2 +gz = 0$$\n$$\\eta_t +(\\nabla \\phi)\\cdot (\\nabla \\eta) = \\phi_z$$\nwhere $\\eta$ is the free surface displacement, and these equations are evaluated at the free surface, i.e. $z = \\eta$, and the bottom boundary condition \n$\\phi_z = 0$ at $z=-h$, with h the depth of water, constitute the complete set of equations. Also, here $g$ is the acceleration due to gravity.  \nThe governing equation is linear, i.e. Laplace's equations, but the BC are nonlinear, and furthermore are evaluated at a point that we must solve for, which makes these equations very difficult to solve.\nTo make any kind of analytic progress, we make asymptotic approximations. Depending on whether you are describing deep or shallow water waves, different dimensionless parameters come into play. For linear waves however, they both share the common small parameter $\\epsilon \\equiv ak$, which describes the wave slope. \nIn this case, the governing equations, to $\\mathcal{O}(\\epsilon)$ are \n$\\nabla^2\\phi = 0$, with $\\phi_t+ g\\eta = 0$ and $\\eta_t = \\phi_z$, both evaluated at $z=0$, while $\\phi_z = 0$ at $z=-h$.\nFor simplicity let's consider waves of two dimensions, where $x$ is the horizontal direction, and $z$ is the vertical coordinate. Assuming the solutions are permanent progressive waves of the form $$\\eta = a\\ cos(kx-\\omega t)$$ with $a$ the amplitude, $k$ the wavenumber and $\\omega$ the frequency, we find that the linear governing equations imply \n$$\\omega^2 = gk \\tanh(kh)$$\nNow, if we follow waves of constant phase $\\theta = kx -\\omega t$, we see that these waves travel at a speed $c = \\omega/k$. In shallow water, $kh \\gg 1$, so that \n$$\\omega^2 \\approx ghk^2\\\\ (\\text{and}) \\\\c = \\sqrt{gh},$$\nwhile in deep water, $kh \\ll 1$ so that\n$$\\omega^2  \\approx gk\\\\ (\\text{and}) \\\\ c= \\sqrt{\\frac{g}{k}}$$ \nThe first thing we notice is that in deep water, the waves are dispersive, meaning the phase velocity depends on the wavenumber. This is why, for instance, when swells come to shore, it is the longest waves that arive first. In shallow water, to first order, the waves are not dispersive. \nTo first order, wakes are nothing more than linear superposition of waves, due to a moving point disturbance. This is known as the Kelvin ship wake problem, and I discussed a way to derive this result here. \nNow, the above description barely constitutes a summary. For instance, there are many interesting effects that happen when capillary effects are included. For deep water capillary waves\n$$\\omega^2 = Tk^3$$\nwhere $T$ is the surface tension of water. We see that for these waves, the velocity increases with wavenumber, in contrast with gravity waves. However, this equation is academic, as any description of capillary waves must necessarily include dissipation, which is significantly more difficult to model (and has only been done for nonlinear cases numerically). \nSecond order effects (eg in shallow water solitons, in deep water Stokes effects and the nonlinear Schr\u00f6dinger equation) are really interesting but involve heavier lifting.", "meta": {"post_id": 121327, "input_score": 27, "output_score": 38, "post_title": "What determines the speed of waves in water?"}}
{"input": "Why can't cables used for computer networking transfer data really fast, say at the speed of light?\nI ask this because electricity travels at the speed of light. Take Ethernet cables for example, I looked them up on wikipedia. \nPropagation speed   0.64        c\n\nWhy only 64% What does propagation speed mean? I know there are other variables affecting the latency and perceived speed of computer network connections, but surely this is a bottle neck.\nIn other words, I'm asking, what is it about a fiber-optics cable that makes it faster than an Ethernet cable?", "output": "Since cables carry electricity moving at the speed of light, why aren't computer networks much faster?\n\nPerhaps I can address your confusion with a rhetorical question:\nSince air carries sound moving at the speed of sound, why can't I talk to you much faster?\nThe speed of sound is much slower than light, but at 340 m/s in air, it's still pretty damn fast. However, this isn't the speed of the channel, it is its latency. That is, if you are 340 meters away, you will hear me 1s after I make a sound. That says nothing about how fast I can communicate with you, which is limited by how effectively I can speak, and how well you can hear me.\nIf we are in a quiet room, I can probably speak very quickly and you can still hear me. If we are far apart or the environment is noisy, I will have to speak more slowly and clearly.\nWith electrical communications the situation is much the same. The speed limit is not due to the latency, but rather how fast one end can transmit with the other end still being able to reliably receive. This is limited by noise picked up from the environment and distortions introduced by the cable.\nAs it turns out, especially for long distances, it is easier (and more economical) to manufacture a fiber optic cable that does not permit outside interference and introduces very little distortion, and that is why fiber optic cables are preferred for long distance, high speed networking.\nThe reasons for optical fiber's superior properties are many, but a significant development is single-mode fiber. These are fibers which, through carefully controlled geometry and research clever enough to earn a Nobel prize, support electromagnetic propagation in just one mode. This significantly reduces modal dispersion, which has the undesirable effect of \"smearing\" or \"spreading\" pulses which encode information. This is a kind of distortion that if excessive, renders the received signal unintelligible, thus limiting the maximum rate at which information can be transmitted.\nA further advantage is that fiber optic communications operate at an extremely high frequency, which reduces chromatic dispersion, a distortion due to different frequencies propagating at different speeds. Typical wavelengths used in fiber are in the neighborhood of 1550 nm, or a frequency of around 193000 GHz. By comparison, category 6a cable is specified only up to 0.5 GHz. Now, in order to transmit information we must modulate some aspect of the signal. A very simple modulation would be turning the transmitter on and off. However, these transitions mean the signal can not consist of just one frequency of light (Fourier components), so the different frequency components of the pulse will be subject to chromatic dispersion. As we increase the carrier frequency but hold the bitrate the same, the fractional bandwidth decreases. That is, the transitions from the modulation become slower relative to the carrier frequency. Thus, chromatic dispersion is decreased, since the signal becomes more like just one frequency of light.\nModern single-mode fiber is so good that the information rate is usually limited by our technology to manufacture the receivers and transmitters at the ends, not by the cable. As an example, wavelength-division multiplexing was developed (and is constantly improved even today) to allow multiple channels to coexist on the same fiber. Several times, networks have been upgraded by upgrading the transceivers at the ends, leaving the cable unchanged. Considering the cost of upgrading a transcontinental cable, the economic advantage should be obvious.", "meta": {"post_id": 129626, "input_score": 34, "output_score": 71, "post_title": "Since cables carry electricity moving at the speed of light, why aren't computer networks much faster?"}}
{"input": "Whenever the Doppler effect is mentioned, it's typically in the context of sound waves or electromagnetic radiation. On the cosmological scale, red-shifting is also important because of the enormous speed of receding galaxies, thanks to the expansion of the universe. \nYet, red-shift is always discussed as the red-shifting of electromagnetic waves. Can gravitational waves be red-shifted? If so, could observations of them be used like red-shifted electromagnetic waves from distant sources are; that is, to figure out how fast an object is receding?", "output": "Yes, gravitational waves will undergo the same red-shift as any wave that propagates at $c$. There were probably very violent gravitational waves in the very early universe. If those waves hadn't been red-shifted, they'd be ripping us apart right now.\n\nIf so, could observations of them be used like red-shifted electromagnetic waves from distant sources are - that is, to figure out how fast an object is receding?\n\nGravitational waves have frequencies that vary over time and that also depend on the particular physical characteristics of the emitting systems. Therefore we don't know a priori what frequency a wave should have had when emitted. This is different from electromagnetic waves in a discrete spectrum.", "meta": {"post_id": 137292, "input_score": 39, "output_score": 38, "post_title": "Can gravitational waves be red-shifted?"}}
{"input": "On a clear morning, light comes through this window (viewed from the inside)\n\nIt then hits the door on the opposite side (so viewing from the outside the door straight on the other side)\n\nThere is nothing particularly special going on. \nHowever, if I go through the door and turn around to face the door, I see this\n\nLight seems to be dispersing into the color spectrum solely because of the hole in the wooden door. Some days it's even clearer than it is today.\nWhat gives? I know light can do this through prisms, but how come it's happening with only a hole in a door?\n\nEdit\nAs per Floris' instruction, I did a little more experimenting. Here are the results (extra hint/spoiler):\n\n \n\n\n It's far from perfect because I made the hole using a black gym bag and some masking tape, and used a handheld mirror to reflect it onto the door, but I think it shows his explanation to be correct pretty well!", "output": "You have created a rather poor pinhole camera (camera obscura). You can see an \"image\" of the sky, a green space (trees) and even a reddish brown blur that is your driveway.\nThis is not diffraction or refraction - it's geometrical (classical) optics. Because the hole is pretty big, you see a very blurry image. But basically, the light from the sky falling through the hole hits one part of the door; the light from the trees hits a slightly different part; and the light from the driveway (the lowest object on the outside) hits the highest part on the inside, after coming through the hole.\n\nIncidentally - if you took a picture from the perspective of the hole in the door, I am guessing you would see more of the sky - in your photo of the view, the sky is barely visible, but in the doorhole image it's much more prominent; and conversely, one sees less of the driveway. This is consistent with the photo being taken from a different vantage point.", "meta": {"post_id": 138003, "input_score": 92, "output_score": 121, "post_title": "Why does my wooden door disperse light into a rainbow color spectrum?"}}
{"input": "For all machines (cars, elevators, computers, etc), when size, power requirements, dimensions are scaled by a constant N, will it work just as is?\nWill a car with all its parts 10x larger still work like a normal car, just larger?", "output": "This is a great question. An influential early discussion of it was given in a 1959 talk by Richard Feynman, There's Plenty of Room at the Bottom. Basically the answer is no, machines are not linearly scalable. For example, lubrication doesn't work for very small machines. A general way of looking at this is that we have various physical quantities, and they scale in different ways. For example, area is proportional to length squared, while volume goes like length cubed. Because different things scale differently, what works on one scale doesn't work on another. A good example is the animal world -- after all, animals are a type of machine. A spider the size of an elephant would collapse under its own weight. This is because the strength of the animal's limbs go like the cross-sectional area, while the weight the limbs have to support is proportional to volume.", "meta": {"post_id": 139092, "input_score": 31, "output_score": 48, "post_title": "Are all machines linearly scalable?"}}
{"input": "I have read different speeds of Earth in different sources. $382\\;{\\rm km}/{\\rm s}$, $12\\;{\\rm m}/{\\rm s}$ and even $108,000\\;{\\rm km}/{\\rm h}$. Basically, it's moving too fast around the Sun. And the Solar System is moving too. So why don't we feel it and why doesn't it harm us in any way? Inertia can only be a part of it. But what's the whole reason?", "output": "Speed doesn't kill us, but acceleration does. \nWhen astronauts go into space at launch and when fighter pilots turn very tight turns at high speed they experience 'high g forces' - their bodies are accelerated very fast as they accelerate and gain speed to go into space or as the direction of their speed changes. One of the problems with this is that for fighter pilots the blood can rush to the feet (black out) or to the head (red out). Too much acceleration makes people pass out and could at extremes be fatal I guess.\nTo go around the sun in (nearly) a circular path we are acclerated by the gravity from the sun. The acceleration can be calculated by $v^2/r$ where $v$ is our speed and $r$ is the distance to the centre of the sun. This acceleration turns out to be $\\sim~0.006~m/s^2$. By contrast the acceleration that we feel here at the surface due to the gravitational pull of the earth on us is $\\sim~10~m/s^2$. So the acceleration due to travelling around the sun is so small we don't notice it. We do notice the pull of gratvity from the earth on us, but our bodies are used to it and can cope with it. \nTo think about it another way we can go very fast in a car on a motorway/highway without noticing it, the big danger is having to stop very quickly or crashing when we change speeds very rapidly - acceleration is the rate of change of speed so changing speed very rapidly is equivalent to a very high acceleration - in a car we might call this deceleration.\n[for calculation above $v=3 \\times 10^4~m/s$ and $r=1.5 \\times 10^{11}m$]\nafter good comment from hdhoundt -\nFor astronauts in orbit (e.g. in the space station) they can cope with the acceleration they experience, which holds them in orbit around the earth. Indeed they feel weightless because they are not held by the gravity of earth on the surface. Instead they and their surroundings are in 'constant free fall'. The speed of the space station in orbit is $7.71 km/s$, which is $\\sim~ 17,000 ~mph$.\nFull discussion of this topic might venture into relativity, but I think that is beyond the scope of the question.\nafter good comment from Mooing Duck -\nPerhaps even more dangerous than acceleration is jerk, which is the rate of change of acceleration and other higher order terms. Jerk would be very severe in the case of car collisions. - But also if the driver of a car or bus has to 'brake' and slow down very suddenly it can be very uncomfortable for the passengers. \nAfter good comment from Jim (and Cory)-\nGood point raised about acceleration and/or jerk on a human body. If every part (and every particle) of the body experience the same acceleration or jerk then the body will suffer significantly less (possibly no) damage compared to when one part of the body is accelerated of jerked and the acceleration or jerk is transmitted to other parts of the body by the structure of the body. The classic example here is 'whiplash' neck injury, where a jerk on the body is transmitted to the head through the neck. To reduce the damage this may cause seats in cars generally hare head rests that will support the back of the head and for people who are involved in motor sports (e.g. car racing) may wear a neck brace/support that prevents the head from swinging backwards and forwards on the neck in the event of a collision. \nAnother aspect of acceleration to all part of the body concerns rocket launch for astronauts. The rockets will be designed so that as much as possible all part of the body are equally supported and the body lies 'flat with respect to the acceleration' so that the blood in the astronaut's body does not rush to the feet or head. This is a serious consideration and Memory Foam came from research by NASA into safety for aircraft cushions and helped cushion astronauts in rockets.", "meta": {"post_id": 144736, "input_score": 19, "output_score": 41, "post_title": "Why doesn't the speed of Earth (moving through space) kill us?"}}
{"input": "In a physics text book I read the following:\n\n$$e/m=1.758820150(44) \u00d710^{11} \\mathrm{C/kg} $$ \n  In this expression, $(44)$ indicates the likely uncertainty in the last two digits, $50$.\n\nHow should I understand this uncertainty? Does it mean $\\pm 44$ on the last two digits?", "output": "The digits in parentheses are the uncertainty, to the precision of the same number of least significant digits. (The meaning of the uncertainty is context-dependent but generally represents a standard deviation, or a 95% confidence interval.) So:\n$$e/m=1.758\\,820\\,1\\color{blue}{50}\\,\\color{magenta}{(44)}\u00d710^{11} \\ \\mathrm{C/kg}=\\left(1.758\\,820\\,1\\color{blue}{50}\u00d710^{11} \\pm 0.000\\,000\\,0\\color{magenta}{44}\u00d710^{11}\\right) \\ \\mathrm{C/kg}$$", "meta": {"post_id": 158589, "input_score": 26, "output_score": 38, "post_title": "Uncertainty in parenthesis"}}
{"input": "It is common in popular science culture to assume that Hawking radiation causes black holes to vaporize. And, in the end, the black hole would explode. I also remember it being mentioned in A Brief History of Time.\nWhy would a black hole explode? Why can't it gradually vanish to zero? What is the exact mechanism or theory which causes a black hole to explode?", "output": "The expression for the power emitted as Hawking radiation is\n$$ P = \\frac{\\hbar c^6}{15360 \\pi G^2 M^2} = 3.6\\times10^{32} M^{-2}\\ \\text{W} = -c^2 \\frac{dM}{dt},$$\nwhere the term on the far right hand side expresses the rate at which the black hole mass decreases due to the emission of Hawking radiation.\nYou can see that what happens is that the power emitted actually increases as $M$ decreases. At the same time, the rate at which the mass decreases also increases.\nSo as the black hole gets less massive, the rate at which it gets less massive increases rapidly and hence the power it emits increases very, very rapidly. \nBy solving this differential equation it can be shown that the time to evaporate to nothing is given by\n$$ t = 8.4\\times10^{-17} M^3\\ \\text{s},$$\nso for example a 100 tonne black hole would evaporate in $8.4 \\times10^{-2}\\ \\text{s}$, emitting approximately $E = Mc^2 = 9\\times 10^{21}$ joules of energy as it does so \u2013 equivalent to more than a million megatons of TNT. I guess you could call this an explosion!\nThis will be the fate of all evaporating black holes, but most will take a very long time to get to this stage (even supposing they do not accrete any matter).\nThe evaporation time is only less than the age of the universe for $M < $ a few $10^{11}\\ \\text{kg}$. A 1 solar mass black hole takes $2\\times10^{67}$ years to evaporate.\nEDIT: The Hawking radiation temperature is given by\n$$ kT = \\frac{\\hbar c^3}{8 \\pi GM}.$$\nUnless the temperature is well above the ambient temperature (at a minimum the cosmic microwave background temperature), the black hole will always absorb more energy than it radiates, and get bigger. i.e. to evaporate\n$$ \\frac{\\hbar c^3}{8 \\pi GM} > kT_{\\rm ambient}$$\n$$ M < \\frac{1.2\\times10^{23}}{T_{\\rm ambient}}\\ {\\rm kg}$$\nTherefore unless I've made a mistake, this proviso is of no practical importance other than for evaporating black holes (i.e. those with $M<10^{11}$ kg) in the early universe. \nThe temperature of a black hole goes as its evaporation timescale as $t_{\\rm evap}^{-1/3}$. The temperature of the early, radiation-dominated, universe scales as $t^{-1/2}$. Thus it appears to be the case that at some point in the past, a black hole that might have had an evaporation timescale shorter than the age of the universe is incapable of doing so.", "meta": {"post_id": 159937, "input_score": 30, "output_score": 51, "post_title": "Why would a black hole explode?"}}
{"input": "The Andromeda galaxy is 2,538,000 light years away, so if we view Andromeda from a telescope, we see Andromeda how it was 2,538,000 years ago. Now the diameter of the visible universe is 92 billion light years so if we say that we are at the center so the radius is 46 billion light years. So, if we see the farthest we can from our point, that will be 46 billion light years, so it means that we have seen the universe how it was 46 billion years ago, so why can't we say that universe was born 46 billion years ago?\nAnd if still someone argues that 13.8 billion years ago universe was born then we should have seen the universe of how it was even before the singularity.\nAnd if my logic of 49 billion years seems right then the thing we say that universe was born 13.8 billion years ago should be wrong, shouldn't it?\nHoping for a excellent answer with excellent explanation! :)", "output": "There are two parts to your question. First, why can we see things \"46 billion light years away\" if the Universe is only about 13.8 billion years old? Because the Universe is expanding. How far does a photon travel in 13.8 billion years in an expanding Universe? It depends on the rate of expansion. I'll give a simplified example to illustrate the point: \nImagine a Universe that is 10 billion years old. Its expansion history is simple. It started out with size $R$, which remained constant for 5 billion years, then the size suddenly doubled to $2R$, and remained constant for another 5 billion years. So, after 10 billion years, how far is the photon from its starting point? Well, it travels 5 billion light years in the first 5 billion years. When the size of the Universe doubles, so does the space between it and its point of origin, so just after the doubling it is 10 billion light years from where it started. Then in the next 5 billion years it travels another 5 billion light years, ending 15 billion light years from where it started. Notice that the constant speed of light from special relativity comes through intact here - the photon ends 15 billion light years from where it started after 10 billion years, but always moves at speed $c$ and only \"travelled\" 10 billion light years. Obviously a sudden doubling of size is not realistic, but the same idea applies to a more gradual, smooth expansion. Note that the expansion does not necessarily need to be \"faster than light\" (whatever that means). Any expansion at all will mean that the photon will be further from its starting point than expected in a static Universe when it arrives.\nSecond part to your question: why can't we see the Big Bang? Because a photon cannot reach us directly from the Big Bang. On a sunny day, I can see the Sun clearly because most of its photons that I observe leave the solar surface and travel along unimpeded to reach me. If it's cloudy, there's still sunlight - solar photons are reaching me - but I can't see the Sun directly because the photons are scattered along the way by the clouds. The early Universe was \"cloudy\" - it was full of an ionized plasma that scattered photons very frequently. As the Universe expanded and the plasma cooled, it eventually became transparent to the photons and the \"Big Bang photons\" have been travelling more or less without scattering ever since. This \"surface of last scattering\" is visible as the cosmic microwave background, and is the closest we'll get to seeing the Big Bang (except perhaps we could observe neutrinos or gravity waves from beyond the CMB because they are not scattered as strongly in the early Universe).", "meta": {"post_id": 178008, "input_score": 31, "output_score": 40, "post_title": "Why haven't we seen the big bang?"}}
{"input": "In talking about Higgs mechanism, the first part is always some introduction to the concept of spontaneous  symmetry breaking (SSB), some people saying that Higgs mechanism is the results of SSB of local gauge symmetry, some people says that we can formulate Higgs mechanism in a gauge invariant way, some people also says that we need only a non-zero vaccum expectation value... I am confused about this different or maybe same point of views.\nIn this post: How does the Higgs mechanism work? , the most highly voted answer, I still can't feel how SSB worked in Higgs mechanism. It seems that the validity of the last part, the appearance of a mass term for $A$, is guaranteed if we have a non-zero equilibrium value $\\phi_0$ to expand around. I do not see that the requirement that the phase of the field $\\phi$ need to be fixed at some particular value to generate mass term. Thus it seems to me it is not true that SSB is really indispensable for Higgs mechanism.\nTo put it simply:\nThe spontaneous breaking of what is attributed to Higgs mechanism?\n\nlocal gauge symmetry\n\nglobal symmetry, since breaking of a \"gauge symmetry\" should not have any effect on physics. In Higgs mechanism, the really broken symmetry is a global one. Mathematically, it is similar in looking as fixing a gauge, but one should not think of it as a spontaneous breakdown of local gauge symmetry.\n\nother.\n\n\nIs SSB really indispensable for Higgs mechanism?\n\nyes, Higgs mechanism is relied on the SSB of some symmetry (above question), the other approaches of description eventually has spontaneously broke some symmetry.\n\nNo, the SSB is just one way to describe Higgs mechanism (or even not a complete way), what is really need is the non-zero vacuum expectation value, for example in the linked post the requirement for the mass term to occur is to have some non-zero expectation value of $\\phi$ to expand around, we do not need the phase of the field to be fixed, thus the symmetry is not broken.\n\nOther.\n\n\nsome reference materials:\n\nIs Elitzur's theorem valid only in lattice field theory? States that SSB of local gauge symmetry is impossible.\n\nGauge invariant accounts of the Higgs mechanism in the abstract states that:\n\n\n\ngauge symmetries merely reflect a redundancy in the state description\nand therefore the spontaneous breaking can not be an essential\ningredient. Indeed, as already shown by Higgs and Kibble, the\nmechanism can be explained in terms of gauge invariant variables,\nwithout invoking spontaneous symmetry breaking\n\n\nIs electromagnetic gauge invariance spontaneously violated in superconductors? In the introduction it says:\n\n\nIn particular, we emphasize that global U(1) phase rotation symmetry,\nand not gauge symmetry, is spontaneously violated, and show that the\nBCS wave function is, contrary to claims in the literature, fully\ngauge invariant", "output": "It is frequently stated the Higgs mechanism involves spontaneous breaking of the gauge symmetry. This is, however, entirely wrong. In fact, gauge symmetries cannot be spontaneously broken. \nA standard argument for this is that gauge symmetries are not actual symmetries, they are just a\nreflection of a redundancy in our description the system; two states related by\na gauge transformation are actually the same physical state. Thus, a gauge\nsymmetry is physically a \"do-nothing transformation\" and thus it does not make\nsense for it to be\nspontaneously broken.\nThis argument does seem like a bit of a cop-out, though -- I could just declare\nany symmetry to be a ``do-nothing transformation'' by fiat if I wanted to.\nA more satisfying explanation is: even if we interpret\ngauge symmetries as real symmetries, they can never be spontaneously broken.\nThis result is known as Elitzur's theorem, and it's quite easy to\nunderstand why it should be true.  Let's focus on classical thermal systems\n-- quantum systems at zero temperature map onto classical thermal systems in\none higher space dimension so the argument should carry over.\nFirst recall the\nhand-waving argument for why spontaneous symmetry breaking can take place in,\nsay, the 2-D Ising model at finite temperature. The 2-D Ising model has two symmetry-breaking ground states: all\n$\\uparrow$ and all $\\downarrow$. But, if I want to get between them by local\nthermal fluctuations then I have to create a domain and grow it until it\nencompasses the whole system, which implies an extensive energy penalty due to\nthe energy cost of the domain wall. Thus, at low temperatures transitions\nbetween the two ground states are exponentially suppressed in the system size\nand so the system gets stuck in either all $\\uparrow$ or all $\\downarrow$, so\nthe symmetry is spontaneously broken. (The same argument shows why the\n1-D Ising model cannot have spontaneous symmetry breaking at finite\ntemperature, because there is no extensive energy penalty to get from all\n$\\uparrow$ to all $\\downarrow$.)\nOn the other hand, since a gauge symmetry is a local symmetry, this\nargument breaks down. Any two symmetry-breaking ground states are related by a\nsequence of local gauge transformations, which (since they commute with the\nHamiltonian) have exactly zero energy penalty. Thus, there is no energy barrier\nbetween different ground states, and the system will explore the entire space of\nground states -- so no symmetry-breaking. We expressed everything here in terms\nof classical thermal systems, but it will be important for later that the quantum version of no\nsymmetry breaking is that the Hamiltonian must have a unique ground state\n(at least with appropriate boundary conditions), because degenerate ground\nstates can always couple to each other through quantum fluctuations to create a\nsuperposition state with lower energy.\nSo now that we have established that the Higgs mechanism does not, and cannot,\ncorrespond to spontaneous symmetry breaking, let's take a look at what's really\nhappening. For simplicity we will look at the simplest case, namely (quantum, $T = 0$)\n$\\mathbb{Z}_2$ lattice gauge theory. This comprises two-dimensional quantum systems on\nall the vertices and links of a square lattice. The ones on the vertices\ncomprise the \"matter field\" and the ones on the links comprise the \"gauge\nfield\". We denote the Pauli matrices on the links by $\\sigma_{ab}^x$, etc. and on\nthe vertices by $\\tau_{a}^x$, etc.\nThe Hamiltonian is\n$$\n  H = -g \\sum_{\\langle a, b\\rangle} \\sigma^x_{ab} - \\frac{1}{g} \\sum_{\\square}\n  \\sigma^z \\sigma^z \\sigma^z \\sigma^z - \\lambda \\sum_{a} \\tau^x_a -\n  \\frac{1}{\\lambda} \\sum_{\\langle a, b \\rangle} \\tau_a^z \\sigma^z_{ab} \\tau_b^z\n$$\n[the second-term is a sum of four-body $\\sigma^z$ interactions on squares of the lattice (\"plaquettes\"), and $\\langle a, b \\rangle$ means a sum over nearest neighbor pairs of vertices.]\nThis Hamiltonian has a gauge symmetry $\\tau^x_a \\prod_{\\langle a, b \\rangle}\n\\sigma^x_b$ for each vertex $a$.\nOne can map out the phase diagram of this Hamiltonian in detail, but here we\nwill just want to focus on the \"Higgs\" phase, which occurs when $g$ and\n$\\lambda$ are small so that the second and fourth terms dominate. We will take\nthe limit $g \\to 0$, claiming without proof that the $g$ small but not\nzero case is qualitatively similar. In this limit the ground state must be a\n$+1$ eigenstate of the product of $\\sigma^z$\naround every plaquette (\"no-flux\" condition). If the model is defined on a space with no\nnon-contractible loops, this implies that we can write, for every ``no-flux''\nconfiguration, $\\sigma^z_{ab} = \\widetilde{\\sigma}^z_a \\widetilde{\\sigma}^z_b$\nfor some choice of $\\{ \\widetilde{\\sigma}^z_a \\} = \\pm 1$.\nHence, all \"no-flux\" configurations can be made to satisfy $\\sigma^z_{ab} = 1$\nby an appropriate gauge transformation. Thus, under this gauge-fixing condition, the Hamiltonian reduces to the\ntransverse-field quantum Ising model on the matter fields:\n\\begin{equation}\n  H_{gf} = -\\lambda \\sum_{a} \\tau^x_a - \\frac{1}{\\lambda} \\sum_{\\langle a,b \\rangle} \\tau_a^z \\tau_b^z\n\\end{equation}\nwhich we know will have a symmetry-breaking phase (i.e. a two-fold degenerate\nground state) for small $\\lambda$. This is\nthe Higgs phase.\nQ: But hang on, now, doesn't Elitzur's theorem say that gauge symmetries can't be\nspontaneously broken?\nA: Well, actually in fixing the gauge we used up the local\npart of the gauge symmetry, and the above Hamiltonian $H_{gf}$ only has a\n$\\mathbb{Z}_2$ global symmetry. Thus, it does not violate\nElitzur's theorem for it to have spontaneous symmetry breaking.\nQ: But what about the original Hamiltonian, $H$? It had a\n  gauge symmetry, and it's equivalent to the new Hamiltonian $H_{gf}$, which has\n  spontaneous symmetry-breaking, so the original Hamiltonian must have\nspontaneous symmetry-breaking too?\nA: You have to be very careful about the sense in which $H$ and $H_{gf}$ are\nequivalent, because the \"gauge-fixing\" transformation which relates them\nisn't unitary (since it's many-to-one). Still, if one thinks hard enough and\nuses the fact that $H$ is invariant under the gauge symmetry, it\nis not hard to show that there is a correspondence between eigenstates of $H$\nand of $H_{gf}$. However, because the two degenerate ground states of $H_{gf}$ are\nrelated by a gauge transformation, they actually correspond only to a single\nunique ground state of $H$, in accordance with Elitzur's theorem. This unique\nground state $|\\Psi\\rangle_H$ of $H$ can be found in terms of the ground states  $|\\Psi\\rangle_{H_{gf}}$ of $H_{gf}$ by\nsymmetrizing them to make them gauge-invariant, i.e.\n\\begin{equation}\n  |\\Psi\\rangle_H = \\sum_{\\mathcal{G}} \\mathcal{G} |\\Psi\\rangle_{H_{gf}},\n\\end{equation}\nwhere the sum is over all possible gauge transformations $\\mathcal{G}$ (since\nthe two degenerate ground states are related by a gauge transformation, this\ngives the same $|\\Psi\\rangle_H$ regardless of which one you choose to be\n$|\\Psi\\rangle_{H_{gf}}$.)\nSo in summary, the Higgs mechanism appears to resemble spontaneous symmetry breaking in a particular choice of gauge, but this is an illusion. The true ground state is unique and gauge-invariant.", "meta": {"post_id": 190416, "input_score": 45, "output_score": 47, "post_title": "What role does \"spontaneous symmetry breaking\" play in the \"Higgs Mechanism\"?"}}
{"input": "There seem to be two different things one must consider when representing a symmetry group in quantum mechanics:\n\nThe universal cover: For instance, when representing the rotation group $\\mathrm{SO}(3)$, it turns out that one must allow also $\\mathrm{SU}(2)$ representations, since the negative sign a \"$2\\pi$ rotation\" induces in $\\mathrm{SU}(2)$ is an overall phase that doesn't change the physics. Equivalently, all representations of the Lie algebra are what we seek. ($\\mathfrak{so}(3) = \\mathfrak{su}(2)$, but although every representation of the algebra is one of the universal cover, not every representation of the algebra is one of $\\mathrm{SO}(3)$.)\nCentral extensions: In conformal field theory, one has classically the Witt algebra of infinitesimal conformal transformations. From the universal cover treatment one is used to in most other cases, one would expect nothing changes in the quantum case, since we are already seeking only representation of an algebra. Nevertheless, in the quantization process, a \"central charge\" appears, which is often interpreted to arise as an \"ordering constant\" for the now no longer commuting fields, and we have to consider the Virasoro algebra instead.\n\nThe question is: What is going on here? Is there a way to explain both the appearence of universal covers and central extensions in a unified way?", "output": "Yes. Both universal covers and central extensions incurred during quantization come from the same fundamental concept:\nProjective representations\nIf $\\mathcal{H}$ is our Hilbert space of states, then distinct physical states are not vectors $\\psi\\in\\mathcal{H}$, but rays, since multiplication by a complex number does not change the expectation values given by the rule\n$$ \\langle A\\rangle_\\psi = \\frac{\\langle \\psi \\vert A \\vert \\psi \\rangle}{\\langle \\psi \\vert \\psi \\rangle}$$\nnor the transition probabilities\n$$ P(\\lvert \\psi \\rangle \\to \\lvert \\phi \\rangle) = \\frac{\\lvert \\langle \\psi \\vert \\phi \\rangle\\rvert^2}{\\langle \\phi \\vert \\phi \\rangle\\langle \\psi \\vert \\psi \\rangle}$$\nThe proper space to consider, where every element of the space is indeed a distinct physical state, is the projective Hilbert space\n$$ \\mathrm{P}\\mathcal{H} := \\mathcal{H} /\\sim$$\n$$ \\lvert \\psi \\rangle \\sim \\lvert \\phi \\rangle :\\Leftrightarrow \\exists c\\in\\mathbb{C}: \\lvert \\psi \\rangle = c\\lvert\\phi\\rangle$$\nwhich is just a fancy way to write that every complex ray has been shrunk to a point. By Wigner's theorem, every symmetry should have some, not necessarily unique, unitary representation $\\rho : G \\to \\mathrm{U}(\\mathcal{H})$. Since it has to descend to a well-defined ray transformation, the action of the symmetry is given by a group homomorphism into the projective unitary group $G \\to \\mathrm{PU}(\\mathcal{H})$, which sits in an exact sequence\n$$ 1 \\to \\mathrm{U}(1) \\to \\mathrm{U}(\\mathcal{H}) \\to \\mathrm{PU}(\\mathcal{H}) \\to 1$$\nwhere $\\mathrm{U}(1)$ represents the \"group of phases\" that is divided out when passing to the projective space. It is already important to notice that this means $\\mathrm{U}(\\mathcal{H})$ is a central extension of $\\mathrm{PU}(\\mathcal{H})$ by $\\mathrm{U}(1)$.\nTo classify all possible quantumly allowed representations of a symmetry group $G$, we need to understand the allowed Lie group homomorphisms $\\sigma : G\\to\\mathrm{PU}(\\mathcal{H})$. Since linear representations are nicer to work with than these weird projective things, we will look at\nClassifying projective representations by unitary linear representations\nFor any $g\\in G$, choose a representative $\\Sigma(g)\\in\\mathrm{U}(\\mathcal{H})$ for every $\\sigma(g)\\in\\mathrm{PU}(\\mathcal{H})$. This choice is highly non-unique, and is essentially responsible for how the central extension appears. Now, since for any $g,h\\in G$ we have $\\sigma(g)\\sigma(h) = \\sigma(gh)$, the choices of representatives must fulfill\n$$ \\Sigma(g)\\Sigma(h) = C(g,h)\\Sigma(gh)$$\nfor some $C : G\\times G\\to\\mathrm{U}(1)$. Applying associativity to $\\Sigma(g)\\Sigma(h)\\Sigma(k)$ gives the consistency requirement\n$$ C(g,hk)C(h,k) = C(g,h)C(gh,k)\\tag{1}$$\nwhich is also called the cocycle identity. For any other choice $\\Sigma'$, we must have\n$$ \\Sigma'(g) = f(g)\\Sigma(g) $$\nfor some $f : G \\to \\mathrm{U}(1)$. $\\Sigma'$ has an associated $C'$, and so we get\n$$ C'(g,h)\\Sigma'(gh) = \\Sigma'(g)\\Sigma'(h) = f(g)f(h)C(g,h)f(gh)^{-1}\\Sigma'(gh)$$\nwhich yields the consistency requirement\n$$ C'(g,h)f(gh) = f(g)f(h)C(g,h)\\tag{2}$$\nTherefore, projective representations are classified giving the choice of unitary representatives $\\Sigma$, but those that are related by $(2)$ give the same projective representation. Formally, the set\n$$ H^2(G,\\mathrm{U}(1)) := \\{C : G\\times G \\to \\mathrm{U}(1)\\mid C \\text{ fulfills } (1)\\} / \\sim$$\n$$ C \\sim C' :\\Leftrightarrow \\exists f : (2) \\text{ holds }$$\nclassifies the projective representations of $G$. We want to use it to construct a unitary representation of something that classifies the projective representation:\nDefine $G_C := G \\times_C \\mathrm{U}(1)$ for any representative $C$ of an element in $H^2(G,\\mathrm{U}(1)$ by endowing the Cartesian product $G \\times \\mathrm{U}(1)$ with the multiplication\n$$ (g,\\alpha)\\cdot(h,\\beta) := (gh,\\alpha\\beta C(g,h))$$\nOne may check that it is a central extension, i.e. the image of $\\mathrm{U}(1)\\to G \\times_C\\mathrm{U}(1)$ is in the center of $G_C$, and\n$$ 1 \\to \\mathrm{U}(1) \\to G_C \\to G \\to 1$$\nis exact. For any projective representation $\\sigma$, fix $\\Sigma,C$ and define the linear representation\n$$ \\sigma_C : G_C \\to \\mathrm{U}(\\mathcal{H}), (g,\\alpha) \\mapsto \\alpha\\Sigma(g)$$\nConversely, every unitary representation $\\rho$ of some $G_C$ gives a pair $\\Sigma,C$ by $\\Sigma(g) = \\alpha^{-1}\\rho(g,\\alpha)$.\nTherefore, projective representations are in bijection to linear representations of central extensions.\nOn the level of the Lie algebras, we have $\\mathfrak{u}(\\mathcal{H}) = \\mathfrak{pu}(\\mathcal{H})\\oplus\\mathbb{R}$, where the basis element $\\mathrm{i}$ of $\\mathbb{R}$ generates multiples of the identity $\\mathrm{e}^{\\mathrm{i}\\phi}\\mathrm{Id}$. We omit the $\\mathrm{Id}$ in the following, whenever a real number is added to an element of the Lie algebra, it is implied to be multiplied by it.\nRepeating the arguments above for the Lie algebras, we get that the projective representation $\\sigma : G \\to \\mathrm{PU}(\\mathcal{H})$ induces a representation of the Lie algebra $\\phi : \\mathfrak{g}\\to\\mathfrak{pu}(\\mathcal{H})$. A choice of representatives $\\Phi$ in $\\mathfrak{u}(H)$ classifies such a projective representation together with an element $\\theta$ in\n$$ H^2(\\mathfrak{g},\\mathbb{R}) := \\{\\theta : \\mathfrak{g}\\times\\mathfrak{g} \\to \\mathbb{R}\\mid \\text{ fulfills } (1') \\text{ and } \\theta(u,v) = -\\theta(v,u)\\} / \\sim$$\n$$ \\theta \\sim \\theta' :\\Leftrightarrow \\exists (b : \\mathfrak{g}\\to\\mathbb{R}) :\\theta'(u,v) = \\theta(u,v) + b([u,v])$$\nwith consistency condition\n$$ \\theta([u,v],w) + \\theta ([w,u],v) + \\theta([v,w],u) = 0 \\tag{1'}$$\nthat $\\theta$ respects the Jacobi identity, essentially.\nThus, a projective representation of $\\mathfrak{g}$ is classified by $\\Phi$ together with a $\\theta\\in H^2(\\mathfrak{g},\\mathbb{R})$. Here, the central extension is defined by $\\mathfrak{g}_\\theta := \\mathfrak{g}\\oplus\\mathbb{R}$ with Lie bracket\n$$ [u\\oplus y,v\\oplus z] = [u,v]\\oplus\\theta(u,v)$$\nand we get a linear representation of it into $\\mathfrak{u}(\\mathcal{H})$ by\n$$ \\phi_\\theta(u\\oplus z) := \\Phi(u) + a$$\nAgain, we obtain a bijection between projective representations of $\\mathfrak{g}$ and those of its central extensions $\\mathfrak{g}_\\theta$.\nUniversal covers, central charges\nWe are finally in the position to decide which representations of $G$ we must allow quantumly. We distinguish three cases:\n\nThere are no non-trivial central extensions of either $\\mathfrak{g}$ or $G$. In this case, all projective representations of $G$ are already given by the linear representations of $G$. This is the case for e.g. $\\mathrm{SU}(n)$.\n\nThere are no non-trivial central extensions of $\\mathfrak{g}$, but there are discrete central extensions of $G$ by $\\mathbb{Z}_n$ instead of $\\mathrm{U}(1)$. Those evidently also descend to projective representations of $G$. Central extensions of Lie groups by discrete groups are just covering groups of them, because the universal cover $\\overline{G}$ gives the group $G$ as the quotient $\\overline{G}/\\Gamma$ by a discrete central subgroup $\\Gamma$ isomorphic to the fundamental group of the covered group. Thus we get that all projective representations of $G$ are given by linear representations of the universal cover. No central charges occur. This is the case for e.g. $\\mathrm{SO}(n)$.\n\nThere are non-trivial central extensions of $\\mathfrak{g}$, and consequently also of $G$. If the element $\\theta\\in H^2(\\mathfrak{g},\\mathbb{R})$ is not zero, there is a central charge - the generator of the $\\oplus\\mathbb{R}$ in $\\mathfrak{g}_\\theta$, or equivalently the conserved charge belonging to the central subgroup $\\mathrm{U}(1)\\subset G_C$. This happens for the Witt algebra, where inequivalent $\\theta(L_m,L_n) = \\frac{c}{12}(m^3 - m)\\delta_{m,-n}$ are classified by real numbers $c\\in \\mathbb{R}$.", "meta": {"post_id": 203944, "input_score": 95, "output_score": 95, "post_title": "Why exactly do sometimes universal covers, and sometimes central extensions feature in the application of a symmetry group to quantum physics?"}}
{"input": "Why is the shape of the fringes in Young's double slit experiment hyperbolic? Morever what type of fringe pattern is obtained if slits are almost perpendicular to the screen?\n\nCan someone explain it to me with detailed mathematical calculations and images if possible? \nThis qoura link is not so rigorous.", "output": "I will give you the mathematical details at the last, first just visualize what is going on. I am assuming that slits are like pinholes because if you took into account that they are thin rectangles then fringes won't be exactly hyperbolic and it will be mixed problem of interference and diffraction.\nIn all the diagrams and animations, blue axis is Z, red is X and green is Y.\nThis is how a fringe looks on a screen (Pink) perpendicular to the y-axis(green) when two slits A and B are placed along the z-axis(Blue). \n\nNow a lot of people explain this by saying that:\n\"A fringe is obtained when path difference of interfering waves is constant. So, the locus of that point from which the difference between the distances from A and B to that point is constant is a Hyperbola. Hence, the fringes are Hyperbolic.\" This is true if we are looking, for the locus of those points, on a plane which passes through A & B. As the gif below shows different planes passing through A and B contain those hyperbolas:\n\nBut, that's not true, in general, if you are looking for the points in a plane which doesn't pass through points A and B. For example, if you look for fringes in a plane that is perpendicular to the line joining A and B, then the fringes will be CIRCULAR.\n\nBecause, it is true that for each plane passing through A and B locus of those points is a hyperbola, and whole 3D space can be thought as made up of infinite planes passing through points A & B, the locus in 3D space will be all those hyperbolas combined to form a hyperboloid; as shown below:\n\nNow if we want to find locus on any plane we can just take the intersection of this hyperboloid with the plane.\nMathematical Details:\nI will first prove that the locus is hyperboloid and then will take the intersections to find fringe shapes on desired planes.\nLet A be $(0,0,a)$ and B be $(0,0,-a)$. Coordinates are in the order (x,y,z). Locus of points which have a constant path difference is:\n$\\sqrt{(z+a)^2+(x^2)+(y^2)}-\\sqrt{(z-a)^2+(x^2)+(y^2)} = d $\n$\\sqrt{(z+a)^2+(x^2)+(y^2)} =\\sqrt{(z-a)^2+(x^2)+(y^2)} + d $\nSquaring both sides:\n${(z+a)^2+(x^2)+(y^2)} ={(z-a)^2+(x^2)+(y^2)} + 2\\sqrt{(z-a)^2+(x^2)+(y^2)}d + d^2 $\n$4za  = 2\\sqrt{(z-a)^2+(x^2)+(y^2)}d + d^2$\n$(2za - \\frac{d^2}{2})^2 = ((z-a)^2+(x^2)+(y^2)) d^2 $\nRe-arrange to get:\n$z^2 - \\frac{x^2 + y^2}{\\frac{4a^2}{d^2} -1} = \\frac{d^2}{4}$\nLet $\\frac{4a^2}{d^2} -1=k^2$\nSo you get: $z^2 - \\frac{x^2 + y^2}{k^2} = \\frac{d^2}{4}$\nNow, $x^2 + y^2 = {\\rho}^2$\n,where $\\rho$ is the distance of any point from z-axis or if you know cylindrical coordinates, it is the cylindrical radius.\nOur equation now becomes:\n$z^2 - \\frac{{\\rho}^2}{k^2} = \\frac{d^2}{4}$\nSo, it is a hyperboloid.\nIf the screen is perpendicular to y-axis(green axis), the equation of the plane would be $y = h$. Substitute $y=h$ in the equation of hyperboloid, you will get an equation of hyperbola (in x and z):\n$z^2 - \\frac{x^2}{k^2} = \\frac{d^2}{4} - \\frac{h^2}{k^2} $\nIt is shown below as as the black curve of intersection: \n\nIf the screen is perpendicular to line joining A and B (or perpendicular to z-axis) then substitute $z = h$ in the equation of the hyperboloid and you will get a circle in x and y, giving you the circular fringes $x^2 + y^2 = (h^2 - \\frac{d^2}{4})k^2$ as shown below as the black curve of intersection:", "meta": {"post_id": 210375, "input_score": 10, "output_score": 36, "post_title": "Why is the shape of the fringes in Young's double slit experiment hyperbolic?"}}
{"input": "As far as I understand, one requires that in order for the scalar product between two vectors to be invariant under Lorentz transformations $x^{\\mu}\\rightarrow x^{\\mu^{'}}=\\Lambda^{\\mu^{'}}_{\\,\\,\\alpha}x^{\\alpha}$, we require that the metric $\\eta_{\\mu\\nu}$ transform as $\\eta_{\\mu\\nu}\\rightarrow \\eta_{\\mu^{'}\\nu^{'}}=\\Lambda^{\\alpha}_{\\,\\,\\mu^{'}}\\eta_{\\alpha\\beta}\\Lambda^{\\beta}_{\\,\\,\\nu^{'}}$. \n[Since we require that $x^{\\mu^{'}}x_{\\mu^{'}}=x^{\\alpha}x_{\\alpha}\\Rightarrow x^{\\mu^{'}}x_{\\mu^{'}}=\\eta_{\\mu^{'}\\nu^{'}}x^{\\mu^{'}}x^{\\nu^{'}}=\\eta_{\\mu^{'}\\nu^{'}}\\Lambda^{\\mu^{'}}_{\\,\\,\\alpha}\\Lambda^{\\nu^{'}}_{\\,\\,\\beta}x^{\\alpha}x^{\\beta}=x^{\\alpha}x_{\\alpha}=\\eta_{\\alpha\\beta}x^{\\alpha}x^{\\beta}$].\nWhat confuses me, is that I've been reading up on the cosmological constant problem and in several sets of notes it is claimed that the contribution of the vacuum energy density to the energy-momentum tensor should be of the form $$T^{vac}_{\\mu\\nu}=-\\rho^{vac}g_{\\mu\\nu}$$ the argument being that the vacuum must be Lorentz invariant and the only Lorentz invariant tensor is the metric tensor $\\eta_{\\mu\\nu}$ (apart from the Levi-Civita tensor (density)). \nI don't see how this is the case by looking at $\\eta_{\\mu^{'}\\nu^{'}}=\\Lambda^{\\alpha}_{\\,\\,\\mu^{'}}\\eta_{\\alpha\\beta}\\Lambda^{\\beta}_{\\,\\,\\nu^{'}}$, how is it obvious that this is Lorentz invariant? Shouldn't it be something like $\\eta_{\\mu^{'}\\nu^{'}}=\\eta_{\\mu\\nu}$?\nApologies if this is a stupid question, but I'm just having a mental block over it.", "output": "I believe it can be useful to define the following concepts (I won't be very formal here for pedagogical reasons):\nAny event can be described through four real numbers, which we take to be: the moment in time it happens, and the position in space where it takes place. We call this four numbers the coordinates of the event. We collect these numbers in a tuple, which we call $x\\equiv (t,\\boldsymbol r)$. These numbers depend, of course, on which reference frame we are using: we could, for example, use a different origin for $t$ or a different orientation for $\\boldsymbol r$. This means: for $x$ to make sense, we must pick a certain reference frame. Call it $S$ for example.\nHad we chosen a different frame, say $S'$, the components of the same event would be $x'$, i.e., four real numbers, in principle different from those before. We declare that the new reference frame is inertial if and only if $x'$ and $x$ are related through\n$$\nx'=\\Lambda x \\tag{1}\n$$\nfor a certain matrix $\\Lambda$, that depends, for example, on the relative orientations of both reference frames. There are certain conditions $\\Lambda$ must fulfill, which will be discussed in a moment.\nWe define a vector to be any set of four real numbers such that, if its components in $S$ are $v=(v^0,\\boldsymbol v)$, then in $S'$ its components must be\n$$\nv'=\\Lambda v \\tag{2}\n$$\nFor example, the coordinates $x$ of an event are, by definition, a vector, because of $(1)$. There are more examples of vectors in physics, for example, the electromagnetic potential, or the current density, the momentum of a particle, etc.\nIt turns out that it is really useful to define the following operation for vectors: if $u,v$ are two vectors, then we define\n$$\nu\\cdot v\\equiv u^0 v^0-\\boldsymbol u\\cdot\\boldsymbol v\\tag{3}\n$$\nThe reason this operation is useful is that it is quite ubiquitous in physics: there are many formulas that use this. For example, any conservation law, the wave equation, the Dirac equation, the energy-momentum relation, etc.\nWe define the operation $\\cdot$ through the components of the vectors, but we know these components are frame-dependent, so if $\\cdot$ is to be a well-defined operation, we must have\n$$\nu\\cdot v=u'\\cdot v' \\tag{4}\n$$\nbecause otherwise $\\cdot$ would be pretty useless.\nThis relation $(4)$ won't be true in general, but only for some matrices $\\Lambda$. Thus, we declare that the matrices $\\Lambda$ can only be those which make $(4)$ to be true. This is a restriction on $\\Lambda$: only some matrices will represent changes of reference frames. Note that in pure mathematics, any invertible matrix defines a change of basis. In physics only a subset of matrices are acceptable changes of basis.\nSo, what are the possible $\\Lambda$'s that satisfy $(4)$? Well, the easier way to study this is to rewrite $(3)$ using a different notation: define \n$$\n\\eta=\\begin{pmatrix} 1 &&&\\\\&-1&&\\\\&&-1&\\\\&&&-1\\end{pmatrix} \\tag{5}\n$$\nThis is just a matrix that will simplify our discussion. We should not try to find a deep meaning for $\\eta$ (it turns out there is a lot of geometry behind $\\eta$, but this is not important right now). Using $\\eta$, its easy to check that $(3)$ can be written as\n$$\nu\\cdot v=u^\\mathrm{T}\\eta v \\tag{6}\n$$\nwhere in the r.h.s. we use the standard matrix product. If we plug $v'=\\Lambda v$ and $u'=\\Lambda v$ here, and set $u\\cdot v=u'\\cdot v'$, we find that we must have\n$$\n\\Lambda^\\mathrm{T} \\eta \\Lambda=\\eta \\tag{7}\n$$\nThis is a relation that defines $\\Lambda$: any possible change of reference frame must be such that $(7)$ is satisfied. If it is not, the $\\Lambda$ cannot relate two different frames. This relation is not in fact a statement of how $\\eta$ transforms (as you say in the OP), but actually a restriction of $\\Lambda$. It is customary to say that $\\eta$ transforms as $(7)$, which will be explained in a moment. For now, just think of $(7)$ as what are the possible matrices $\\Lambda$.\nAt this point, it is useful to introduce index notation. If $v$ is a vector, we call its components $v^\\mu$, with $\\mu=0,1,2,3$. On the other hand, we write the components of changes of frames $\\Lambda^\\mu{}_\\nu$. With this notation, $(2)$ can be written as\n$$\nv'^\\mu=\\Lambda^\\mu{}_\\nu v^\\nu \\tag{8}\n$$\nAlso, using index notation, the product of two vectors can be written as\n$$\nu\\cdot v=\\eta_{\\mu\\nu}u^\\mu v^\\nu \\tag{9}\n$$\nwhere $\\eta_{\\mu\\nu}$ are the components of $\\eta$.\nIndex notation is useful because it allows us to define the following concept: a tensor is an object with several indices, e.g. $A^{\\mu\\nu}$. But not any object with indices is a tensor: the components of a tensor must change in different frames of reference, such that they are related through\n$$\n\\begin{align}\n&A'^{\\mu\\nu}=\\Lambda^\\mu{}_\\rho \\Lambda^\\nu{}_\\sigma\\ A^{\\rho\\sigma} \\\\\n&B'^\\mu{}_\\nu=\\Lambda^\\mu{}_\\rho(\\Lambda^\\mathrm{T})_\\nu{}^\\sigma\\ B^\\rho{}_\\sigma\\\\\n&C'^{\\mu\\nu}{}_\\pi{}^\\tau=\\Lambda^\\mu{}_\\rho \\Lambda^\\nu{}_\\sigma (\\Lambda^\\mathrm{T})_\\pi{}^\\psi \\Lambda^\\tau{}_\\omega\\ C^{\\rho\\sigma}{}_\\psi{}^\\omega\n\\end{align}\\tag{10}\n$$\nand the obvious generalisation for more indices: for every upper index, there is a factor of $\\Lambda$, and for every lower index, a factor of $\\Lambda^\\mathrm{T}$. If the components of an object with indices don't satisfy  $(10)$ then that object is not a tensor. According to this definition, any vector is a tensor (with just one index).\nI don't like to use index notation too much: $v'=\\Lambda v$ is easier that $v'^\\mu=\\Lambda^\\mu{}_\\nu v^\\nu$, don't you think?. But sometimes we have to use index notation, because matrix notation is not possible: when using tensors with three or more indices, matrices cannot be used. Tensors with one index are just vectors. You'll hear sometimes that matrices are tensors with two indices, which is not quite true: if you remember from your course on linear algebra, you know that when you make a change of basis, matrices transform like $M\\to C^\\mathrm{T} M C$, which is like $(10)$ in the case of one upper/one lower index. Therefore, matrices are like tensors with one uppe/one lower index. This is the reason we wrote $\\Lambda$ as $\\Lambda^\\mu{}_\\nu$. This is a matrix, but it is also a tensor.\nAlso, $(7)$ pretty much looks like $(10)$, right? This is the reason people say $(7)$ expresses the transformation properties of $\\eta$. While not false, I you recommend not to take this too seriously: formally, it is right, but in principle $\\eta$ is just a set of numbers that simplifies our notation for scalar products. It turns out you can think of it as a tensor, but only a-posteriori. In principle, it is not defined as a tensor, but it turns out it is. Actually, it is a trivial tensor (the only one!) whose components are the same in every frame of reference (by definition). If you were to calculate what are the components of $\\eta$ in another frame of reference using $(10)$, you'll find out that they are the same. This is stated as the metric is invariant. We actually define it to be invariant. We define what a change of reference frame through the restriction of $\\eta$ being invariant. It doesn't make sense to try to prove $\\eta$ is invariant, as this is a definition. $(7)$ doesn't really prove $\\eta$ is invariant, but actually defines what a change of reference is.\nFor completeness I'd like to make the following definitions:\n\nWe say an object is invariant if it takes the same value on any frame of reference. You can check that if $v$ is a vector, then $v\\cdot v$ takes the same value on any frame, i.e., $v^2$ is invariant.\nWe say an object is covariant if it doesn't take the same value on every frame of reference, but the different values are related in a well defined way: the components of a covariant object must satisfy $(10)$. This means tensors are covariant by definition.\n\nFor example, a vector is not invariant because its components are frame-dependent. But as vectors are tensors, they are covariant. We really like invariant objects because they simplify a lot of problems. We also like covariant objects because, even though these objects are frame-dependent, they transform in a well-defined way, making them easy to work with. You'll understand this better after you solve many problems in SR and GR: in the end you will be thankful for covariant objects.\nSo, what does it mean for $\\eta$ to be invariant? It means its components are the same in every (inertial) frame of reference. How do we prove this? we actually can't, because we define this to be true. How can we prove $\\eta$ is the only invariant tensor? We can't, because it is not actually true. The most general invariant tensor is proportional to the metric. Proof: let $N^\\mu{}_\\nu$ be an invariant tensor by definition. Then, as it is a tensor, we have\n$$\nN'=\\Lambda^\\mathrm{T}N\\Lambda \\tag{11}\n$$\nBut we also must have $N'=N$ for it to be invariant. This means $\\Lambda^\\mathrm T N\\Lambda=N$. Multiply on the right by $\\eta \\Lambda^\\mathrm{T} \\eta$ and use $(7)$ to get $[N,\\Lambda^\\mathrm{T}]=0$. By Shur's Lemma, $N$ must be proportional to the identity. QED.\n\nAnd what about the Levi-Civita symbol? we are usually told that it is also an invariant tensor, which is not actually true: it is invariant, but it is not a tensor, it is a pseudo-tensor. In SR it doesn't satisfy $(10)$ for any $\\Lambda$, but only for a certain subset of matrices $\\Lambda$ (check Proper Orthochronus Lorentz Group), and in GR it is a tensor density (discussed in many posts on SE).\nThe proof of the covariance of the LC symbol is usually stated as follows (you'll have to fill in the details): the definition of the determinant of a matrix is can be stated as $\\text{det}(A)\\varepsilon^{\\mu\\nu\\sigma\\rho}=\\varepsilon^{abcd}A^\\mu{}_a A^\\nu{}_b A^\\rho{}_c A^\\sigma{}_d$. The proper Orthochronus Lorentz Group consists of the subset of matrices with unit determinant, i.e., $\\text{det}(\\Lambda)=1$. If you use this together with the definition of $\\text{det}$, you get $\\varepsilon^{\\mu\\nu\\rho\\sigma}=\\varepsilon^{abcd}\\Lambda^\\mu{}_a\\Lambda^\\nu{}_b\\Lambda^\\rho{}_c\\Lambda^\\sigma{}_d$, which is the same as $(10)$ for the object $\\varepsilon^{\\mu\\nu\\rho\\sigma}$. This proves that, when restricted to this subset of the Lorentz Group, the Levi-Civita symbol is a tensor.\n\nRaising and Lowering indices: this is something that is usually made more important that it really is. IMHO, we can fully formulate SR and GR without even mentioning raising and lowering indices. If you define an object with its indices raised, you should keep its indices where they are. In general there is no good reason as why would someone want to move an index. That being said, I'll explain what these are, just for completeness.\nThe first step is to define the inverse of the metric. Using matrix notation, the metric is its own inverse: $\\eta \\eta=1$. But we want to use index notation, so we define another object, call it $\\zeta$, with components $\\zeta^{\\mu\\nu}=\\eta_{\\mu\\nu}$. With this, you can check that $\\eta\\eta=1$ can be writen as $\\eta_{\\mu\\nu}\\zeta^{\\nu\\rho}=\\delta^\\mu_\\rho$, where $\\delta$ is the Kronecker symbol. For now, $\\delta$ is just a symbol that simplifies the notation. Note that $\\zeta$ is not standard notation, but we will keep it for the next few paragraphs.\n(People usually use the same letter for both $\\eta$ and $\\zeta$, and write $\\eta_{\\mu\\nu}=\\eta^{\\mu\\nu}$; we'll discuss why in a moment. For now, note that these are different objects, with different index structure: $\\eta$ has lower indices and $\\zeta$ has upper indices)\nWe can use $\\eta$ and $\\zeta$ to raise and lower indices, which we now define.\nLet's say you have a certain tensor $A^{\\mu\\nu}{}_\\rho$. We want to define what it means to raise the index $\\rho$: it means to define a new object $\\bar A$ with components\n$$\n\\bar A^{\\mu\\nu\\rho}\\equiv \\zeta^{\\rho\\sigma}A^{\\mu\\nu}{}_\\sigma \\tag{12}\n$$\n(this is called to raise the index $\\rho$ for obvious reasons)\nUsing $(10)$ you can prove that this new object is actually a tensor. We usually drop the bar $\\bar{\\phantom{A}}$ and write $A^{\\mu\\nu\\rho}$. We actually shouldn't do this: these objects are different. We can tell them apart from the index placement, so we relax the notation by not writing the bar. In this post, we'll keep the bar for pedagogical reasons.\nIn an analogous way, we can lower an index, for example the $\\mu$ index: we define another object $\\tilde A$, with components\n$$\n\\tilde A_\\mu{}^\\nu{}_\\rho\\equiv \\eta_{\\mu\\sigma} A^{\\sigma\\nu}{}_\\rho \\tag{13}\n$$\n(we lowered $\\mu$)\nThis new object is also a tensor. The three objects $A,\\bar A,\\tilde A$ are actually different, but we can tell them apart through the indices placement, so we can  drop the tildes and bars. For now, we won't.\nWe'll discuss the usefulness of these operations in a moment. For now, note that if you raise both indices of the metric, you get\n$$\n\\bar{\\bar{\\eta}}^{\\mu\\nu}\\equiv\\zeta^{\\mu\\rho}\\zeta^{\\nu\\sigma} \\eta_{\\rho\\sigma}=\\zeta^{\\mu\\rho}\\delta^\\nu_\\rho=\\zeta^{\\mu\\nu} \\tag{14}\n$$\nwhich means that $\\bar{\\bar{\\eta}}=\\zeta$. As we usually drop the bars, this means that we can use the same letter $\\eta$ for both objects. In principle, they are different: $\\eta_{\\mu\\nu}$ is the metric, and $\\zeta^{\\mu\\nu}$ is its inverse. In practice, we use $\\eta_{\\mu\\nu}$ and $\\eta^{\\mu\\nu}$ for both these objects, and even call them both metric. From now on, we will use $\\eta$ both for the metric and its inverse, but we keep the bars for other objects.\nWith this in mind, we get the following important result:\n$$\n\\eta_{\\mu\\nu}\\eta^{\\nu\\rho}=\\delta_\\mu^\\rho \\tag{15}\n$$\nwhich is actually a tautology: it is the definition of the inverse of the metric.\nSo, what is the use of these operations? for example, what do we get if we lower the index of a vector $v$? Well, we get a new tensor, but it is not a vector (you can check that $(2)$ is not satisfied), so we call it a covector. This is not really important in SR, but in other branches of physics vectors and covectors are really really different.\nSo, what is the covector associated to $v$? Call this covector $\\bar v$. Its components will be $\\bar v_\\mu=\\eta_{\\mu\\nu} v^\\nu$ by definition. Why is this useful? Well, one reason is that by lowering an index, the scalar product $\\cdot$ turns into standard matrix product:\n$$\nu\\cdot v=\\bar u v \\tag{16}\n$$\nas you can check (compare this to $(3)$ or $(6)$). So in principle, raising and lowering indices is supposed to simplify notation. Actually, in the end, you'll see that people write $uv$ instead of $u\\cdot v$ or $u_\\mu v^\\mu$. So you see that the notation is simplified without the need of raising/lowering any index.\nThe following fact is rather interesting: we know that if we raise both indices of the metric we get the metric again. But what do we get if we raise only one index to the metric? that is, what is $\\bar \\eta$?, or, put it another way, what is $\\eta^\\mu{}_\\nu$? Well, according to the definition, it is\n$$\n\\eta^\\mu{}_\\nu=\\eta_{\\nu\\rho}\\eta^{\\mu\\rho}=\\delta^\\mu_\\nu \\tag{17}\n$$\nwhere I used $(15)$. This means that $\\bar \\eta=\\delta$: the metric is the same object as the Kronecker symbol, which is a cool result. As we know that raising and lowering indices from a tensor results in a new tensor, we find that the Kronecker symbol is actually a tensor! We can even prove this from the definition of tensors, i.e., we can check that $(10)$ is satisfied for $\\delta$. But we don't need to: we know that it must be true (check it if you want to).\n\nAs a side note: you (as many people) write prime marks on the indices, while I (as many others) write the primes on the tensors. IMHO the latter convention is the best, because it is the tensor what is changing, not the indices. For example, what you wrote $\\eta_{\\mu'\\nu'}=\\eta_{\\mu\\nu}$ looks better when written $\\eta'_{\\mu\\nu}=\\eta_{\\mu\\nu}$, because the $\\mu\\nu$ component of both objects are equal, and not the $\\mu'$ is equal to the $\\mu$ component (which actually makes no sense and makes the indices mismatched).", "meta": {"post_id": 230495, "input_score": 25, "output_score": 42, "post_title": "Lorentz invariance of the Minkowski metric"}}
{"input": "I was reading this and it says that Microsoft put a server farm at the bottom of the ocean because it's cooler there. Particularly it seems to imply that it get's colder as you go deeper, \"Since ocean water gets pretty cold toward the sea floor...\" But I know that pressure causes heat, for example it is responsible for igniting fusion at the center of the sun.. what gives?", "output": "There's two main misconceptions in your question that cause your confusion.\nFirst, pressure doesn't cause higher temperature. This misconception is probably a result of a massive oversimplification with relation to the ideal gas equation. The actual relation is \"increasing the pressure of an ideal gas while volume remains constant increases the temperature of the gas\".\nTwo notable things here:\n\nWater and other liquids are barely compressible, so they behave nothing like an ideal gas (which is perfectly compressible). Ideal liquid doesn't compress at all.\nTemperature only increases as you put more stuff in the same volume. That is, it isn't pressure that increases temperature, it's compression. If you compress a volume of air, the temperature will rise, and if you release it again, the temperature will drop again.\n\nSecond, any closed system evolves toward thermal equillibrium. In simple terms, if you leave a hot coffee on your table, it will eventually cool down to room temperature. Even though compression increases temperature, this doesn't mean that constant pressure keeps producing more and more heat. When you compress a lot of air into a soccer ball, it will feel hot to the touch. But as it exchanges heat with the environment, it will cool down. This is very useful, of course, because it allows you to expend energy to cool things down, like in your A/C :) \nWhat effect this has on pressure in turn again depends on the properties of the material you're working with. If you have a volume of air in a bottle, as you cool it down, the gas pressure decreases. If you heat it up, the pressure increases. This is the reason why you need to tweak the pressure in your car's tires even if they aren't leaking - you need to adjust for current temperature.\nHowever, with a liquid, this isn't anywhere as simple. While there is a relation between temperature and density, it's nowhere near as big as in an ideal gas. The same goes with pressure and density - if it didn't, you wouldn't be able to walk (imagine that your legs would shorten by half every time you raised one leg - that just wouldn't work).\nSo, let's put this to use in our ocean example. Undisturbed, water will tend to be \"vertically ordered\" by density. Usually, this means that warmer water will tend to rise up, while colder water will tend to go down. So the weird thing is actually how relatively warm in the depths. The ocean floor tends to be around the same temperature, regardless of how warm or cold the upper layers are.\nThere's two main reasons for that, specific to water:\n\nThe water anomaly - the peak of density occurs around 4 \u00b0C in water; both increasing and decreasing temperature from this point results in lower density. The effect is very important, because it means that even during winter, the bottom layers of lakes will have temperature around 4 \u00b0C even when the surface is frozen. And ice is actually a pretty good insulator too :) EDIT: As noted by David, this doesn't occur in ocean water, due to the high salinity which pushes the peak below freezing (around -4 \u00b0C). So in an ocean, the deepest layers are formed of water between about 0 \u00b0C to 3 \u00b0C.\nIce - when water freezes, it forms ice, which has lower density than water. This is somewhat unusual (solids are usually higher-density than liquids), and it means that as water bodies start to freeze, it rises again.\n\nWith supercooled water, this effect is even more pronounced - a water at -30 \u00b0C has about the same density as water at 60 \u00b0C.\nOceans cool mostly by evaporation - the surface layers of water \"spontaneously\" changing state from liquid to gaseous. You get a balancing act between energy lost to evaporation, and incoming sunlight. However, there's a huge gap between the surface and the deeps, a lot of water mass - the incoming sunlight is nowhere near enough to warm ocean waters throughout. So you get warm surface waters, then a gradient of cooler and cooler water, and finally about 0-3 \u00b0C in the deep. To illustrate how big this gap is, about 90% of the worldwide ocean water is in the 0-3 \u00b0C range (hence the \"nowhere near enough sunlight to heat the whole thing through\").\nOf course, a 4 \u00b0C body of water is great for cooling systems running at 40 \u00b0C and more. Air is actually a pretty good insulator, so air cooling gets tricky with large systems. Water, on the other hand, is pretty thermally conductive, and it easily convects, so cooling a huge data centre becomes almost trivial.\nEDIT:\nLet me address the Sun part, since there seems to be some confusion there as well.\nNuclear fusion is something that happens very infrequently. Two nuclei must come very close together to fuse, and they need enough kinetic energy to overcome the repulsion between each other (since both have the same electric charge).\nThe first problem is solved by increasing density. The more nuclei you have in the same volume, the higher the likelihood of close contact. This is where pressure comes in - that's how you get a higher density. Stars are made of plasma, and plasma is easily compressible, similar to a gas, so as pressure increases, so does density. How compressed is it? Well, the Sun's core, where the fusion reactions are actually happening, contains 34% of the Sun's mass, in only 0.8% of the Sun's volume. In the centre, the density is around 150 times the density of liquid water. The pressure is about 100 000 times the pressure in the Earth's core, and about 100 000 000 times the pressure of the water on the bottom of the Mariana trench.\nThe second problem is solved by increasing the kinetic energy of the individual nuclei. In other words, increasing the temperature. Just like with compressing air, pressure is only a one-off deal in increasing temperature; the fusion reaction in the Sun was started using the residual heat of the collapse of matter forming the star (the gravitational potential energy) - I'm not sure how much of a factor was compression in particular. But again, this was only responsible for the initial ignition - today, the reaction is running entirely on the heat produced by fusion and the pressure supplied by gravity (which is actually lowered by the outward pressure of the energy released in the core - the two pressures form a stable equilibrium).\nAs a side note, despite the high temperatures and pressures, the fusion reaction powering the Sun is incredibly weak. If we could magically reproduce the same conditions on the Earth, it wouldn't really be usable for power generation at all - the energy produced is about 300 Watts per cubic metre at the very centre. To have a comparison, this is comparable to power density of a compost heap, and less than the power density of human metabolism. Yes, your own body is producing more power than the same volume of the centre of the Sun. I unsuccessfully tried to find data on power density of fission reactors, but a single CANDU reactor produces about 900 MW (that's \"million watts\"), and it sure isn't three million times as big.", "meta": {"post_id": 233409, "input_score": 76, "output_score": 82, "post_title": "Why is it cold on the sea floor if pressure heats things?"}}
{"input": "Why is a second equal to the duration of 9,192,631,770 periods of radiation corresponding to the transition between two hyperfine levels of the ground state of the caesium-133 atom?\nWhy is the number of periods so complicated? \nIt could be any simple number, why is it exactly 9,192,631,770?", "output": "That number, 9192631770, was chosen to make the new definition of the second as close as possible to the less precise old second definition.  This means that--except for the most precise measurements--instruments calibrated before the new second was defined would not have to be recalibrated.", "meta": {"post_id": 243144, "input_score": 63, "output_score": 120, "post_title": "Why is a second equal to the duration of exactly 9,192,631,770 periods of radiations?"}}
{"input": "Every advert I come across for LED bulbs advertise them as the equivalent of a higher W incandescent bulbs. \nThis makes no sense to me, if the room requires 40W to lighten it up then it'll always require 40W of energy. How is it possible for 6W of energy to do the job? What am I missing here?", "output": "A 40W incandescent light bulb has a luminous efficiency of 1.9%. That means only 1.9%, or 0.76W, of the energy consumed by the bulb ends up as visible light.\nLED bulbs have an efficiency of around 10% - the efficiency depends on the design and can be as high as 15% or as low as 8%. So a 6W LED bulb will produce between 0.9 and 0.48W of visible light.\nThe claim that a 6W LED bulb produces as much light as a 40W incandescent bulb requires the efficiency of the LED bulb to be 12.7%, which is well within the range of efficiencies that LED bulbs can achieve.", "meta": {"post_id": 252802, "input_score": 62, "output_score": 128, "post_title": "How is 6W equivalent to 40W, as claimed by adverts for LED light bulbs?"}}
{"input": "It is said that immediately after the Big Bang, the fundamental forces of nature were unified. It is also said that later they decoupled, becoming separate forces.\nIndeed, if we look at the list of states of matter on Wikipedia we see:\n\n\nWeakly symmetric matter: for up to $10^{\u221212}$ seconds after the Big Bang the strong, weak and electromagnetic forces were unified.\n\nStrongly symmetric matter: for up to $10^{\u221236}$ seconds after the Big Bang, the energy density of the universe was so high that the four forces of nature \u2014 strong, weak, electromagnetic, and gravitational \u2014 are thought to have been unified into one single force. As the universe expanded, the temperature and density dropped and the gravitational force separated, a process called symmetry breaking.\n\n\n\nNot only is it said that the forces were once unified, but this is also somehow related to the states of matter.\nI want to understand all of this better. What does it truly mean, from a more rigorous standpoint, to say that the forces were unified and later decoupled? How this relate to the states of matter anyway?", "output": "When we say that the forces were unified, we mean that the interaction was described by a single gauge group. For example, in the original grand unified theory, this group was $SU(5)$, which spontaneously broke down to $SU(3) \\times SU(2) \\times U(1)$ as the universe cooled. These three components yield the strong, weak, and electromagnetic forces respectively.\nI'll try to give a math-free explanation of what this means. To do so I'll have to do a decent amount of cheating.\n\nFirst, consider the usual strong force. Roughly speaking, the \"strong charge\" of a quark is a set of three numbers, the red, green, and blue color charges. However, we don't consider the strong force three separate forces because these charges are related by the gauge group: a red quark can absorb a blue anti-red gauge boson and become blue. In the case of the strong force, we call those bosons gluons, and there are 8 of them.\nAt regular temperatures, the strong force is separate from the electromagnetic force, whose charge is a single number, the electric charge, and whose gauge boson is the photon. There is no gauge boson that converts between color charge and electric charge; the two forces are independent, rather than unified.\nWhen we say all the forces were unified, we mean that all of the Standard Model forces were described by a common set of charges, which are intermixed by 24 gauge bosons. These gauge bosons are all identical in the same way that the 8 gluons are identical. In particular, you can't point at some subset of the 24 and say \"these are the gluons\", or \"this one is the photon\". They were all completely interchangeable.\n\nAs the universe cooled, spontaneous symmetry breaking occurred. To understand this, consider slowly cooling a lump of iron to below the Curie temperature. As this temperature is passed, the iron spontaneously magnetizes; since the magnetization picks out a specific direction, rotational symmetry is broken.\nIn the early universe, the same process occurred, though the magnetization field is replaced with an analogue of the Higgs field. This split apart the $SU(5)$ gauge group into the composite gauge group we have today. \nThe process of spontaneous symmetry breaking is closely analogous to phase transitions, like the magnetization of iron or the freezing of water, which is why we talk about 'strongly/weakly unified' matter as separate states of matter. Like the iron, which state we are in is determined by the temperature of the universe. However, a exact theoretical description of this process requires thermal quantum field theory.", "meta": {"post_id": 275428, "input_score": 36, "output_score": 56, "post_title": "What does it mean to say that \"the fundamental forces of nature were unified\"?"}}
{"input": "Why is it that there exists a classical macroscopic field of photons and gravitons but not that of $Z, W^{\\pm}$ bosons, gluons or Higgs boson?", "output": "There are slightly different answers for each particle type.\n\nMacroscopic photon and graviton fields can exist because these forces are long-ranged, which is directly related to the force carriers being massless. The $W$ and $Z$ bosons are extremely massive, so they're very short ranged and we can't see their effects on a macroscopic scale.\nAnother problem is that classical macroscopic fields arise from quantum fields through coherent states, which require many particles. Since the $W$ and $Z$ are so heavy, this is impossible at everyday energies.\nGluons are massless, but there's no macroscopic gluon field because the strong interaction becomes stronger at low energies, strong enough to bind color charged particles together. As a result, every macroscopic object we see has exactly zero color charge, so we see no gluon field.\nThe Higgs boson is massive, but there is a macroscopic Higgs field, in the sense that the field value is nonzero due to spontaneous symmetry breaking. You are, in some sense, measuring this field every time you measure the mass of an elementary particle. However, you can't make macroscopic waves in the Higgs field (i.e. excitations about the constant field value) for the same reason as the $W$ and $Z$.", "meta": {"post_id": 287718, "input_score": 26, "output_score": 38, "post_title": "Why we don't have macroscopic fields of Higgs bosons or gluons?"}}
{"input": "What does the Pauli Exclusion Principle mean if time and space are continuous?\nAssuming time and space are continuous, identical quantum states seem impossible even without the principle. I guess saying something like: the closer the states are the less likely they are to exist, would make sense, but the principle is not usually worded that way, it's usually something along the lines of: two identical fermions cannot occupy the same quantum state", "output": "Real particles are never completely localised in space (except possibly in the limit case of a completely undefined momentum), due to the uncertainty principle. Rather, they are necessarily in a superposition of a continuum of position and momentum eigenstates.\nPauli's Exclusion Principle asserts that they cannot be in the same exact quantum state, but a direct consequence of this is that they tend to also not be in similar states.\nThis amounts to an effective repulsive effect between particles.\nYou can see this by remembering that to get a physical two-fermion wavefunction you have to antisymmetrize it.\nThis means that if the two single wavefunctions are similar in a region, the total two-fermion wavefunction will have nearly zero probability amplitude in that region, thus resulting in an effective repulsive effect.\nTo see this more clearly, consider the simple 1-dimensional case, with two fermionic particles with partially overlapping wavefunctions.\nLet's call the wavefunctions of the first and second particles $\\psi_A(x)$ and $\\psi_B(x)$, respectively, and let us assume that their probability distributions have the form:\n\nThe properly antisymmetrized wavefunction of the two fermions will be given by:\n$$\n\\Psi(x_1,x_2) = \\frac{1}{\\sqrt2}\\left[ \\psi_A(x_1) \\psi_B(x_2)- \\psi_A(x_2) \\psi_B(x_1) \\right].\n$$\nFor any pair of values $x_1$ and $x_2$, $\\lvert\\Psi(x_1,x_2)\\rvert^2$ gives the probability of finding one particle in the position $x_1$ and the other particle in the position $x_2$.\nPlotting $\\lvert\\Psi(x_1,x_2)\\rvert^2$ we get the following:\n\nAs you can clearly see from the picture, for $x_1=x_2$ the probability vanishes. This is an immediate consequence of Pauli's exclusion principle: you cannot find the two identical fermions in the same position state.\nBut you also see that, the more $x_1$ is close to $x_2$, the smaller is the probability, as it must be due to continuity of the wavefunction.\nAddendum: Can the effect of Pauli's exclusion principle be thought of as a force in the conventional $F=ma$ sense?\nThe QM version of what is meant by force in the classical setting is an interaction mediated by some potential, like the electromagnetic interaction between electrons.\nThis corresponds to additional terms in the Hamiltonian, which says that certain states (say, same charges very close together) correspond to high-energy states and are therefore harder to reach, and vice versa for low-energy states.\nPauli's exclusion principle is conceptually entirely different: it is not due to an increase of energy associated with identical fermions being close together, and there is no term in the Hamiltonian that mediates such \"interaction\" (important caveat here: this \"exchange forces\" can be approximated to a certain degree as \"regular\" forces).\nRather, it comes from the inherently different statistics of many-fermion states: it is not that identical fermions cannot be in the same state/position because there is a repulsive force preventing it, but rather that there is no physical (many-body) state associated with them being in the same state/position.\nThere simply isn't: it's not something compatible with the physical reality described by quantum mechanics.\nWe naively think of such states because we are used to reasoning classically, and cannot wrap our heads around what the concept of \"identical particles\" really means.\nOk, but what about things like degeneracy pressure then?\nIn some circumstances, like in dying stars, Pauli's exclusion principle really seems to behave like a force in the conventional sense, contrasting the gravitational force and preventing white dwarves from collapsing into a point.\nHow do we reconcile the above described \"statistical effect\" with this?\nWhat I think is a good way of thinking about this is the following:\nyou are trying to squish a lot of fermions into the same place.\nHowever, Pauli's principle dictates a vanishing probability of any pair of them occupying the same position.\nThe only way to reconcile these two things is that the position distribution of any fermion (say, the $i$-th fermion) must be extremely localised at a point (call it $x_i$), different from all the other points occupied by the other fermions.\nIt is important to note that I just cheated for the sake of clarity here: you cannot talk of any fermion as having an individual identity: any fermion will be very strictly confined in all the $x_i$ positions, provided that all the other fermions are not.\nThe net effect of all this is that the properly antisymmetrized wavefunction of the whole system will be a superposition of lots of very sharp peaks in the high dimensional position space.\nAnd it is at this point that Heisenberg's uncertainty comes into play: very peaked distribution in position means very broad distribution in the momentum, which means very high energy, which means that the more you want to squish the fermions together, the more energy you need to provide (that is, classical speaking, the harder you have to \"push\" them together).\nTo summarize: due to Pauli's principle the fermions try so hard to not occupy the same positions, that the resulting many-fermion wavefunction describing the joint probabities becomes very peaked, highly increasing the kinetic energy of the state, thus making such states \"harder\" to reach.\nHere (and links therein) is another question discussing this point.", "meta": {"post_id": 288762, "input_score": 37, "output_score": 60, "post_title": "What's the point of Pauli's Exclusion Principle if time and space are continuous?"}}
{"input": "My question is in the title: Do black holes have a moment of inertia?\nI would say that it is: $$I ~\\propto~ M R_S^2,$$ where $R_S$ is the Schwarzschild radius, but I cannot find anything in the literature.", "output": "The angular velocity of a Kerr black hole with mass $M$ and angular momentum $J$ is\n$$ \\Omega = \\frac{J/M}{2M^2 +  2M \\sqrt{M^2 - J^2/M^2}} $$\nThe moment of inertia of an object can be thought of as a map from the object's angular velocity to its angular momentum. However, here we see that the relationship between these two quantities is non-linear. If we want to think of moment of inertia in the usual sense, we should linearise the above equation. When we do so, we find the relationship\n$$ J = 4 M^3 \\Omega \\qquad (\\mathrm{to\\ first\\ order})$$\nAnd so the moment of inertia is\n$$ I = 4 M^3 $$\nIn other words, the expression you guessed is correct, and the constant of proportion is unity. Note that since the Schwarschild radius of a black hole is merely twice its mass, and since the only two parameters that describe the black hole are its mass and angular momentum, any linear relationship between the angular velocity and angular momentum of our black hole must be of the form $J = k\\, M R_S^2\\, \\Omega$ on dimensional grounds.\nNote that $G = c = 1$ throughout.\n\nEDIT. \nAs pointed out in the comments, it's not obvious how one should define the angular velocity of a black hole. At the risk of being overly technical, we can do this as follows. First consider the Killing vector field $\\xi = \\partial_t + \\Omega \\partial_\\phi$ (using Boyer-Lindquist coordinates), where $\\Omega$ is defined to be as above. The orbits, or integral curves, of this vector field are the lines $\\phi = \\Omega t + \\mathrm{const.}$, which correspond to rotation at angular velocity $\\Omega$ with respect to a stationary observer at infinity.\nOne can show that this vector field is tangent to the event horizon, and its orbits lying on the event horizon are geodesics. These geodesics hence rotate at angular velocity $\\Omega$ (with respect to an observer at infinity), and hence it is natural to interpret the quantity $\\Omega$ as the angular velocity of the black hole. Whether it is possible to make a more definite statement than this I do not know.", "meta": {"post_id": 310881, "input_score": 28, "output_score": 40, "post_title": "Do black holes have a moment of inertia?"}}
{"input": "Geiger and Marsden's experiment led Rutherford to believe that the positive charge and most of the mass of the atom was concentrated in a small region. I understand what led him to conclude the way the positive charge is positioned in the atom. But how did he conclude that most of the mass was in a small region (the nucleus)?\nHow did the distribution of the mass matter after all? Given that the electric force is greater than the gravitational force by many magnitudes, the force between the positice charge and the electrons was predominantly electric. \nSo how did Rutherford conclude that most of the mass is in the nucleus?", "output": "This is a good example of how Science works.\nGeiger and Marsden observed that some of the alpha particles were being backscattered. This is inconceivable if the alpha particle is scattered by a lighter particle. \nIf one considers a particle of mass $m$ and initial velocity $v_1$ striking a target of mass $m'$ at rest, without changing its direction, then its final velocity $v_2$ can assume two possible values,\n$$v_2=v_1,\\quad\\mathrm{or}\\quad v_2=-v_1\\left(\\frac{m'-m}{m'+m}\\right).$$\nThe second solution gives that backscattering is only possible if the target has greater mass than the incident particle. By the time, the mass of the electron was known to be much smaller than the mass of the alpha particle so a backscattering event would imply that the scattering centers were in fact heavy positive nuclei. And indeed those scatterings were observed. \nTo formally check this, Rutherford obtained a formula for the number of scattered particles as a function of the scattering angle using the hypothesis of heavy nuclei (which is justified by the above paragraph). Geiger and Marsden did the experiment and the data agreed with Rutherford formula.", "meta": {"post_id": 326320, "input_score": 29, "output_score": 41, "post_title": "How did Rutherford conclude that most of the mass (as well as the positive charge) was concentrated in the nucleus?"}}
{"input": "My intuition tells me if gases conduct electricity, it should happen at high pressure, then the atoms will be closer together and electric field can ionize them. \nBut my textbook says low pressure is favoured for the gas discharge. Doesn't this mean discharge happens more vigorously in a vacuum which is absurd? May I know how low pressure contributes to the discharge?", "output": "At high pressure, the mean free path of electrons is quite low. The electrons don't get enough time to get accelerated. If the electrons don't accelerate for long, they can't gain the high velocity or kinetic energy that is required to ionize other atoms.\nWhile your argument that if there are more atoms, more electrons can be obtained through ionization makes sense, you don't account for the fact that only high energy electrons can ionize electrons from the gas atoms. If there are too many gas atoms, the electrons collide much before they have enough kinetic energy to ionize the atoms. If you cannot get a high number of electrons moving, you won't get sufficient current.\nWhen the gas pressure is low (but not too low), the electrons get enough time (or distance) to accelerate. By the time they collide with an atom, they have gained enough kinetic energy from the electric field to ionize other atoms. Even though there are not many atoms from which electrons can be obtained compared to a gas at high pressure, there is more than enough to produce a measurable current.\nIf the gas pressure goes too low, your argument comes to play. There won't be enough atoms to ionize and the conductivity decreases.\n\nMathematical Details:\n$$V_{B} = \\frac{Bpd}{ln(Apd) - ln(ln(1 + \\frac{1}{\\gamma_{se}}))}$$\nwhere $V_B$ is the breakdown voltage (minimum voltage required to observe a measurable current), $p$ is the pressure of the gas, $d$ is the distance between the electrodes, $A$ is the saturation ionization of the gas and $\\gamma_{se}$ is the secondary electron emission coefficient and $B$ is a constant which is related to the ionization energy.\n\nIntution:\nWhen the pressure is too low, it is difficult to obtain significant number of electrons to produce a measurable current.\nFor a pressure which is not too low nor too high, how conductivity varies can be understood as follows.\nIf a free electron was moving through two electrodes with a potential difference of $V$ in a perfect vacuum, the kinetic energy gained by the electron is:\n$$K.E = eV$$\nLet the distance between the electrodes be $L$. If the electron travels a distance $x$ (mean free path) before colliding with an atom, the kinetic energy gained by the electron is:\n$$K.E = e(Ex) = ex\\frac{V}{L}$$\nAn electron needs to have at least $W$ (let's call this work function) energy to ionize an atom.\nIf significant ionization must occur, then:\n$$K.E \\ge W$$\n$$ex\\frac{V}{L} \\ge W \\tag{1}$$\nThe mean free path of an electron is proportional to (if not equal) the mean free path of the gas. The mean free path of a gas varies as follows:\n$$\\lambda = k\\frac{T}{P}\\tag{2}$$\nSubstiuting equation $(2)$ in equation $(1)$, we get:\n$$k_1 \\frac{T}{P}\\frac{V}{L} \\ge W$$\nLet us consider $P$ and $L$ as variables and fix $T$ (we assume that we are performing the experiment at constant temperature)\n$$V \\ge k_2 PL$$\nThe minimum $V$ required to see a observable current is given by:\n$$V_{min} = V_{\\text{breakdown}} = V_{B} = k_2PL$$", "meta": {"post_id": 339283, "input_score": 30, "output_score": 45, "post_title": "Why do gases conduct at low pressure?"}}
{"input": "I am not planning on staring into the sun during an eclipse or any other time.\nI have been reading about how no variety of regular sunglasses are safe enough to view the eclipse with. I'm not talking about being able to see things clearly, but just actual eye safety. \nFrom what I understand it is the ultraviolet light that causes damage to the retina, but maybe it is more complicated. \nHow do my eyes get hurt if I am looking at the sun through so called \"100% UV protection\" and what makes the eclipse glasses sold in stores different?\nedit: To clarify this is not about how the rays from the sun are dangerous, but about why \"100% UV blocking\" sunglasses fail. Do other dangerous rays get through? Is the \"100%\" marketing? Essentially, in what way are the best consumer sunglasses inadequate for looking at an eclipse.\nAnswers about pupil dilation and what makes an eclipse more dangerous for naked-eye viewers are not what I'm after.", "output": "You are correct that almost always it is the UV content of sunlight and not its power that is the main hazard in staring at the Sun. \nThe lighting during a total eclipse is one of those situations outside the \"almost always\". Eclipses did not weigh heavily on our evolution, so we are ill kitted to deal with them.\nMoreover, UV sunglasses are not designed to attenuate direct sunlight, only reflected sunlight.\nNormally, the eye's pupil is shrunken to about a millimeter diameter in bright sunlight. This means that it admits about a milliwatt of sunlight, which, for healthy retinas, is nowhere near enough to do thermal damage (see my answer here for further discussion).\nDuring an eclipse, the pupil dilates to about $7\\,\\mathrm{mm}$ diameter to adapt for the low light levels of the eclipse's twilight. Thus its aperture is fifty times bigger than it normally is in sunlight. This means it admits a great deal more UV than normal (and the corona, at $100\\,000\\,\\mathrm K$, radiates a great deal of this). You're getting about $50$ times the dose you would normally get even looking directly at the Sun. \nFurthermore, suddenly the diamond ring phase begins, and high levels of sunlight reach the retina before the pupil can shrink again. The latter happens only very slowly. So even thermal damage is a risk here.", "meta": {"post_id": 352914, "input_score": 49, "output_score": 43, "post_title": "Why aren't 100% UV blocked sunglasses safe to view an eclipse with?"}}
{"input": "So my friend and I had a debate. He stated that we don't have to worry about the sun consuming the Earth \u2500 we'll already be broken apart by then. He states that as the sun expands, its Roche limit will also expand. The Earth will have been broken apart long before the sun touches its orbit.\nI'm arguing that the sun isn't changing mass (ignoring Mercury, Venus, and solar winds) and its gravitational force won't change, ergo eventually the boundary of the sun will be further than the Roche limit. The Earth will stay intact as it gets cooked.\nWhich, if either, of us is correct?", "output": "You are correct, and your friend is not.\nSo long as the Sun remains spherically symmetric, its gravitational field can be replaced with the field of a point mass at its centre of mass, which is what determines the Roche limit (so, in particular, it fixes both the gravitational field and the gravitational field gradient at any position you care to name). The radial extent of the mass distribution is irrelevant so long as the spherical symmetry is retained.\nI should also say I find it dubious that the Earth would break apart even if it did skim the Roche limit of some other body, because the Roche limit sets the break-apart point for systems that are bound gravitationally, i.e. for loose piles of rubble held together by their own gravity. This is not the case for the Earth, which is held together by strong chemical bonds in the rock of the mantle and core. Given a strong enough gravitational field gradient you can imagine the Earth getting torn apart, but this will happen a good bit further in than the Roche limit, I should think.", "meta": {"post_id": 357882, "input_score": 27, "output_score": 39, "post_title": "As the sun expands, will its Roche limit also expand?"}}
{"input": "I am reading The Elegant Universe by Brian Greene.\nIn many places it's directly/indirectly mentioned that the LHC may not be able to detect (with the current technology) heavy particles to prove Super-Symmetry.\nWhat prevents such accelerators from detecting such heavy particles?\nI always thought it would be the opposite as heavy particles can make a stronger impression on detectors than light particles.", "output": "It's not detecting the particles that is hard, it's making them in the collisions.\nAlthough the LHC collision energy is 14TeV, collisions aren't between the protons but rather between individual quarks inside the protons. Since the energy is shared between the three quarks in a proton the actual quark-quark collision energy is a lot less than 14TeV. Even then, for various reasons to do with conservation of momentum not all that energy can go into creating new particles. The end result is that it's hard to create particles much about above a TeV in weight. More on this in What is the maximal particle mass one can create via the LHC? Can we create dark-matter particles via the LHC? if you want to pursue this further.\nThe upshot is that if the heavy particles have a mass much greater than a TeV the LHC can't create them, and obviously if they can't be created they can't be detected. All is not completely lost since we might be able to detect heavy particles indirectly by the influence they have on the collisions we can detect. Even so the upper mass limit is still restricted.", "meta": {"post_id": 358956, "input_score": 23, "output_score": 42, "post_title": "Why can't the LHC detect heavy particles?"}}
{"input": "Just recently, LIGO and Virgo successfully detected new signs of gravitational waves. This time, instead of colliding black holes, it is a pair of colliding neutron stars. This collision emits light and gravitational waves.\nI read in CNN: First-seen neutron star collision that this collision had a signal that lasted for 100 seconds. I read before that the first gravitational wave detection of two colliding black holes had a signal lasting for a split second, and this is also an indication of how long the merging takes place. Is this accurate?\nIf so, if the colliding neutron star has signal lasting for 100s, does that mean that the merging takes a longer time? In addition, if the merging of two black holes happen almost instantly (short time), then why does the merging of two neutron star take up more amount of time?", "output": "It is not that the merger of two neutron stars takes longer, the inspiral and merger of a pair of neutron stars just spends a longer time in the frequency range where LIGO is most sensitive. Let me try to explain in more detail.\nLIGO is sensitive only to gravitational waves with frequencies between approx. 10 Hz and 10 kHz. (See LIGO sensitivity curve). As has been much discussed in the press announcements, the gravitational waves from the merger of a compact binary follow a \"chirp\" pattern increasing both in amplitude and frequency until it cuts off at the merger. The maximum frequency reached is inversely proportional to the \"chirp mass\" a rather arcance combination of the masses of the two components of the binary. \nThe upshot of this, is that heavier binaries have a lower maximum frequency than lighter binaries. For the first event, GW150914, which was very heavy, this meant that LIGO was only sensitive to the very last part of the inspiral (only the last few cycles). The lightest BH binary merger to date, GW151226, already spent a lot more cycles of its inspiral in LIGO's sensitivity range.\nNow neutron stars are obviously even lighter, allowing LIGO to see even more of the cycles of the inspiral before the merger (around 3000). In fact, for the GW170817,  the final merger happens in a frequency range where LIGO is no longer that sensitive. The most accurate data is obtained from the inspiral phase.", "meta": {"post_id": 363306, "input_score": 31, "output_score": 53, "post_title": "Why did the neutron star merger signal last for so much longer than the black hole merger signals?"}}
{"input": "I've recently come across a strange result when comparing the Hamiltonian and Lagrangian formulations of classical mechanics.\nSuppose we are working in the regime where we can say the Hamiltonian $H$ is equal to the total energy $$H=T+V.\\tag{1}$$ That is, the constraints are holonomic and time-independent, and the potential is $V=V(q)$ where $q$ a the generalized position vector $q=(q_1,q_2,\\ldots,q_n)$. Let $$L=T-V\\tag{2}$$ be the Lagrangian.\nNow, the Euler-Lagrange equations tell us \n$$\\frac{d}{dt}\\frac{\\partial L}{\\partial \\dot{q_\\sigma}} - \\frac{\\partial L}{\\partial q_\\sigma} = 0,\\tag{3}$$\nfor the generalized coordinate $q_\\sigma,$ with $\\sigma\\in\\{1,\\ldots,n\\}$. \nWe also know that the conjugate momenta are defined by $p_\\sigma = \\frac{\\partial L}{\\partial \\dot{q_\\sigma}}$. So this equation tells us\n$$\\dot{p_\\sigma} - \\frac{\\partial L}{\\partial q_\\sigma} = 0.\\tag{4}$$\nIn the Hamiltonian formalism, we know that\n$$\\dot{p_\\sigma} = -\\frac{\\partial H}{\\partial q_\\sigma}.\\tag{5}$$\nCombining these gives\n$$\\frac{\\partial H}{\\partial q_\\sigma}=-\\frac{\\partial L}{\\partial q_\\sigma}.\\tag{6}$$\nNow, this seems very strange because in the regime we are considering, this implies that\n$$\\frac{\\partial (T+V)}{\\partial q_\\sigma}=-\\frac{\\partial (T-V)}{\\partial q_\\sigma}\\Rightarrow \\frac{\\partial T}{\\partial q_\\sigma}=0. \\tag{7}$$\nOf course, there are many examples where this is not true. I.e., simply consider the free particle analyzed using polar coordinates. Then we have\n$$H = L = T = \\frac{1}{2}m(\\dot{r}^2 + r^2\\dot{\\theta}^2),\\tag{8}$$\nand so\n$$\\frac{\\partial T}{\\partial r } \\neq 0.\\tag{9}$$\nWhat is the explanation for this strange discrepancy? Am I making a silly mistake somewhere?", "output": "The problem is that the Lagrangian and the Hamiltonian are functions of different variables, so you must be exceedingly careful when comparing their partial derivatives. \nConsider the differential changes in $L$ and $H$ as you shift their arguments:\n$$dL = \\left(\\frac{\\partial L}{\\partial q}\\right) dq + \\left(\\frac{\\partial L}{\\partial \\dot q}\\right) d\\dot q$$\n$$dH = \\left(\\frac{\\partial H}{\\partial q}\\right) dq + \\left( \\frac{\\partial H}{\\partial p}\\right) dp$$\nFinding $\\frac{\\partial L}{\\partial q}$ corresponds to wiggling $q$ while holding $\\dot q$ fixed.  On the other hand, finding $\\frac{\\partial H}{\\partial q}$ corresponds to wiggling $q$ while holding $p$ fixed.  If $p$ can be expressed a function of $\\dot q$ only, then these two situations coincide - however, if it also depends on $q$, then they do not, and the two partial derivatives are referring to two different things.\nExplicitly, write $p = p(q,\\dot q)$.  Then using the chain rule, we find that\n$$dH = \\left(\\frac{\\partial H}{\\partial q}\\right) dq + \\left(\\frac{\\partial H}{\\partial p}\\right)\\left[\\frac{\\partial p}{\\partial q} dq + \\frac{\\partial p}{\\partial \\dot q} d\\dot q\\right]$$\nSo, if we shift $q$ but hold $\\dot q$ fixed, we find that\n$$ dL = \\left(\\frac{\\partial L}{\\partial q} \\right)dq$$\nwhile\n$$ dH = \\left[\\left(\\frac{\\partial H}{\\partial q} \\right) + \\left(\\frac{\\partial H}{\\partial p}\\right)\\left(\\frac{\\partial p}{\\partial q} \\right)\\right]dq$$\nIf $L(q,\\dot q) = H(q,p(q,\\dot q))$ as in the case of a free particle, then we would find that\n$$dL = dH$$\nso\n$$\\left(\\frac{\\partial L}{\\partial q}\\right)= \\left(\\frac{\\partial H}{\\partial q} \\right) + \\left(\\frac{\\partial H}{\\partial p}\\right)\\left(\\frac{\\partial p}{\\partial q} \\right)$$\n\nWe can check this for the free particle in polar coordinates, where\n$$L = \\frac{1}{2}m(\\dot r^2 + r^2 \\dot \\theta^2)$$\n$$ H = \\frac{p_r^2}{2m} + \\frac{p_\\theta^2}{2mr^2}$$\n$$ p_r = m\\dot r \\hspace{1 cm} p_\\theta = mr^2 \\dot \\theta$$\nfor the left hand side,\n$$ \\frac{\\partial L}{\\partial r} = mr \\dot \\theta^2$$\nFor the right hand side,\n$$ \\frac{\\partial H}{\\partial r} = -\\frac{p_\\theta^2}{mr^3} = -mr\\dot\\theta^2$$\n$$ \\frac{\\partial H}{\\partial p_\\theta} = \\frac{p_\\theta}{mr^2} = \\dot \\theta$$\n$$ \\frac{\\partial p_\\theta}{\\partial r} = 2mr\\dot \\theta$$\nso\n$$ \\frac{\\partial H}{\\partial r} + \\frac{\\partial H}{\\partial p_\\theta} \\frac{\\partial p_\\theta}{\\partial r} = -mr\\dot \\theta^2 + (\\dot \\theta)(2mr\\dot \\theta) = mr\\dot \\theta^2$$\nas expected.\n\nYour mistake was subtle but common.  In thermodynamics, you will often find quantities written like this:\n$$ p = -\\left(\\frac{\\partial U}{\\partial V}\\right)_{S,N}$$\nwhich means\n\nThe pressure $p$ is equal to minus the partial derivative of the internal energy $U$ with respect to the volume $V$, holding the entropy $S$ and particle number $N$ constant\n\nThis reminds us precisely what variables are being held constant when we perform our differentiation, so we don't make mistakes.", "meta": {"post_id": 365390, "input_score": 21, "output_score": 40, "post_title": "Apparent paradox between Lagrangian and Hamiltonian formulations of classical mechanics"}}
{"input": "There are so many times that something leaves you stumped. I was recently reading the paper \"Feynman's derivation of Maxwell's equations and extra dimensions\" and the derivation of the Maxwell's equations from just Newton's second law and the quantum mechanical commutation relations really intrigued me. They only derived the Bianchi set, yet with slight tweakings with relativity, the other two can be derived.\nAwesome as it is, does this even have a physical interpretation? How is it possible to mix together classical and quantum equations for a single particle, which aren't even compatible, and produce a description of the electromagnetic field?", "output": "Feynman's derivation is wonderful, and I want to sketch why we would expect it to work, and what implicit assumptions it's really making. The real issue is that by switching back and forth between quantum and classical notation, Feynman sneaks in physical assumptions that are sufficiently restrictive to determine Maxwell's equations uniquely.\nTo show this, I'll give a similar proof in fully classical, relativistic notation. By locality, we expect the force on a particle at position $x^\\mu$ with momentum $p^\\mu$ depends solely on $p^\\mu$ and $F(x^\\mu$). (This is Eq. 1 in the paper.) Then the most general possible expression for the relativistic four-force is \n$$\\frac{d p^\\mu}{d\\tau}= F_1^\\mu(x^\\mu) + F_2^{\\mu\\nu}(x^\\mu)\\, p_\\nu + F_3^{\\mu\\nu\\rho}(x^\\mu)\\, p_\\nu p_\\rho + \\ldots$$\nwhere we have an infinite series of $F_i$ tensors representing the field $F$. (Of course, we already implicitly used rotational invariance to get this.) I'll suppress the $x^\\mu$ argument to save space.\nIt's clear that we need more physical assumptions at this point since the $F_i$ are much too general. The next step is to assume that the Lagrangian $L(x^\\mu, \\dot{x}^\\mu, t)$ is quadratic in velocity. Differentiating, this implies that the force must be at most linear in momentum, so we have\n$$\\frac{d p^\\mu}{d\\tau}= F_1^\\mu + F_2^{\\mu\\nu}\\, p_\\nu.$$\nThis is a rather strong assumption, so how did Feynman slip it in? It's in equation 2, \n$$[x_i, v_j] = i \\frac{\\hbar}{m} \\delta_{ij}.$$\nNow, to go from classical Hamiltonian mechanics to quantum mechanics, we perform Dirac's prescription of replacing Poisson brackets with commutators, which yields the canonical commutation relations $[x_i, p_j] = i \\hbar \\delta_{ij}$ where $x_i$ and $p_i$ are classically canonically conjugate. Thus, Feynman's Eq. 2 implicitly uses the innocuous-looking equation\n$$\\mathbf{p} = m \\mathbf{v}.$$ \nHowever, since the momentum is defined as \n$$p \\equiv \\frac{\\partial L}{\\partial \\dot{x}}$$\nthis is really a statement that the Lagrangian is quadratic in velocity, so the force is at most linear in velocity. Thus we get a strong mathematical constraint by using a familiar, intuitive physical result.\nThe next physical assumption is that the force does not change the mass of the particle. Feynman does this implicitly when moving from Eq. 2 to Eq. 4 by not including a $dm/dt$ term. On the other hand, since $p^\\mu p_\\mu = m^2$, in our notation $dm/dt = 0$ is equivalent to the nontrivial constraint\n$$0 = p_\\mu \\frac{dp^\\mu}{d\\tau} = F_1^\\mu p_\\mu + F_2^{\\mu\\nu} p_\\mu p_\\nu.$$\nFor this to always hold, we need $F_1 = 0$ and $F_2$ (hereafter called $F$) to be an antisymmetric tensor and hence a rank two differential form. We've now recovered the Lorentz force law\n$$\\frac{d p^\\mu}{d\\tau} = F^{\\mu\\nu} p_\\nu.$$\nOur next task is to restore Maxwell's equations. That seems impossible because we don't know anything about the field's dynamics, but again the simplicity of the Hamiltonian helps. Since it is at most quadratic in momentum, the most general form is\n$$H = \\frac{p^2}{2m} + \\mathbf{A}_1 \\cdot \\mathbf{p} + A_2.$$\nCollecting $\\mathbf{A}_1$ and $A_2$ into a four-vector $A^\\mu$, Hamilton's equations are\n$$\\frac{dp^\\mu}{d\\tau} = (dA)^{\\mu\\nu} p_\\nu$$\nwhere $d$ is the exterior derivative. That is, the simplicity of the Hamiltonian forces the field $F$ to be described in terms of a potential, $F = dA$. Since $d^2 = 0$ we conclude\n$$dF = 0$$\nwhich contains two of Maxwell's equations, specifically Gauss's law for magnetism and Faraday's law. So far we haven't actually used relativity, just worked in relativistic notation, and indeed this is where our derivation and Feynman's run out of steam. To get the other two equations, we need relativity proper.\n\nThe basic conclusion is that Feynman's derivation is great, but not completely mysterious. In particular, it isn't really mixing classical and quantum mechanics at all -- the quantum equations that Feynman uses are equivalent to classical ones derived from Hamilton's equations, because he is using the Dirac quantization procedure, so the only real purpose of the quantum mechanics is to slip in $\\mathbf{p} = m \\mathbf{v}$, and by extension, the fact that the Hamiltonian is very simple, i.e. quadratic in $\\mathbf{p}$. The other assumptions are locality and mass conservation.\nIt's not surprising that electromagnetism pops out almost 'for free', because the space of possible theories really is quite constrained. In the more general framework of quantum field theory, we can get Maxwell's equations by assuming locality, parity symmetry, Lorentz invariance, and that there exists a long-range force mediated by a spin 1 particle, as explained elsewhere on this site. This has consequences for classical physics, because the only classical physics we can observe are those quantum fields which have a sensible classical limit.", "meta": {"post_id": 391744, "input_score": 77, "output_score": 72, "post_title": "Does Feynman's derivation of Maxwell's equations have a physical interpretation?"}}
{"input": "Consider a simple situation like this- an object is sitting on a table. In classical mechanics, we say that the net force on the object is zero because gravity (treated as a force) and normal reaction force are equal and opposite to each other, and hence, it's acceleration is zero. But according to Einstein's General Theory of Relativity, gravity isn't a force at all, but instead curvature created in spacetime by a massive object, and objects near it tend to move towards it because they are just moving along the geodesic paths in that curved spacetime.  So if an object kept on a table gets acted only by the normal reaction force (as gravity ain't a force), how is the net force on it zero?", "output": "So if an object kept on a table gets acted only by the normal reaction force (as gravity ain't a force), how is the net force on it zero?\n\nI've quoted what I think is the key part of your question, and it's key because the net force is not zero. The object on the table experiences a net force of $mg$ and as a result it is experiencing an upwards acceleration of $g$.\nThe way you can tell if no force is acting on you is by whether you are weightless or not. If you were floating in space far from any other objects then there would be no forces acting upon you and you'd be weightless. If we fixed a rocket to you and turned it on then you'd no longer be weightless because now the rocket is exerting a force on you. Technically you have a non-zero proper acceleration.\nIn general relativity your acceleration (your four-acceleration) has two components. We write it as:\n$$ a^{\\mu}= \\frac{\\mathrm du^\\mu}{\\mathrm d\\tau}+\\Gamma^\\mu_{\\alpha \\beta}u^{\\alpha}u^{\\beta} $$\nThe first term $\\mathrm du^\\mu/\\mathrm d\\tau$ is the rate of change of your (coordinate) velocity with time, so it is what Newton meant by acceleration, and the second term is the gravitational acceleration. The key thing about general relativity is that we don't distinguish between the two - they both contribute to your acceleration.\nIf you're falling freely then the two terms are equal and opposite so they cancel out and you''re left wit an acceleration of zero:\n$$ a^{\\mu}= 0 $$\nThis is when the net force on you is zero. For the object on the table the coordinate bit of the acceleration is zero but the second term is not and the acceleration is:\n$$ a^{\\mu}= \\Gamma^{\\mu}_{\\alpha \\beta}u^{\\alpha}u^{\\beta} $$\nSo the object sitting on the table has a non-zero acceleration and the net force on it is not zero.\nMaybe this sounds like I'm playing with words a bit, by defining what I do and don't mean by acceleration. But this is absolutely key to understanding how general relativity describes the motion of bodies. The key point is that gravitational and coordinate acceleration are treated on an equal footing, and if you are stationary in a gravitational field that means you are accelerating.\nIf you're interested in pursuing this further there is a fuller description in How can you accelerate without moving?. There is more on why spacetime curvature makes you accelerate in How does \"curved space\" explain gravitational attraction?\nA footnote\nGiven the attention this answer has received I think it is worth elaborating on exactly how relativists view this situation.\nThe question gives an example of an object sitting stationary on a table, but let's start with an object a few metres above the table and falling freely towards it.\n\nIt seems obvious that the apple is accelerating down towards the table. It seems obvious because we are used to taking the surface of the Earth as stationary because that's our rest frame (even though the surface of the Earth is most certainly not at rest :-).\nBut if you were the apple then it would seem natural to take your rest frame as stationary, and in that case the apple is not accelerating downwards - the table \nis accelerating upwards to meet it.\nSo which view is correct? The answer is that both are correct. Whether it's the apple or the table that is stationary is just a choice of rest frame, i.e. a choice of coordinates, and it is a fundamental principle in general relativity that all coordinates are equally good when it comes to describing physics.\nBut if we can randomly choose our coordinates it seems hard to say anything concrete. We could choose frames accelerating at any rate, or rotating, or expanding or all sorts of bizarre frames. Isn't there something concrete we can say about the situation? Well there is.\nIn relativity there are quantities called invariants that do not depend on the coordinates used. For example the speed of light is an invariant - all observers measuring the speed of light find it has the same value of $c$. And in our example of the apple and table there is an important invariant called the proper acceleration. While the apple and the table disagree about which of them is accelerating towards the other, if they compute their respective proper accelerations they will both agree what those values are.\nIn Newtonian mechanics acceleration is a vector $(a_x, a_y, a_z)$, but in relativity spacetime is four dimensional so vectors have four components. The four-acceleration is the relativistic equivalent of the three dimensional Newtonian acceleration that we are all used to. While it's a bit more complicated, the four acceleration is just a vector in 4D spacetime, and like all vectors it has a magnitude \u2013 in relativity we call this quantity the norm. And the norm of the four-acceleration is just the proper acceleration that I talk about above.\nThe proper acceleration can be complicated to calculate. There's a nice explanation of how to calculate it for an object like our table in What is the weight equation through general relativity? It turns out that the proper acceleration of the table is:\n$$ A = \\frac{GM}{r^2}\\frac{1}{\\sqrt{1-\\frac{2GM}{c^2r}}} $$\nwhere $M$ is the mass of the Earth and $r$ is the radius of the Earth.\nBut hang on \u2013 that tells me the proper acceleration of the table is non-zero. But ... but ... isn't the table stationary? Well, this takes us back to where we started. The table and the apple disagree about who is accelerating, but they both agree that the table has a non-zero proper acceleration. And in fact if we calculate the proper acceleration of the apple it turns out to be zero so both the apple and the table agree the apple has a proper acceleration of zero.\nThere is a simple physical interpretation of the proper acceleration. To measure your proper acceleration you just need to hold an accelerometer. Suppose you're floating around weightless in outer space, then your accelerometer will read zero, and that means your proper acceleration is zero. If you're standing on the surface of the Earth (alongside the table perhaps) then your accelerometer will read $9.81\\ \\mathrm{m/s^2}$, and indeed your proper acceleration is approximately $9.81\\ \\mathrm{m/s^2}$ not zero.\nTo summarise, a comment asks me:\n\nSo, let's just get this straight. The book sitting on the table in front of me is accelerating upwards all the time? But when I push it off the table and it falls down, then as it falls down it is not accelerating? Is that what you're saying?\n\nWhat I'm saying, and what all relativist would say, is that:\n\nthe book on the table has a non-zero proper acceleration\nthe falling book has a zero proper acceleration\n\nAnd this is all we can say. The question of which has a non-zero three-acceleration (Newtonian acceleration) is meaningless because that quantity is not frame invariant. The question of which has a non-zero proper acceleration is meaningful \u2013 even if the answer isn't what you expected.", "meta": {"post_id": 392863, "input_score": 22, "output_score": 40, "post_title": "If gravity isn't a force, then how are forces balanced in the real world?"}}
{"input": "It's a well-known fact that when one soaks a thin piece of fabric, it will often become more transparent than it was before.\nWhat is the reason behind this? I can't put glass behind the fabric and increase its transparency.\n(Also, just in case this seems like a duplicate, I am not concerned necessarily with why the fabric become darker but just the transparency aspect, unless, of course, the causes of these two phenomena are not disjoint.)", "output": "The fabric is made of many thin fibers of fabric, with air in between. This structure causes light to bounce around many times inside, making it hard for light to get through. \nWhen you make the fabric wet, you replace the air with water, which has a closer index of refraction to the fibers. So the reflections inside are less important, and more light just goes straight through.\nSome people might interpret this as the clothing getting darker, especially if somebody is wearing the clothes, but that\u2019s just because no light is coming from the other side. If you hold the fabric up to the sun, it should be clear the effect is really just an increase in transparency.\nFor the same reason, paper becomes transparent when it gets oily, as anybody who has ever eaten pizza on a paper plate knows.", "meta": {"post_id": 408432, "input_score": 79, "output_score": 105, "post_title": "Why does soaking a fabric make it more transparent?"}}
{"input": "I remember years ago in school my chemistry teacher showed us a tangled wire that untangled itself when a current is applied, can anyone suggest what the material may be?", "output": "You are almost certainly thinking of nitinol wire or \"memory wire\".\nHowever, it's not electricity that makes it untangle.  It's heat.  Running current through the wire is just a way to heat it.\nWhen at room temperature, nitinol wire can be easily bent.  When heated, it acts like a spring trying to go back to its unbent shape.  You can see the same effect by twisting some wire, then dropping it into boiling water.\nThere have been \"electric pistons\" built on this principle.  The piston is driven by a spring of memory wire.  When cold, the piston is easily compressed.  When the spring is heated by running electric current thru it, it pushes against the piston harder than what it took to push the piston in when cold.  This effect has niche uses but is mostly a curiosity.  The overall cycle is not very efficient.", "meta": {"post_id": 408771, "input_score": 32, "output_score": 49, "post_title": "Material that untangles itself when a current is applied?"}}
{"input": "If a person is sitting on a chair his momentum is zero and his uncertainty in position should be infinite. But we can obviously position him at most within few chair lengths. \nWhat am I missing? Do we have to invoke earth's motion, motion of the galaxy etc. to resolve the issue?", "output": "If a person is sitting on a chair his momentum is zero...\n\nHow close to zero?\nThe uncertainty principle says that if $\\Delta x$ is the uncertainty in position and $\\Delta p$ is the uncertainty in momentum, then $\\Delta x\\,\\Delta p\\sim \\hbar$. So, consider an object with the mass of a person, say $M = 70\\ \\mathrm{kg}$. Suppose the uncertainty in this object's position is roughly the size of a proton, say $\\Delta x = 10^{-15}\\ \\mathrm m$. The uncertainty principle says that the uncertainty in momentum must be \n$$\n  \\Delta p\\sim\\frac{\\hbar}{\\Delta x}\\approx\\frac{1 \\times 10^{-34}\\ \\mathrm m^2\\ \\mathrm{kg/s}}{10^{-15}\\ \\mathrm m}\\approx 1\\times 10^{-19}\\ \\mathrm{m\\ kg/s},\n$$\nso the uncertainty in the object's velocity is\n$$\n  \\Delta v=\\frac{\\Delta p}{M}\\approx \\frac{\\approx 1\\times 10^{-19}\\ \\mathrm{m\\ kg/s}}{70\\ \\mathrm{kg}}\\sim 1\\times 10^{-21}\\ \\mathrm{m/s}.\n$$\nIn other words, the uncertainty in the person's velocity would be roughly  one proton-radius per month. \nThis shows that the uncertainties in a person's position and momentum can both be zero as far as we can ever hope to tell, and this is not at all in conflict with the uncertainty principle.", "meta": {"post_id": 440399, "input_score": 19, "output_score": 107, "post_title": "Uncertainty principle for a sitting person"}}
{"input": "What if we take a cylindrical vessel with an inside surface completely reflecting and attach a piston such that it is also reflecting. What will happen to light if we compress it like this?", "output": "Suppose there is an amount of light (electromagnetic radiation) inside the cylinder. Note that electromagnetic radiation is composed of particles called photons, and if we consider that there is a very large number of photons inside the cylinder, we may use statistical mechanics to create a model of a photon gas. Yes, the system you describe will act like a gas, and its properties may be derived from statistics and from the properties of photons.\nIf a photon's frequency is $f$, its energy is $E_\u03b3 = hf$, where $h$ is Planck's constant. It is also important to remember that photons have linear momentum $$p = \\frac{E_\u03b3}{c} = \\frac{hf}{c}$$\nBut the fact that photons have nonzero linear momentum implies that they will exert pressure against the cylinder's walls. Once the photon reflects on the wall, its momentum will have changed direction, and this imples that the wall has exerted a force on the photon to make it change directions. Therefore, the photon gas exerts pressure against the walls. \nIt can be shown that if the total energy of the photon gas is $U$, then the relationship between the pressure $P$ and the volume $V$ of the gas is $U = 3PV$.\nIf you push the piston, you'll do positive work and therefore give energy to the system. It can also be shown that if you push the piston very slowly (reversible process) while keeping the system isolated (adiabatic transformation), the relationship between pressure and volume will be:\n$$PV^{4/3} = \\text{constant}$$\nIn other words, yes, light can be compressed and will act just like any other gas inside of a cylinder. Once you push the piston, you will feel an increase in pressure (the pressure of the photon gas increases)!\nThis photon gas can be used to make a simple model of stars, as is discussed in The Feynman Lectures on Physics, Vol. 1. The derivation of the other results presented before can also be found in this same book.\nAs pointed out in Yly's answer, the increase in energy as you push the piston will cause an increase in the frequency of the radiation, essentially causing a blueshift.", "meta": {"post_id": 444407, "input_score": 36, "output_score": 36, "post_title": "Can light be compressed?"}}
{"input": "I recently read an old physics news about the Higgs boson where it was observed to decay into 2 photons and I was wondering why it wouldn't have decayed into a single photon with the combined energy of 2 photons?", "output": "No massive particle can decay into a single photon.\nIn its rest frame, a particle with mass $M$ has momentum $p=0$. If it decayed to a single photon, conservation of energy would require the photon energy to be $E=Mc^2$, while conservation of momentum would require the photon to maintain $p=0$.  However, photons obey $E=pc$ (which is the special case of $E^2 = (pc)^2 + (mc^2)^2$ for massless particles).  It's not possible to satisfy all these constraints at once.  Composite particles may emit single photons, but no massive particle may decay to a photon.", "meta": {"post_id": 453657, "input_score": 12, "output_score": 39, "post_title": "Why can a particle decay into two photons but not one?"}}
{"input": "The no-hair theorem of black holes says they're completely categorised by their charge and angular momentum and mass.\nBut imagine two black holes colliding. At some point their event horizons would merge and I imagine the combined event horizon would not be spherical.\nYou could even imagine 50 black holes merging. Then the combined event horizon would be a very odd shape.\nWhy does this not disprove the no-hair theorem? Since the information about the shape of the event horizon is surely more than just charge, angular momentum and mass?", "output": "No. The no-hair conjecture applies to stable solutions of the Einstein-Maxwell equations. In the case of merging black holes, it applies to the end state of the merger into a single quiescent black hole, after the \u201cringdown\u201d has stopped.", "meta": {"post_id": 460041, "input_score": 39, "output_score": 58, "post_title": "Why don't merging black holes disprove the no-hair theorem?"}}
{"input": "I read this somewhere:\n\nWhere are the protons and electrons in a neutron star? When the\u00a0neutron\u00a0star forms, most of the\u00a0protons and electrons combine\u00a0together to\u00a0form neutrons. \n\nBut on a true/false quiz, I saw the question\n\nA neutron is formed by an electron and a proton combining together and therefore it is neutral. \n\nbut the answer was false. Why are these not contradictory?", "output": "You're asking about two distinct phenomena.  The difference between them is subtle, and I think there is some context missing from the second question that you quote, which makes things more confusing than they need to be.\n\nWhen the neutron star forms, most of the protons and electrons combine together to form neutrons\n\nThis is mostly correct.  The process is known as \"electron capture,\" and the full reaction is\n$$\\rm p + e^- \\to n + \\nu_e$$\nThe other particle in the final state (represented by a nu) is a neutrino.  The neutrino is an uncharged, very low-mass electron-like particle, in the same way that neutrons and protons are different charge states of the same sort of particle.  So far as we know, in physics, the number of electron-like \"leptons\" and the number of proton-like \"baryons\" isn't changed in any physical process.  The neutrinos play an important role in the dynamics of the stellar collapses where neutron stars are formed, but in some authors who write very elementary explanations of neutron stars will leave the neutrinos out of their descriptions.  There are advantages and disadvantages to this approach; your confusion here is one of the disadvantages.\n\nA neutron is formed by an electron and a proton combining together, therefore it is neutral: true or false? Answer: false\n\nThis is a fundamentally flawed true-false question, because it makes several statements at the same time, some of which are correct.  The question I was expecting to find here, based on the title of your question, was more like\n\nThe neutron is an electron and a proton that are \"stuck together\" somehow.  (Answer: false)\n\nWe have another name for an electron and a proton that are semi-permanently \"stuck together,\" and the dynamics of that system are very different from the dynamics of the neutron.\nWhen you \"combine together\" macroscopic objects in ordinary life, the things that you combined are still somehow present in the combination.  But in particle physics, the situation is different.  The electron-capture process that we're talking about here fundamentally changes both the baryon and the lepton parts of the system.  To the extent that a neutron behaves like a composite particle, it behaves as if it is made out of quarks.", "meta": {"post_id": 462101, "input_score": 21, "output_score": 41, "post_title": "Why does this quiz question say that protons and electrons do not combine to form neutrons?"}}
{"input": "Place the beaker full of steel balls and submerge the table tennis ball under the steel balls. The table tennis ball does not float up. Why does it not float up? Do table tennis balls float when the diameter of steel balls is reduced? How to calculate the buoyancy of steel balls?\nWould it come up without friction?", "output": "The ball bearings are behaving as a solid because the forces between the steel balls (i.e. friction) are large enough to hold the balls in position relative to each other.\nIf you apply enough force to a solid you will cause it to fracture or to cause plastic flow. So for example if you attached a string to the ball and pulled upwards with enough force it would cause the steel balls to flow over each other and the table tennis ball would move up. The force required is related to the yield stress of the solid formed by the steel balls.\nYou can make the steel balls behave as a fluid by making a gas flow through them. This creates a fluidised bed. The gas pushes the steel balls apart so the friction between them is removed, and in this state the steel balls will behave like a fluid and the table tennis ball would float upwards.\nAlternatively just shake the beaker. This is equivalent to adding thermal energy i.e. heating the system until it melts. If you shake the beaker you'll find the table tennis ball floats upwards.", "meta": {"post_id": 469105, "input_score": 16, "output_score": 40, "post_title": "Why doesn't a table tennis ball float on a surface of steel balls? How do we calculate buoyancy here?"}}
{"input": "Instantaneous velocity is defined as the limit of average velocity as the time interval \u2206t becomes infinitesimally small. Average velocity is defined as the change in position divided by the time interval during which the displacement occurs.\nWhen the time interval is infinitesimally small, there shouldn't be any considerable change in position. Thus the instantaneous velocity should be 0.", "output": "$$v_\\text{average}=\\frac{\\Delta s}{\\Delta t}$$\n$$v_\\text{instantaneous}=\\lim_{\\Delta t\\to0}\\frac{\\Delta s}{\\Delta t}$$\n\nIf the time interval gets infinitesimally small $\\Delta t\\to 0$, then you are dividing with something very, very tiny - so the number should become very big: $$\\frac{\\cdots}{\\Delta t}\\to \\infty \\quad\\text{ when } \\quad\\Delta t\\to0$$\nIf the change in position gets infinitesimally small $\\Delta s\\to 0$, then you are multiplying with something very, very tiny - so the number should become very small: $$\\frac{\\Delta s}{\\cdots}\\to 0 \\quad\\text{ when } \\quad\\Delta s\\to0$$\n\nNow, what if both happen at the same time, $\\frac{\\Delta s}{\\Delta t}$? What if, as in your case, the $\\Delta s$ is tied to $\\Delta t$ so that when one becomes very small, the other one does as well? Then how do you know, which of them that affects the number the most?  The denominator or the numerator? Does the number become very large or very tiny?\n$$\\frac{\\Delta s}{\\Delta t}\\to\\text{ ?}\\quad\\text{ when } \\quad\\Delta t\\to0$$\nYou seem to be assuming that the tiny change in position $\\Delta s$ is the one that dominates, so the result should go towards $0$ - but why wouldn't you assume the tiny time interval $\\Delta t$ to dominate instead, so the result goes towards infinity $\\infty$?\nThe answer is that anything can happen, depending on the values. It depends on the exact relationship between them. If the result goes towards an infinitely large number, we say that it is diverging. If it stabilises at some number, we say that it is converging. In work with physics you will often see it converging, since you will often deal with values that are interdependent and that \"balance off\" at some resulting number. In the case of velocity, the result does indeed converge towards some value, which we then choose to call the instantaneous velocity.\nThis is what calculus is all about: the mathematical discipline of going towards - converging towards - a limit and then figuring out what that limit is.", "meta": {"post_id": 500901, "input_score": 5, "output_score": 38, "post_title": "How does instantaneous velocity or acceleration have any other numerical value than 0?"}}
{"input": "When electrons transition from a higher energy state to a lower energy state (energy difference $E$), they produce massless photon with frequency $\\nu$ where \n$ \\Delta E= h \\nu$\n(h is Planck constant). We know energy-mas relation $ E=mc^2$. Why not create  some kind particle, in this case a particle that has mass m that we could calculate from the energy difference of the two states of the electron? Is there any kind critical energy difference $\\Delta E_c$ such that lower than $\\Delta E_c$ always  is creating photon and higher than $\\Delta E_c$ its  value create particle with mass?", "output": "There are a few reasons why the particle produced needs to be a photon. Aside from conserving energy, we also need to conserve momentum, charge and spin, for example. So you would need to ask what other particle, instead of a photon, could be emitted while satisfying all those conservation requirements. \nIf you just consider energy and spin conservation, the total amount of energy available in electron transitions in an atom is small, and not enough to make any of the other massive Bosons. To use your terminology, the maximum energy difference in electron transitions, \u0394, is way below the energy \u0394 you would need to create any of the other known massive particles that satisfy the other conservation requirements.", "meta": {"post_id": 505593, "input_score": 9, "output_score": 38, "post_title": "Why does transition from one electron shell to another shell always produce massless photon?"}}
{"input": "In his book Gravitation and Cosmology, Steven Weinberg says that the Cosmic Microwave Background (CMB) makes it \"difficult to doubt that the universe has evolved from a hotter, denser early stage\".\nIn my understanding, CMB is just a peculiar isotropic radiation representing a black body at ~ 2.7K.\nHow and why does the CMB point to the early Universe being hotter and denser?", "output": "Beyond the fact that the cosmic microwave background (CMB) is a direct prediction of the big bang model, there is the question of how you would produce it in any other way. It is remarkably close to being isotropic and remarkably close to being a blackbody spectrum - i.e. it is almost a perfect blackbody radiation field.\nA blackbody radiation field is emitted by material in complete thermodynamic equilibrium (CTE). An example would be the interior of a star. A requirement for (CTE) is that the matter and radiation field are characterised by the same temperature and that the material is \"optically thick\" - meaning that it is opaque to that radiation at basically all wavelengths.\nGiven that the universe is mainly made up of hydrogen, helium and (presently) traces of heavier elements, we can ask how is it possible to produce a perfect blackbody radiation field? Cold hydrogen and helium are transparent to microwaves. To make them opaque they need to be ionised, so that the free electrons can be a source of opacity at all wavelengths via Thomson scattering. But this requires much higher temperatures - about 3000 K.\nHow do we uniformly raise the temperature of a gas (adiabatically)? By squeezing it. A smaller, denser universe would be hot enough to have ionised hydrogen and would be opaque to the radiation within it. As it expanded and cooled, the electrons combined with protons to form atoms and the universe becomes transparent, but filled with a perfect blackbody radiation spectrum. The light, originally at a temperature of 3000 K and mainly in the visible and infrared, has had its wavelengths stretched by a factor of 1100 by expansion of the universe, meaning we now see it mainly as microwaves.\nAdditional evidence for this model is that the radiation field is not absolutely isotropic. These small ripples encode information such as the expansion rate of the universe at the time of (re)combination and the density of matter. When inferred from measurements, these parameters agree very closely with other determinations that are independent of the CMB, such as  the Hubble redshift distance relationship and estimates of the primordial abundance of Deuterium and Helium.\nThere is now direct evidence that the CMB was hotter in the past and by exactly the amount predicted by an adiabatic expansion. The source of this evidence is measurements of the frequency-independence of the Sunyaev-Zel'dovich effect towards galaxy clusters (e.g. Luzzi et al. 2009); or more precisely by probing the excitation conditions in gas clouds at high redshift using even more distant quasars as probes (e.g. Srianand et al. 2008. New results have been published by Li et al. (2021). They describe measurements of the Sunyaev-Zel'dovich effect to hundreds of galaxy clusters in the redshift range $0.07<z<1.4$ and show that, the temperature of the CMB goes as $T_0(1 + z)^{0.983^{+0.032}_{-0.029}}$, consistent with an adiabatic expansion to 3%.", "meta": {"post_id": 530411, "input_score": 29, "output_score": 61, "post_title": "Why is the Cosmic Microwave Background evidence of a hotter, denser early universe?"}}
{"input": "Why do you need 13.8 MJ/kg (9% of energy content) to compress hydrogen to 200 bar, but only 1.4 MJ/kg (2.5% of energy content) for methane?\nI looked into compressibility factors and the compressibility factor for methane is way lower than for hydrogen (up until high pressures). Does this determine how much work is required?", "output": "The essential reason is that a kilogram of hydrogen contains 8 times as many molecules as a kilogram of methane (because the mass of a hydrogen molecule is about 1/8  of the mass of a methane molecule).\nIf we assume, for the sake of argument, that the compression is isothermal (constant temperature, $T$) the work needed to compress a sample of $N$ molecules of an ideal gas from pressure $p_1$ to pressure $p_2$ is\n$$\\text{Work}=Nk_BT \\ln \\left(\\frac{p_2}{p_1}\\right)\\ \\ \\ \\ [k_B= \\text{Boltzmann's constant}]$$\nSo if the gases were ideal, 8 times more work would be needed per kilogram for the hydrogen, but at such high pressures the gases are far from ideal. Intermolecular forces and the finite volumes occupied by the molecules are significant and different for different gases. That would account for why the ratio of work needed is not exactly 8:1", "meta": {"post_id": 548857, "input_score": 25, "output_score": 36, "post_title": "Why is it so much more energy intensive to compress hydrogen than methane?"}}
{"input": "Suppose there are $N$ radioactive atoms and the half life of decay is $t$. Then after one half life the number of remaining atoms will be $\\frac{N}{2}$. And so after each half life the number will be halved.\nWhich means,\n$1/2$ of the atoms will have a life of $t$\nHalf of the the remaining half or $1/4$ of the atoms will have a life of $2t$ and so on.\nThen if the mean time for decay is $\\tau$, then it should be:\n$\\tau = \\frac{(\\frac{N}{2}t+\\frac{N}{4}2t+\\frac{N}{8}3t+...)}{N}$\nor $\\tau = t(\\frac{1}{2}+\\frac{2}{4}+\\frac{3}{8}+...)$\nBut this infinite series doesn't equal to $\\frac{1}{ln2}$.\nAnd we know that, $\\tau =\\frac{t}{ln2}$\nSo obviously my calculation is wrong. Why is this way of calculating the mean time for decay wrong?", "output": "Your mistake is here:\n\nWhich means, 1/2 of the atoms will have a life of t\nHalf of the the remaining half or 1/4\nof the atoms will have a life of 2t and so on.\n\nThe corrected statement is:\n\nWhich means, 1/2 of the atoms will have a life $\\le t$\nHalf of the the remaining half or 1/4\nof the atoms will have a life between $t$ and $2t$ and so on.", "meta": {"post_id": 551336, "input_score": 16, "output_score": 46, "post_title": "Why is this way of calculating mean life of radioactive atoms incorrect?"}}
{"input": "In my life I hear/read this statement a lot:\n\nA non-linear equation or theory leads to self-interactions.\n\nFor example in GR, we say that gravity can interact with itself because it is non-linear.\nFor some reason I always assumed it was correct. However now I think about it, I can not see a clear reason in the maths for why this statement holds. Can someone help me out? :D\nEdit$_1$: As Vadim pointed out. The statement should be the other way around.\n\nA self interacting physical system leads to non-linear equations.\n\nEdit$_2$: The questions is beautifully answered by @gandalf61 for 2 variable system. However, still do not really understand what is going on for 1 variable system, e.g. in general relativity. Could someone maybe also give an example there? Thank you in advance. :D\nIn the comments on the answer of @gandalf61, you will also find the answer of edit$_2$.", "output": "If I go to a shop and buy $5$ apples and $10$ bananas then I can usually take the price of one apple $a$ and the price of one banana $b$ and add these together to get a total cost of $5a+10b$. And I pay the same total amount if I buy apples and bananas at the same time or I buy apples, then go back to the shop later and buy bananas - my purchases do not interact with one another. This is a linear system.\nBut if there is an offer of \"$5$ apples for the price of $3$\" or \"one free banana with every $5$ apples\" or \"$10\\%$ off if you spend more than $\\$5$\" then the cost of $5$ apples and $10$ bananas will no longer be $5a+10b$. This is a non-linear system, and there is an interaction between my different purchases.", "meta": {"post_id": 600790, "input_score": 18, "output_score": 40, "post_title": "How do non-linear equations lead to self-interaction?"}}
{"input": "I'm trying to understand Manishearth's experiment  in the answer here,\n\nTo try this out, close one eye. Now hold your arms straight out, nearly stretched, but not completely stretched. Now extend your index fingers (there should be about one inch between them). Now try touching them together. Try this a few times, then repeat with both eyes open. You'll realise how necessary the second eye is for judging depth.\n\nI tried the experiment a few times but I am really not sure what I am supposed to see/ how the experiment works.\nThe one part I do understand is the reason they have said not to completely stretch the arms. If one does that, then by the sensation of arm being stretched will give a sense of depth, so it is necessary to not extend till to total arm length.\n\nP.S: I completely understand the mathematics and fact we need two rays, but I think I am not getting the correct result for the experiment. Ideally an answer with pictures would be best.", "output": "The problem with the two finger experiment is that your body\u2019s sense of proprioception is so accurate and so instinctive that you don\u2019t need binocular vision to touch your finger tips together. In fact, you don\u2019t need vision at all. Try the experiment with your eyes closed. You will find that you can still touch your finger tips together quite accurately without even seeing them.\nTo get a better sense of the power of binocular vision, use a pen or pencil held in each hand instead of finger tips, to reduce the effect of proprioception. Wave the pens/pencils around to randomise the starting positions, and then try to make the ends of the pens/pencils meet. With both eyes open this task is very easy. With only one eye open you will find it is surprisingly difficult.", "meta": {"post_id": 659624, "input_score": 28, "output_score": 78, "post_title": "Experiment to show that we need two eyes to determine depth"}}
{"input": "Suppose I have a bottle of pills and I throw the bottle in the air vertically. I wonder if the pills inside the box also fly up, or do they remain stable at the bottom of the bottle?\nI tried this experiment several times and I think the pills remain stable. I took the top of the bottle off and moved the bottle quickly vertically and observed the pills don't go up. But what if I throw it to the air very quickly? Do they still remain stable?\nI don't know if my guess is correct and what physics rule is behind that?", "output": "In a vacuum, the moment the bottle leaves your hand it will be in free-fall, and both the pills and the bottle will be subject to exactly the same acceleration - namely, $9.8\\ \\text{m/s}^2$ toward the floor.  As a result, they will move together.\nOn the other hand, in real life there will be a small amount of air resistance which acts on the bottle (because the air in the room is stationary) but not the pills (because the air trapped in the bottle is moving with the same speed as the pills/bottle are when they leave your hand).  As a result, at the moment the bottle leaves your hand the downward acceleration of the bottle will be slightly more than it would be in vacuum, and therefore slightly more than the pills, so the pills will begin to rise very slightly.\nOnce the pill bottle reaches its apex and begins to fall back down toward the floor, the situation is reversed - the bottle will accelerate toward the floor at slightly less than $9.8\\ \\text{m/s}^2$ - and the pills will gently fall back down to the bottom.\nFinally, depending on the properties of the pills and bottle, this effect might be swamped by friction or adhesion which would act to keep the pills stationary. Experiments would be required to work out what actually happens on a case-by-case basis.", "meta": {"post_id": 667819, "input_score": 12, "output_score": 44, "post_title": "Throwing a bottle containing pills to the air vertically"}}
{"input": "The no hair theorem says that a black hole can have only three properties: mass, charge and angular momentum. But why don't we say that linear momentum is one of its properties? If we throw an object into it at a certain velocity, it's clear the linear momentum will increase. So why isn't it a fundamental property? Is it because its velocity and hence linear momentum depends on the reference frame? But then doesn't its angular momentum as well if the frame is non-inertial?", "output": "In relativity the covariant properties are tensors. The linear momentum you are referring to is a 3-vector and therefore is not covariant. In particular its magnitude is not a scalar invariant and therefore cannot be a fundamental property of a black hole.\nIn plainer terms the value of the momentum depends on the frame of reference of the observer. Observers moving at different velocities would observe the black hole to have different values of momentum. A fundamental property needs to have the same value for all observers.\nThe relativistic version of momentum is the four-momentum, and a black hole can have this property. However the associated invariant, i.e. the magnitude of the four-momentum, is just the rest mass of the black hole, and as you say the rest mass is one of the three fundamental properties a black hole can have.", "meta": {"post_id": 677983, "input_score": 26, "output_score": 54, "post_title": "Why doesn't a black hole have linear momentum?"}}
{"input": "In a racing video game series named Trackmania, there is a game mechanic where when you hit a jump and the car is in mid-air, you can stop the car from pitching downward by tapping on the brakes.\nI am curious if this mechanic has some basis in real physics. What would happen if a car were pitching nose down while in the air, and you hit the brakes thus stopping the rotating wheels. Would that affect the car's pitch, and if so, how?", "output": "It will affect pitch, but not the way it works in the game. In the game, braking while in the air stops your pitch axis rotation. In real life, it does something completely different.\nThe wheels have angular momentum. When the wheels are slowed, this angular momentum must be conserved. This results in a transfer of angular momentum from the wheel to the vehicle.\nSince the wheels are moving clockwise in relation to a vehicle travelling left-to-right (i.e. the top of the wheel is moving toward the front of the car, and the bottom of the wheel is moving toward the rear) the car will also start to rotate clockwise, pitching the nose down. For a car already starting to pitch down after a jump, this will cause it to pitch down even faster, the opposite of what it does in-game.\nWe can even calculate a rough magnitude of the effect!\nFor simplicity, let's state some assumptions:\n\nthis is a rear-wheel drive vehicle with stationary front wheels\nboth rear wheels are moving at the same angular velocity (no slip diff)\nboth rear wheels are the same size and have the same mass\nthe rear axle is a rigid balanced cylinder (i.e. its center of mass is the center of the axle)\nthe brakes bring the wheels to a complete stop\nwe ignore the motion of the driveshaft, flywheel, clutch, gearbox, and other parts of the drivetrain\nwe ignore air resistance, lift, and all other aerodynamics\n\nEach of the two rear wheels can be approximated as a cylindrical mass whose center of mass is the axle joint. The same can be said for the rear driveshaft - it's a long cylinder. As such, the momentum of each of these bodies can be described by spin angular momentum, which is angular momentum about the center of mass. This is in contrast to orbital angular momentum, which is angular momentum about an arbitrary point.\nAngular momentum is expressed as $L=I\\omega$, where $I$ is the angular moment of inertia and $\\omega$ is the angular velocity in radians per second. You can think of the angular moment of inertia as a way to describe the mass distribution of an object about its axis (or axes) of rotation. A cube, a cylinder, and a sphere all have different moments of inertia, and those moments also change depending on where you put the axis of rotation (through the center, on an edge, etc.)\nA cylinder with mass $m$ and radius $r$ rotating about its $z$ axis has an angular moment of inertia described by $I = \\frac 1 2 mr^2$.\n\nAs such, the moment of inertia for each wheel can be approximated by $I = \\frac 1 2 mr^2$, where $m$ is the mass of the wheel and $r$ is the radius of the wheel. The moment of inertia for the axle can be described similarly, since we can model that as a cylinder too.\nGiven that we have two wheels rotating about the same axis, we can think of them as a combined cylinder of the same radius but with twice the mass, which cancels out the $\\frac 1 2$ term. We can then add the moment of inertia for the axle to get the total moment of inertia:\n$$I_T = m_W {r_W}^2 + \\frac 1 2 m_A {r_A}^2$$\n(with $T$ meaning total, $W$ meaning wheels, and $A$ meaning axle)\nThis can then be plugged into the angular momentum equation, $L=I\\omega$, where $\\omega$ is the angular velocity in radians per second.\n$$L = \\omega \\left(m_W {r_W}^2 + \\frac 1 2 m_A {r_A}^2\\right)$$\nIf we assume that the vehicle's wheels have remained at a constant angular velocity since leaving the ground, we can estimate $\\omega$ from the vehicle's land speed at the time of take-off and the radius of the wheel including the tyre.\nOne revolution of the wheel moves the vehicle forward by the circumference of that wheel, and the circumference is $2\\pi r$. If we take the car's velocity in meters per second (1mph \u2248 0.447m/s) and divide it by the wheel circumference, that tells us how many times the wheel was rotating per second. One rotation is 360\u00b0, or $2\\pi$ radians. As such:\n$$\\omega \\approx \\frac {v_C} {2\\pi {r_W}} \\times 2\\pi = \\frac {v_C} {r_W}$$\nWhere $v_C$ is the car's velocity at the point of take-off, and $r_W$ is the wheel radius.\nSubstituting this into our previous equation, we get:\n$$L = \\frac {v_C} {r_W} \\left(m_W {r_W}^2 + \\frac 1 2 m_A {r_A}^2\\right)$$\nWhere $L$ is the angular momentum, $v_C$ is the velocity of the car at take-off (for the purposes of angular velocity estimation), $r_W$ is the radius of the rear wheels including the tyre, $m_W$ is the mass of each of the two rear wheels including the tyre, $m_A$ is the mass of the rear axle, and $r_A$ is the radius of the rear axle.\nFor the sake of simplicity in this worked example, we'll assume that the front wheels aren't spinning, even though in practice it would make sense for the front wheels to be rotating at the same angular velocity as the rear wheels. While it is entirely possible to calculate the resultant angular velocity of the car as a result of both the front and rear wheels, including the case where the front wheels are not facing straight forward, the calculations are much easier to follow in a system with angular momentum being transferred between two bodies in a single axis.\nLet's try a quick test-case:\n\nEach wheel weighs 25 kg including the tyre.\nThe rear wheels have a radius of 25 cm (approximating a 16\" diameter alloy with 2\" thick tyres).\nThe rear axle is 6 cm in diameter and weighs 50 kg.\nThe car was travelling at 40 m/s (roughly 90 mph) when it left the ground.\n\nPlugging these numbers in, we get:\n$$L = \\frac {40~\\mathrm{m~s}^{-1}} {0.25~\\mathrm{m}} \\left(25~\\mathrm{kg} \\times (0.25~\\mathrm{m})^2 + \\frac 1 2 50~\\mathrm{kg} \\times (0.06~\\mathrm{m})^2\\right) = 265.4~\\mathrm{kg}\u22c5\\mathrm{m}^2\u22c5\\mathrm{s}^{-1}$$\nNote that kg\u22c5m2\u22c5s\u22121 are the units for momentum.\nThis is all well and good, but what does this mean in terms of the movement of the car?\nSince angular momentum must be conserved, the change in momentum in the wheels is passed on to the body of the car. The equations we used above can be used in reverse - we can start with angular momentum and a moment of inertia and use it to find the resulting angular velocity!\nHowever, there's a bit of a hitch: the angular momentum isn't being applied at the center of mass of the car, but instead at the location of the rear axle. This means that the car's movement is described by orbital angular momentum, not spin angular momentum. The car also isn't a cylinder, so we need a different equation.\nTo keep things simple, let's imagine the car is a cuboid of uniform mass with the real axle running along one of the bottom edges:\n\nThe moment of inertia for such a cuboid is described by:\n$$I = \\frac {m(a^2 + b^2)} {12}$$\nwhere $m$ is the mass, $a$ is the side of length a in meters, and $b$ is the side of length b in meters.\nWe can now derive the equation for estimating the angular momentum of the car, using $L=I\\omega$:\n$$L_C \\approx \\omega \\times \\frac {m_C(l^2 + h^2)} {12}$$\nwhere $L_C$ is the angular momentum of the car, $\\omega$ is the angular velocity of the car, $m_C$ is the mass of the car, and $l$ and $h$ are the length and height of the car respectively in meters.\nThe equation above is written in terms of $L_C$, so to find the resulting angular velocity of the car we need to rearrange it in terms of $\\omega$:\n$$\\omega \\approx \\frac {L_C} {\\left(\\frac {m_C(l^2 + h^2)} {12}\\right)} = \\frac {12L_C} {m_C(l^2 + h^2)}$$\nLet's continue with our test case by defining the last few parameters:\n\nThe car is approximately 1.25 m tall and 4.75 m long.\nThe car weighs 1600 kg. After subtracting the mass of the wheels and rear axle, that's 1500 kg. (edit: thanks to nitsua60 for pointing out that since the wheels and axle move as part of the car, their mass counts as part of the overall moment of inertia and should not be subtracted)\n\nSince we know that the angular momentum being transferred from the wheels and axle to the car is 265.4 kg\u22c5m2\u22c5s-1, we can now plug everything in:\n$$\\omega \\approx \\frac {12 \\times 265.4~\\mathrm{kg}\u22c5\\mathrm{m}^2\u22c5\\mathrm{s}^{-1}} {1600~\\mathrm{kg} \\times (4.75^2 + 1.25^2)~\\mathrm{m}^2} = 0.0825~\\mathrm{rad/s}$$\nThis is equivalent to 4.73\u00b0/s of nose-down rotation - small, but fairly noticeable!\nThe approximations here are crude, but they give you a good idea of how the conservation of angular momentum results in the downward pitch when the brakes slow down the spinning wheels.\nIt is possible to calculate the system's behaviour more accurately by considering the three-dimensional moment of inertia around the rear axle, angular momentum transfer of the flywheel and drivetrain (the car will tend to tilt slightly to one side as the drivetrain slows), non-uniform mass distribution of the car, air resistance, lift, and other aerodynamic effects, but the calculations are significantly more complicated and beyond the scope of this answer.\n\nAs a final wrap-up point, if you express the conservation of angular momentum between two objects ($a$ and $b$) as a single equation, you can gain some intuition for the behaviour of the objects as a function of their mass, size, and velocity.\n$$I_a\\omega_a = I_b\\omega_b$$\nIf we rearrange for $\\omega_b$ we can see how a change in angular velocity on object $a$ affects the angular velocity of object $b$:\n$$\\omega_b = \\frac {I_a} {I_b} \\omega_a$$\nWhen angular momentum is transferred, the change in angular velocity in object $b$ is a function of the ratio between the two angular moments of inertia. Since the moment of inertia of an object is proportional to its mass and size, a smaller lighter object imparts less angular velocity to a larger heavier object.", "meta": {"post_id": 734513, "input_score": 39, "output_score": 59, "post_title": "Could pressing the brakes on a car in mid-air affect its pitch rotation?"}}
{"input": "I was studying the phenomena of the formation of a rainbow. In my book, the following diagram is given:\n\nSo, the rays at the red end of the spectrum make a larger angle with the incident ray than the rays at the violet end of the spectrum. However, whenever we see a primary rainbow, the red is always on the top.\nWhy is it so? I know there is an obvious explanation and I am surely going wrong somewhere in my understanding. Please help me understand my mistake.", "output": "Yes. It is precisely the larger angle that makes this happen. Because the red is angled \"down\" more the red droplets are the ones located higher in your field of view.", "meta": {"post_id": 774776, "input_score": 31, "output_score": 80, "post_title": "A Rainbow Paradox"}}
{"input": "I'm currently taking a third-year electromagnetism course (we use Griffiths), and we have begun covering approximations of our potential function, $\\text{V} =\\int\\frac{k \\text{dQ}}{\\textbf{||r||}}$, where dQ is the charge distribution that can depend on r. Mainly, we've used both the Taylor Series and the Multipole Expansion to help approximate our potential function at large distances.\nHowever, I'm still very confused about the purpose of using these approximations. What do they tell us that our regular potential function doesn't? Is there something revealing if we use an approximation rather than the potential function? Is it \"easier\" to find the value of the potential using, for example, the Multipole Expansion, rather than just using our regular potential function? Why is the regular potential function not sufficient?\nI haven't had a clear answer to this yet, and I've been told that it's because \"we want something to tell us more than the fact that the potential is 0 when r is very large.\" However, I'm confused why that just isn't the answer? It makes sense that the potential is 0 at a large distance away from a charge distribution, why would it be anything different and how would the approximations give that? For example, in this passage in Griffiths:\n\nHow does an approximation (Taylor or Multipole) give us something \"more informative?\" As far as I'm aware, they will result in 0 anyways at a large distance. For example, Multipole expansion results in terms that depend on and go from $$\\frac{1}{r}, \\frac{1}{r^2}, \\frac{1}{r^3}...$$\nThis, of course, will be 0 at large r, which is what our potential function also shows.\nMoreover, for the Taylor Series, my professor did an example here:\n\n\nFor when z very large and also greater than R, I can see that the potential function goes to 0. Moreover, even after the Taylor Series expansion and the subsequent expression, it still goes to 0 at large z. However, I do admit that the Taylor Series expression does look like a point charge, which is interesting!", "output": "What does the electric potential of a water molecule look like?\n\nImagine a cartoon picture of a water molecule, in which the oxygen atom has charge $-2q$ and sits at the origin and the hydrogen atoms each have charge $q$ and sit at $x=\\pm d\\cos(\\theta), y=0, z=-d\\sin(\\theta)$ with $d\\approx 94$ pm and $\\theta \\approx 52.2^\\circ$.  What does the electric potential look like at distances very large compared to $d$?\nYour question suggests that your response would be \"the potential is basically zero.\" That is extremely unhelpful, however, if I asked my question with the intent of understanding how water molecules interact with one another. Those interactions may or may not be particularly strong, but if I want to understand the nature of them then I need something to work with.\n\"Aha!\" You say, \"I can simply write down the answer:\"\n$$ V(x,y,z) = -\\frac{2q}{4\\pi \\epsilon_0 \\sqrt{x^2+y^2+z^2}}+ \\frac{q}{4\\pi\\epsilon_0\\sqrt{(x-d\\cos(\\theta))^2+y^2+(z+d\\sin(\\theta))^2}}+ \\frac{q}{4\\pi\\epsilon_0\\sqrt{(x+d\\cos(\\theta))^2+y^2+(z+d\\sin(\\theta))^2}}\\tag{$\\star$}$$\nOkay, fair enough. So now, can you tell me how one water molecule interacts with another? Can you compute, for example, the torque that this water molecule applies to another which is located at some other position in a different orientation? In principle, sure. But it's going to be messy, and tedious, and not particularly illuminating.\nIs there a better solution? From your time sitting in calculus classes, you may realize that you could approximate these results assuming that $d$ is small. This might provide a nearly equivalent answer which is far simpler to write down, and gives you vastly more insight into the behavior of water molecules.\nIn particular, notice that\n$$(x\\pm d\\cos(\\theta)^2+y^2+(z+d\\sin(\\theta))^2 = x^2+y^2+z^2 \\pm 2xd\\cos(\\theta)+2zd\\sin(\\theta) + d^2$$\n$$\\equiv r^2\\left(1 \\pm \\frac{2xd}{r^2}\\cos(\\theta) + \\frac{2zd}{r^2}\\sin(\\theta) + \\frac{d^2}{r^2}\\right)$$\nTaking the square root and computing the reciprocal yields\n$$\\frac{1}{r}\\left(1 \\mp \\frac{xd}{r^2}\\cos(\\theta) - \\frac{zd}{r^2}\\sin(\\theta)\\right)$$\nwhere we have approximated $(1+ \\ldots)^{-1/2}$ and neglected $d^2/r^2$, which we take to be far smaller than the terms we have kept. Applying this approximation to each term in the nightmare above yields the following:\n$$V(x,y,z) \\approx -\\frac{2q}{4\\pi\\epsilon_0 r} + \\frac{q}{4\\pi\\epsilon_0 r}\\left(1- \\frac{xd}{r^2}\\cos(\\theta) - \\frac{zd}{r^2}\\sin(\\theta)\\right)$$\n$$+\\frac{q}{4\\pi\\epsilon_0 r}\\left(1 + \\frac{xd}{r^2}\\cos(\\theta) - \\frac{zd}{r^2}\\sin(\\theta)\\right)$$\n$$= \\frac{(-2q + q + q)}{4\\pi \\epsilon_0 r} - \\frac{2qzd\\sin(\\theta)}{4\\pi \\epsilon_0 r^3}$$\nHopefully you agree that this is a vast improvement in clarity. Things are improved further by noting that the first term cancels out because the total charge of the molecule is $-2q+q+q=0$, leaving\n$$V(x,y,z)\\approx \\frac{\\mathbf p \\cdot \\mathbf r}{4\\pi \\epsilon_0 r^3}\\tag{$\\star\\star$}$$\nwhere $\\mathbf p \\equiv -(2q)d\\sin(\\theta) \\hat z$ is the molecule's dipole moment. I'm sure you will agree that $(\\star\\star)$ is vastly preferable to $(\\star)$ both in conceptual clarity and computational efficiency - and for $d\\ll r$, the difference between them is a small fraction of a percent.\nWhat we've actually done is compute the first two terms of the multipole expansion, which formalizes what we did by hand and makes it very efficient. The monopole contribution vanishes because the net charge is zero, but the dipole moment is nonzero and so the second term in the expansion survives (as do others, but they are much smaller at large distances). We can now use it to answer my questions from before:\n\nCan you compute, for example, the torque that this water molecule applies to another which is located at some other position in a different orientation?\n\nSure. The electric field due to the dipole is\n$$\\mathbf E = -\\nabla V = -\\frac{\\mathbf p}{4\\pi\\epsilon_0r^3} + \\frac{3(\\mathbf p \\cdot \\mathbf r)\\mathbf r}{4\\pi \\epsilon_0 r^5}$$\n(have fun calculating that for $(\\star)$). An elementary result tells us that the torque on a second dipole $\\mathbf p'$ is\n$$\\boldsymbol{\\tau} = \\mathbf p' \\times \\mathbf E = -\\frac{\\mathbf p'\\times \\mathbf p}{4\\pi \\epsilon_0 r^3} + \\frac{3(\\mathbf p\\cdot \\mathbf r)(\\mathbf p' \\times \\mathbf r)}{4\\pi \\epsilon_0 r^5}$$\n\ncan you tell me how one water molecule interacts with another?\n\nEach water molecule creates an approximate dipole field, and other molecules feel a torque which encourages them to align with that dipole field. Two isolated water molecules will therefore seek to align with one another (this is part of hydrogen bonding), and networks of water molecules will assume a configuration which most effectively aligns them with one another (which results in the crystalline structure of ice).", "meta": {"post_id": 786488, "input_score": 20, "output_score": 39, "post_title": "Purpose of Using Taylor Series and Multipole Expansion to Approximate Potential"}}
