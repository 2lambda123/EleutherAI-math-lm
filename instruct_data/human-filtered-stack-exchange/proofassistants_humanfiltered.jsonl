{"input": "I know that Proof Assistants can be used in fact-checking, but what else can they be used for? How would they be used for specific roles, including industry jobs and everyday life?", "output": "The seL4 microkernel (approx ~9000 lines of C) was verified in Isabelle/HOL. See this page for a discussion of just what this proof means (e.g., in terms of what assumptions underpin it). This code has been deployed by the likes of Collins Aerospace and Boeing as part of DARPA research projects.\nThe CakeML system is a verified compiler for a functional programming language that has proofs of correctness for every transformation from input strings to machine code, and bootstraps itself.", "meta": {"post_id": 6, "input_score": 16, "output_score": 10, "post_title": "What are some examples of proof assistants doing something useful?"}}
{"input": "Formal verification is\n\nthe act of proving or disproving the correctness of intended algorithms underlying a system with respect to a certain formal specification or property, using formal methods of mathematics.\n\nProof assistants can help with that; it's only a small jump from algorithms to computer source code. Let's say I have some code written in [insert the language of your choice here]: can I use proof assistants to verify whether it's free from bugs? You may assume it's a low-level language if that matters, but I expect it doesn't because almost all programming languages are Turing complete.", "output": "An important point to clarify is the meaning of \"free of bugs\". Correctness only makes sense relative to a specification. Only once you have decided what property you care about (your definition of \"correctness\"), can you start to think about how to prove it.\nFor safety properties (memory safety (buffer overflows, use after free, etc.), undefined arithmetic (overflow, divide by zero, etc.), unhandled exceptions, etc.), there are popular approaches to detect or prevent them automatically, via type systems (\"well-typed programs do not go wrong\") or program analyses (e.g., Infer).\nFunctional correctness is a class of properties that relate your program to a \"high-level\" specification. For example you may expect that a function int sum(int* x) does compute a sum $\\sum_i x_i$, and that allows you to think about that function as the mathematical sum without worrying about how the numbers are laid out in memory. Since there is no hope for full automation for the most expressive specification languages, this is an area where proof assistants have a lot of potential (and it has been active for decades).\nA most popular example is sel4, a microkernel written in C and verified in Isabelle/HOL. In the following excerpt, note again the precision of \"against its specification\":\n\nseL4's implementation is formally (mathematically) proven correct (bug-free) against its specification, has been proved to enforce strong security properties, and if configured correctly its operations have proven safe upper bounds on their worst-case execution times. It was the world's first operating system with such a proof, and is still the only proven operating system featuring fine-grained capability-based security and high performance. It also has the most advanced support for mixed criticality real-time systems.\n--- https://sel4.systems/About/\n\nFor another example, VST provides a program logic for C embedded in the Coq proof assistant. VST is particularly notable because it is formally related to a verified compiler, CompCert: there is a proof that VST's program logic is sound with respect to the same operational semantics that CompCert was proved against. Software Foundations, Volume 2 contains an introduction in Coq to Hoare logic, a core idea in the development of program logics for imperative languages, such as VST.\nFor a functional language such as Haskell, it is a lambda calculus at its core, similar to proof assistants based on type theory (Coq, Lean, Agda). hs-to-coq banks on that similarity, by translating functions into the proof assistant's language, so you can prove any properties expressible there.", "meta": {"post_id": 9, "input_score": 9, "output_score": 18, "post_title": "Could proof assistants be used to prove that some piece of code is free of bugs?"}}
{"input": "I am trying to update a large body of Lean code to work with the current version of mathlib.  This is difficult because there have been a large number of backwards-incompatible changes even since I last did this in mid-November.  When I come across something that no longer works, I guess some keywords and try to search for commits or issues or current code in github that explains what has changed and why.  Is there any recommended method that is more systematic than this?", "output": "The mathlib commit log serves as a de facto changelog. Since the project updates far too frequently to keep a traditional changelog, a good method if you know approximately when breaking changes occured is to look at commits around that date. Titles are hopefully descriptive, and link to the pull request which explains the change in more detail.\nThe leanprover-community organization hosts CI for third-party projects, including a GitHub Actions script that will try to update your project periodically. If changes in mathlib break your code, it will open an issue on your repository linking to a diff of the mathlib changes that may be to blame.\nNote that this action is most helpful if you fix the breakage relatively quickly. Breaking changes can compound, and it can only alert you at the first breaking change.", "meta": {"post_id": 71, "input_score": 22, "output_score": 17, "post_title": "How to track backwards-incompatible changes in mathlib?"}}
{"input": "I started programming a Haskell-clone recently (source code).\nAfter basic hindley-milner, problems start to arise. Implementation of data/codata statements seem to ensure my language is breaking up on every front.\nAt this point I seem to lack foundations for the language. System F introduces kinds, but would it be better to approach theorem provers and pick a different calculus as foundation?\nAlso looking for overall suggestions for this kind of a project.", "output": "If you are asking \"can we use proof assistants to develop foundations of programming languages\" then the answer is positive. Two well-known such developments are:\n\nSoftware foundations by Benjamin Pierce, implemented in Coq.\nProgramming language foundations in Agda by Phil Wadler, implemented in Agda.\n\nThere are also specialized proof assistants that make it easier to develop the meta-theory of a programming language, such as Twelf, Abella and Beluga.", "meta": {"post_id": 205, "input_score": 15, "output_score": 12, "post_title": "Can theorem provers be used to form foundations for programming languages?"}}
{"input": "One could define streams in the following manner\nSection stream.\n  Variable A : Type.\n\n  CoInductive stream : Type :=\n  | Cons : A -> stream -> stream.\nEnd stream.\n\nBut as far as I can tell, such a coinductive stream is isomorphic to a function nat -> A. Arguably, working with the coinductive definition is harder.\nWhat is an example of a situation where working with a coinductive type is a more intuitive option to express a certain object? When is it more convenient to use a coinductive proof? What are some instances when the coinductive proof/value makes the most sense?", "output": "First a note: you are using the syntax for so-called \"positive\" coinductive types, which makes them look like inductive types, defined by \"constructors\".  This has various problems: it's not well-justified semantically, and syntactically it breaks \"subject reduction\".  Modern versions of Coq also support \"negative\" coinductive types, which look like record types rather than inductive types, defined by \"fields\", and are much better-behaved, so it is suggested to use those instead.  See the reference manual.\nAs for the actual question, I believe one place that coinduction is valuable is when computational behavior matters.  An infinite list represented by a function nat -> A is \"random access\": you can ask it for f n whenever you wish, and it doesn't in principle need to know anything about f k for k < n to compute f n.  Whereas the elements of a coinductive stream must be computed in order.  This certainly makes the function-representation easier to reason about.\nHowever, if your \"infinite list\" has the property that in practice we have to compute all the f k for k < n in order to find f n, then working with the coinductive version respects this, and encourages the user to take account of it.  Given a stream we can turn it into a function where f n is computed by pulling off n elements of the stream and returning the last one, but this performs a lot of computation if n is large, and if we call f a lot of times it could be very inefficient.  A coinductive data representation encourages the writing of corecursive functions, which force us to deal with this kind of stepwise-computed list more efficiently.\nStreams are arguably a bit too simple for this behavior to be clearly visible.  I like to think of a general coinductive type as a \"server\", in line with Conor McBride's comment in Let's see how things unfold:\n\nAs a total programmer, I am often asked 'how do I implement a server as a program in your terminating language?', and I reply that I do not: a server is a coprogram in a language guaranteeing liveness.\n\nAn element of a coinductive \"server type\" represents the server in a particular state.  When we call its destructor, we pass it some request from a client, and it returns a response to the client and also the new state of the server.  By contrast, using the corresponding \"functional\" representation, in order to compute the response of the server to any query we would have to replay the entire history of interaction of all clients with the server up to that point.  Clearly this is inefficient, and also a bad representation of how a real-world server actually works.\nCoinductive types can also be valuable in situations where type dependency makes it tricky to even come up with a functional representation, and if you do come up with one it's more awkward.  I'm most familiar with this in the case of homotopy theory and higher category theory.  For instance, a \"globular set\" can be defined coinductively as a set $A$ together with a family of globular sets indexed by $A\\times A$:\nCoInductive GSet : Type := {\n  carr : Type;\n  hom : carr -> carr -> GSet;\n}.\n\nThe corresponding functional representation is much less clear.  This can be enhanced to deal with infinite-dimensional categories in a surprisingly clean way.", "meta": {"post_id": 208, "input_score": 18, "output_score": 18, "post_title": "When to use coinductive types?"}}
{"input": "In Lean, when proving basic theorems, one runs into the following kind of thing:\nimport tactic\nvariables (P : Prop)\n\nexample : P \u2192 P :=\nbegin\n  intro p,\n  exact p,\nend\n\nAfter the intro p, step, the tactic state is\nP : Prop\np : P\n\u22a2 P\n\nAt this point, we need to use the exact tactic to close the goal. All exact seems to do is to tell Lean that the hypothesis p is the same (syntactically? definitionally?) as the target.  It seems as if it would be a reasonable design goal (in the interest of efficiency) to have Lean automatically close the goal once the target is at least syntactically identical to one of the hypotheses.\nIs this a design choice, or is there some deeper reason why this doesn't happen, and what is it?", "output": "My take on that is that, in their first approximation, tactics are just ways to build terms (typically proof terms), so it is expected to have basic tactics that closely correspond to the various term formers. In particular, in your example\n\nintro x for \u03bb x, \u2026\nexact e for e.\n\nThis hopefully justifies the existence of a basic tactic like exact.\nAnd it may also justify why, unless you ask for it, no automation happens. Consider using tactics to build terms, and imagine end would just close goals using any tactic:\ndef fst {a : Type} : (a,a) \u2192 a :=\nbegin intro x, cases x with x1 x2, end\n\nNow there are two assumptions that can be used, but the choice certainly matters.\nBut when using more advanced tactics, some of these do have such automation built in, e.g. simpa.", "meta": {"post_id": 289, "input_score": 12, "output_score": 15, "post_title": "In Lean, why is the exact tactic necessary when the goal is the same as a hypothesis?"}}
{"input": "Type systems, and the proof assistants based on them, are frequently divided into predicative and impredicative.\nWhat exactly does this mean? I've heard the slogan \"impredicativity means you can't quantify over things you haven't defined yet\", but I don't know how to apply this definition to a type system.\n\nPredicativity is mentioned here in this answer to this question. I don't really understand predicativity and don't understand how the concept in a classical setting lines up with or doesn't line up with the concept in a proof assistant setting.\nThis question form the Mathematics Stack Exchange and its answer describe what predicativity is when applied to the axiom schema of separation in ZFC.\nI'll do something a little nonstandard in the notation and always split the variable intepretations fed to $\\varphi(\\vec{p}; \\vec{x})$ into parameters $\\vec{p}$ and ordinary variables $\\vec{x}$.\nThe impredicative version is the ordinary one, given below.\n$$ \\forall x \\exists y \\forall z \\mathop. (z \\in y) \\leftrightarrow \n((z \\in x) \\land \\varphi(\\vec{p}; z)) \\;\\; \\text{is impredicative separation} $$\nThe predicative version is similar, but $\\varphi(\\vec{p}; z)$ is constrained to contain exclusively quantifiers bound by a parameter, i.e. $\\forall x \\in q \\mathop. \\square$ and $\\exists x \\in q \\mathop. \\square$ where $q$ is in $\\vec{p}$ or is bound by an earlier quantifier.\nBased on my understanding on the text quoted in the linked answer, this does not constitute a complete ban on impredicative quantification since the axiom schema of predicative separation itself contains unbound quantifiers $\\forall x \\exists y \\forall z \\mathop. \\square$ in its prenex that cannot be paraphrased away.\nSo in this case, \"predicativity\" applies only to the value of the metavariable $\\varphi(\\cdots)$ and a set theory with this axiom would still be an \"impredicative theory\". (Maybe?)\nChanging gears a little bit, if I look at the inference rules of the calculus of constructions, on which the proof assistant Coq is based, I'm not sure how to assess whether the formalism is predicative or not.\nHere are the rules for convenience.\n$K$ and $L$ range over $\\{P, T\\}$.\n$$ \\frac{}{\\Gamma \\vdash P : T} \\;\\; \\text{$P$ is a large type} $$\n$$ \\frac{}{\\Gamma, x: A, \\Gamma' \\vdash x : A} $$\n$$ \\frac{\\Gamma \\vdash A : K \\;\\;\\text{and}\\;\\; \\Gamma, x : A \\vdash B:L}{\\Gamma \\vdash (\\forall x : A \\mathop. B) : L} \\;\\; \\text{is universal introduction}$$\n$$ \\frac{\\Gamma \\vdash A : K \\;\\;\\text{and}\\;\\; \\Gamma, x: A \\vdash N :B}{\\Gamma \\vdash (\\lambda x: A \\mathop. N):(\\forall x : A \\mathop. B)} \\;\\; \\text{is function introdction} $$\n$$ \\frac{\\Gamma \\vdash M : (\\forall x : A \\mathop. B) \\;\\; \\text{and}\\;\\; \\Gamma \\vdash N:A }{\\Gamma \\vdash M(N) : B[x:=N]} \\;\\; \\text{is function elimination (but dependent!)} $$\n$$ \\frac{\\Gamma \\vdash M:A \\;\\;\\text{and} \\;\\; A=_\\beta B \\;\\;\\text{and}\\;\\; \\Gamma \\vdash B:K}{\\Gamma \\vdash M : B } $$\nIn CoC, the \"quantifiers\" are always bound, but the text of the article implies that the calculus of inductive constructions is impredicative, perhaps suggesting that CoC itself is too.\n\nSome of its variants include the calculus of inductive\nconstructions (which adds inductive types), the calculus of\n(co)inductive constructions (which adds coinduction), and the\npredicative calculus of inductive constructions (which removes some\nimpredicativity).", "output": "Impredicativity is one of those soft concepts that appears in many related forms, but it is difficult to explain what precisely they share. Let me try anyhow.\nImpredicativity allows us to single out, construct, or characterize a particular entity $e$ of some totality (set, type, universe) $T$ by quantification over all of $T$. Such constructions are sometimes considered problematic, especially when $T$ is a \"non-completed\", \"large\" or otherwise mysterious collection, say the class of all sets, or the subsets of an infinite set.\nIf we ignore the fears that haunt predicative mathematicians, there still remains the technical observation that impredicativity often greatly increases the logical strength of a formal system. In fact, unbridled impredicativity was the culprit for the early paradoxes of set theory.\nHere are some examples.\nThe axiom schema of separation\nIn set theory we may define an element of the class $\\mathsf{Set}$, i.e. a set, by quantifying over the entire class $\\mathsf{Set}$ using unbounded quantifiers. For example,\n$$\\{x \\in P(\\emptyset) \\mid \\forall y . y \\times x \\cong y\\}$$\nis a silly way of constructing the set $\\{\\{\\emptyset\\}\\}$ (sorry, I cannot think of a real example right now, but I am sure set theorists can come up with essential uses of unbounded separation). This is considered impredicative because $y$ ranges over all of $\\mathsf{Set}$, including the set that is being defined.\nIt should be clear that bounded separation $\\{x \\in A \\mid \\phi\\}$ in which all quantifiers appearing in $\\phi$ are bounded (of the form $\\forall y \\in S$ and $\\exists y \\in S$) may be considered predicative since the sets over which the quantifiers range have been constructed already (or else we could not mention them).\nThe related principle of unbounded comprehension, stating that for any predicate $\\phi$ there is a set $\\{x \\mid \\phi\\}$ is of course a form of impredicativity. In fact, this form of impredicativity is too strong, as it leads to Russell's paradox. It shows that impredicativity is not to be trifled with.\nComplete lattices\nA poset $(P, {\\leq})$ is a complete lattice when it is closed under arbitrary suprema (in which case it is also closed under arbitrary infima).\nThis is impredicative because it allows us to obtain an element $x \\in P$ by quantifying over a subset $S \\subseteq P$ of which $x$ may be an element (\u201c$x$ is supremum of $S$\u201d quantifies over $S$). The prime example is Tarski's fixed-point theorem: given a monotone map $f : P \\to P$, the least fixed-point $x$ of $f$ is defined as\n$$x \\mathbin{{:}{=}} \\sup \\{ y \\in P \\mid y \\leq f(y) \\}.$$\nThis definition of $x$ is impredicative because $x = f(x)$ and so $x$ is the element of the set that was used to specify $x$.\nPowersets are complete lattices and thus may be considered a source of impredicativity. It should be noted that as soon as the powerset of the singleton $\\{\\star\\}$ exists, all powersets exist because $P(A) \\cong P(\\{\\star\\})^A$. So the haunting is already done by the smallest non-trivial powerset. This is why topos theory is impredicative at its core: the subobject classifier $\\Omega$ is precisely $P(\\{\\star\\})$.\nImpredicativity in type theory\nIn type theory quantification is carried out by products. An impredicative universe $U$ is thus one that is closed under quantification over $U$:\n$$\n\\frac{\\vdash F : U \\to U}{\\vdash (\\Pi (A {:} U) \\,.\\, F A) : U}\n$$\nAn example is the universe of propositions $\\mathsf{Prop}$ which is closed under arbitrary products:\n$$\n\\frac{\\vdash A \\, \\mathsf{type}\n\\quad\nx {:} A \\vdash P(x) : \\mathsf{Prop}\n}{\\vdash \\forall x {:} A . P(x) : \\mathsf{Prop}}\n$$\nThe universe $\\mathsf{Prop}$ is impredicative because as a special case of the above we may quantify over $\\mathsf{Prop}$ itself. This is very useful, of course, as it allows us to define logical connectives by Church encodings, e.g.,\n$$p \\lor q = \\forall r {:} \\mathsf{Prop} \\,.\\, (p \\to r) \\to (q \\to r) \\to r.$$\nThe above definition is impredicative because the meaning of $p \\lor q$ is given by quantification over all propositions, one of which is $p \\lor q$ itself.\nSystem F is impredicative because it allows a type to be defined by quantification over all types, in much the same way as the impredicative encodings in $\\mathsf{Prop}$. For related reasons second-order Peano arithmetic is considered impredicative (a predicate may be defined by quantification over all predicates).\nA universe $U$ that contains itself and is closed under products is impredicative \u2013 and this is the case of impredicativity having gone too far because it leads to an inconsistency.\nPredicativity\nThose who feel uneasy about impredicativity, and those who want to carefully callibrate the logical strength of their formal systems, look for ways of avoiding impredicativity. In general this works by replacing self-referential constructions with iterative and inductive constructions which \"build the object from below\".\nFor example, Tarski's theorem (see above) may be proved as follows: give a monotone map $f : L \\to L$, its least fixed point is the limit of the ordinal-indexed chain\n\\begin{align*}\nx_{\\beta}  &\\mathrel{{:}{=}} \\sup \\{ f(\\alpha) \\mid \\alpha < \\beta \\} \n\\end{align*}\nWe have replaced impredicativity with transfinite recursion on ordinals \u2013 and in any specific case only a set-sized amount of such recursion is required.\nIn type theory impredicativity is typically avoided by introduction of universe levels, so that quantification over a universe $U_k$ yields a type in the next universe $U_{k+1}$.\nOne might still wonder whether some impredicativity is involved even in the most innocuous looking constructions. For example, when we replace the Church encoding of $p \\lor q$ with direct-style inference rules, we might write the elimination rule as\n$$\n\\frac{p \\vdash r \\qquad q \\vdash r}{p \\lor q \\vdash r}\n$$\nIs this not quantification over all propositions $r$, just as before?\nNo, there is an important difference: in the case of the Church encoding of $p \\lor q$ the quantification was internal to the formal system (we used a quantifier that is one of the constructors of type theory), whereas the above rules use external or meta-level or schematic quantification. The latter has much less of a punch.", "meta": {"post_id": 326, "input_score": 37, "output_score": 35, "post_title": "What is predicativity?"}}
{"input": "TL;DR: How / where to formalize results concerning the logical strength of systems? Are proof assistants having a weak base theory but also enough infrastructure to make it feasible?\n\nI'll start by giving some context. In studying Logic and foundations, a clear interest is the consistency of the set of axioms that you use; especially when showing that some statement is \u201cindependent\u201d (or simply doesn't follow) from others. The cardinal example (pun slightly intended) of this is the Continuum Hypothesis (CH) that since Cohen we know that it can't be proved nor disproved with current mathematical methods.\nThe catch, obviously is that \u201ccurrent mathematical methods\u201d above corresponds to \u201cZFC set theory\u201c (for which it was proved), and even by adding large cardinal assumptions (which include, by translation, CIC with universes). But if those foundations are self-contradictory, the previous paragraph is wrong. The correct reading is: If ZFC is consistent, then it doesn't prove CH; to the effects of the present question, the interesting version is: If ZFC is consistent, so is ZFC + \u00acCH.\nThere are other equiconsistency results as that. For example, the following theories are equiconsistent:\n\nZF + Choice for countable families + \u201cEvery subset of $\\mathbb{R}$ is Lebesgue measurable\u201d;\nZFC + \u201cthere exists an inaccessible cardinal\u201d (i.e., there exists a set universe).\n\nIn order to be able to formalize this theorem in a reasonable context, the underlying logic of the proof assistant should be at least weaker that ZFC plus one universe. Same goes for the independence of CH. On the other hand, proof assistants like Lean (and Coq?) assume a sequence of universes from the start; also, Isabelle/HOL has a session devoted to set theory, but its consistency strength is that of statement 2 above.\nThe question arises even for Isabelle/ZF if you want to work with theories weaker than ZFC. In this state of affairs, I would like to know if there is any proof assistant that has a very weak foundation, that allows to work smoothly with theories of varying strength.\nBy searching the site, I found a related question asking for the formalization of model theory, and another relevant one\nmentioning also other systems of different strength (Peano / Primitive Recursive Arithmetic / Bounded Arithmetic, systems of reverse mathematics). But one point to be considered is that if one starts with plain PA / PRA then you have to code all the reasoning inside it, and usually tactics work only at the surface.", "output": "You could address your goals by using a generic proof assistant, one that supports user-definable theories, such as Isabelle and Metamath, and I am sure there are others. These allow you to define your own weak formal system and work with it.\nHowever, once you define your favorite formal system, you will have a bare-bones proof assistant that will only become usable once you implement a substantial library of basic facts and constructions \u2013 and that is a rather daunting task. We need to learn how to lower the bar to having domain-specific proof assistants.\nAnother possibility is to use a popular proof assistant that supports a very strong formalism, but to carefully avoid its power. While not entirely satisfactory, doing so will allow you to actually get things done.\nSpecifically, suppose you want to show that if $\\mathrm{ZFC} + X$ is consistent then so is $\\mathrm{ZFC} + Y$, and you'd like to do this by demonstrating that a model of $\\mathrm{ZFC} + X$ yields a model of $\\mathrm{ZFC} + Y$. In whatever proof assistant you like, formalize the basics of Tarskian semantics: the syntax and logic of the first-order theory $\\mathrm{ZFC}$, $\\in$-structures, models of $\\mathrm{ZFC}$ etc. Then you prove a theorem\nZFCX\u21d2ZFCY : \u03a0 (M : \u2208-structure) . (M \u22a8 ZFC+X) \u2192 \u03a3 (N : \u2208-structure) . (N \u22a8 ZFC+Y)\nZFCX\u21d2ZFCY = \u2329proof-goes-here\u232a\n\nSince your proof assistant is too powerful, it allows you to just construct a model N of ZFC+Y from scratch, but you shouldn't do that. Instead you resist the Dark Side and use forcing to construct N from M in the weak fragment that you wish you were working in.\nThis is not ideal but is still well-worth doing. Think of it as partial formalization. You have formalized the desired construction, but you still have to manually check the proof to verify that it remains within the confines of a weak fragment (this may not be so simple if you use the standard library and lose track of what the library is doing). People actually do such things for lack of a better method. For example, the UniMath library formalizes mathematics in Univalent foundations on top of the assumption Type : Type \u2013 which is inconsistent! The authors review the code carefully and avoid dangerous moves. (I have it on good authority that the inconsistent assumption keeps them awake at nights.)", "meta": {"post_id": 425, "input_score": 13, "output_score": 9, "post_title": "Attempts to accommodate theories of different consistency strength in single assistant"}}
{"input": "What is the difference between intensional vs extensional type theories and how come the type checking is undecidable for extensional type theory? Also, how does it affect the expressiveness of theorem provers?", "output": "Extensional type theory is characterized by the reflection rule, which says that if the identity type ${\\rm Id}(a,b)$ is inhabited, then $a\\equiv b$ ($a$ and $b$ are judgmentally equal).  It is called extensional type theory because this means that the judgmental equality coincides with the identity type, and the latter is extensional (or, at least, more extensional than the judgmental equality would be in the absence of the reflection rule --- just how extensional it is depends on whether you have principles like function extensionality and univalence).  Intensional type theory is so-called because its judgmental equality is intensional, whereas its identity types can be even more extensional than those in extensional type theory (because the reflection rule is incompatible with the \"strongest extensionality principle\", namely univalence).\nIn a dependent type theory, type-checking is complicated because of the conversion rule that if $a:A$ and $A\\equiv B$ then $a:B$.  This essentially requires that a type-checking algorithm must include an algorithm for checking judgmental equality.  When combined with the reflection rule, this means a type-checking algorithm would have to include an algorithm for checking inhabitation of a type (namely the identity type).  But inhabitation of types can be used to encode the truth of arbitrary mathematical statements, so (e.g. by the halting problem) it is impossible to have a terminating algorithm for checking inhabitation of types, and hence impossible to have a terminating type-checking algorithm for extensional type theory.\nThere is a theorem, due I believe to Martin Hofmann (Conservativity of Equality Reflection over Intensional Type Theory), that extensional type theory is conservative over intensional type theory extended by axioms of uniqueness-of-identity-proofs and function extensionality.  Thus, there is no difference in the \"expressiveness\" of these theories.  Given the undecidability of type-checking for extensional type theory, therefore, very few proof assistants have tried to implement it.", "meta": {"post_id": 470, "input_score": 9, "output_score": 9, "post_title": "Type Checking Undecidable in Extensional Type Theory"}}
{"input": "How can I prove that the matched pattern is equal to the original argument?\nFor example, in the following function, what can I write instead of sorry to prove the equality?\ndef e1 (x: Option Nat): Nat :=\n  match x with\n  | none => 1\n  | some y =>\n    have : some y = x := sorry\n    y+1\n\n\nThe only option I could come up with was using a pair with an equality proof, but that seems a bit too complex:\ndef e2 (x: Option Nat): Nat :=\n  let x' := x\n  have x'_eq: x' = x := rfl\n  match x', x'_eq with\n  | none, _ => 1\n  | some y, y_eq =>\n    have : some y = x := y_eq\n    y+1\n\nIs there an easier way to do this?", "output": "In Lean 3, you can solve this using the following syntax:\ndef e1 (x : option \u2115) : \u2115 :=\nmatch _, rfl : \u2200 y, y = x \u2192 _ with\n| none, h := 1\n| some y, h :=\n  have some y = x := h,\n  y+1\nend\n\nThe match x, y : T with syntax means \"generate a function of type T called e1._match or similar, and then replace this match expression with e1._match x y\". T is usually therefore of the form X \u2192 Y \u2192 _, where _ is the type of the values within the match expression.\nNote that this is essentially the same as your solution, but the match expression lets us combine it all into one line.", "meta": {"post_id": 485, "input_score": 7, "output_score": 9, "post_title": "Preserve equality with match expression"}}
{"input": "The $\\lambda\\mu$-calculus is a variant of the $\\lambda$ calculus introduced by Parigot to capture classical logic. The Wikipedia article describing it in more detail is here. In modern proof assistants, it is expected that the user should opt-in to breaking canonicity via adding their own axioms if they want to enjoy classical reasoning.\nThere is an alternative world though, where classical logic is the basis for the core logic. The $\\lambda\\mu$-calculus is one such calculus that allows this to be possible. I am interested in it specifically because a $\\lambda\\mu$-cube was constructed for it without much difficulty. It is known that given the Calculus of Constructions that a proof assistant with inductive types is only a stone's throw away by adding on strong sigmas, bolting on an inductive datatype theory, or some other combinations of core types.\nThere are existing approaches that use classical reasoning such as HOL and other LCF logics where a classical logic can be embedded. However, I am interested in the class of proof assistants that are on equal footing with Coq, Agda, and Lean. That is, they ought to have dependent types at the very least.\nYet, I do not know of any proof assistants that have tried (and definitely none that have had any success!) in using the $\\lambda\\mu$-calculus as the computational basis. My question is thus in two parts: First, what difficulties might one run into when attempting this? Second, has anyone tried it?\nI want to dispense with the obvious objection of normal forms. The calculus does not have a strong notion of normal form (or at least, you have to choose between confluence and normal forms). This is not a show-stopper, a designer can pick confluence and use that for definitional equality while allowing propositional equality to \"repair\" the lack of strong normal forms. I do not think even usability will be hurt, as I imagine the $\\lambda$-calculus fragment can still enjoy $\\beta\\eta$-equality. If my assumptions here are wrong I would be interested to know.", "output": "I think that the first question can be generalized to \"What difficulties are there in adding side-effects to a proof assistant based on dependent type theory.\"\nFirst-class continuations are just one particular side-effect\nThe \u03bb\u03bc-calculus is only an instance of a more general class of extensions of the \u03bb-calculus with side-effects. There is no unique definition of what a side-effect is, but a good generic approximation is \"any feature of the language that makes the difference between call-by-name and call-by-value observable\". One can for instance mention exceptions, mutable state, IO, threads and whatnot.\nThe effect introduced by the \u03bb\u03bc-calculus is the notion of first-class exceptions. The \u03bc binder, indeed, allows to capture the current continuation,  which can be resumed at a later time with the [\u03b1]t construct. This is not possible in the standard \u03bb-calculus, and it is precisely what introduce classical abilities in this system.\nIn PLT, we ain't afraid of no effects\nThis other answer insists at length, and rightfully, on the fact that first-class continuations break the CbN-CbV equivalence and thus should be endowed with a stricter reduction strategy to preserve the equational theory. This is not a problem tied to dependent types specifically, but rather by definition the landmark of side-effects.\nNow, dependent types rely on the runtime semantics of the proofs, so the degeneracy of the equational theory percolates immediately in the logic. But the very same problem happens already with effectful non-dependent programming languages, and there, it is folklore that one needs to care about the exact reduction strategy. No sane programmer would expect a call-by-name equation to hold in their favourite ML implementation.\nSo in this regard, I believe that that answer is somewhat missing the really problematic point.\nI Can Haz callcc?\nDependent type theories are biased towards call-by-name. The one rule that allows lifting computation to typing is the conversion rule. But this rule bakes in the fact that conversion is call-by-name, as it is generated by the unrestricted \u03b2-rule.\nSo one could expect that throwing side-effects into MLTT is going to be fine, since it already made a choice of strategy for you. Obviously you have to be careful that indeed your effects are call-by-name, but apart from this technical detail it should be fine, shouldn't it?\nAlas! If you do this with callcc (which is essentially a flavour of \u03bb\u03bc-calculus) you get an inconsistent theory. What went wrong?\nThe real problem with effects and dependent types\nWhat really separates dependent type theory from other higher-order logics is that it features inductive types equipped with large dependent elimination. The latter is what allows the user to write weird types like forall (b : bool), if b then nat else empty where the shape of a type really depends on the value of a term.\nThis is precisely this feature that causes the issue with side-effects, and there is a simple intuitive and mostly correct explanation for this phenomenon.\nAs OP observed, side-effects break the canonicity property of the theory. A term, while reducing to a value, may perform side-effects that are observable. Thus, for instance, not all terms M : bool are convertible to either true or false in presence of effects. A typical PLT-centric way to phrase that is the progress lemma, which says that terms are either values or reduce. And indeed, values of an inductive type have the right shape, but by contrast terms can be wild.\nNow, large dependent elimination bakes in the fact that arbitrary terms behave like values. For booleans, for instance, it states that P true and P false are enough to prove forall b : bool, P b for any P : bool -> Type. But obviously, in presence of side-effects there are non-standard boolean terms that are neither true nor false.\nNo wonder why this principle results in an inconsistent theory!\nEmbracing effects\nEffectful dependent types are a pretty niche area. Still, we do have some proposals for it to work properly.\nSome effects can be added relatively straightforwardly and justified by a syntactic translation. As already argued, we need to do something with large elimination or face inconsistency. We believe that a simple linearity criterion is enough to separate the wheat from the chaff.\nLinearity is the critical insight of Baclofen Type Theory (BTT), a restriction of MLTT compatible with side-effects. In a nutshell, BTT restricts large elimination to predicates P : bool -> Type that are linear, i.e. which satisfy an equation ensuring that they actually behave as if they were evaluating their argument in a call-by-value / strict way.\nToo good to be true?\nUnfortunately, while BTT seems to validate a large class of effects, we still do not have a reasonable syntactic model of BTT for first-class continuations. The reason are technical and tied to the impredicative nature of the CPS monad. Yet, we believe that it may be possible to present a variant of BTT with first-class continuations as a standalone theory whose properties are proved directly on the syntax. This requires more work, and novel research, which is why there is no such thing yet.\nIn any case, BTT might not be a theory you want to work in.\n\nFrom a mathematical standpoint, it really puts emphasis on the potentially effectful nature of proofs-as-programs. This is clearly at odds with the standard mathematical practice.\nFrom a programming standpoint, mixing call-by-name and effects is not very nice. You always have to program defensively and rely on weird storage operators to ensure you actually get a value.\n\nIt might be more tenable in the long term to switch to a call-by-value (or more generally, call-by-push-value / polarized) type theory. Nonetheless, this move would only make the life of the computer scientist easier, while making the whole experience even more alien to the mathematically inclined user.", "meta": {"post_id": 541, "input_score": 19, "output_score": 13, "post_title": "What difficulties are there in basing a proof assistant on the $\\lambda\\mu$-calculus and has any proof assistant tried?"}}
{"input": "W-types are said to be \"a well-founded inductive type\" that is parameterized over arities and constructors, similar to a \"tree of possible constructions\". On nlab, it is said that a lot of inductive types can be encoded with W-type.\nHowever, from that description I still don't understand what's well-foundedness in terms of the syntax of inductive types. I can see that Agda's non-mutual inductive families are \"well-founded\" because it's a rooted tree, but what about inductive-recursive and inductive-inductive types? I think these are known to be not equivalent to non-mutual inductive families and they have a more complex model. I think someone told me that strictly positive inductive families are well-founded, but what exactly makes a(n inductive) type well-founded?\nCan we encode all well-founded inductive types with the W-type?", "output": "\"Well-founded\" and \"inductive\" mean roughly the same thing. I think the reason different terminology tends to get used for W-types is that their definition looks similar to notation for ordinals (imagining that the branching of the trees is like a limit of the children). They're distinct from the other inductive types given in Martin-l\u00f6f type theory in that they are potentially infinitely wide. But they're still supposed to be (intuitively) finitely deep, which is what the \"inductive\" and \"well-founded\" refer to\nWhether or not you can encode various other sorts of inductively specified types as W-types is a complicated question.\n\nIt's pretty easy to show that you can encode plain inductive types using W-types if you have various sorts of extensionality. The typical schemas for what constitutes an 'inductive definition' are like finite polynomials, while W-types are trees built from any (infinite) polynomial definable in type theory. The main discrepancy is how the 'products' act. The finite products in inductive schemas have a canonical form, while the functions used in W-types do not, and the most obvious way to fix that is with function extensionality.\n\nHowever, you can also get by without extensionality. You only need some eta rules. The idea is to use W-types to build the right sort of trees, then define the subtype of 'canonical' trees by (W-type) induction. It happens that the recursion rule for this subtype has the judgmental behavior matching the schema for inductive definitions.\n\nYou can also encode indexed W-types using normal W-types and the identity type using a similar strategy. You use W-types to build a larger type of trees on the 'total spaces' involved, and then define a subtype of well-indexed trees by induction. This file shows how to do it.\n\nYou can (I believe) encode indexed inductive types/families using indexed W-types, including the encoded version of those, using a strategy similar to the Why Not W? paper. My Agda file above shows how to do this for a fairly simple indexed type that was mentioned in another question here.\n\nYou can encode mutual inductive and inductive-inductive types with indexed inductive types. For mutual inductive types, you just add a finite index type to turn N definitions into a single N-indexed definition. For induction-induction, you follow a similar strategy as for building indexed W-types: define mutual inductive types that contain too many values, then define the subtypes with proper indexing afterward.\n\nYou cannot encode all inductive-recursive definitions as (indexed) inductive definitions. I-R definitions were invented as a schema that would let you write down the definition of universes as a special case. However, the additional power comes from simultaneously being able to define a recursive type family. If instead you just simultaneously define a recursive function into an existing type, I believe they are encodable using a strategy like above. This might mean that if you have enough universes, you can use them with inductive definitions to encode everything you could write by just having a theory that admits inductive-recursive definitions (but with no pre-specified universes). I'm unsure about this, though.\n\nHaving a universe that classifies inductive-recursive definitions is even stronger, and isn't itself an instance of induction-recursion. It's actually inconsistent to be able to do induction on such a universe (while the I-R definable universes in 6 can have an associated induction principle).\n\nQuotient/higher inductive types can't be encoded as any of the previous sorts of definition in general. Quotients where you can compute a canonical representative for each equivalence class can be defined, but not all quotients are like that.\n\n\nI don't think strict positivity has anything to do with being inductive/well-founded (negativity does, though; see the comments). It's necessary to guarantee that 'all' inductive definitions are meaningful in various sorts of models. For instance, you can't have a classical set theoretic model of an inductive type $T \\cong 2^{2^T}$ (which is positive, but not strictly positive), because $2$ classifies the propositions, and you can't have a type equivalent to its double power type. Constructively you might be able to admit some such types, and for instance, $\u03bb \\_ \u2192 0$ and $\u03bb\\_ \u2192 1$ give you a starting point for building up your finitely-deep values. However, these sorts of non-strictly positive types can conflict with other features than just classical mathematics, so you need to be very careful.\nVarious bits of the above are subject to caveats about the details of what counts as an \"inductive definition.\" There's literature out there rigorously defining various schemata for what constitutes an (indexed) inductive(-recursive/inductive) definition (etc.). Agda (for instance) is not super rigorous, and runs a checker that lets you conveniently do things that could probably be encoded in those more rigorous schemata in a more inconvenient way. Or perhaps you couldn't, but it's still fine; or isn't.", "meta": {"post_id": 926, "input_score": 10, "output_score": 13, "post_title": "What are well-founded inductive types?"}}
{"input": "I've heard about a folklore claim that\n\nIf all terms of \u2115 are literals, all closed terms admit canonical form.\n\nIn MLTT-style type theories.\nI am assured that it's true for Bool if one also assumes consistency, namely the canonicity for empty type. Unfortunately, I don't know much about the general case, and couldn't find references. I suppose that it's related to encoding terms by natural numbers or something similar...\nDoes anyone know a rigorous formulation or a proof (or a disproof)?", "output": "Your question is quite vague, so let me give you both an intuition on why this ought to be true, and a counterexample.\nAs for intuition, let me show how supposing only canonicity\nfor $\\mathbb{N}$ (natural numbers) one can deduce canonicity for $\\mathbb{B}$ (booleans). Suppose we are given a closed boolean $\\vdash b : \\mathbb{B}$, and consider\n$$\\mathtt{if}~b~\\mathtt{then}~0~\\mathtt{else}~0$$\nThis is a natural number in the empty context, so it must reduce to a canonical form. But to do so it must be the case that $b$ also reduces to\na canonical form, because this is the only way for the $\\mathtt{if}$ statement to reduce!\nAbstracting a bit, if we can construct a context $\\vdash C[\\cdot] : T \\Rightarrow T'$, that is a term with a hole such that whenever a term $\\vdash t : T$ is plugged in said hole the whole term is of type $T'$, and such that $C[t]$ has a canonical form only if $t$ has, then canonicity for $T'$ implies canonicity for $T$.\nBut there are perfectly valid cases where such a context cannot be built, and this is intentional! My favorite example is the sort of (proof-irrelevant) propositions $\\mathtt{SProp}$. As shown in a recent article (and its predecessor), you can prove canonicity for natural numbers in MLTT extended with $\\mathtt{SProp}$ without proving canonicity of inhabitants of strict propositions \u2013 you only have to assume consistency. The trick is to control the way one can use those to build relevant terms (in our case, natural numbers) so that no context like the above can be built. The idea is roughly to allow for an eliminator from $\\mathtt{SProp}$ to $\\mathbb{N}$ only for the false proposition. This ensures that a natural number in the empty context cannot be stuck on this eliminator since that would mean that one has an inconsistency in the theory \u2013 the term on which the eliminator is applied would be a proof of falsity in the empty context.", "meta": {"post_id": 1026, "input_score": 13, "output_score": 19, "post_title": "Does the canonicity of natural number imply that of all types?"}}
{"input": "Mostly when I read about impredicativity I see people bemoaning its downsides.\nBut it's not clear to me why I would want impredicativity in the first place.\nImpredicativity is useful for analyzing impredicative systems. And impredicative Pi types can be used to encode recursive datatypes without going up a universe. However, from what I understand Cedille has to go through a few contortions to have induction principles over impredicative encodings of datatypes.", "output": "There are some tricks that only work when you have access to an impredicative universe. They tend to construct \"the smallest object\" of some kind, without an explicit construction, i.e. a textbook impredicative encoding.\nA fancy one that comes to my mind is Mendler encoding. In a nutshell, given some function P : (Prop -> Prop) -> (Prop -> Prop) in CIC, this encoding constructs the \"free strictly positivization\" of P. This can be used to compose inductive predicate constructions in a modular way, since one effectively abstracts over the syntactic criterion of strict positivity.", "meta": {"post_id": 1037, "input_score": 17, "output_score": 8, "post_title": "What are the advantages to impredicativity?"}}
{"input": "I've been trying to prove this in Agda:\nlemma : (P : \u2115 \u2192 Set)\n  \u2192 ((n : \u2115) \u2192 Dec (P n))\n  \u2192 Dec (\u03a3[ n \u2208 \u2115 ] \u00ac (P n))\n\nIn words:  We have an infinite sequence of decidable propositions.  Can we conclude that either a) all the propositions are true or b) you can find a counterexample?\nI'm 70% sure this is not a conclusion you can draw without some extra axiom.  Is there a name for this, or some papers I can read?  If you need an extra axiom, what's a good one to go with?\n(I came to this after working for a bit on Konig's Lemma, which I also suspect can't be proven without some additional assumptions.)", "output": "This is equivalent to solving the Halting Problem (perhaps relativized to an oracle), so this is a very strong assumption.\nFix a Turing machine M, suppose P n is the statement that M does not halt after being run n steps. This is decidable by simply running the machine. However, \u03a3[ n \u2208 \u2115 ] \u00ac (P n)) asks whether it is possible to find an n such that M halts in n steps. That is undecidable for a general Turing machine M.\nAs a general principle, being able to solve the Halting Problem relative to any oracle, is equivalent to the Limited Principle of Omniscience (LPO) as mentioned by Trebor. K\u00f6nig's Lemma (KL) for general finitely branching trees is known to be equivalent to this, provided one has an enumeration of the nodes. In the most general possible setting, one might first need a weak form of choice \u2014 namely, to choose one from each of a countably infinite sequence of nonempty finite sets \u2014 and then use LPO to prove the full form of K\u00f6nig's Lemma.\nHowever, the Weak K\u00f6nig's Lemma (WKL), which is limited to trees of finite $0,1$-sequences is known to be strictly weaker. In fact, it is related to the Lesser Limited Principle of Omniscience (LLPO) in the sense that for any infinite decidable tree T of finite $0,1$-sequences there is an infinite sequences of LLPO instances such that any simultaneous solution to all of these can be used to compute an infinite path through T.", "meta": {"post_id": 1039, "input_score": 7, "output_score": 8, "post_title": "Decidability for an infinite sequence of decidable propositions"}}
{"input": "I have often seen the claim that in a classical setting, well-foundedness of a relation > defined as the absence of an infinite descent x_0 > x_1 > x_2 > ... is equivalent to the constructive definition using an accessibility predicate as in Coq's Acc:\nInductive Acc (x: A) : Prop :=\n  Acc_intro : (forall y:A, R y x -> Acc y) -> Acc x.\n\nDefinition well_founded := forall a:A, Acc a.\n\nwhere R : A -> A -> Prop.\nIt seems it requires some version of choice but I don't know which is weakest one has to assume to construct such a proof.", "output": "This is not a Coq proof, but it's a proof sketch using the axiom of dependent choice and LEM to exhibit an equivalence. I believe this is the weakest choice principle you can get away with, but I cannot find a reference. It's too long for a comment unfortunately.\nEdit: it's no longer just a paper proof! @kyo dralliam has formalized the below argument in Coq and gone further to show that the choice additional axioms (dependent choice, LEM) are also necessary as well as sufficient.\n\nLet's define $\\mathsf{idc}(A,R,a)$ to be the proposition which states that there is an infinite descending chain in $(A,R)$ starting with $a$:\n$$\n\\mathsf{idc}(A,R,a) = \\exists f : \\mathbb{N} \\to A.\\ f(0) = a \\land (\\forall n.\\ f(n) \\mathrel{R} f(n + 1))\n$$\nWe will show that $\\neg \\mathsf{idc}(A,R,a) \\iff \\mathsf{Acc}(A,R,a)$. The $\\Leftarrow$ direction follows by induction on $\\mathsf{Acc}$ and requires no non-constructive principles. The inductive step can be summarized as \"if $\\mathsf{idc}(A,R,a)$ holds, there is some $b$ such that $a \\mathrel{R} b$ and $\\mathsf{idc}(A,R,b)$ holds.\"\nFor the other direction, let's use LEM and assume $\\neg \\mathsf{Acc}(A,R,a)$ to derive a contradiction. We will achieve this contradiction by constructing an infinite descending chain and this is where we will use the axiom of dependent choice.\nTo that end, consider the type $B(a) = \\{x : A \\mid a \\mathrel{R^*} x \\land \\neg \\mathsf{Acc}(A,R,x)\\}$ and write $S$ for the restriction of $R$ to this type. Let's prove that $S$ is entire, that is if $b : B(a)$ then there exists some $c$ such that $b \\mathrel{S} c$. I've deferred this lemma to the bottom of the answer, to not clutter up the proof. Since $(B(a),S)$ is entire and non-empty with $a : B$ by assumption, the axiom of dependent choice gives us an infinite descending chain within $B(a)$: $b_0 \\mathrel{S} b_1 \\mathrel{S} b_2 \\mathrel{S} b_3 \\dots$. By definition of $S$, this induces a chain $b_0 \\mathrel{R} b_1 \\mathrel{R} b_2 \\dots$. Moreover, by definition of $B(a)$ we can extend this chain so that it starts with $a$. We now derive our contradiction from $\\neg\\mathsf{idc}(A,R,a)$.\n\nLemma. $(B(a),S)$ is entire.\nProof. Assume we are given $b : B(a)$. By assumption, $\\neg \\mathsf{Acc}(A,R,b)$. Unfolding this, we see that it's equivalent to the following:\n$$\n\\neg (\\forall b. a \\mathrel{R} b \\to \\mathsf{Acc}(A,R,b))\n$$\nBy LEM again, we obtain $c : A$ such that $a \\mathrel{R} c$ and $\\neg \\mathsf{Acc}(A,R,c)$. Therefore, $c : B(a)$ and $b \\mathrel{S} c$ as required.", "meta": {"post_id": 1077, "input_score": 16, "output_score": 16, "post_title": "Well-foundedness: classical equivalence of no infinite descent and accessibility"}}
{"input": "Agda has a reflection mechanism (not equality reflection or reflexivity, but something related to metaprogramming based on goals and contexts to generate terms) and people have developed some libraries that simulate Coq tactics, for example acata.\nHowever, some people still don't consider Agda to have tactics (for example in Kevin Buzzard's \"the future of mathematics\" talk, the Q&A section).\nOn the other hand, Coq and Lean are considered to \"have tactics\", but what I see is just another syntax for writing reflection code like in Agda. I think it's because I don't understand tactics in these languages good enough. So, what particular feature do they support so that they can be considered to \"have tactics\"? I have a clear understanding of what reflection is (like in Agda -- the compile time reflection with access to the type-checking monad and bidirectional type checking functions), but I am unsure what do people mean by \"tactics\".", "output": "Consider a reasonable type theory $T$ with decidable checking. Think of it as the core type theory implemented in the kernel of a proof assistant, i.e., with fully elaborated and annotated judgements that nobody wants to write with bare hands.\nA central task of formalization is inhabitation of a type: given a derivable judgement $\\Gamma \\vdash A \\; \\mathsf{type}$ (the goal), the user provides an expression $e$ (the solution), and the kernel checks whether $\\Gamma \\vdash e : A$ is derivable. How can we do this in a practical way?\nIt is not practical for the user to write down a fully annotated term $e$. Instead, they write down an expression $c$ in a surface language $V$ (the vernacular) which is elaborated or evaluated by the proof assistant to give a fully annotated expression $e$. In order to account for the possibility of a user error, the proof assistant can be seen as a map\n$$\\textstyle\nP : \\prod_{\\Gamma, A} \\, (\\Gamma \\vdash A \\; \\mathsf{type}) \\to V \\to \\{\\mathsf{error}\\} + \\sum_{e} \\, (\\Gamma \\vdash e : A).$$\nWe read the above as: given a derivable type $A$ in context $\\Gamma$ (the goal) and an expression $c$ of type $V$ (the suggested solution), the proof assistant either recognizes that $c$ evaluates to an expression $e$ such that $\\Gamma \\vdash e : A$, or it reports an error.\nActually, apart from errors, there could also be other computational effects, such as non-termination, state, user interaction, etc. We thus generalize the above to a suitable computational monad $M$:\n$$\\textstyle\nP : \\prod_{\\Gamma, A} \\, (\\Gamma \\vdash A \\; \\mathsf{type}) \\to V \\to M(\\sum_{e} \\, (\\Gamma \\vdash e : A)).$$\nWith the general setup explained, we can address the question. What kind of proof assistant one gets depends on the design of the vernacular $V$ and the computational monad $M$. Some possibilities are:\n\nAgda: to give the user the impression that they are working with $T$ directly, we design the vernacular $V$ to look like an abridged version of $T$ and call the expressions of $V$ (proof) terms. The computational monad $M$ supports interactive construction of terms through \u201dholes\u201c that represent subgoals. (Agda also support meta-programming through which the user can implement proof search and other techniques that people call \u201ctactics\u201d.)\n\nCoq and Lean: make the vernacular $V$ look like a command-based programming language. The commands are called tactics. The monad $M$ incorporates the current goal as state that is manipulated by the user through tactics. The command-based language allows general recursion and construction of non-terminating programs.\n\nIsabelle/HOL: make the vernacular $V$ look like a meta-level programming language. There is a built-in abstract data type of judgements, which is controlled by a trusted kernel. The user writes programs that evaluate to judgements. There is a library of useful functions for constructing judgements, called tactics. The user is free to implement their own functions, as well as Tetris.\n\n\nReflection is the ability for the vernacular $V$ to access the abstract syntax trees of computed judgements. Again, there is more than one way of doing this:\n\nAgda reflects judgements into a datatype of abstract syntax trees (this is also known as reification)\nCoq has matching on goals and hypotheses\nLean metaprogramming also allows one to decompose judgements\nIsabelle/HOL has reflection too, though the abstract data type of judgements. In addition, there is also a mechanism for matching on goals and hypotheses similar to the one for Coq.\n\n(If someone can provide better descriptions and links to reflection for Lean and Isabelle, that would be grand.)\nReflection is not to be confused with Boolean reflection, which is a proof technique for (ab)using the equality checker as a decision procedure.  Please ask a separate question if you'd like to know more.", "meta": {"post_id": 1103, "input_score": 18, "output_score": 18, "post_title": "What's the difference between reflection and tactics?"}}
{"input": "I have this function:\nDefinition bexp x y := bexp_r x y [true].\n\nAnd I have this goal:\nvalue (bexp [] y) = 0 ^ value y\n\nI want to replace the call to bexp with the underlying bexp_r.\nI tried to use the simpl tactic but it did not replace it.", "output": "The tactic you are looking for is probably unfold. If you write unfold bexp it will replace it with its body.\nIn certain cases, unfolding the definition will unfold too much and if you want more control over it you can prove unfolding lemmas instead and rewrite with them.", "meta": {"post_id": 1297, "input_score": 6, "output_score": 10, "post_title": "How to replace a function by its body"}}
{"input": "A neutral/normal term in the lambda calculus is typically defined\ndata nf = Lam of nf | Neu of ne\ndata ne = Var of int | App of ne * nf\n\nNow the question is what to do about constructors and eliminators such as pairs, projections, natural numbers, or the recursor.\n\nWe could view them all neutral terms because they are just variables pair, fst, snd, zero, succ, rec that happen to have some semantic meaning. For example:\n\ndata ne = Var of int | App of ne * nf \n| Pair of nf * nf | Fst of nf | Snd of nf\n| Zero | Succ of nf | Rec of nf * nf * nf\n\n\nBut this question considers an alternative, namely to view constructors (pairs, natural numbers) as normal terms and eliminators (projections, recursor) as neutral terms, which also seems to make sense considering Lam is the constructor for function types and App the eliminator. For example:\n\ndata nf = Lam of nf | Neu of ne\n| Pair of nf * nf \n| Zero | Succ of nf\ndata ne = Var of int | App of ne * nf\n| Fst of ne | Snd of ne \n| Rec of nf * nf * ne\n\n(Edit) It seems in the first approach, terms are only normal up to $\\lambda$-reductions, whereas in the second, terms are in fully normal form.\nIs there an advantage to one approach over the other?", "output": "A neutral term is a variable, or an eliminator stuck on a neutral term. Basically a stack of eliminators applied to a variable.\nThese terms are called neutral, and distinguished from other normal forms, because they have not reduced to a constructor, but they cannot reduce further (because the eliminators are stuck on a variable).\nWith this in mind, your second definition of the type of normals and neutrals is the correct one. I would say this approach has the advantage of actually representing normal forms. I'm not sure why you would want a language with pairs where fst (pair zero zero) does not reduce.\nI would also caution that constructors like pair and zero, and eliminators like fst and rec really are not \"just variables\", anymore than lam is just a variable. Of course they are \"variables\" in the sense that they are strings of characters, but as you say, they have semantic meaning distinct from variables. When I used \"variable\" earlier in this answer, I meant a thing with the semantics of a variable, that can be the subject of substitution.", "meta": {"post_id": 1397, "input_score": 7, "output_score": 9, "post_title": "What is a neutral term?"}}
{"input": "I am a high school senior going into college and I am applying to a scholarship in which I must write an essay about a potential future technology that would dramatically impact humans. I immediately thought of proof assistants, which already exist, but I'm sure there are some limitations that can be overcome. I don't really know much about proof assistants, so I would like to learn more. I feel as though they might help to prove significant theorems that we currently have no answer to (if not already) that can benefit humanity massively.\nIf you could respond or link me to a place where I could learn more about the current state of proof assistants, I would greatly appreciate it. Here are some important questions I have:\n\nWhat types of theorems can proof assistants solve, and what types can they not at the present moment?\nHow can they be improved?\nWhat avoidable and unavoidable limitations are there?\nIs there anything else I should know about the current and potential future states of proof assistants?", "output": "These are broad questions and I doubt you will get a complete answer in a single stack exchange answer.  But since you seem ernest and interested, let me at least try to help clarify some of your questions.\n\nWhat types of theorems can proof assistants solve, and what types can they not at the present moment?\n\nFirst, to be clear, the primary purpose of proof assistants isn't to solve new theorems in mathematics automatically.  It is to help a human write proofs in an air-tight form.  Think of them as a programing language but instead of writing code, you write a proof---and instead of compiling and running the code, the computer checks that the proof is correct.\nThe three primary use cases of proof assistants are:\n\nTo prove the correctness of computer code and hardware.  Unlike mathematical proofs, these proofs are very tedious and a small missing case could mean the difference between correct code and a costly bug.  Proof assistants help to do this tedious work and not miss edge cases.\nTo build a library of formal mathematics.  By formalizing all of mathematics we can begin to make mathematics more accessible to computers and unify all of mathematics into a few curated digital libraries of mathematics.\nTo explore new types of logical systems.  New logics can be unintuitive and formal systems can help work with them.  Conversely, new foundational systems may be better suited for formalizing mathematics on a computer.\n\nA related technology called automated theorem provers are used to prove theorems automatically.  SAT solvers, SMT solvers, and resolution theorem provers are some examples.  They are often used for industrial applications, but they also have been used to solve certain combinatorial theorems.\nHaving said all this, there is a continuum between proof assistants and automated theorem provers.  More proof assistants have some levels of automation (some using full powered automated theorem provers) which fill in \"obvious proof steps\". Further a lot of current work in AI theorem proving uses data from proof assistant libraries to train AI models.\nNow, if I misunderstood your question and you meant what types of theorems can a proof assistant be used for formalize, here is the answer: In principle, all correct theorems should be formalizable since they follow from the axioms of mathematics.  In practice, some types of mathematics are easier than others.  Obviously, theorems like Fermat's Last Theorem which both depend on a lot of other kinds of mathematics and are large proofs in themselves, would be a lot of work to formalize.  It is better to build a library of mathematics slowly adding in more and more until you have the theorems and tools you need to prove modern theorems.\nAlso, some subjects like calculus and statistics are import so we teach them to college freshman, but their foundations are actually quite complicated making them difficult to formalize.\n\nHow can they be improved?\n\nUsability is a big concern.  Proof assistants are still hard to work with.  Formalizing is slow and it is a specialized skill.  Adding the state of art in program language design and interactive development environment tools would help.\nMathematics in a proof assistant is also very different looking than informal mathematics.  Bridging this gap would go a long way to speeding up formal proofs.\nBetter automation might help.  Then the user could have the computer fill in the obvious and not-so-obvious steps.  A dream would even have a computer system which could auto-formalize mathematics from say an informal LaTeX proof to a formal proof.  This is incredible challenging, but an exciting research goal.\nProof repair is an interesting topic.  Proofs break if you change the theorem you are proving.  This is especially common when proving the correctness of a piece of computer code which is subject to change.  But in many cases, it should be straight forward to repair the proof, and the computer in principle should be able to do it for you.\nThere are many proof assistants, but they are incompatible with each other.  A proof in one proof assistant isn't usable by any other proof assistants.  Better interchangeability would go a long way.\nThere is also the problem that formalization is not well rewarded in academics or industry.\n\nWhat avoidable and unavoidable limitations are there?\n\nI think I mentioned many avoidable limitations.\nAs far as unavoidable ones, baring human-level artificial intelligence, it is likely going to continue to be a somewhat tedious human process which gets progressively easier with better tools.\n\nIs there anything else I should know about the current and potential future states of proof assistants?\n\nProbably.  But at the same time, just get started playing with proof assistants if they interest you.  They are video-game level addictive!  I recommend the natural number game as a fun starting point.  After doing that, pick a proof assistant that interests you, get to know the community, and start formalizing stuff!", "meta": {"post_id": 1456, "input_score": 7, "output_score": 13, "post_title": "What is the current state of proof assistants?"}}
{"input": "What is a weak function space and what does it have to do with higher order abstract syntax?\nI mean I know what a weak function space is. It's that thing you use for HOAS in Lambda Prolog or toolkits like Beluga!\nBut what are the technical details here?\nIn category theory functions are abstracted away to exponential objects of closed Cartesian categories (not the same as a Cartesian closed category, STLC with product types is Cartesian closed, STLC without product types is closed Cartesian) and residuals/internal homs of closed monoidal categories.\nI have a hunch weak function spaces don't really work like exponentials at all.", "output": "In category theory the adjective \u201cweak\u201d is used when the uniqueness parts of a universal property is removed.\nFor example, a weak product of $A$ and $B$ is an object $P$ with morphisms $p_1 : P \\to A$ to $p_2 : P \\to B$, such that, for all $f : C \\to A$ and $g : C \\to B$ there exists (not necessarily unique!) $h : C \\to P$ satisfying $p_1 \\circ h = f$ and $p_2 \\circ h = g$.\nWe may apply the same idea to exponentials. A weak exponential of $A$ and $B$ is an object $E$ with a morphism $e : E \\times A \\to B$ such that, for all $f : C \\times A \\to B$ there exists (not necessarily unique!) $h : C \\to E$ such that $e \\circ (h \\times \\mathrm{id}_A) = h$. This is just the usual universal property of exponentials, with the uniqueness part removed.\nAn example of a category which has weak exponentials but no exponentials is the category of topological spaces and continuous maps. In more syntactic settings, such as logical frameworks, removing the uniqueness part from the definition of exponentials corresponds to removing the $\\eta$-rule. Consequently, given a term $z : C, x : A \\vdash f : B$, there may be many terms $z : C \\vdash h : A \\to B$ satisfying $$z : C, x : A \\vdash f \\equiv h\\, x : B.$$\nTo see that the $\\eta$-rule gives uniqueness, given $h_1$ and $h_2$ satisfying the above equation, observe that $$h_1 \\equiv (\\lambda x \\,. h_1 \\, x) \\equiv (\\lambda x \\,.f) \\equiv (\\lambda x \\,. h_2 \\, x) \\equiv h_2.$$\nConversely, from uniqueness we get $\\eta$-rule as follows: given any $z : C \\vdash h : A \\to B$, observe that\n$$z : C, x : A \\vdash h\\,x \\equiv h\\,x : B$$\nand by $\\beta$-reduction\n$$z : C, x : A \\vdash h\\,x \\equiv (\\lambda y \\,. h\\,y) \\, x : B$$\ntherefore by uniqueness $z : C \\vdash h \\equiv (\\lambda y \\,. h\\,y) : A \\to B$.\nAs an exercise you can verify that weakness of products correspond to absence of the $\\eta$-rule $(\\pi_1\\,t, \\pi_2\\,t) \\equiv t : A \\times B$.\nLet us also try to answer the question \u201cwhat does it have to do with HOAS?\u201c Recall that in HOAS we use the meta-level function space to model binding in the object-level terms. Does the meta-level $\\eta$-rule transfer to the object-level $\\eta$-rule? For that we would need something like (I am using $\\mathtt{typeface}$ to denote object-level syntactic constructs):\n$$\\mathtt{lambda}(\\lambda x \\,. \\mathtt{app}(h,x)) \\equiv h,$$\nwhich is not the case because \u201cobject-level application $\\mathtt{app}$ is not meta-level application\u201c. So in HOAS the object-level $\\eta$-rule is not available, hence \u201cweak\u201d exponentials.\nIncidentally, the meta-level $\\beta$-reduction fails to transfer to object-level $\\beta$-reduction also, because the object-level $\\beta$-reduction is something like\n$$\\mathtt{app}(\\mathtt{lambda}(t), u) \\equiv t \\, u,$$\nand once again the equation does not hold. Of course, one could consider HOAS with object-level equations, in which case both the $\\beta$-reduction and the $\\eta$-rule could be imposed.", "meta": {"post_id": 1491, "input_score": 5, "output_score": 8, "post_title": "What is a weak function space and what does it have to do with HOAS?"}}
{"input": "How can we define in a proof assistant (eg., Coq) a notion of a 2-player game, where each player is a program that has access to the opponent's source code?\nBackground: In Open Source Game Theory, we think about bots that reason about each other (prove theorems), knowing the other's source code. I would like implement such bots in a proof assistant, if possible. (https://arxiv.org/pdf/2208.07006.pdf, Open Problem 4)\nWhat I have in mind would looks like this:\nInductive outcome := Cooperate | Defect.\n(*  Dupoc is short for Defect Unless Proof of Cooperation   *)\nDefinition Dupoc (n:N) (bot2 : N -> bot -> outcome) : N -> bot -> outcome :=\n    'try for n steps to find a proof that bot2 n self = Cooperate, if found':\n        return Cooperate\n    else\n        return Defect.\n\nThe point is that we want to run the agents together with each other as input:\nDefinition game n1 bot1 n2 bot2 := (bot1 n1 bot2, bo2 n2 bo1).\n\nOf course, the type bot does not exist as I have written it. Is there a way to actually make this happen?\nThe other problem is that the bot's function is trying to find a proof and returning a bool that reflects the success. Is this possible in some proof assistant? The proof assistant would have to have access to its own inner workings somehow, which seems hard.\nI think I could solve the problem by having a Coq implementation in Coq.\nThen I could have, like in the paper:\nInductive CoqTokens := ...\nDefinition BotExpression := ... (* A valid expression for a Bot *)\nClass Bot := {\n    play : BotExpression -> outcome,\n    source : BotExpression (* This should be the source code for 'play' in our Coq-in-Coq implementation *)\n}.\nDefinition game bot1 bot2 := (bot1.play bot2.source, bot2.play bot1.source).\n\nBut this seems very much work if it is possible. The Coq implementation in Coq still needs to contain everything about proofing. And I am not sure if it actually solves the problem.", "output": "As you found out, the usual technique to solve this kind of difficulty is to introduce a notion of \"code\" (what you called BotExpression), which expresses the behaviour of your bot. Once you are happy with your codes, you can in a second time define a \"decoding\" function, something which takes in a code and spits out the expression, but this time as an actual Coq function. Taking the notations from your question, this means that you should be able to define a function that takes in source and outputs play. Note that to do this you do not have to reify all the syntax of Coq. Indeed, the actions available for your bots can probably be defined with a set of primitives smaller than full-fledged Coq. This lets you avoid the problem of using some form of self-description of the meta-language (which are very complicated beasts).\nSimilarly, you might also want to have such an encoding for proofs, again because your bots need to manipulate \"concrete\" data rather than meta-proofs in the ambient theory. Regarding formalization of logic, and also to give you ideas on the general code/decoding setting, you might want to give a look at eg. this library formalizing first-order logic.\nFinally, there is a second issue you might stumble upon, either in the definition of your decoding function, or that of a play, which is related to the definition of functions in Coq. Indeed, as Coq lets you only define total/terminating functions, quite a lot of things with a \"self-recursive\" flavour are not definable as functions, as they would lead to non-terminating behaviour. In such a case, a standard solution is to replace the type A -> B by the type A -> B -> Prop, ie. replace an actual function by its graph. This avoids termination issues, and also determinism: since you do not encode a game as a function, you can have multiple choices to move on. Moreover, if you define your relation as an inductive one, you can reason by induction on it, which is probably the kind of reasoning principles you will be after.", "meta": {"post_id": 1779, "input_score": 10, "output_score": 9, "post_title": "How can we formalize a game where each player is a program having access to opponent's code?"}}
{"input": "In Zermelo-Fraenkel axiomatics, one does not need to use the axiom of choice to resolve unique existential quantifiers, the axiom of replacement is enough for this.\nBut it seems that Type theory does not allow that: if you have a family of singletons, there is no way to get the family of its members.\nIf it is true, that can be proven by constructing a model of Type theory in which this does not hold.\nI suspect that \u201chomotopic\u201d models can be useful there \u2014 there are families of contractible spaces which have no section, but I have no clue about how to do it for real.", "output": "Let $\\exists! z \\in C . P(z)$ be shorthand for $\\exists z \\in C . (P(z) \\land \\forall w \\in C . P(w) \\to z = w)$.\nYour question is related to the axiom of unique choice (AUC): given a relation $R : A \\to B \\to \\mathsf{Prop}$ satisfying\n$$\\forall x \\in A . \\exists! y \\in B . R(x, y), \\tag{1}$$\nis there a map $f : A \\to B$ such that $\\forall x \\in A . R(x, f x)$? Indeed, $R$ can be thought of as a singleton in $B$ parameterized by $A$, and $f$ is the unique element of $B$ (still parameterized by $A$).\nA relation satisfying (1) is called a functional relation.\nAnother way to state AUC is this: the graph of $f : A \\to B$ is the relation $\\Gamma_f : A \\to B \\to \\mathsf{Prop}$ defined by\n$$\\Gamma_f \\, a\\, b \\mathrel{{:}{=}} (f a = b).$$\nThen AUC states that every functional relation is the graph of a function.\nWhether AUC holds depends on how precisely we set up foundations.\nIn toposes AUC holds, so in particular it holds in ZFC and other set theories.\nIn Martin-L\u00f6f type theory AUC holds if we write (1) as\n$$\\textstyle\n\\prod_{x : A}\n(\\sum_{y : B}\nR(x,y) \\times \\prod_{z : B} R(x,z) \\to \\mathsf{Id}(y,z))\n$$\nThat's because we used $\\Sigma$ in place of $\\exists$, so we can extract the witness $y$. (Of course, for the same reason MLTT validates the full axiom of choice.)\nIn homotopy type theory AUC holds. Note that\n$$\n\\textstyle\n\\exists z \\in C . (P(z) \\land \\forall w \\in C . P(w) \\to z = w)\n$$\nis defined to be\n$$\n\\textstyle\n\\|\\sum_{z : C} (P(z) \\times \\prod_{w : C} P(w) \\to z = w)\n\\|\n$$\nBecause the type inside the truncation is a proposition, we may apply Lemma 3.9.1 of HoTT book to extract $z : C$.\nIn the Calculus of Inductive Constructions, i.e., the type theory of Coq, AUC does not hold when we use $\\mathsf{Prop}$. This is so because we cannot eliminate from the proposition $\\exists! y \\in B . R(x, y)$ to $B$, unless $B$ itself is a proposition.\nSo the question really is: which formalism are you using?", "meta": {"post_id": 1783, "input_score": 5, "output_score": 8, "post_title": "Does one need a type-theoretical axiom of choice for singletons?"}}
{"input": "I am wondering whether a rule like the following is consistent with decidable conversion and type-checking for dependent type theory:\n$$ \\frac{f\\, g : (x:\\mathsf{bool}) \\to C~x\\quad f~\\mathsf{tt} \\equiv g~\\mathsf{tt} \\quad f~\\mathsf{ff} \\equiv g~\\mathsf{ff}}{f\\equiv g} $$\nThat is, if two functions with domain $\\mathsf{bool}$ agree definitionally on $\\mathsf{tt}$ and $\\mathsf{ff}$, then they are convertible.  An analogous rule for functions on general inductive types like $\\mathbb{N}$ is certainly bad, but it seems not too ridiculous to me to wonder whether the special case of $\\mathsf{bool}$ (and other non-recursive inductive types, like sum-types and enumerated types) might be possible.\nOne thing that makes me somewhat hopeful is that this rule would make $(x:\\mathsf{bool}) \\to C~x$ behave very much like $C~\\mathsf{tt} \\times C~\\mathsf{ff}$, and indeed be definitionally isomorphic to it if the latter also has an $\\eta$-rule.  Since such a rule for products is possible, I thought maybe it could also be possible for the function-type.  And implementation-wise, I could imagine a bidirectional conversion-checking algorithm noticing when the type is a function with domain $\\mathsf{bool}$ and deciding to apply this rule instead of the ordinary $\\eta$-rule for functions.", "output": "If we have $\\eta$ for functions and also your pointwise conversion rule, that implies the full $\\eta$ rule for the (finite) domain type. When checking conversion of arbitrary $t,u$, we can abstract over an arbitrary $\\mathsf{bool}$ subterm $v$ to get an equivalent conversion problem\n$$(\\lambda~(x:\\mathsf{bool}).~ t')~v\\equiv(\\lambda~(x:\\mathsf{bool}).~ u')~v$$\nFor instance\n$$\\mathsf{if}~b~\\mathsf{then}~t~\\mathsf{else}~t \\equiv (\\lambda~x.~\\mathsf{if}~x~\\mathsf{then}~t~\\mathsf{else}~t)~b \\equiv (\\lambda~x.t)~b \\equiv t$$\nThe full $\\eta$-rules for finite sums are rather complicated and expensive to check. There's a reference for STLC with finite sums and products. However, I do not know any reference for deciding finite sum $\\eta$ in richer systems.\nI expect that $\\eta$ for non-empty finite sums remains decidable even in the fully dependent type theories. $\\eta$ for the empty type is decidable only when consistency of typing contexts is decidable.\nMore specifically for our current case, let's assume that $\\bot \\to A$ is definitionally irrelevant. Then, if we have $p : \\bot$ and $t,~u : A$, then\n$$t \\equiv (\\lambda~x.~t)~p \\equiv (\\lambda~x.~u)~p \\equiv u$$\nTherefore, if $\\bot$ is provable then all terms are convertible. This is undecidable for the usual $\\bot$ in type theories, but it might be decidable  in other settings. For example, in ABCFHL cubical type theory all judgments hold when the empty cofibration is implied by the context. This is still decidable because cofibrations are decidable. This is implemented in cooltt.\nAlternatively, we can drop the function $\\eta$ rule. Then, we recover the finite product types as $(x : A) \\to C~x$ for finite $A$, and everything is decidable. I don't think this configuration is useful for anything though.", "meta": {"post_id": 1885, "input_score": 9, "output_score": 9, "post_title": "Strong eta-rules for functions on sum types"}}
